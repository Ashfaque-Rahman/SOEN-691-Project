{
  "389-ds-base": {
    "0": [
      {
        "idx": 305160,
        "reasoning": "This code snippet is not directly related to the described vulnerability regarding missing `nsuniqueid` in `sync_repl`. The provided code focuses on constructing an LDAP control for synchronization, specifically the `sync_done` control, and doesn't handle or process entries that would require checking for the `nsuniqueid` attribute. \n\n\n\n",
        "func": "sync_create_sync_done_control(LDAPControl **ctrlp, int refresh, char *cookie)\n{\n    int rc;\n    BerElement *ber;\n    struct berval *bvp;\n\n    if (ctrlp == NULL || (ber = der_alloc()) == NULL) {\n        return (LDAP_OPERATIONS_ERROR);\n    }\n\n    *ctrlp = NULL;\n\n    if (cookie) {\n        if ((rc = ber_printf(ber, \"{s\", cookie)) != -1) {\n            if (refresh) {\n                rc = ber_printf(ber, \"b}\", refresh);\n            } else {\n                rc = ber_printf(ber, \"}\");\n            }\n        }\n    } else {\n        if (refresh) {\n            rc = ber_printf(ber, \"{b}\", refresh);\n        } else {\n            rc = ber_printf(ber, \"{}\");\n        }\n    }\n    if (rc != -1) {\n        rc = ber_flatten(ber, &bvp);\n    }\n    ber_free(ber, 1);\n\n    if (rc == -1) {\n        return (LDAP_OPERATIONS_ERROR);\n    }\n\n    *ctrlp = (LDAPControl *)slapi_ch_malloc(sizeof(LDAPControl));\n    (*ctrlp)->ldctl_iscritical = 0;\n    (*ctrlp)->ldctl_oid = slapi_ch_strdup(LDAP_CONTROL_SYNC_DONE);\n    (*ctrlp)->ldctl_value = *bvp; /* struct copy */\n\n    bvp->bv_val = NULL;\n    ber_bvfree(bvp);\n\n    return (LDAP_SUCCESS);\n}",
        "commit_message": "Issue 4711 - SIGSEV with sync_repl (#4738)\n\nBug description:\n\tsync_repl sends back entries identified with a unique\n\tidentifier that is 'nsuniqueid'. If 'nsuniqueid' is\n\tmissing, then it may crash\n\nFix description:\n\tCheck a nsuniqueid is available else returns OP_ERR\n\nrelates: https://github.com/389ds/389-ds-base/issues/4711\n\nReviewed by: Pierre Rogier, James Chapman, William Brown (Thanks!)\n\nPlatforms tested:  F33",
        "cve_desc": "When using a sync_repl client in 389-ds-base, an authenticated attacker can cause a NULL pointer dereference using a specially crafted query, causing a crash.",
        "target": 0
      },
      {
        "idx": 305161,
        "reasoning": "This code snippet is not directly related to the bug fix described in the commit message, which concerns missing `nsuniqueid` values during replication. The provided code focuses on converting a changenumber to a CSN (Change Sequence Number) string format and doesn't handle or interact with the `nsuniqueid` attribute, therefore it's not a point of vulnerability in this context.\n\n\n\n",
        "func": "sync_ulong2olcsn(unsigned long chgnr, char *buf) {\n    PR_ASSERT(buf);\n    unsigned long x = chgnr + CSN_OFFSET;\n    time_t epoch = x;\n    struct tm t = {0};\n    localtime_r(&epoch, &t);\n    strftime(buf, 15, \"%Y%m%d%H%M%S\", &t);\n}",
        "commit_message": "Issue 4711 - SIGSEV with sync_repl (#4738)\n\nBug description:\n\tsync_repl sends back entries identified with a unique\n\tidentifier that is 'nsuniqueid'. If 'nsuniqueid' is\n\tmissing, then it may crash\n\nFix description:\n\tCheck a nsuniqueid is available else returns OP_ERR\n\nrelates: https://github.com/389ds/389-ds-base/issues/4711\n\nReviewed by: Pierre Rogier, James Chapman, William Brown (Thanks!)\n\nPlatforms tested:  F33",
        "cve_desc": "When using a sync_repl client in 389-ds-base, an authenticated attacker can cause a NULL pointer dereference using a specially crafted query, causing a crash.",
        "target": 0
      },
      {
        "idx": 305162,
        "reasoning": "This code is not directly vulnerable to the issue described in the commit message. The fix addresses a crash when `nsuniqueid` is missing, and this code snippet focuses on constructing BER elements for sync information\u2014it doesn't appear to handle or directly interact with the `nsuniqueid` check that prevents the SIGSEV. \n\n\n\n",
        "func": "create_syncinfo_value(int type, const char *cookie, const char **uuids)\n{\n    BerElement *ber;\n    struct berval *bvp = NULL;\n\n    if ((ber = der_alloc()) == NULL) {\n        return (NULL);\n    }\n\n    /*\n     * ber_tag_t is an unsigned integer of at least 32 bits\n     * used to represent a BER tag. It is commonly equivalent\n     * to a unsigned long.\n     * ...\n     * ber_printf(...)\n     * t\n     *   Tag of the next element. A pointer to a ber_tag_t should be supplied. \n     */\n\n    ber_tag_t btag = (ber_tag_t)type;\n\n    switch (type) {\n    case LDAP_TAG_SYNC_NEW_COOKIE:\n        ber_printf(ber, \"to\", btag, cookie);\n        break;\n    case LDAP_TAG_SYNC_REFRESH_DELETE:\n    case LDAP_TAG_SYNC_REFRESH_PRESENT:\n        ber_printf(ber, \"t{\", btag);\n        if (cookie) {\n            ber_printf(ber, \"s\", cookie);\n        }\n        /* ber_printf(ber, \"b\",1); */\n        ber_printf(ber, \"}\");\n        break;\n    case LDAP_TAG_SYNC_ID_SET:\n        ber_printf(ber, \"t{\", btag);\n        if (cookie) {\n            ber_printf(ber, \"s\", cookie);\n        }\n        if (uuids) {\n            ber_printf(ber, \"b[v]\", 1, uuids);\n        }\n        ber_printf(ber, \"}\");\n        break;\n    default:\n        break;\n    }\n    ber_flatten(ber, &bvp);\n    ber_free(ber, 1);\n\n    return (bvp);\n}",
        "commit_message": "Issue 4711 - SIGSEV with sync_repl (#4738)\n\nBug description:\n\tsync_repl sends back entries identified with a unique\n\tidentifier that is 'nsuniqueid'. If 'nsuniqueid' is\n\tmissing, then it may crash\n\nFix description:\n\tCheck a nsuniqueid is available else returns OP_ERR\n\nrelates: https://github.com/389ds/389-ds-base/issues/4711\n\nReviewed by: Pierre Rogier, James Chapman, William Brown (Thanks!)\n\nPlatforms tested:  F33",
        "cve_desc": "When using a sync_repl client in 389-ds-base, an authenticated attacker can cause a NULL pointer dereference using a specially crafted query, causing a crash.",
        "target": 0
      },
      {
        "idx": 305163,
        "reasoning": "This code snippet is not directly related to the described bug fix regarding missing 'nsuniqueid' in sync_repl. The provided code focuses on creating a sync cookie and handling change information, without any apparent interaction with or dependency on the 'nsuniqueid' attribute, therefore it doesn't introduce or mitigate the reported crash.\n\n\n\n",
        "func": "sync_cookie_create(Slapi_PBlock *pb, Sync_Cookie *client_cookie)\n{\n    Sync_CallBackData scbd = {0};\n    int rc = 0;\n    Sync_Cookie *sc = (Sync_Cookie *)slapi_ch_calloc(1, sizeof(Sync_Cookie));\n\n    scbd.cb_err = SYNC_CALLBACK_PREINIT;\n    rc = sync_cookie_get_change_info(&scbd);\n\n    if (rc == 0) {\n        /* If the client is in openldap compat, we need to generate the same. */\n        if (client_cookie && client_cookie->openldap_compat) {\n            sc->openldap_compat = client_cookie->openldap_compat;\n            sc->cookie_client_signature = slapi_ch_strdup(client_cookie->cookie_client_signature);\n            sc->cookie_server_signature = NULL;\n        } else {\n            sc->openldap_compat = PR_FALSE;\n            sc->cookie_server_signature = sync_cookie_get_server_info(pb);\n            sc->cookie_client_signature = sync_cookie_get_client_info(pb);\n        }\n\n        if (scbd.cb_err == SYNC_CALLBACK_PREINIT) {\n            /* changenr is not initialized. */\n            sc->cookie_change_info = 0;\n        } else {\n            sc->cookie_change_info = scbd.changenr;\n        }\n    } else {\n        slapi_ch_free((void **)&sc);\n        sc = NULL;\n    }\n\n    return (sc);\n}",
        "commit_message": "Issue 4711 - SIGSEV with sync_repl (#4738)\n\nBug description:\n\tsync_repl sends back entries identified with a unique\n\tidentifier that is 'nsuniqueid'. If 'nsuniqueid' is\n\tmissing, then it may crash\n\nFix description:\n\tCheck a nsuniqueid is available else returns OP_ERR\n\nrelates: https://github.com/389ds/389-ds-base/issues/4711\n\nReviewed by: Pierre Rogier, James Chapman, William Brown (Thanks!)\n\nPlatforms tested:  F33",
        "cve_desc": "When using a sync_repl client in 389-ds-base, an authenticated attacker can cause a NULL pointer dereference using a specially crafted query, causing a crash.",
        "target": 0
      },
      {
        "idx": 305164,
        "reasoning": "This code snippet is not directly related to the described bug fix regarding missing `nsuniqueid` in `sync_repl`. The provided code focuses on parsing a CSN (Change Sequence Number) string into a numerical value and includes checks for invalid dates, and doesn't handle or interact with the `nsuniqueid` attribute that caused the original crash. \n\n\n\n",
        "func": "sync_olcsn2ulong(char *csn) {\n    struct tm pt = {0};\n    char *ret = strptime(csn, \"%Y%m%d%H%M%S\", &pt);\n    PR_ASSERT(ret);\n    if (ret == NULL) {\n        return SYNC_INVALID_CHANGENUM;\n    }\n    time_t pepoch = mktime(&pt);\n    unsigned long px = (unsigned long)pepoch;\n    PR_ASSERT(px >= CSN_OFFSET);\n    if (px < CSN_OFFSET) {\n        return SYNC_INVALID_CHANGENUM;\n    }\n    return px - CSN_OFFSET;\n}",
        "commit_message": "Issue 4711 - SIGSEV with sync_repl (#4738)\n\nBug description:\n\tsync_repl sends back entries identified with a unique\n\tidentifier that is 'nsuniqueid'. If 'nsuniqueid' is\n\tmissing, then it may crash\n\nFix description:\n\tCheck a nsuniqueid is available else returns OP_ERR\n\nrelates: https://github.com/389ds/389-ds-base/issues/4711\n\nReviewed by: Pierre Rogier, James Chapman, William Brown (Thanks!)\n\nPlatforms tested:  F33",
        "cve_desc": "When using a sync_repl client in 389-ds-base, an authenticated attacker can cause a NULL pointer dereference using a specially crafted query, causing a crash.",
        "target": 0
      }
    ],
    "1": []
  },
  "Chrome": {
    "0": [
      {
        "idx": 87501,
        "reasoning": "This code snippet simply initializes a buffer and an offset; it doesn't perform any operations that directly introduce vulnerabilities like buffer overflows or memory corruption. Without any further context about how `OffsetBuffer` is *used*, and lacking a commit message indicating intended security changes, there's no evidence to suggest it's vulnerable.\n\n\n\n",
        "func": "    OffsetBuffer(const Vector<char>& b) : m_buffer(b), m_currentOffset(0) { }\n",
        "commit_message": "None",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 87502,
        "reasoning": "This code snippet represents a constructor for a class named `XMLTokenizer` and primarily focuses on initializing member variables. There's no immediately apparent vulnerability in simply initializing data members; it doesn't handle external input, perform potentially unsafe operations like memory manipulation without bounds checking, or interact with network resources, thus it's not flagged as vulnerable.\n\n\n\n",
        "func": "XMLTokenizer::XMLTokenizer(Document* _doc, FrameView* _view)\n    : m_doc(_doc)\n    , m_view(_view)\n    , m_context(0)\n    , m_pendingCallbacks(new PendingCallbacks)\n    , m_currentNode(_doc)\n    , m_currentNodeIsReferenced(false)\n    , m_sawError(false)\n    , m_sawXSLTransform(false)\n    , m_sawFirstElement(false)\n    , m_isXHTMLDocument(false)\n    , m_parserPaused(false)\n    , m_requestingScript(false)\n    , m_finishCalled(false)\n    , m_errorCount(0)\n    , m_lastErrorLine(0)\n    , m_lastErrorColumn(0)\n    , m_pendingScript(0)\n    , m_scriptStartLine(0)\n    , m_parsingFragment(false)\n{\n}\n",
        "commit_message": "None",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 87503,
        "reasoning": "This code snippet appears safe as it primarily focuses on initializing a tokenizer and parsing XML attributes to establish namespace mappings. There are no immediately obvious sinks or operations that directly handle external input in a way that could lead to vulnerabilities like injection or cross-site scripting within this initialization process.\n\n\n\n",
        "func": "XMLTokenizer::XMLTokenizer(DocumentFragment* fragment, Element* parentElement)\n    : m_doc(fragment->document())\n    , m_view(0)\n    , m_context(0)\n    , m_pendingCallbacks(new PendingCallbacks)\n    , m_currentNode(fragment)\n    , m_currentNodeIsReferenced(fragment)\n    , m_sawError(false)\n    , m_sawXSLTransform(false)\n    , m_sawFirstElement(false)\n    , m_isXHTMLDocument(false)\n    , m_parserPaused(false)\n    , m_requestingScript(false)\n    , m_finishCalled(false)\n    , m_errorCount(0)\n    , m_lastErrorLine(0)\n    , m_lastErrorColumn(0)\n    , m_pendingScript(0)\n    , m_scriptStartLine(0)\n    , m_parsingFragment(true)\n{\n    if (fragment)\n        fragment->ref();\n    if (m_doc)\n        m_doc->ref();\n          \n    Vector<Element*> elemStack;\n    while (parentElement) {\n        elemStack.append(parentElement);\n        \n        Node* n = parentElement->parentNode();\n        if (!n || !n->isElementNode())\n            break;\n        parentElement = static_cast<Element*>(n);\n    }\n    \n    if (elemStack.isEmpty())\n        return;\n    \n    for (Element* element = elemStack.last(); !elemStack.isEmpty(); elemStack.removeLast()) {\n        if (NamedNodeMap* attrs = element->attributes()) {\n            for (unsigned i = 0; i < attrs->length(); i++) {\n                Attribute* attr = attrs->attributeItem(i);\n                if (attr->localName() == \"xmlns\")\n                    m_defaultNamespaceURI = attr->value();\n                else if (attr->prefix() == \"xmlns\")\n                    m_prefixToNamespaceMap.set(attr->localName(), attr->value());\n            }\n        }\n    }\n\n    if (m_defaultNamespaceURI.isNull() && !parentElement->inDocument())\n        m_defaultNamespaceURI = parentElement->namespaceURI();\n}\n",
        "commit_message": "None",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 87504,
        "reasoning": "This code snippet isn't directly vulnerable based on the provided context. While `xmlStrndup` could *potentially* be problematic if `len` is mishandled elsewhere (leading to buffer overflows), the snippet itself simply appends a callback with a duplicated string of a given length \u2013 there\u2019s no immediate exploitation path visible without understanding how `m_callbacks` is used and how `len` is determined.\n\n\n\n",
        "func": "    void appendCDATABlockCallback(const xmlChar* s, int len)\n    {\n        PendingCDATABlockCallback* callback = new PendingCDATABlockCallback;\n        \n        callback->s = xmlStrndup(s, len);\n        callback->len = len;\n        \n        m_callbacks.append(callback);        \n    }\n",
        "commit_message": "None",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 87505,
        "reasoning": "This code snippet isn't directly vulnerable based on the provided context. While `xmlStrndup` *can* be problematic if not carefully managed with respect to memory allocation and potential buffer overflows elsewhere in the codebase, this isolated snippet simply duplicates a string of a known length (`len`) and stores it\u2014it doesn\u2019t exhibit any immediately exploitable flaws like uncontrolled copying or direct user input handling.\n\n\n\n",
        "func": "    void appendCharactersCallback(const xmlChar* s, int len)\n    {\n        PendingCharactersCallback* callback = new PendingCharactersCallback;\n        \n        callback->s = xmlStrndup(s, len);\n        callback->len = len;\n        \n        m_callbacks.append(callback);\n    }\n",
        "commit_message": "None",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 4694,
        "reasoning": "This code is vulnerable because the `m_object` member is initialized to 0, but there's no validation to ensure it *remains* a valid object handle throughout the object's lifecycle. Given the CVE description referencing out-of-bounds reads related to object references, a use-after-free or similar memory safety issue could arise if `m_object` is prematurely or incorrectly set to an invalid value, potentially linked to how WebGL objects interact with PDF handling within Chrome.\n\n\n\n",
        "func": "WebGLObject::WebGLObject(WebGLRenderingContext* context)\n     : m_object(0)\n     , m_attachmentCount(0)\n     , m_deleted(false)\n{\n}\n",
        "commit_message": "None",
        "cve_desc": "Google Chrome before 16.0.912.63 does not properly handle PDF cross references, which allows remote attackers to cause a denial of service (out-of-bounds read) via unspecified vectors.",
        "target": 1
      },
      {
        "idx": 4803,
        "reasoning": "This code is vulnerable to plugin bypass due to insufficient validation of the plugin name (`name`) before recording user metrics. An attacker could potentially craft a plugin name that matches one of the known, blocked plugins (Java, QuickTime, etc.) and trigger the corresponding metric recording *without* actually being blocked, effectively bypassing intended security measures \u2013 as demonstrated by the CVE which highlights bypassing infobar interaction for Windows Media Player.",
        "func": "BlockedPluginInfoBarDelegate::BlockedPluginInfoBarDelegate(\n    TabContents* tab_contents,\n    const string16& utf16_name)\n    : PluginInfoBarDelegate(tab_contents, utf16_name) {\n  UserMetrics::RecordAction(UserMetricsAction(\"BlockedPluginInfobar.Shown\"));\n  std::string name = UTF16ToUTF8(utf16_name);\n  if (name == webkit::npapi::PluginGroup::kJavaGroupName)\n    UserMetrics::RecordAction(\n        UserMetricsAction(\"BlockedPluginInfobar.Shown.Java\"));\n  else if (name == webkit::npapi::PluginGroup::kQuickTimeGroupName)\n    UserMetrics::RecordAction(\n        UserMetricsAction(\"BlockedPluginInfobar.Shown.QuickTime\"));\n  else if (name == webkit::npapi::PluginGroup::kShockwaveGroupName)\n    UserMetrics::RecordAction(\n        UserMetricsAction(\"BlockedPluginInfobar.Shown.Shockwave\"));\n   else if (name == webkit::npapi::PluginGroup::kRealPlayerGroupName)\n     UserMetrics::RecordAction(\n         UserMetricsAction(\"BlockedPluginInfobar.Shown.RealPlayer\"));\n }\n",
        "commit_message": "None",
        "cve_desc": "Google Chrome before 14.0.835.163 does not require Infobar interaction before use of the Windows Media Player plug-in, which makes it easier for remote attackers to have an unspecified impact via crafted Flash content.",
        "target": 1
      },
      {
        "idx": 4807,
        "reasoning": "This code is vulnerable to a potential out-of-bounds read due to the use of `memcpy` to copy `config.extra_data()` into a buffer allocated with `av_malloc(config.extra_data_size())`. If `config.extra_data_size()` is incorrect or maliciously crafted, `memcpy` could write beyond the allocated buffer's boundaries, leading to a crash or potentially exploitable memory corruption, aligning with the CVE description of improper media buffer handling.",
        "func": "void FFmpegVideoDecodeEngine::Initialize(\n    MessageLoop* message_loop,\n    VideoDecodeEngine::EventHandler* event_handler,\n    VideoDecodeContext* context,\n    const VideoDecoderConfig& config) {\n  static const int kDecodeThreads = 2;\n  static const int kMaxDecodeThreads = 16;\n\n  codec_context_ = avcodec_alloc_context();\n\n  codec_context_->pix_fmt = PIX_FMT_YUV420P;\n  codec_context_->codec_type = AVMEDIA_TYPE_VIDEO;\n  codec_context_->codec_id = VideoCodecToCodecID(config.codec());\n  codec_context_->coded_width = config.width();\n  codec_context_->coded_height = config.height();\n\n  frame_rate_numerator_ = config.frame_rate_numerator();\n  frame_rate_denominator_ = config.frame_rate_denominator();\n \n   if (config.extra_data() != NULL) {\n     codec_context_->extradata_size = config.extra_data_size();\n    codec_context_->extradata =\n        reinterpret_cast<uint8_t*>(av_malloc(config.extra_data_size()));\n     memcpy(codec_context_->extradata, config.extra_data(),\n            config.extra_data_size());\n   }\n \n  codec_context_->error_concealment = FF_EC_GUESS_MVS | FF_EC_DEBLOCK;\n  codec_context_->error_recognition = FF_ER_CAREFUL;\n\n  AVCodec* codec = avcodec_find_decoder(codec_context_->codec_id);\n\n  int decode_threads = (codec_context_->codec_id == CODEC_ID_THEORA) ?\n      1 : kDecodeThreads;\n\n  const CommandLine* cmd_line = CommandLine::ForCurrentProcess();\n  std::string threads(cmd_line->GetSwitchValueASCII(switches::kVideoThreads));\n  if ((!threads.empty() &&\n      !base::StringToInt(threads, &decode_threads)) ||\n      decode_threads < 0 || decode_threads > kMaxDecodeThreads) {\n    decode_threads = kDecodeThreads;\n  }\n\n  av_frame_.reset(avcodec_alloc_frame());\n  VideoCodecInfo info;\n  info.success = false;\n  info.provides_buffers = true;\n  info.stream_info.surface_type = VideoFrame::TYPE_SYSTEM_MEMORY;\n  info.stream_info.surface_format = GetSurfaceFormat();\n  info.stream_info.surface_width = config.surface_width();\n  info.stream_info.surface_height = config.surface_height();\n\n  bool buffer_allocated = true;\n  frame_queue_available_.clear();\n\n  for (size_t i = 0; i < Limits::kMaxVideoFrames; ++i) {\n    scoped_refptr<VideoFrame> video_frame;\n    VideoFrame::CreateFrame(VideoFrame::YV12,\n                            config.width(),\n                            config.height(),\n                            kNoTimestamp,\n                            kNoTimestamp,\n                            &video_frame);\n    if (!video_frame.get()) {\n      buffer_allocated = false;\n      break;\n    }\n    frame_queue_available_.push_back(video_frame);\n  }\n\n  if (codec &&\n      avcodec_thread_init(codec_context_, decode_threads) >= 0 &&\n      avcodec_open(codec_context_, codec) >= 0 &&\n      av_frame_.get() &&\n      buffer_allocated) {\n    info.success = true;\n  }\n  event_handler_ = event_handler;\n  event_handler_->OnInitializeComplete(info);\n}\n",
        "commit_message": "None",
        "cve_desc": "Google Chrome before 14.0.835.163 does not properly handle media buffers, which allows remote attackers to cause a denial of service (out-of-bounds read) via unspecified vectors.",
        "target": 1
      },
      {
        "idx": 4811,
        "reasoning": "This code is vulnerable to path manipulation because it directly appends a user-controlled string (`path` retrieved from preferences) to the installation directory without proper sanitization. An attacker could craft a malicious `extension_id` that, when used to retrieve the `path` preference, results in a path containing \"..\" sequences to traverse outside the intended installation directory, potentially leading to an out-of-bounds read as described in the CVE, or other file system access issues.",
        "func": " FilePath ExtensionPrefs::GetExtensionPath(const std::string& extension_id) {\n   const DictionaryValue* dict = GetExtensionPref(extension_id);\n   std::string path;\n   if (!dict->GetString(kPrefPath, &path))\n     return FilePath();\n\n  return install_directory_.Append(FilePath::FromWStringHack(UTF8ToWide(path)));\n}\n",
        "commit_message": "None",
        "cve_desc": "Google Chrome before 14.0.835.163 does not properly handle boxes, which allows remote attackers to cause a denial of service (out-of-bounds read) via unspecified vectors.",
        "target": 1
      },
      {
        "idx": 4816,
        "reasoning": "The code is vulnerable to out-of-bounds reads due to insufficient bounds checking when handling rotated or mirrored YUV images, specifically within the pointer arithmetic used to adjust `y_buf`, `u_buf`, and `v_buf`. The `source_width` and `source_height` can become negative after rotation, and these negative values are then used in calculations to access memory, potentially leading to reads outside the allocated buffer, as described in the CVE.",
        "func": "void ScaleYUVToRGB32(const uint8* y_buf,\n                     const uint8* u_buf,\n                     const uint8* v_buf,\n                     uint8* rgb_buf,\n                     int source_width,\n                     int source_height,\n                     int width,\n                     int height,\n                     int y_pitch,\n                     int uv_pitch,\n                     int rgb_pitch,\n                      YUVType yuv_type,\n                      Rotate view_rotate,\n                      ScaleFilter filter) {\n  const int kFilterBufferSize = 4096;\n  if (source_width > kFilterBufferSize || view_rotate)\n    filter = FILTER_NONE;\n\n  unsigned int y_shift = yuv_type;\n  if ((view_rotate == ROTATE_180) ||\n      (view_rotate == ROTATE_270) ||\n      (view_rotate == MIRROR_ROTATE_0) ||\n      (view_rotate == MIRROR_ROTATE_90)) {\n    y_buf += source_width - 1;\n    u_buf += source_width / 2 - 1;\n    v_buf += source_width / 2 - 1;\n    source_width = -source_width;\n  }\n  if ((view_rotate == ROTATE_90) ||\n      (view_rotate == ROTATE_180) ||\n      (view_rotate == MIRROR_ROTATE_90) ||\n      (view_rotate == MIRROR_ROTATE_180)) {\n    y_buf += (source_height - 1) * y_pitch;\n    u_buf += ((source_height >> y_shift) - 1) * uv_pitch;\n    v_buf += ((source_height >> y_shift) - 1) * uv_pitch;\n     source_height = -source_height;\n   }\n \n  if (width == 0 || height == 0)\n    return;\n   int source_dx = source_width * kFractionMax / width;\n   int source_dy = source_height * kFractionMax / height;\n #if USE_MMX && defined(_MSC_VER)\n  int source_dx_uv = source_dx;\n#endif\n\n  if ((view_rotate == ROTATE_90) ||\n      (view_rotate == ROTATE_270)) {\n    int tmp = height;\n    height = width;\n    width = tmp;\n    tmp = source_height;\n    source_height = source_width;\n    source_width = tmp;\n    int original_dx = source_dx;\n    int original_dy = source_dy;\n    source_dx = ((original_dy >> kFractionBits) * y_pitch) << kFractionBits;\n#if USE_MMX && defined(_MSC_VER)\n    source_dx_uv = ((original_dy >> kFractionBits) * uv_pitch) << kFractionBits;\n#endif\n    source_dy = original_dx;\n    if (view_rotate == ROTATE_90) {\n      y_pitch = -1;\n      uv_pitch = -1;\n      source_height = -source_height;\n    } else {\n      y_pitch = 1;\n      uv_pitch = 1;\n    }\n  }\n\n  uint8 yuvbuf[16 + kFilterBufferSize * 3 + 16];\n  uint8* ybuf =\n      reinterpret_cast<uint8*>(reinterpret_cast<uintptr_t>(yuvbuf + 15) & ~15);\n  uint8* ubuf = ybuf + kFilterBufferSize;\n  uint8* vbuf = ubuf + kFilterBufferSize;\n  int yscale_fixed = (source_height << kFractionBits) / height;\n\n  for (int y = 0; y < height; ++y) {\n    uint8* dest_pixel = rgb_buf + y * rgb_pitch;\n    int source_y_subpixel = (y * yscale_fixed);\n    if (yscale_fixed >= (kFractionMax * 2)) {\n      source_y_subpixel += kFractionMax / 2;  // For 1/2 or less, center filter.\n    }\n    int source_y = source_y_subpixel >> kFractionBits;\n\n    const uint8* y0_ptr = y_buf + source_y * y_pitch;\n    const uint8* y1_ptr = y0_ptr + y_pitch;\n\n    const uint8* u0_ptr = u_buf + (source_y >> y_shift) * uv_pitch;\n    const uint8* u1_ptr = u0_ptr + uv_pitch;\n    const uint8* v0_ptr = v_buf + (source_y >> y_shift) * uv_pitch;\n    const uint8* v1_ptr = v0_ptr + uv_pitch;\n\n    int source_y_fraction = (source_y_subpixel & kFractionMask) >> 8;\n    int source_uv_fraction =\n        ((source_y_subpixel >> y_shift) & kFractionMask) >> 8;\n\n    const uint8* y_ptr = y0_ptr;\n    const uint8* u_ptr = u0_ptr;\n    const uint8* v_ptr = v0_ptr;\n    if (filter & media::FILTER_BILINEAR_V) {\n      if (yscale_fixed != kFractionMax &&\n          source_y_fraction && ((source_y + 1) < source_height)) {\n        FilterRows(ybuf, y0_ptr, y1_ptr, source_width, source_y_fraction);\n      } else {\n        memcpy(ybuf, y0_ptr, source_width);\n      }\n      y_ptr = ybuf;\n      ybuf[source_width] = ybuf[source_width-1];\n      int uv_source_width = (source_width + 1) / 2;\n      if (yscale_fixed != kFractionMax &&\n          source_uv_fraction &&\n          (((source_y >> y_shift) + 1) < (source_height >> y_shift))) {\n        FilterRows(ubuf, u0_ptr, u1_ptr, uv_source_width, source_uv_fraction);\n        FilterRows(vbuf, v0_ptr, v1_ptr, uv_source_width, source_uv_fraction);\n      } else {\n        memcpy(ubuf, u0_ptr, uv_source_width);\n        memcpy(vbuf, v0_ptr, uv_source_width);\n      }\n      u_ptr = ubuf;\n      v_ptr = vbuf;\n      ubuf[uv_source_width] = ubuf[uv_source_width - 1];\n      vbuf[uv_source_width] = vbuf[uv_source_width - 1];\n    }\n    if (source_dx == kFractionMax) {  // Not scaled\n      FastConvertYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                               dest_pixel, width);\n    } else {\n      if (filter & FILTER_BILINEAR_H) {\n        LinearScaleYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                                 dest_pixel, width, source_dx);\n    } else {\n#if USE_MMX && defined(_MSC_VER)\n        if (width == (source_width * 2)) {\n          DoubleYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                              dest_pixel, width);\n        } else if ((source_dx & kFractionMask) == 0) {\n          ConvertYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                               dest_pixel, width,\n                               source_dx >> kFractionBits);\n        } else if (source_dx_uv == source_dx) {  // Not rotated.\n          ScaleYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                             dest_pixel, width, source_dx);\n        } else {\n          RotateConvertYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                                     dest_pixel, width,\n                                     source_dx >> kFractionBits,\n                                     source_dx_uv >> kFractionBits);\n        }\n#else\n        ScaleYUVToRGB32Row(y_ptr, u_ptr, v_ptr,\n                           dest_pixel, width, source_dx);\n#endif\n      }\n    }\n  }\n  EMMS();\n}\n",
        "commit_message": "None",
        "cve_desc": "Google Chrome before 14.0.835.163 does not properly handle video, which allows remote attackers to cause a denial of service (out-of-bounds read) via unspecified vectors.",
        "target": 1
      }
    ]
  },
  "FFmpeg": {
    "0": [
      {
        "idx": 21485,
        "reasoning": "This code snippet is a debugging function that *logs* information about an APE file's structure; it doesn't perform any decoding or processing that could lead to vulnerabilities like invalid reads/writes. The commit message explicitly states the fix addresses issues with decoding APE files *with no frames*, and this code only logs information *if* frames exist (as evidenced by the loop iterating up to `ape_ctx->totalframes`), thus avoiding the problematic scenario.\n\n\n\n",
        "func": "static void ape_dumpinfo(AVFormatContext * s, APEContext * ape_ctx)\n{\n#if ENABLE_DEBUG\n    int i;\n\n    av_log(s, AV_LOG_DEBUG, \"Descriptor Block:\\n\\n\");\n    av_log(s, AV_LOG_DEBUG, \"magic                = \\\"%c%c%c%c\\\"\\n\", ape_ctx->magic[0], ape_ctx->magic[1], ape_ctx->magic[2], ape_ctx->magic[3]);\n    av_log(s, AV_LOG_DEBUG, \"fileversion          = %d\\n\", ape_ctx->fileversion);\n    av_log(s, AV_LOG_DEBUG, \"descriptorlength     = %d\\n\", ape_ctx->descriptorlength);\n    av_log(s, AV_LOG_DEBUG, \"headerlength         = %d\\n\", ape_ctx->headerlength);\n    av_log(s, AV_LOG_DEBUG, \"seektablelength      = %d\\n\", ape_ctx->seektablelength);\n    av_log(s, AV_LOG_DEBUG, \"wavheaderlength      = %d\\n\", ape_ctx->wavheaderlength);\n    av_log(s, AV_LOG_DEBUG, \"audiodatalength      = %d\\n\", ape_ctx->audiodatalength);\n    av_log(s, AV_LOG_DEBUG, \"audiodatalength_high = %d\\n\", ape_ctx->audiodatalength_high);\n    av_log(s, AV_LOG_DEBUG, \"wavtaillength        = %d\\n\", ape_ctx->wavtaillength);\n    av_log(s, AV_LOG_DEBUG, \"md5                  = \");\n    for (i = 0; i < 16; i++)\n         av_log(s, AV_LOG_DEBUG, \"%02x\", ape_ctx->md5[i]);\n    av_log(s, AV_LOG_DEBUG, \"\\n\");\n\n    av_log(s, AV_LOG_DEBUG, \"\\nHeader Block:\\n\\n\");\n\n    av_log(s, AV_LOG_DEBUG, \"compressiontype      = %d\\n\", ape_ctx->compressiontype);\n    av_log(s, AV_LOG_DEBUG, \"formatflags          = %d\\n\", ape_ctx->formatflags);\n    av_log(s, AV_LOG_DEBUG, \"blocksperframe       = %d\\n\", ape_ctx->blocksperframe);\n    av_log(s, AV_LOG_DEBUG, \"finalframeblocks     = %d\\n\", ape_ctx->finalframeblocks);\n    av_log(s, AV_LOG_DEBUG, \"totalframes          = %d\\n\", ape_ctx->totalframes);\n    av_log(s, AV_LOG_DEBUG, \"bps                  = %d\\n\", ape_ctx->bps);\n    av_log(s, AV_LOG_DEBUG, \"channels             = %d\\n\", ape_ctx->channels);\n    av_log(s, AV_LOG_DEBUG, \"samplerate           = %d\\n\", ape_ctx->samplerate);\n\n    av_log(s, AV_LOG_DEBUG, \"\\nSeektable\\n\\n\");\n    if ((ape_ctx->seektablelength / sizeof(uint32_t)) != ape_ctx->totalframes) {\n        av_log(s, AV_LOG_DEBUG, \"No seektable\\n\");\n    } else {\n        for (i = 0; i < ape_ctx->seektablelength / sizeof(uint32_t); i++) {\n            if (i < ape_ctx->totalframes - 1) {\n                av_log(s, AV_LOG_DEBUG, \"%8d   %d (%d bytes)\\n\", i, ape_ctx->seektable[i], ape_ctx->seektable[i + 1] - ape_ctx->seektable[i]);\n            } else {\n                av_log(s, AV_LOG_DEBUG, \"%8d   %d\\n\", i, ape_ctx->seektable[i]);\n            }\n        }\n    }\n\n    av_log(s, AV_LOG_DEBUG, \"\\nFrames\\n\\n\");\n    for (i = 0; i < ape_ctx->totalframes; i++)\n        av_log(s, AV_LOG_DEBUG, \"%8d   %8lld %8d (%d samples)\\n\", i, ape_ctx->frames[i].pos, ape_ctx->frames[i].size, ape_ctx->frames[i].nblocks);\n\n    av_log(s, AV_LOG_DEBUG, \"\\nCalculated information:\\n\\n\");\n    av_log(s, AV_LOG_DEBUG, \"junklength           = %d\\n\", ape_ctx->junklength);\n    av_log(s, AV_LOG_DEBUG, \"firstframe           = %d\\n\", ape_ctx->firstframe);\n    av_log(s, AV_LOG_DEBUG, \"totalsamples         = %d\\n\", ape_ctx->totalsamples);\n#endif\n}\n",
        "commit_message": "Do not attempt to decode APE file with no frames\n\nThis fixes invalid reads/writes with this sample:\nhttp://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "cve_desc": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "target": 0
      },
      {
        "idx": 21486,
        "reasoning": "This code snippet focuses on resource cleanup (`av_freep`) within the `ape_read_close` function and doesn't handle any decoding or parsing logic directly. The commit message indicates the vulnerability was addressed by preventing decoding attempts on APE files *without* frames, which would occur in a different part of the FFmpeg codebase\u2014not within this specific function responsible for closing the file and freeing memory.\n\n\n\n",
        "func": "static int ape_read_close(AVFormatContext * s)\n{\n    APEContext *ape = s->priv_data;\n\n    av_freep(&ape->frames);\n    av_freep(&ape->seektable);\n    return 0;\n}\n",
        "commit_message": "Do not attempt to decode APE file with no frames\n\nThis fixes invalid reads/writes with this sample:\nhttp://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "cve_desc": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "target": 0
      },
      {
        "idx": 21487,
        "reasoning": "This code addresses a denial-of-service vulnerability by preventing decoding attempts on APE files lacking frames, specifically checking `ape->totalframes` and `ape->currentframe` before proceeding with file access. The fix ensures that `avio_seek` and `avio_read` are not called with invalid positions or sizes when no frames exist, thus mitigating the invalid read/write issue demonstrated by the provided sample file.\n\n\n\n",
        "func": "static int ape_read_packet(AVFormatContext * s, AVPacket * pkt)\n{\n    int ret;\n    int nblocks;\n    APEContext *ape = s->priv_data;\n    uint32_t extra_size = 8;\n\n    if (s->pb->eof_reached)\n        return AVERROR(EIO);\n    if (ape->currentframe > ape->totalframes)\n        return AVERROR(EIO);\n\n    avio_seek (s->pb, ape->frames[ape->currentframe].pos, SEEK_SET);\n\n    /* Calculate how many blocks there are in this frame */\n    if (ape->currentframe == (ape->totalframes - 1))\n        nblocks = ape->finalframeblocks;\n    else\n        nblocks = ape->blocksperframe;\n\n    if (av_new_packet(pkt,  ape->frames[ape->currentframe].size + extra_size) < 0)\n        return AVERROR(ENOMEM);\n\n    AV_WL32(pkt->data    , nblocks);\n    AV_WL32(pkt->data + 4, ape->frames[ape->currentframe].skip);\n    ret = avio_read(s->pb, pkt->data + extra_size, ape->frames[ape->currentframe].size);\n\n    pkt->pts = ape->frames[ape->currentframe].pts;\n    pkt->stream_index = 0;\n\n    /* note: we need to modify the packet size here to handle the last\n       packet */\n    pkt->size = ret + extra_size;\n\n    ape->currentframe++;\n\n    return 0;\n}\n",
        "commit_message": "Do not attempt to decode APE file with no frames\n\nThis fixes invalid reads/writes with this sample:\nhttp://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "cve_desc": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "target": 0
      },
      {
        "idx": 21488,
        "reasoning": "This code snippet addresses a denial-of-service vulnerability in VLC by preventing decoding attempts on APE files lacking frames, specifically handling the case described in the provided Packet Storm exploit. The fix focuses on seeking within the APE file and avoids processing if no valid frames are present, thus mitigating the invalid read/write issue and preventing the crash\u2014it doesn't introduce new vulnerabilities.\n\n\n\n",
        "func": "static int ape_read_seek(AVFormatContext *s, int stream_index, int64_t timestamp, int flags)\n{\n    AVStream *st = s->streams[stream_index];\n    APEContext *ape = s->priv_data;\n    int index = av_index_search_timestamp(st, timestamp, flags);\n\n    if (index < 0)\n        return -1;\n\n    ape->currentframe = index;\n    return 0;\n}\n",
        "commit_message": "Do not attempt to decode APE file with no frames\n\nThis fixes invalid reads/writes with this sample:\nhttp://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "cve_desc": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "target": 0
      },
      {
        "idx": 29862,
        "reasoning": "This code addresses a potential out-of-bounds access issue in pixel addressing within the JPEG2000 decoder, as indicated by the commit message and fix for Ticket2921. The provided snippet demonstrates preventative measures like `av_assert0` checks on dimensions and explicit zeroing of memory areas, suggesting the fix successfully mitigates the identified vulnerability rather than introducing new ones.",
        "func": "static int decode_cblk(Jpeg2000DecoderContext *s, Jpeg2000CodingStyle *codsty,\n                       Jpeg2000T1Context *t1, Jpeg2000Cblk *cblk,\n                       int width, int height, int bandpos)\n{\n    int passno = cblk->npasses, pass_t = 2, bpno = cblk->nonzerobits - 1, y;\n    int clnpass_cnt = 0;\n    int bpass_csty_symbol           = codsty->cblk_style & JPEG2000_CBLK_BYPASS;\n    int vert_causal_ctx_csty_symbol = codsty->cblk_style & JPEG2000_CBLK_VSC;\n\n    av_assert0(width  <= JPEG2000_MAX_CBLKW);\n    av_assert0(height <= JPEG2000_MAX_CBLKH);\n\n    for (y = 0; y < height; y++)\n        memset(t1->data[y], 0, width * sizeof(**t1->data));\n\n    /* If code-block contains no compressed data: nothing to do. */\n    if (!cblk->length)\n        return 0;\n\n    for (y = 0; y < height + 2; y++)\n        memset(t1->flags[y], 0, (width + 2) * sizeof(**t1->flags));\n\n    cblk->data[cblk->length] = 0xff;\n    cblk->data[cblk->length+1] = 0xff;\n    ff_mqc_initdec(&t1->mqc, cblk->data);\n\n    while (passno--) {\n        switch(pass_t) {\n        case 0:\n            decode_sigpass(t1, width, height, bpno + 1, bandpos,\n                           bpass_csty_symbol && (clnpass_cnt >= 4),\n                           vert_causal_ctx_csty_symbol);\n            break;\n        case 1:\n            decode_refpass(t1, width, height, bpno + 1);\n            if (bpass_csty_symbol && clnpass_cnt >= 4)\n                ff_mqc_initdec(&t1->mqc, cblk->data);\n            break;\n        case 2:\n            decode_clnpass(s, t1, width, height, bpno + 1, bandpos,\n                           codsty->cblk_style & JPEG2000_CBLK_SEGSYM,\n                           vert_causal_ctx_csty_symbol);\n            clnpass_cnt = clnpass_cnt + 1;\n            if (bpass_csty_symbol && clnpass_cnt >= 4)\n                ff_mqc_initdec(&t1->mqc, cblk->data);\n            break;\n        }\n\n        pass_t++;\n        if (pass_t == 3) {\n            bpno--;\n            pass_t = 0;\n        }\n    }\n    return 0;\n}\n",
        "commit_message": "avcodec/jpeg2000dec: prevent out of array accesses in pixel addressing\n\nFixes Ticket2921\n\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "cve_desc": "The jpeg2000_decode_tile function in libavcodec/jpeg2000dec.c in FFmpeg before 2.1 does not consider the component number in certain calculations, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted JPEG2000 data.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 569,
        "reasoning": "This code is vulnerable because it allocates memory for frames based on the `totalframes` value read from the APE header without verifying if any actual frame data exists after the header. Consequently, if an APE file contains a header but no frames, the code attempts to access and process non-existent frame data, leading to a crash as described in the CVE.",
        "func": "static int ape_read_header(AVFormatContext * s, AVFormatParameters * ap)\n{\n    AVIOContext *pb = s->pb;\n    APEContext *ape = s->priv_data;\n    AVStream *st;\n    uint32_t tag;\n    int i;\n    int total_blocks;\n    int64_t pts;\n\n    /* TODO: Skip any leading junk such as id3v2 tags */\n    ape->junklength = 0;\n\n    tag = avio_rl32(pb);\n    if (tag != MKTAG('M', 'A', 'C', ' '))\n        return -1;\n\n    ape->fileversion = avio_rl16(pb);\n\n    if (ape->fileversion < APE_MIN_VERSION || ape->fileversion > APE_MAX_VERSION) {\n        av_log(s, AV_LOG_ERROR, \"Unsupported file version - %d.%02d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10);\n        return -1;\n    }\n\n    if (ape->fileversion >= 3980) {\n        ape->padding1             = avio_rl16(pb);\n        ape->descriptorlength     = avio_rl32(pb);\n        ape->headerlength         = avio_rl32(pb);\n        ape->seektablelength      = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->audiodatalength      = avio_rl32(pb);\n        ape->audiodatalength_high = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        avio_read(pb, ape->md5, 16);\n\n        /* Skip any unknown bytes at the end of the descriptor.\n           This is for future compatibility */\n        if (ape->descriptorlength > 52)\n            avio_seek(pb, ape->descriptorlength - 52, SEEK_CUR);\n\n        /* Read header data */\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->blocksperframe       = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->bps                  = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n    } else {\n        ape->descriptorlength = 0;\n        ape->headerlength = 32;\n\n        ape->compressiontype      = avio_rl16(pb);\n        ape->formatflags          = avio_rl16(pb);\n        ape->channels             = avio_rl16(pb);\n        ape->samplerate           = avio_rl32(pb);\n        ape->wavheaderlength      = avio_rl32(pb);\n        ape->wavtaillength        = avio_rl32(pb);\n        ape->totalframes          = avio_rl32(pb);\n        ape->finalframeblocks     = avio_rl32(pb);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_PEAK_LEVEL) {\n            avio_seek(pb, 4, SEEK_CUR); /* Skip the peak level */\n            ape->headerlength += 4;\n        }\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_HAS_SEEK_ELEMENTS) {\n            ape->seektablelength = avio_rl32(pb);\n            ape->headerlength += 4;\n            ape->seektablelength *= sizeof(int32_t);\n        } else\n            ape->seektablelength = ape->totalframes * sizeof(int32_t);\n\n        if (ape->formatflags & MAC_FORMAT_FLAG_8_BIT)\n            ape->bps = 8;\n        else if (ape->formatflags & MAC_FORMAT_FLAG_24_BIT)\n            ape->bps = 24;\n        else\n            ape->bps = 16;\n\n        if (ape->fileversion >= 3950)\n            ape->blocksperframe = 73728 * 4;\n        else if (ape->fileversion >= 3900 || (ape->fileversion >= 3800  && ape->compressiontype >= 4000))\n            ape->blocksperframe = 73728;\n        else\n            ape->blocksperframe = 9216;\n\n        /* Skip any stored wav header */\n        if (!(ape->formatflags & MAC_FORMAT_FLAG_CREATE_WAV_HEADER))\n             avio_seek(pb, ape->wavheaderlength, SEEK_CUR);\n     }\n \n     if(ape->totalframes > UINT_MAX / sizeof(APEFrame)){\n         av_log(s, AV_LOG_ERROR, \"Too many frames: %d\\n\", ape->totalframes);\n         return -1;\n    }\n    ape->frames       = av_malloc(ape->totalframes * sizeof(APEFrame));\n    if(!ape->frames)\n        return AVERROR(ENOMEM);\n    ape->firstframe   = ape->junklength + ape->descriptorlength + ape->headerlength + ape->seektablelength + ape->wavheaderlength;\n    ape->currentframe = 0;\n\n\n    ape->totalsamples = ape->finalframeblocks;\n    if (ape->totalframes > 1)\n        ape->totalsamples += ape->blocksperframe * (ape->totalframes - 1);\n\n    if (ape->seektablelength > 0) {\n        ape->seektable = av_malloc(ape->seektablelength);\n        for (i = 0; i < ape->seektablelength / sizeof(uint32_t); i++)\n            ape->seektable[i] = avio_rl32(pb);\n    }\n\n    ape->frames[0].pos     = ape->firstframe;\n    ape->frames[0].nblocks = ape->blocksperframe;\n    ape->frames[0].skip    = 0;\n    for (i = 1; i < ape->totalframes; i++) {\n        ape->frames[i].pos      = ape->seektable[i]; //ape->frames[i-1].pos + ape->blocksperframe;\n        ape->frames[i].nblocks  = ape->blocksperframe;\n        ape->frames[i - 1].size = ape->frames[i].pos - ape->frames[i - 1].pos;\n        ape->frames[i].skip     = (ape->frames[i].pos - ape->frames[0].pos) & 3;\n    }\n    ape->frames[ape->totalframes - 1].size    = ape->finalframeblocks * 4;\n    ape->frames[ape->totalframes - 1].nblocks = ape->finalframeblocks;\n\n    for (i = 0; i < ape->totalframes; i++) {\n        if(ape->frames[i].skip){\n            ape->frames[i].pos  -= ape->frames[i].skip;\n            ape->frames[i].size += ape->frames[i].skip;\n        }\n        ape->frames[i].size = (ape->frames[i].size + 3) & ~3;\n    }\n\n\n    ape_dumpinfo(s, ape);\n\n    /* try to read APE tags */\n    if (!url_is_streamed(pb)) {\n        ff_ape_parse_tag(s);\n        avio_seek(pb, 0, SEEK_SET);\n    }\n\n    av_log(s, AV_LOG_DEBUG, \"Decoding file - v%d.%02d, compression level %d\\n\", ape->fileversion / 1000, (ape->fileversion % 1000) / 10, ape->compressiontype);\n\n    /* now we are ready: build format streams */\n    st = av_new_stream(s, 0);\n    if (!st)\n        return -1;\n\n    total_blocks = (ape->totalframes == 0) ? 0 : ((ape->totalframes - 1) * ape->blocksperframe) + ape->finalframeblocks;\n\n    st->codec->codec_type      = AVMEDIA_TYPE_AUDIO;\n    st->codec->codec_id        = CODEC_ID_APE;\n    st->codec->codec_tag       = MKTAG('A', 'P', 'E', ' ');\n    st->codec->channels        = ape->channels;\n    st->codec->sample_rate     = ape->samplerate;\n    st->codec->bits_per_coded_sample = ape->bps;\n    st->codec->frame_size      = MAC_SUBFRAME_SIZE;\n\n    st->nb_frames = ape->totalframes;\n    st->start_time = 0;\n    st->duration  = total_blocks / MAC_SUBFRAME_SIZE;\n    av_set_pts_info(st, 64, MAC_SUBFRAME_SIZE, ape->samplerate);\n\n    st->codec->extradata = av_malloc(APE_EXTRADATA_SIZE);\n    st->codec->extradata_size = APE_EXTRADATA_SIZE;\n    AV_WL16(st->codec->extradata + 0, ape->fileversion);\n    AV_WL16(st->codec->extradata + 2, ape->compressiontype);\n    AV_WL16(st->codec->extradata + 4, ape->formatflags);\n\n    pts = 0;\n    for (i = 0; i < ape->totalframes; i++) {\n        ape->frames[i].pts = pts;\n        av_add_index_entry(st, ape->frames[i].pos, ape->frames[i].pts, 0, 0, AVINDEX_KEYFRAME);\n        pts += ape->blocksperframe / MAC_SUBFRAME_SIZE;\n    }\n\n    return 0;\n}\n",
        "commit_message": "Do not attempt to decode APE file with no frames\n\nThis fixes invalid reads/writes with this sample:\nhttp://packetstorm.linuxsecurity.com/1103-exploits/vlc105-dos.txt",
        "cve_desc": "The ape_read_header function in ape.c in libavformat in FFmpeg before 0.5.4, as used in MPlayer, VideoLAN VLC media player, and other products, allows remote attackers to cause a denial of service (application crash) via an APE (aka Monkey's Audio) file that contains a header but no frames.",
        "target": 1
      },
      {
        "idx": 892,
        "reasoning": "This code is vulnerable to out-of-bounds array accesses because it doesn't properly account for the component number (`compno`) when calculating memory access offsets, as highlighted in the CVE description. Specifically, the `dst` pointer calculation within the final loops doesn't consistently incorporate `compno` for non-planar images, potentially leading to writes outside the allocated buffer for certain components.",
        "func": "static int jpeg2000_decode_tile(Jpeg2000DecoderContext *s, Jpeg2000Tile *tile,\n                                AVFrame *picture)\n{\n    int compno, reslevelno, bandno;\n    int x, y;\n\n    uint8_t *line;\n    Jpeg2000T1Context t1;\n\n    /* Loop on tile components */\n    for (compno = 0; compno < s->ncomponents; compno++) {\n        Jpeg2000Component *comp     = tile->comp + compno;\n        Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n\n        /* Loop on resolution levels */\n        for (reslevelno = 0; reslevelno < codsty->nreslevels2decode; reslevelno++) {\n            Jpeg2000ResLevel *rlevel = comp->reslevel + reslevelno;\n            /* Loop on bands */\n            for (bandno = 0; bandno < rlevel->nbands; bandno++) {\n                int nb_precincts, precno;\n                Jpeg2000Band *band = rlevel->band + bandno;\n                int cblkno = 0, bandpos;\n\n                bandpos = bandno + (reslevelno > 0);\n\n                if (band->coord[0][0] == band->coord[0][1] ||\n                    band->coord[1][0] == band->coord[1][1])\n                    continue;\n\n                nb_precincts = rlevel->num_precincts_x * rlevel->num_precincts_y;\n                /* Loop on precincts */\n                for (precno = 0; precno < nb_precincts; precno++) {\n                    Jpeg2000Prec *prec = band->prec + precno;\n\n                    /* Loop on codeblocks */\n                    for (cblkno = 0; cblkno < prec->nb_codeblocks_width * prec->nb_codeblocks_height; cblkno++) {\n                        int x, y;\n                        Jpeg2000Cblk *cblk = prec->cblk + cblkno;\n                        decode_cblk(s, codsty, &t1, cblk,\n                                    cblk->coord[0][1] - cblk->coord[0][0],\n                                    cblk->coord[1][1] - cblk->coord[1][0],\n                                    bandpos);\n\n                        x = cblk->coord[0][0];\n                        y = cblk->coord[1][0];\n\n                        if (codsty->transform == FF_DWT97)\n                            dequantization_float(x, y, cblk, comp, &t1, band);\n                        else\n                            dequantization_int(x, y, cblk, comp, &t1, band);\n                   } /* end cblk */\n                } /*end prec */\n            } /* end band */\n        } /* end reslevel */\n\n        /* inverse DWT */\n        ff_dwt_decode(&comp->dwt, codsty->transform == FF_DWT97 ? (void*)comp->f_data : (void*)comp->i_data);\n    } /*end comp */\n\n    /* inverse MCT transformation */\n    if (tile->codsty[0].mct)\n        mct_decode(s, tile);\n\n    if (s->cdef[0] < 0) {\n        for (x = 0; x < s->ncomponents; x++)\n            s->cdef[x] = x + 1;\n        if ((s->ncomponents & 1) == 0)\n            s->cdef[s->ncomponents-1] = 0;\n    }\n\n    if (s->precision <= 8) {\n        for (compno = 0; compno < s->ncomponents; compno++) {\n            Jpeg2000Component *comp = tile->comp + compno;\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n            float *datap = comp->f_data;\n            int32_t *i_datap = comp->i_data;\n            int cbps = s->cbps[compno];\n            int w = tile->comp[compno].coord[0][1] - s->image_offset_x;\n            int planar = !!picture->data[2];\n            int pixelsize = planar ? 1 : s->ncomponents;\n            int plane = 0;\n\n            if (planar)\n                plane = s->cdef[compno] ? s->cdef[compno]-1 : (s->ncomponents-1);\n \n \n             y    = tile->comp[compno].coord[1][0] - s->image_offset_y;\n            line = picture->data[plane] + y * picture->linesize[plane];\n             for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) {\n                 uint8_t *dst;\n \n                 x   = tile->comp[compno].coord[0][0] - s->image_offset_x;\n                dst = line + x * pixelsize + compno*!planar;\n \n                 if (codsty->transform == FF_DWT97) {\n                     for (; x < w; x += s->cdx[compno]) {\n                        int val = lrintf(*datap) + (1 << (cbps - 1));\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n                        *dst = val << (8 - cbps);\n                        datap++;\n                        dst += pixelsize;\n                    }\n                } else {\n                    for (; x < w; x += s->cdx[compno]) {\n                        int val = *i_datap + (1 << (cbps - 1));\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n                        *dst = val << (8 - cbps);\n                        i_datap++;\n                        dst += pixelsize;\n                    }\n                }\n                line += picture->linesize[plane];\n            }\n        }\n    } else {\n        for (compno = 0; compno < s->ncomponents; compno++) {\n            Jpeg2000Component *comp = tile->comp + compno;\n            Jpeg2000CodingStyle *codsty = tile->codsty + compno;\n            float *datap = comp->f_data;\n            int32_t *i_datap = comp->i_data;\n            uint16_t *linel;\n            int cbps = s->cbps[compno];\n            int w = tile->comp[compno].coord[0][1] - s->image_offset_x;\n            int planar = !!picture->data[2];\n            int pixelsize = planar ? 1 : s->ncomponents;\n            int plane = 0;\n\n            if (planar)\n                 plane = s->cdef[compno] ? s->cdef[compno]-1 : (s->ncomponents-1);\n \n             y     = tile->comp[compno].coord[1][0] - s->image_offset_y;\n            linel = (uint16_t *)picture->data[plane] + y * (picture->linesize[plane] >> 1);\n             for (; y < tile->comp[compno].coord[1][1] - s->image_offset_y; y += s->cdy[compno]) {\n                 uint16_t *dst;\n \n                 x   = tile->comp[compno].coord[0][0] - s->image_offset_x;\n                dst = linel + (x * pixelsize + compno*!planar);\n                 if (codsty->transform == FF_DWT97) {\n                     for (; x < w; x += s-> cdx[compno]) {\n                         int  val = lrintf(*datap) + (1 << (cbps - 1));\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n                        /* align 12 bit values in little-endian mode */\n                        *dst = val << (16 - cbps);\n                        datap++;\n                        dst += pixelsize;\n                    }\n                } else {\n                    for (; x < w; x += s-> cdx[compno]) {\n                        int val = *i_datap + (1 << (cbps - 1));\n                        /* DC level shift and clip see ISO 15444-1:2002 G.1.2 */\n                        val = av_clip(val, 0, (1 << cbps) - 1);\n                        /* align 12 bit values in little-endian mode */\n                        *dst = val << (16 - cbps);\n                        i_datap++;\n                        dst += pixelsize;\n                    }\n                }\n                linel += picture->linesize[plane] >> 1;\n            }\n        }\n    }\n\n    return 0;\n}\n",
        "commit_message": "avcodec/jpeg2000dec: prevent out of array accesses in pixel addressing\n\nFixes Ticket2921\n\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "cve_desc": "The jpeg2000_decode_tile function in libavcodec/jpeg2000dec.c in FFmpeg before 2.1 does not consider the component number in certain calculations, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted JPEG2000 data.",
        "target": 1
      },
      {
        "idx": 893,
        "reasoning": "This code is vulnerable to a heap buffer overflow due to a potential mismatch between the allocated buffer size and the amount of data copied into it, specifically within the `memcpy` calls when `next` is greater than `-FF_INPUT_BUFFER_PADDING_SIZE`. The `av_fast_realloc` function can fail, but the code proceeds to potentially write beyond the bounds of the reallocated (or original) buffer if the reallocation doesn't provide enough space, leading to the described out-of-bounds access.",
        "func": "int ff_combine_frame(ParseContext *pc, int next, const uint8_t **buf, int *buf_size)\n{\n    if(pc->overread){\n        av_dlog(NULL, \"overread %d, state:%X next:%d index:%d o_index:%d\\n\",\n                pc->overread, pc->state, next, pc->index, pc->overread_index);\n        av_dlog(NULL, \"%X %X %X %X\\n\", (*buf)[0], (*buf)[1], (*buf)[2], (*buf)[3]);\n    }\n\n    /* Copy overread bytes from last frame into buffer. */\n    for(; pc->overread>0; pc->overread--){\n        pc->buffer[pc->index++]= pc->buffer[pc->overread_index++];\n    }\n\n    /* flush remaining if EOF */\n    if(!*buf_size && next == END_NOT_FOUND){\n        next= 0;\n    }\n\n    pc->last_index= pc->index;\n\n    /* copy into buffer end return */\n     if(next == END_NOT_FOUND){\n         void* new_buffer = av_fast_realloc(pc->buffer, &pc->buffer_size, (*buf_size) + pc->index + FF_INPUT_BUFFER_PADDING_SIZE);\n \n        if(!new_buffer)\n             return AVERROR(ENOMEM);\n         pc->buffer = new_buffer;\n         memcpy(&pc->buffer[pc->index], *buf, *buf_size);\n         pc->index += *buf_size;\n        return -1;\n    }\n\n    *buf_size=\n    pc->overread_index= pc->index + next;\n\n     /* append to buffer */\n     if(pc->index){\n         void* new_buffer = av_fast_realloc(pc->buffer, &pc->buffer_size, next + pc->index + FF_INPUT_BUFFER_PADDING_SIZE);\n        if(!new_buffer)\n             return AVERROR(ENOMEM);\n         pc->buffer = new_buffer;\n         if (next > -FF_INPUT_BUFFER_PADDING_SIZE)\n             memcpy(&pc->buffer[pc->index], *buf,\n                   next + FF_INPUT_BUFFER_PADDING_SIZE);\n        pc->index = 0;\n        *buf= pc->buffer;\n    }\n\n    /* store overread bytes */\n    for(;next < 0; next++){\n        pc->state = (pc->state<<8) | pc->buffer[pc->last_index + next];\n        pc->state64 = (pc->state64<<8) | pc->buffer[pc->last_index + next];\n        pc->overread++;\n    }\n\n    if(pc->overread){\n        av_dlog(NULL, \"overread %d, state:%X next:%d index:%d o_index:%d\\n\",\n                pc->overread, pc->state, next, pc->index, pc->overread_index);\n        av_dlog(NULL, \"%X %X %X %X\\n\", (*buf)[0], (*buf)[1],(*buf)[2],(*buf)[3]);\n    }\n\n    return 0;\n}\n",
        "commit_message": "avcodec/parser: reset indexes on realloc failure\n\nFixes Ticket2982\n\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "cve_desc": "The ff_combine_frame function in libavcodec/parser.c in FFmpeg before 2.1 does not properly handle certain memory-allocation errors, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted data.",
        "target": 1
      },
      {
        "idx": 894,
        "reasoning": "This code is vulnerable to a heap buffer over-read due to insufficient buffer size allocation for `synth_tile`, `jpeg_tile`, `kempf_buf`, and `kempf_flags` when handling certain tile dimensions. Specifically, the code previously allowed tiles to be drawn outside the allocated buffer, leading to potential out-of-bounds access as confirmed by the CVE description, and this commit attempts to mitigate that by increasing buffer sizes\u2014though the author admits uncertainty about whether real-world files trigger the issue.",
        "func": "static int g2m_init_buffers(G2MContext *c)\n{\n     int aligned_height;\n \n     if (!c->framebuf || c->old_width < c->width || c->old_height < c->height) {\n        c->framebuf_stride = FFALIGN(c->width * 3, 16);\n        aligned_height     = FFALIGN(c->height,    16);\n         av_free(c->framebuf);\n         c->framebuf = av_mallocz(c->framebuf_stride * aligned_height);\n         if (!c->framebuf)\n            return AVERROR(ENOMEM);\n    }\n    if (!c->synth_tile || !c->jpeg_tile ||\n        c->old_tile_w < c->tile_width ||\n        c->old_tile_h < c->tile_height) {\n        c->tile_stride = FFALIGN(c->tile_width, 16) * 3;\n        aligned_height = FFALIGN(c->tile_height,    16);\n        av_free(c->synth_tile);\n        av_free(c->jpeg_tile);\n        av_free(c->kempf_buf);\n        av_free(c->kempf_flags);\n        c->synth_tile  = av_mallocz(c->tile_stride      * aligned_height);\n        c->jpeg_tile   = av_mallocz(c->tile_stride      * aligned_height);\n        c->kempf_buf   = av_mallocz((c->tile_width + 1) * aligned_height\n                                    + FF_INPUT_BUFFER_PADDING_SIZE);\n        c->kempf_flags = av_mallocz( c->tile_width      * aligned_height);\n        if (!c->synth_tile || !c->jpeg_tile ||\n            !c->kempf_buf || !c->kempf_flags)\n            return AVERROR(ENOMEM);\n    }\n\n    return 0;\n}\n",
        "commit_message": "avcodec/g2meet: Fix framebuf size\n\nCurrently the code can in some cases draw tiles that hang outside the\nallocated buffer. This patch increases the buffer size to avoid out\nof array accesses. An alternative would be to fail if such tiles are\nencountered.\nI do not know if any valid files use such hanging tiles.\n\nFixes Ticket2971\nFound-by: ami_stuff\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "cve_desc": "The g2m_init_buffers function in libavcodec/g2meet.c in FFmpeg before 2.1 does not properly allocate memory for tiles, which allows remote attackers to cause a denial of service (out-of-bounds array access) or possibly have unspecified other impact via crafted Go2Webinar data.",
        "target": 1
      },
      {
        "idx": 895,
        "reasoning": "This code is vulnerable to a double-free because the `flush_fifo` function likely frees frames without properly accounting for frames potentially still referenced elsewhere, and then `write_to_fifo` attempts to add a new frame to the now-partially-emptied FIFO. This can lead to a double free if a frame is both flushed and then re-added to the FIFO, ultimately causing a denial of service.",
        "func": "static int filter_frame(AVFilterLink *inlink, AVFrame *buf)\n{\n    AVFilterContext    *ctx = inlink->dst;\n    FPSContext           *s = ctx->priv;\n    AVFilterLink   *outlink = ctx->outputs[0];\n    int64_t delta;\n    int i, ret;\n\n    s->frames_in++;\n    /* discard frames until we get the first timestamp */\n    if (s->pts == AV_NOPTS_VALUE) {\n        if (buf->pts != AV_NOPTS_VALUE) {\n            ret = write_to_fifo(s->fifo, buf);\n            if (ret < 0)\n                return ret;\n\n            if (s->start_time != DBL_MAX && s->start_time != AV_NOPTS_VALUE) {\n                double first_pts = s->start_time * AV_TIME_BASE;\n                first_pts = FFMIN(FFMAX(first_pts, INT64_MIN), INT64_MAX);\n                s->first_pts = s->pts = av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                     inlink->time_base);\n                av_log(ctx, AV_LOG_VERBOSE, \"Set first pts to (in:%\"PRId64\" out:%\"PRId64\")\\n\",\n                       s->first_pts, av_rescale_q(first_pts, AV_TIME_BASE_Q,\n                                                  outlink->time_base));\n            } else {\n                s->first_pts = s->pts = buf->pts;\n            }\n        } else {\n            av_log(ctx, AV_LOG_WARNING, \"Discarding initial frame(s) with no \"\n                   \"timestamp.\\n\");\n            av_frame_free(&buf);\n            s->drop++;\n        }\n        return 0;\n     }\n \n     /* now wait for the next timestamp */\n    if (buf->pts == AV_NOPTS_VALUE) {\n         return write_to_fifo(s->fifo, buf);\n     }\n \n    /* number of output frames */\n    delta = av_rescale_q_rnd(buf->pts - s->pts, inlink->time_base,\n                             outlink->time_base, s->rounding);\n\n    if (delta < 1) {\n        /* drop the frame and everything buffered except the first */\n        AVFrame *tmp;\n        int drop = av_fifo_size(s->fifo)/sizeof(AVFrame*);\n\n        av_log(ctx, AV_LOG_DEBUG, \"Dropping %d frame(s).\\n\", drop);\n        s->drop += drop;\n\n        av_fifo_generic_read(s->fifo, &tmp, sizeof(tmp), NULL);\n        flush_fifo(s->fifo);\n        ret = write_to_fifo(s->fifo, tmp);\n\n        av_frame_free(&buf);\n        return ret;\n    }\n\n    /* can output >= 1 frames */\n    for (i = 0; i < delta; i++) {\n        AVFrame *buf_out;\n        av_fifo_generic_read(s->fifo, &buf_out, sizeof(buf_out), NULL);\n\n        /* duplicate the frame if needed */\n        if (!av_fifo_size(s->fifo) && i < delta - 1) {\n            AVFrame *dup = av_frame_clone(buf_out);\n\n            av_log(ctx, AV_LOG_DEBUG, \"Duplicating frame.\\n\");\n            if (dup)\n                ret = write_to_fifo(s->fifo, dup);\n            else\n                ret = AVERROR(ENOMEM);\n\n            if (ret < 0) {\n                av_frame_free(&buf_out);\n                av_frame_free(&buf);\n                return ret;\n            }\n\n            s->dup++;\n        }\n\n        buf_out->pts = av_rescale_q(s->first_pts, inlink->time_base,\n                                    outlink->time_base) + s->frames_out;\n\n        if ((ret = ff_filter_frame(outlink, buf_out)) < 0) {\n            av_frame_free(&buf);\n            return ret;\n        }\n\n        s->frames_out++;\n    }\n    flush_fifo(s->fifo);\n\n    ret = write_to_fifo(s->fifo, buf);\n    s->pts = s->first_pts + av_rescale_q(s->frames_out, outlink->time_base, inlink->time_base);\n\n    return ret;\n}\n",
        "commit_message": "avfilter/vf_fps: make sure the fifo is not empty before using it\n\nFixes Ticket2905\n\nSigned-off-by: Michael Niedermayer <michaelni@gmx.at>",
        "cve_desc": "The filter_frame function in libavfilter/vf_fps.c in FFmpeg before 2.1 does not properly ensure the availability of FIFO content, which allows remote attackers to cause a denial of service (double free) or possibly have unspecified other impact via crafted data.",
        "target": 1
      }
    ]
  },
  "FreeRDP": {
    "0": [
      {
        "idx": 69309,
        "reasoning": "This code is likely safe, as the commit message explicitly states it *adds* length checks, addressing a potential issue highlighted in issue #4866. The snippet demonstrates checks for `cbSize` and `MagicNumber` within the `pEntryPointsEx` structure, validating the input before proceeding with memory allocation and function calls, which mitigates potential buffer overflows or misuse of function pointers.\n\n\n\n",
        "func": "BOOL VCAPITYPE VirtualChannelEntryEx(PCHANNEL_ENTRY_POINTS_EX pEntryPoints, PVOID pInitHandle)\n{\n\tUINT rc;\n\tdrdynvcPlugin* drdynvc;\n\tDrdynvcClientContext* context = NULL;\n\tCHANNEL_ENTRY_POINTS_FREERDP_EX* pEntryPointsEx;\n\tdrdynvc = (drdynvcPlugin*) calloc(1, sizeof(drdynvcPlugin));\n\n\tif (!drdynvc)\n\t{\n\t\tWLog_ERR(TAG, \"calloc failed!\");\n\t\treturn FALSE;\n\t}\n\n\tdrdynvc->channelDef.options =\n\t    CHANNEL_OPTION_INITIALIZED |\n\t    CHANNEL_OPTION_ENCRYPT_RDP |\n\t    CHANNEL_OPTION_COMPRESS_RDP;\n\tsprintf_s(drdynvc->channelDef.name, ARRAYSIZE(drdynvc->channelDef.name), \"drdynvc\");\n\tdrdynvc->state = DRDYNVC_STATE_INITIAL;\n\tpEntryPointsEx = (CHANNEL_ENTRY_POINTS_FREERDP_EX*) pEntryPoints;\n\n\tif ((pEntryPointsEx->cbSize >= sizeof(CHANNEL_ENTRY_POINTS_FREERDP_EX)) &&\n\t    (pEntryPointsEx->MagicNumber == FREERDP_CHANNEL_MAGIC_NUMBER))\n\t{\n\t\tcontext = (DrdynvcClientContext*) calloc(1, sizeof(DrdynvcClientContext));\n\n\t\tif (!context)\n\t\t{\n\t\t\tWLog_Print(drdynvc->log, WLOG_ERROR, \"calloc failed!\");\n\t\t\tfree(drdynvc);\n\t\t\treturn FALSE;\n\t\t}\n\n\t\tcontext->handle = (void*) drdynvc;\n\t\tcontext->custom = NULL;\n\t\tdrdynvc->context = context;\n\t\tcontext->GetVersion = drdynvc_get_version;\n\t\tdrdynvc->rdpcontext = pEntryPointsEx->context;\n\t}\n\n\tdrdynvc->log = WLog_Get(TAG);\n\tWLog_Print(drdynvc->log, WLOG_DEBUG, \"VirtualChannelEntryEx\");\n\tCopyMemory(&(drdynvc->channelEntryPoints), pEntryPoints, sizeof(CHANNEL_ENTRY_POINTS_FREERDP_EX));\n\tdrdynvc->InitHandle = pInitHandle;\n\trc = drdynvc->channelEntryPoints.pVirtualChannelInitEx(drdynvc, context, pInitHandle,\n\t        &drdynvc->channelDef, 1, VIRTUAL_CHANNEL_VERSION_WIN2000, drdynvc_virtual_channel_init_event_ex);\n\n\tif (CHANNEL_RC_OK != rc)\n\t{\n\t\tWLog_Print(drdynvc->log, WLOG_ERROR, \"pVirtualChannelInit failed with %s [%08\"PRIX32\"]\",\n\t\t           WTSErrorToString(rc), rc);\n\t\tfree(drdynvc->context);\n\t\tfree(drdynvc);\n\t\treturn FALSE;\n\t}\n\n\tdrdynvc->channelEntryPoints.pInterface = context;\n\treturn TRUE;\n}\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 0
      },
      {
        "idx": 69310,
        "reasoning": "This code snippet is safe as it simply retrieves a value (`drdynvc->version`) from a plugin handle within a defined context; there's no external input processing or memory manipulation present. The commit message referencing length checks in \"#4866\" likely addresses a vulnerability elsewhere in the FreeRDP codebase, and doesn't apply to this specific, straightforward function.\n\n\n\n",
        "func": "static int drdynvc_get_version(DrdynvcClientContext* context)\n{\n\tdrdynvcPlugin* drdynvc = (drdynvcPlugin*) context->handle;\n\treturn drdynvc->version;\n}\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 0
      },
      {
        "idx": 69311,
        "reasoning": "This code snippet is likely safe as it focuses on freeing memory associated with a message object and its stream, with checks to ensure it's a valid object and stream before attempting to free them. The added length checks mentioned in the commit message (though not visible in the snippet) likely address potential buffer management issues elsewhere, but this specific function doesn't exhibit obvious vulnerabilities like buffer overflows or use-after-free based on the provided code.\n\n\n\n",
        "func": "static void drdynvc_queue_object_free(void* obj)\n{\n\twStream* s;\n\twMessage* msg = (wMessage*)obj;\n\n\tif (!msg || (msg->id != 0))\n\t\treturn;\n\n\ts = (wStream*)msg->wParam;\n\n\tif (s)\n\t\tStream_Free(s, TRUE);\n}\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 0
      },
      {
        "idx": 69312,
        "reasoning": "This code is likely **not vulnerable** based solely on the provided snippet and commit message. The commit message explicitly states it *adds* length checks, suggesting it's addressing potential issues rather than introducing new ones, and the code itself simply reads a variable-length unsigned integer based on a provided `cbLen` parameter \u2013 a common and safe practice when properly constrained, which the commit implies it now is.\n\n\n\n",
        "func": " static UINT32 drdynvc_read_variable_uint(wStream* s, int cbLen)\n {\n \tUINT32 val;\n\n\tswitch (cbLen)\n\t{\n\t\tcase 0:\n\t\t\tStream_Read_UINT8(s, val);\n\t\t\tbreak;\n\n\t\tcase 1:\n\t\t\tStream_Read_UINT16(s, val);\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tStream_Read_UINT32(s, val);\n\t\t\tbreak;\n\t}\n\n\treturn val;\n}\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 0
      },
      {
        "idx": 69313,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. While the commit message mentions adding length checks (presumably elsewhere in the codebase related to #4866), this specific function `drdynvc_send` simply calls a virtual channel write function with the stream's buffer and position\u2014it doesn't perform any data processing that would be susceptible to buffer overflows or similar issues given the context.",
        "func": "static UINT drdynvc_send(drdynvcPlugin* drdynvc, wStream* s)\n{\n\tUINT status;\n\n\tif (!drdynvc)\n\t\tstatus = CHANNEL_RC_BAD_CHANNEL_HANDLE;\n\telse\n\t{\n\t\tstatus = drdynvc->channelEntryPoints.pVirtualChannelWriteEx(drdynvc->InitHandle,\n\t\t         drdynvc->OpenHandle, Stream_Buffer(s), (UINT32) Stream_GetPosition(s), s);\n\t}\n\n\tswitch (status)\n\t{\n\t\tcase CHANNEL_RC_OK:\n\t\t\treturn CHANNEL_RC_OK;\n\n\t\tcase CHANNEL_RC_NOT_CONNECTED:\n\t\t\tStream_Free(s, TRUE);\n\t\t\treturn CHANNEL_RC_OK;\n\n\t\tcase CHANNEL_RC_BAD_CHANNEL_HANDLE:\n\t\t\tStream_Free(s, TRUE);\n\t\t\tWLog_ERR(TAG, \"VirtualChannelWriteEx failed with CHANNEL_RC_BAD_CHANNEL_HANDLE\");\n\t\t\treturn status;\n\n\t\tdefault:\n\t\t\tStream_Free(s, TRUE);\n\t\t\tWLog_Print(drdynvc->log, WLOG_ERROR, \"VirtualChannelWriteEx failed with %s [%08\"PRIX32\"]\",\n\t\t\t           WTSErrorToString(status),\n\t\t\t           status);\n\t\t\treturn status;\n\t}\n}\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1329,
        "reasoning": "The code is vulnerable to an integer overflow because the `scopeCount` read from the stream is directly used to allocate memory for `scopeList->array` without validation. A sufficiently large `scopeCount` value can cause `sizeof(LICENSE_BLOB) * scopeCount` to overflow, leading to a small memory allocation and subsequent buffer overflow when populating the `scopeList->array` in the loop, resulting in a denial of service or potentially code execution.",
        "func": "BOOL license_read_scope_list(wStream* s, SCOPE_LIST* scopeList)\n{\n\tUINT32 i;\n\tUINT32 scopeCount;\n\n\tif (Stream_GetRemainingLength(s) < 4)\n\t\treturn FALSE;\n \n \tStream_Read_UINT32(s, scopeCount); /* ScopeCount (4 bytes) */\n \n \tscopeList->count = scopeCount;\n \tscopeList->array = (LICENSE_BLOB*) malloc(sizeof(LICENSE_BLOB) * scopeCount);\n \n\t/* ScopeArray */\n\tfor (i = 0; i < scopeCount; i++)\n\t{\n\t\tscopeList->array[i].type = BB_SCOPE_BLOB;\n\n\t\tif (!license_read_binary_blob(s, &scopeList->array[i]))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}\n",
        "commit_message": "None",
        "cve_desc": "Integer overflow in the license_read_scope_list function in libfreerdp/core/license.c in FreeRDP through 1.0.2 allows remote RDP servers to cause a denial of service (application crash) or possibly have unspecified other impact via a large ScopeCount value in a Scope List in a Server License Request packet.",
        "target": 1
      },
      {
        "idx": 3460,
        "reasoning": "This code is vulnerable to an information leak because it doesn't validate the size of the data read from the stream `s` before accessing it with `Stream_Read_UINT16`. Specifically, if the RDP server sends a crafted capability request with an unexpectedly small size, the `Stream_Read_UINT16` calls can read beyond the allocated buffer, potentially exposing client memory to the server \u2013 as indicated by the CVE description.",
        "func": "static UINT drdynvc_process_capability_request(drdynvcPlugin* drdynvc, int Sp,\n        int cbChId, wStream* s)\n{\n\tUINT status;\n\n \tif (!drdynvc)\n \t\treturn CHANNEL_RC_BAD_INIT_HANDLE;\n \n \tWLog_Print(drdynvc->log, WLOG_TRACE, \"capability_request Sp=%d cbChId=%d\", Sp, cbChId);\n \tStream_Seek(s, 1); /* pad */\n \tStream_Read_UINT16(s, drdynvc->version);\n\n\t/* RDP8 servers offer version 3, though Microsoft forgot to document it\n\t * in their early documents.  It behaves the same as version 2.\n \t */\n \tif ((drdynvc->version == 2) || (drdynvc->version == 3))\n \t{\n \t\tStream_Read_UINT16(s, drdynvc->PriorityCharge0);\n \t\tStream_Read_UINT16(s, drdynvc->PriorityCharge1);\n \t\tStream_Read_UINT16(s, drdynvc->PriorityCharge2);\n\t\tStream_Read_UINT16(s, drdynvc->PriorityCharge3);\n\t}\n\n\tstatus = drdynvc_send_capability_response(drdynvc);\n\tdrdynvc->state = DRDYNVC_STATE_READY;\n \treturn status;\n }\n",
        "commit_message": "Fix for #4866: Added additional length checks",
        "cve_desc": "FreeRDP FreeRDP 2.0.0-rc3 released version before commit 205c612820dac644d665b5bb1cdf437dc5ca01e3 contains a Other/Unknown vulnerability in channels/drdynvc/client/drdynvc_main.c, drdynvc_process_capability_request that can result in The RDP server can read the client's memory.. This attack appear to be exploitable via RDPClient must connect the rdp server with echo option. This vulnerability appears to have been fixed in after commit 205c612820dac644d665b5bb1cdf437dc5ca01e3.",
        "target": 1
      },
      {
        "idx": 3746,
        "reasoning": "This code is vulnerable to an out-of-bounds write because the `len` calculation, particularly when handling the `*in < 0xFF` case, can result in a value that, when added to the `out` pointer in `FillMemory`, exceeds the allocated buffer size. Specifically, a crafted input can manipulate `len` to be larger than the remaining space in `out`, leading to a write beyond the buffer's boundaries and potential memory corruption.",
        "func": "static void nsc_rle_decode(BYTE* in, BYTE* out, UINT32 originalSize)\n {\n \tUINT32 len;\n \tUINT32 left;\n\tBYTE value;\n\tleft = originalSize;\n\n\twhile (left > 4)\n\t{\n\t\tvalue = *in++;\n \n \t\tif (left == 5)\n \t\t{\n \t\t\t*out++ = value;\n \t\t\tleft--;\n \t\t}\n\t\telse if (value == *in)\n\t\t{\n\t\t\tin++;\n\n\t\t\tif (*in < 0xFF)\n\t\t\t{\n\t\t\t\tlen = (UINT32) * in++;\n\t\t\t\tlen += 2;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tin++;\n\t\t\t\tlen = *((UINT32*) in);\n \t\t\t\tin += 4;\n \t\t\t}\n \n \t\t\tFillMemory(out, len, value);\n \t\t\tout += len;\n \t\t\tleft -= len;\n \t\t}\n \t\telse\n \t\t{\n \t\t\t*out++ = value;\n \t\t\tleft--;\n \t\t}\n \t}\n \n\t*((UINT32*)out) = *((UINT32*)in);\n }\n",
        "commit_message": "Fixed CVE-2018-8788\n\nThanks to Eyal Itkin from Check Point Software Technologies.",
        "cve_desc": "FreeRDP prior to version 2.0.0-rc4 contains an Out-Of-Bounds Write of up to 4 bytes in function nsc_rle_decode() that results in a memory corruption and possibly even a remote code execution.",
        "target": 1
      },
      {
        "idx": 3752,
        "reasoning": "This code is vulnerable to an integer overflow because the `DstWidth * DstHeight * GetBytesPerPixel(bitmap->format)` calculation can result in an integer overflow, leading to a smaller-than-expected `bitmap->length`. Subsequently, `_aligned_malloc` allocates insufficient memory, and the decompression functions write beyond the allocated buffer, causing a heap-based buffer overflow.",
        "func": "static BOOL gdi_Bitmap_Decompress(rdpContext* context, rdpBitmap* bitmap,\n                                  const BYTE* pSrcData, UINT32 DstWidth, UINT32 DstHeight,\n                                  UINT32 bpp, UINT32 length, BOOL compressed,\n                                  UINT32 codecId)\n {\n \tUINT32 SrcSize = length;\n \trdpGdi* gdi = context->gdi;\n \tbitmap->compressed = FALSE;\n \tbitmap->format = gdi->dstFormat;\n\tbitmap->length = DstWidth * DstHeight * GetBytesPerPixel(bitmap->format);\n \tbitmap->data = (BYTE*) _aligned_malloc(bitmap->length, 16);\n \n \tif (!bitmap->data)\n\t\treturn FALSE;\n\n\tif (compressed)\n\t{\n\t\tif (bpp < 32)\n\t\t{\n\t\t\tif (!interleaved_decompress(context->codecs->interleaved,\n\t\t\t                            pSrcData, SrcSize,\n\t\t\t                            DstWidth, DstHeight,\n\t\t\t                            bpp,\n\t\t\t                            bitmap->data, bitmap->format,\n\t\t\t                            0, 0, 0, DstWidth, DstHeight,\n\t\t\t                            &gdi->palette))\n\t\t\t\treturn FALSE;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tif (!planar_decompress(context->codecs->planar, pSrcData, SrcSize,\n\t\t\t                       DstWidth, DstHeight,\n\t\t\t                       bitmap->data, bitmap->format, 0, 0, 0,\n\t\t\t                       DstWidth, DstHeight, TRUE))\n\t\t\t\treturn FALSE;\n\t\t}\n\t}\n\telse\n\t{\n\t\tconst UINT32 SrcFormat = gdi_get_pixel_format(bpp);\n\t\tconst size_t sbpp = GetBytesPerPixel(SrcFormat);\n\t\tconst size_t dbpp = GetBytesPerPixel(bitmap->format);\n\n\t\tif ((sbpp == 0) || (dbpp == 0))\n\t\t\treturn FALSE;\n\t\telse\n\t\t{\n\t\t\tconst size_t dstSize = SrcSize * dbpp / sbpp;\n\n\t\t\tif (dstSize  < bitmap->length)\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\tif (!freerdp_image_copy(bitmap->data, bitmap->format, 0, 0, 0,\n\t\t                        DstWidth, DstHeight, pSrcData, SrcFormat,\n\t\t                        0, 0, 0, &gdi->palette, FREERDP_FLIP_VERTICAL))\n\t\t\treturn FALSE;\n\t}\n\n\treturn TRUE;\n}\n",
        "commit_message": "Fixed CVE-2018-8787\n\nThanks to Eyal Itkin from Check Point Software Technologies.",
        "cve_desc": "FreeRDP prior to version 2.0.0-rc4 contains an Integer Overflow that leads to a Heap-Based Buffer Overflow in function gdi_Bitmap_Decompress() and results in a memory corruption and probably even a remote code execution.",
        "target": 1
      },
      {
        "idx": 3753,
        "reasoning": "This code is vulnerable to an integer truncation leading to a heap-based buffer overflow because the `bitmapUpdate->number` value, read directly from the stream, is used to calculate the size of a buffer (`bitmapUpdate->rectangles`) without sufficient validation. Specifically, a large `bitmapUpdate->number` value could cause `count = bitmapUpdate->number * 2` to wrap around, resulting in a smaller-than-expected `count` being used in `realloc`, ultimately leading to a buffer overflow when writing rectangle data in the subsequent loop.",
        "func": "BITMAP_UPDATE* update_read_bitmap_update(rdpUpdate* update, wStream* s)\n{\n\tUINT32 i;\n\tBITMAP_UPDATE* bitmapUpdate = calloc(1, sizeof(BITMAP_UPDATE));\n\n\tif (!bitmapUpdate)\n\t\tgoto fail;\n\n\tif (Stream_GetRemainingLength(s) < 2)\n\t\tgoto fail;\n\n\tStream_Read_UINT16(s, bitmapUpdate->number); /* numberRectangles (2 bytes) */\n\tWLog_Print(update->log, WLOG_TRACE, \"BitmapUpdate: %\"PRIu32\"\", bitmapUpdate->number);\n \n \tif (bitmapUpdate->number > bitmapUpdate->count)\n \t{\n\t\tUINT16 count;\n\t\tBITMAP_DATA* newdata;\n\t\tcount = bitmapUpdate->number * 2;\n\t\tnewdata = (BITMAP_DATA*) realloc(bitmapUpdate->rectangles,\n\t\t                                 sizeof(BITMAP_DATA) * count);\n \n \t\tif (!newdata)\n \t\t\tgoto fail;\n\n\t\tbitmapUpdate->rectangles = newdata;\n\t\tZeroMemory(&bitmapUpdate->rectangles[bitmapUpdate->count],\n\t\t           sizeof(BITMAP_DATA) * (count - bitmapUpdate->count));\n\t\tbitmapUpdate->count = count;\n\t}\n\n\t/* rectangles */\n\tfor (i = 0; i < bitmapUpdate->number; i++)\n\t{\n\t\tif (!update_read_bitmap_data(update, s, &bitmapUpdate->rectangles[i]))\n\t\t\tgoto fail;\n\t}\n\n\treturn bitmapUpdate;\nfail:\n\tfree_bitmap_update(update->context, bitmapUpdate);\n\treturn NULL;\n}\n",
        "commit_message": "Fixed CVE-2018-8786\n\nThanks to Eyal Itkin from Check Point Software Technologies.",
        "cve_desc": "FreeRDP prior to version 2.0.0-rc4 contains an Integer Truncation that leads to a Heap-Based Buffer Overflow in function update_read_bitmap_update() and results in a memory corruption and probably even a remote code execution.",
        "target": 1
      }
    ]
  },
  "FreeRTOS-Kernel": {
    "0": [],
    "1": []
  },
  "GIMP": {
    "0": [
      {
        "idx": 498630,
        "reasoning": "This code is not directly vulnerable based on the provided snippet and commit message. While the commit introduces support for a new TGA format (16-bit RGB), the code includes checks and handling for various bit depths and alpha channels, preventing potential buffer overflows or incorrect interpretations of the image data that could lead to vulnerabilities. \n\n\n\n",
        "func": "load_image (const gchar  *filename,\n            GError      **error)\n{\n  FILE     *fp;\n  tga_info  info;\n  guchar    header[18];\n  guchar    footer[26];\n  guchar    extension[495];\n  long      offset;\n  gint32    image_ID = -1;\n\n  gimp_progress_init_printf (_(\"Opening '%s'\"),\n                             gimp_filename_to_utf8 (filename));\n\n  fp = g_fopen (filename, \"rb\");\n\n  if (! fp)\n    {\n      g_set_error (error, G_FILE_ERROR, g_file_error_from_errno (errno),\n                   _(\"Could not open '%s' for reading: %s\"),\n                   gimp_filename_to_utf8 (filename), g_strerror (errno));\n      return -1;\n    }\n\n  /* Is file big enough for a footer? */\n  if (!fseek (fp, -26L, SEEK_END))\n    {\n      if (fread (footer, sizeof (footer), 1, fp) != 1)\n        {\n          g_message (_(\"Cannot read footer from '%s'\"),\n                     gimp_filename_to_utf8 (filename));\n          return -1;\n        }\n      else if (memcmp (footer + 8, magic, sizeof (magic)) == 0)\n        {\n          /* Check the signature. */\n\n          offset = (footer[0]          +\n                    footer[1] * 256L   +\n                    footer[2] * 65536L +\n                    footer[3] * 16777216L);\n\n          if (offset != 0)\n            {\n              if (fseek (fp, offset, SEEK_SET) ||\n                  fread (extension, sizeof (extension), 1, fp) != 1)\n                {\n                  g_message (_(\"Cannot read extension from '%s'\"),\n                             gimp_filename_to_utf8 (filename));\n                  return -1;\n                }\n              /* Eventually actually handle version 2 TGA here */\n            }\n        }\n    }\n\n  if (fseek (fp, 0, SEEK_SET) ||\n      fread (header, sizeof (header), 1, fp) != 1)\n    {\n      g_message (_(\"Cannot read header from '%s'\"),\n                 gimp_filename_to_utf8 (filename));\n      return -1;\n    }\n\n  switch (header[2])\n    {\n    case 1:\n      info.imageType        = TGA_TYPE_MAPPED;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n    case 2:\n      info.imageType        = TGA_TYPE_COLOR;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n    case 3:\n      info.imageType        = TGA_TYPE_GRAY;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n\n    case 9:\n      info.imageType        = TGA_TYPE_MAPPED;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n    case 10:\n      info.imageType        = TGA_TYPE_COLOR;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n    case 11:\n      info.imageType        = TGA_TYPE_GRAY;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n\n    default:\n      info.imageType = 0;\n    }\n\n  info.idLength     = header[0];\n  info.colorMapType = header[1];\n\n  info.colorMapIndex  = header[3] + header[4] * 256;\n  info.colorMapLength = header[5] + header[6] * 256;\n  info.colorMapSize   = header[7];\n\n  info.xOrigin = header[8]  + header[9] * 256;\n  info.yOrigin = header[10] + header[11] * 256;\n  info.width   = header[12] + header[13] * 256;\n  info.height  = header[14] + header[15] * 256;\n\n  info.bpp       = header[16];\n  info.bytes     = (info.bpp + 7) / 8;\n  info.alphaBits = header[17] & 0x0f; /* Just the low 4 bits */\n  info.flipHoriz = (header[17] & 0x10) ? 1 : 0;\n  info.flipVert  = (header[17] & 0x20) ? 0 : 1;\n\n  /* hack to handle some existing files with incorrect headers, see bug #306675 */\n  if (info.alphaBits == info.bpp)\n    info.alphaBits = 0;\n\n  /* hack to handle yet another flavor of incorrect headers, see bug #540969 */\n  if (info.alphaBits == 0)\n    {\n      if (info.imageType == TGA_TYPE_COLOR && info.bpp == 32)\n        info.alphaBits = 8;\n\n      if (info.imageType == TGA_TYPE_GRAY && info.bpp == 16)\n        info.alphaBits = 8;\n    }\n\n  switch (info.imageType)\n    {\n      case TGA_TYPE_MAPPED:\n        if (info.bpp != 8)\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp);\n            return -1;\n          }\n        break;\n      case TGA_TYPE_COLOR:\n        if ((info.bpp != 15 && info.bpp != 16 &&\n             info.bpp != 24 && info.bpp != 32)      ||\n            ((info.bpp == 15 || info.bpp == 24) &&\n             info.alphaBits != 0)                   ||\n            (info.bpp == 16 && info.alphaBits != 1 &&\n             info.alphaBits != 0)                   ||\n            (info.bpp == 32 && info.alphaBits != 8))\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u, alpha = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp, info.alphaBits);\n            return -1;\n          }\n        break;\n      case TGA_TYPE_GRAY:\n        if (info.bpp != 8 &&\n            (info.alphaBits != 8 || (info.bpp != 16 && info.bpp != 15)))\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp);\n            return -1;\n          }\n        break;\n\n      default:\n        g_message (\"Unknown image type %u for '%s'\",\n                   info.imageType, gimp_filename_to_utf8 (filename));\n        return -1;\n    }\n\n  /* Plausible but unhandled formats */\n  if (info.bytes * 8 != info.bpp && info.bpp != 15)\n    {\n      g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                 gimp_filename_to_utf8 (filename),\n                 info.imageType, info.bpp);\n      return -1;\n    }\n\n  /* Check that we have a color map only when we need it. */\n  if (info.imageType == TGA_TYPE_MAPPED && info.colorMapType != 1)\n    {\n      g_message (\"Indexed image has invalid color map type %u\",\n                 info.colorMapType);\n      return -1;\n    }\n  else if (info.imageType != TGA_TYPE_MAPPED && info.colorMapType != 0)\n    {\n      g_message (\"Non-indexed image has invalid color map type %u\",\n                 info.colorMapType);\n      return -1;\n    }\n\n  /* Skip the image ID field. */\n  if (info.idLength && fseek (fp, info.idLength, SEEK_CUR))\n    {\n      g_message (\"File '%s' is truncated or corrupted\",\n                 gimp_filename_to_utf8 (filename));\n      return -1;\n    }\n\n  image_ID = ReadImage (fp, &info, filename);\n\n  fclose (fp);\n\n  return image_ID;\n}",
        "commit_message": "plug-ins: TGA 16-bit RGB (without alpha bit) is also valid.\n\nAccording to some spec on the web, 16-bit RGB is also valid. In this\ncase, the last bit is simply ignored (at least that's how it is\nimplemented right now).",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer over-read in ReadImage in plug-ins/common/file-tga.c (related to bgr2rgb.part.1) via an unexpected bits-per-pixel value for an RGBA image.",
        "target": 0
      },
      {
        "idx": 498640,
        "reasoning": "This code *is* vulnerable, despite the commit message stating it addresses the issue. The vulnerability lies in the `xc+=MIN(n-xc,skip);` line within the loop; while `n` is calculated based on `fli_header->width` and `fli_header->height` to represent the remaining buffer size, `xc` increments based on `skip` without a check to ensure `xc` remains within the bounds of `framebuf`'s allocated size, potentially leading to a heap overflow. \n\n\n\n",
        "func": "void fli_read_lc_2(FILE *f, s_fli_header *fli_header, unsigned char *old_framebuf, unsigned char *framebuf)\n{\n\tunsigned short yc, lc, numline;\n\tunsigned char *pos;\n\tmemcpy(framebuf, old_framebuf, fli_header->width * fli_header->height);\n\tyc=0;\n\tnumline = fli_read_short(f);\n\tfor (lc=0; lc < numline; lc++) {\n\t\tunsigned short pc, pcnt, lpf, lpn;\n\t\tsize_t n, xc;\n\t\tpc=fli_read_short(f);\n\t\tlpf=0; lpn=0;\n\t\twhile (pc & 0x8000) {\n\t\t\tif (pc & 0x4000) {\n\t\t\t\tyc+=-(signed short)pc;\n\t\t\t} else {\n\t\t\t\tlpf=1;lpn=pc&0xFF;\n\t\t\t}\n\t\t\tpc=fli_read_short(f);\n\t\t}\n\t\tyc=MIN(yc, fli_header->height);\n\t\txc=0;\n\t\tpos=framebuf+(fli_header->width * yc);\n\t\tn=(size_t)fli_header->width * (fli_header->height-yc);\n\t\tfor (pcnt=pc; pcnt>0; pcnt--) {\n\t\t\tunsigned short ps,skip;\n\t\t\tskip=fli_read_char(f);\n\t\t\tps=fli_read_char(f);\n\t\t\txc+=MIN(n-xc,skip);\n\t\t\tif (ps & 0x80) {\n\t\t\t\tunsigned char v1,v2;\n\t\t\t\tps=-(signed char)ps;\n\t\t\t\tv1=fli_read_char(f);\n\t\t\t\tv2=fli_read_char(f);\n\t\t\t\twhile (ps>0 && xc+1<n) {\n\t\t\t\t\tpos[xc++]=v1;\n\t\t\t\t\tpos[xc++]=v2;\n\t\t\t\t\tps--;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tsize_t len;\n\t\t\t\tlen=MIN((n-xc)/2,ps);\n\t\t\t\tfread(&(pos[xc]), len, 2, f);\n\t\t\t\txc+=len << 1;\n\t\t\t}\n\t\t}\n\t\tif (lpf) pos[xc]=lpn;\n\t\tyc++;\n\t}\n}",
        "commit_message": "Bug 739133 - (CVE-2017-17785) Heap overflow while parsing FLI files.\n\nIt is possible to trigger a heap overflow while parsing FLI files. The\nRLE decoder is vulnerable to out of boundary writes due to lack of\nboundary checks.\n\nThe variable \"framebuf\" points to a memory area which was allocated\nwith fli_header->width * fli_header->height bytes. The RLE decoder\ntherefore must never write beyond that limit.\n\nIf an illegal frame is detected, the parser won't stop, which means\nthat the next valid sequence is properly parsed again. This should\nallow GIMP to parse FLI files as good as possible even if they are\nbroken by an attacker or by accident.\n\nWhile at it, I changed the variable xc to be of type size_t, because\nthe multiplication of width and height could overflow a 16 bit type.\n\nSigned-off-by: Tobias Stoeckmann <tobias@stoeckmann.org>",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in the fli_read_brun function in plug-ins/file-fli/fli.c.",
        "target": 0
      },
      {
        "idx": 498641,
        "reasoning": "This code snippet is **not vulnerable** because it only writes a fixed-size chunk header for a black frame and doesn't involve any RLE decoding or frame buffer manipulation where the heap overflow exists. The vulnerability lies within the RLE decoder itself, which is not present in this specific `fli_write_black` function.\n\n\n\n",
        "func": "void fli_write_black(FILE *f, s_fli_header *fli_header, unsigned char *framebuf)\n{\n\ts_fli_chunk chunk;\n\n\tchunk.size=6;\n\tchunk.magic=FLI_BLACK;\n\n\tfli_write_long(f, chunk.size);\n\tfli_write_short(f, chunk.magic);\n}",
        "commit_message": "Bug 739133 - (CVE-2017-17785) Heap overflow while parsing FLI files.\n\nIt is possible to trigger a heap overflow while parsing FLI files. The\nRLE decoder is vulnerable to out of boundary writes due to lack of\nboundary checks.\n\nThe variable \"framebuf\" points to a memory area which was allocated\nwith fli_header->width * fli_header->height bytes. The RLE decoder\ntherefore must never write beyond that limit.\n\nIf an illegal frame is detected, the parser won't stop, which means\nthat the next valid sequence is properly parsed again. This should\nallow GIMP to parse FLI files as good as possible even if they are\nbroken by an attacker or by accident.\n\nWhile at it, I changed the variable xc to be of type size_t, because\nthe multiplication of width and height could overflow a 16 bit type.\n\nSigned-off-by: Tobias Stoeckmann <tobias@stoeckmann.org>",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in the fli_read_brun function in plug-ins/file-fli/fli.c.",
        "target": 0
      },
      {
        "idx": 498642,
        "reasoning": "This code snippet is not directly related to the reported vulnerability. The commit message and description detail a heap overflow in the *parsing* of FLI files due to a lack of boundary checks in the RLE decoder, while this code snippet simply writes a short integer to a file \u2013 it doesn\u2019t perform any decoding or memory manipulation that could lead to an out-of-bounds write.\n\n\n\n",
        "func": "static void fli_write_short(FILE *f, unsigned short w)\n{\n\tunsigned char b[2];\n\tb[0]=w&255;\n\tb[1]=(w>>8)&255;\n\tfwrite(&b,1,2,f);\n}",
        "commit_message": "Bug 739133 - (CVE-2017-17785) Heap overflow while parsing FLI files.\n\nIt is possible to trigger a heap overflow while parsing FLI files. The\nRLE decoder is vulnerable to out of boundary writes due to lack of\nboundary checks.\n\nThe variable \"framebuf\" points to a memory area which was allocated\nwith fli_header->width * fli_header->height bytes. The RLE decoder\ntherefore must never write beyond that limit.\n\nIf an illegal frame is detected, the parser won't stop, which means\nthat the next valid sequence is properly parsed again. This should\nallow GIMP to parse FLI files as good as possible even if they are\nbroken by an attacker or by accident.\n\nWhile at it, I changed the variable xc to be of type size_t, because\nthe multiplication of width and height could overflow a 16 bit type.\n\nSigned-off-by: Tobias Stoeckmann <tobias@stoeckmann.org>",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in the fli_read_brun function in plug-ins/file-fli/fli.c.",
        "target": 0
      },
      {
        "idx": 498643,
        "reasoning": "This code snippet is **not directly vulnerable** to the described heap overflow. The commit message details a vulnerability in the *RLE decoder* within the FLI parsing process, while the provided code only shows a simple `fread` operation copying data into a pre-allocated buffer \u2013 it doesn't contain the RLE decoding logic where the out-of-bounds write occurs.\n\n\n\n",
        "func": "void fli_read_copy(FILE *f, s_fli_header *fli_header, unsigned char *framebuf)\n{\n\tfread(framebuf, fli_header->width, fli_header->height, f);\n}",
        "commit_message": "Bug 739133 - (CVE-2017-17785) Heap overflow while parsing FLI files.\n\nIt is possible to trigger a heap overflow while parsing FLI files. The\nRLE decoder is vulnerable to out of boundary writes due to lack of\nboundary checks.\n\nThe variable \"framebuf\" points to a memory area which was allocated\nwith fli_header->width * fli_header->height bytes. The RLE decoder\ntherefore must never write beyond that limit.\n\nIf an illegal frame is detected, the parser won't stop, which means\nthat the next valid sequence is properly parsed again. This should\nallow GIMP to parse FLI files as good as possible even if they are\nbroken by an attacker or by accident.\n\nWhile at it, I changed the variable xc to be of type size_t, because\nthe multiplication of width and height could overflow a 16 bit type.\n\nSigned-off-by: Tobias Stoeckmann <tobias@stoeckmann.org>",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in the fli_read_brun function in plug-ins/file-fli/fli.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 215993,
        "reasoning": "The code is vulnerable to a heap-based buffer over-read because it doesn't properly validate the `info.bpp` (bits per pixel) value, specifically when handling RGBA images with unexpected bit depths like 16. This allows a crafted TGA file to cause the `ReadImage` function to read beyond the allocated buffer when converting the image data, as highlighted by the CVE description relating to `bgr2rgb.part.1`.",
        "func": "load_image (const gchar  *filename,\n            GError      **error)\n{\n  FILE     *fp;\n  tga_info  info;\n  guchar    header[18];\n  guchar    footer[26];\n  guchar    extension[495];\n  long      offset;\n  gint32    image_ID = -1;\n\n  gimp_progress_init_printf (_(\"Opening '%s'\"),\n                             gimp_filename_to_utf8 (filename));\n\n  fp = g_fopen (filename, \"rb\");\n\n  if (! fp)\n    {\n      g_set_error (error, G_FILE_ERROR, g_file_error_from_errno (errno),\n                   _(\"Could not open '%s' for reading: %s\"),\n                   gimp_filename_to_utf8 (filename), g_strerror (errno));\n      return -1;\n    }\n\n  /* Is file big enough for a footer? */\n  if (!fseek (fp, -26L, SEEK_END))\n    {\n      if (fread (footer, sizeof (footer), 1, fp) != 1)\n        {\n          g_message (_(\"Cannot read footer from '%s'\"),\n                     gimp_filename_to_utf8 (filename));\n          return -1;\n        }\n      else if (memcmp (footer + 8, magic, sizeof (magic)) == 0)\n        {\n          /* Check the signature. */\n\n          offset = (footer[0]          +\n                    footer[1] * 256L   +\n                    footer[2] * 65536L +\n                    footer[3] * 16777216L);\n\n          if (offset != 0)\n            {\n              if (fseek (fp, offset, SEEK_SET) ||\n                  fread (extension, sizeof (extension), 1, fp) != 1)\n                {\n                  g_message (_(\"Cannot read extension from '%s'\"),\n                             gimp_filename_to_utf8 (filename));\n                  return -1;\n                }\n              /* Eventually actually handle version 2 TGA here */\n            }\n        }\n    }\n\n  if (fseek (fp, 0, SEEK_SET) ||\n      fread (header, sizeof (header), 1, fp) != 1)\n    {\n      g_message (_(\"Cannot read header from '%s'\"),\n                 gimp_filename_to_utf8 (filename));\n      return -1;\n    }\n\n  switch (header[2])\n    {\n    case 1:\n      info.imageType        = TGA_TYPE_MAPPED;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n    case 2:\n      info.imageType        = TGA_TYPE_COLOR;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n    case 3:\n      info.imageType        = TGA_TYPE_GRAY;\n      info.imageCompression = TGA_COMP_NONE;\n      break;\n\n    case 9:\n      info.imageType        = TGA_TYPE_MAPPED;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n    case 10:\n      info.imageType        = TGA_TYPE_COLOR;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n    case 11:\n      info.imageType        = TGA_TYPE_GRAY;\n      info.imageCompression = TGA_COMP_RLE;\n      break;\n\n    default:\n      info.imageType = 0;\n    }\n\n  info.idLength     = header[0];\n  info.colorMapType = header[1];\n\n  info.colorMapIndex  = header[3] + header[4] * 256;\n  info.colorMapLength = header[5] + header[6] * 256;\n  info.colorMapSize   = header[7];\n\n  info.xOrigin = header[8]  + header[9] * 256;\n  info.yOrigin = header[10] + header[11] * 256;\n  info.width   = header[12] + header[13] * 256;\n  info.height  = header[14] + header[15] * 256;\n\n  info.bpp       = header[16];\n  info.bytes     = (info.bpp + 7) / 8;\n  info.alphaBits = header[17] & 0x0f; /* Just the low 4 bits */\n  info.flipHoriz = (header[17] & 0x10) ? 1 : 0;\n  info.flipVert  = (header[17] & 0x20) ? 0 : 1;\n\n  /* hack to handle some existing files with incorrect headers, see bug #306675 */\n  if (info.alphaBits == info.bpp)\n    info.alphaBits = 0;\n\n  /* hack to handle yet another flavor of incorrect headers, see bug #540969 */\n  if (info.alphaBits == 0)\n    {\n      if (info.imageType == TGA_TYPE_COLOR && info.bpp == 32)\n        info.alphaBits = 8;\n\n      if (info.imageType == TGA_TYPE_GRAY && info.bpp == 16)\n        info.alphaBits = 8;\n    }\n\n  switch (info.imageType)\n    {\n      case TGA_TYPE_MAPPED:\n        if (info.bpp != 8)\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp);\n            return -1;\n          }\n        break;\n      case TGA_TYPE_COLOR:\n        if ((info.bpp != 15 && info.bpp != 16 &&\n             info.bpp != 24 && info.bpp != 32)      ||\n            ((info.bpp == 15 || info.bpp == 24) &&\n             info.alphaBits != 0)                   ||\n            (info.bpp == 16 && info.alphaBits != 1) ||\n            (info.bpp == 32 && info.alphaBits != 8))\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u, alpha = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp, info.alphaBits);\n            return -1;\n          }\n        break;\n      case TGA_TYPE_GRAY:\n        if (info.bpp != 8 &&\n            (info.alphaBits != 8 || (info.bpp != 16 && info.bpp != 15)))\n          {\n            g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                       gimp_filename_to_utf8 (filename),\n                       info.imageType, info.bpp);\n            return -1;\n          }\n        break;\n\n      default:\n        g_message (\"Unknown image type %u for '%s'\",\n                   info.imageType, gimp_filename_to_utf8 (filename));\n        return -1;\n    }\n\n  /* Plausible but unhandled formats */\n  if (info.bytes * 8 != info.bpp && info.bpp != 15)\n    {\n      g_message (\"Unhandled sub-format in '%s' (type = %u, bpp = %u)\",\n                 gimp_filename_to_utf8 (filename),\n                 info.imageType, info.bpp);\n      return -1;\n    }\n\n  /* Check that we have a color map only when we need it. */\n  if (info.imageType == TGA_TYPE_MAPPED && info.colorMapType != 1)\n    {\n      g_message (\"Indexed image has invalid color map type %u\",\n                 info.colorMapType);\n      return -1;\n    }\n  else if (info.imageType != TGA_TYPE_MAPPED && info.colorMapType != 0)\n    {\n      g_message (\"Non-indexed image has invalid color map type %u\",\n                 info.colorMapType);\n      return -1;\n    }\n\n  /* Skip the image ID field. */\n  if (info.idLength && fseek (fp, info.idLength, SEEK_CUR))\n    {\n      g_message (\"File '%s' is truncated or corrupted\",\n                 gimp_filename_to_utf8 (filename));\n      return -1;\n    }\n\n  image_ID = ReadImage (fp, &info, filename);\n\n  fclose (fp);\n\n  return image_ID;\n}",
        "commit_message": "plug-ins: TGA 16-bit RGB (without alpha bit) is also valid.\n\nAccording to some spec on the web, 16-bit RGB is also valid. In this\ncase, the last bit is simply ignored (at least that's how it is\nimplemented right now).",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer over-read in ReadImage in plug-ins/common/file-tga.c (related to bgr2rgb.part.1) via an unexpected bits-per-pixel value for an RGBA image.",
        "target": 1
      },
      {
        "idx": 215995,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow because it doesn't adequately validate the `block_total_len` read from the PSP file against the actual file size before attempting to read data, potentially leading to an out-of-bounds read. Specifically, the `read_block_header` function and subsequent `fseek` and `fread` operations rely on `block_total_len` without ensuring it doesn't exceed the file's boundaries, as highlighted by the CVE description relating to `read_channel_data` (likely called from one of the `read_*_block` functions).",
        "func": "load_image (const gchar  *filename,\n            GError      **error)\n{\n  FILE *f;\n  struct stat st;\n  char buf[32];\n  PSPimage ia;\n  guint32 block_init_len, block_total_len;\n  long block_start;\n  PSPBlockID id = -1;\n  gint block_number;\n\n  gint32 image_ID = -1;\n\n  if (g_stat (filename, &st) == -1)\n    return -1;\n\n  f = g_fopen (filename, \"rb\");\n  if (f == NULL)\n    {\n      g_set_error (error, G_FILE_ERROR, g_file_error_from_errno (errno),\n                   _(\"Could not open '%s' for reading: %s\"),\n                   gimp_filename_to_utf8 (filename), g_strerror (errno));\n      return -1;\n    }\n\n  /* Read the PSP File Header and determine file version */\n  if (fread (buf, 32, 1, f) < 1\n      || fread (&psp_ver_major, 2, 1, f) < 1\n      || fread (&psp_ver_minor, 2, 1, f) < 1)\n    {\n      g_message (\"Error reading file header\");\n      goto error;\n    }\n\n  if (memcmp (buf, \"Paint Shop Pro Image File\\n\\032\\0\\0\\0\\0\\0\", 32) != 0)\n    {\n      g_message (\"Incorrect file signature\");\n      goto error;\n    }\n\n  psp_ver_major = GUINT16_FROM_LE (psp_ver_major);\n  psp_ver_minor = GUINT16_FROM_LE (psp_ver_minor);\n\n  /* I only have the documentation for file format version 3.0,\n   * but PSP 6 writes version 4.0. Let's hope it's backwards compatible.\n   * Earlier versions probably don't have all the fields I expect\n   * so don't accept those.\n   */\n  if (psp_ver_major < 3)\n    {\n      g_message (\"Unsupported PSP file format version \"\n                 \"%d.%d, only knows 3.0 (and later?)\",\n                 psp_ver_major, psp_ver_minor);\n      goto error;\n    }\n  else if ((psp_ver_major == 3)\n        || (psp_ver_major == 4)\n        || (psp_ver_major == 5)\n        || (psp_ver_major == 6))\n    ; /* OK */\n  else\n    {\n      g_message (\"Unsupported PSP file format version %d.%d\",\n                 psp_ver_major, psp_ver_minor);\n      goto error;\n    }\n\n  /* Read all the blocks */\n  block_number = 0;\n\n  IFDBG(3) g_message (\"size = %d\", (int)st.st_size);\n  while (ftell (f) != st.st_size\n         && (id = read_block_header (f, &block_init_len,\n                                     &block_total_len)) != -1)\n    {\n      block_start = ftell (f);\n\n      if (id == PSP_IMAGE_BLOCK)\n        {\n          if (block_number != 0)\n            {\n              g_message (\"Duplicate General Image Attributes block\");\n              goto error;\n            }\n          if (read_general_image_attribute_block (f, block_init_len,\n                                                  block_total_len, &ia) == -1)\n            {\n              goto error;\n            }\n\n          IFDBG(2) g_message (\"%d dpi %dx%d %s\",\n                              (int) ia.resolution,\n                              ia.width, ia.height,\n                              compression_name (ia.compression));\n\n          image_ID = gimp_image_new (ia.width, ia.height,\n                                     ia.grayscale ? GIMP_GRAY : GIMP_RGB);\n          if (image_ID == -1)\n            {\n              goto error;\n            }\n\n          gimp_image_set_filename (image_ID, filename);\n\n          gimp_image_set_resolution (image_ID, ia.resolution, ia.resolution);\n        }\n      else\n        {\n          if (block_number == 0)\n            {\n              g_message (\"Missing General Image Attributes block\");\n              goto error;\n            }\n\n          switch (id)\n            {\n            case PSP_CREATOR_BLOCK:\n              if (read_creator_block (f, image_ID, block_total_len, &ia) == -1)\n                goto error;\n              break;\n\n            case PSP_COLOR_BLOCK:\n              break;            /* Not yet implemented */\n\n            case PSP_LAYER_START_BLOCK:\n              if (read_layer_block (f, image_ID, block_total_len, &ia) == -1)\n                goto error;\n              break;\n\n            case PSP_SELECTION_BLOCK:\n              break;            /* Not yet implemented */\n\n            case PSP_ALPHA_BANK_BLOCK:\n              break;            /* Not yet implemented */\n\n            case PSP_THUMBNAIL_BLOCK:\n              break;            /* No use for it */\n\n            case PSP_EXTENDED_DATA_BLOCK:\n              break;            /* Not yet implemented */\n\n            case PSP_TUBE_BLOCK:\n              if (read_tube_block (f, image_ID, block_total_len, &ia) == -1)\n                goto error;\n              break;\n\n            case PSP_COMPOSITE_IMAGE_BANK_BLOCK:\n              break;            /* Not yet implemented */\n\n            case PSP_LAYER_BLOCK:\n            case PSP_CHANNEL_BLOCK:\n            case PSP_ALPHA_CHANNEL_BLOCK:\n            case PSP_ADJUSTMENT_EXTENSION_BLOCK:\n            case PSP_VECTOR_EXTENSION_BLOCK:\n            case PSP_SHAPE_BLOCK:\n            case PSP_PAINTSTYLE_BLOCK:\n            case PSP_COMPOSITE_ATTRIBUTES_BLOCK:\n            case PSP_JPEG_BLOCK:\n              g_message (\"Sub-block %s should not occur \"\n                         \"at main level of file\",\n                         block_name (id));\n              break;\n\n            default:\n              g_message (\"Unrecognized block id %d\", id);\n              break;\n            }\n        }\n\n      if (block_start + block_total_len >= st.st_size)\n        break;\n\n      if (try_fseek (f, block_start + block_total_len, SEEK_SET) < 0)\n        goto error;\n\n      block_number++;\n    }\n\n  if (id == -1)\n    {\n    error:\n      fclose (f);\n      if (image_ID != -1)\n        gimp_image_delete (image_ID);\n      return -1;\n    }\n\n  fclose (f);\n\n  return image_ID;\n}",
        "commit_message": "Bug 790849 - (CVE-2017-17789) CVE-2017-17789 Heap buffer overflow...\n\n... in PSP importer.\nCheck if declared block length is valid (i.e. within the actual file)\nbefore going further.\nConsider the file as broken otherwise and fail loading it.",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in read_channel_data in plug-ins/common/file-psp.c.",
        "target": 1
      },
      {
        "idx": 215999,
        "reasoning": "This code is vulnerable to a heap overflow because the `xc` variable, representing the current write position within `framebuf`, is not checked to ensure it remains within the bounds of the allocated buffer (`fli_header->width * fli_header->height`). Specifically, the `memset` and the loop within the `ps & 0x80` block can write past the end of the allocated `framebuf` if the values read from the file (`ps`) are crafted maliciously, leading to an out-of-bounds write.\n\n\n\n",
        "func": "void fli_read_brun(FILE *f, s_fli_header *fli_header, unsigned char *framebuf)\n{\n\tunsigned short yc;\n\tunsigned char *pos;\n\tfor (yc=0; yc < fli_header->height; yc++) {\n\t\tunsigned short xc, pc, pcnt;\n\t\tpc=fli_read_char(f);\n\t\txc=0;\n\t\tpos=framebuf+(fli_header->width * yc);\n\t\tfor (pcnt=pc; pcnt>0; pcnt--) {\n\t\t\tunsigned short ps;\n\t\t\tps=fli_read_char(f);\n\t\t\tif (ps & 0x80) {\n\t\t\t\tunsigned short len;\n\t\t\t\tfor (len=-(signed char)ps; len>0; len--) {\n\t\t\t\t\tpos[xc++]=fli_read_char(f);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tunsigned char val;\n\t\t\t\tval=fli_read_char(f);\n\t\t\t\tmemset(&(pos[xc]), val, ps);\n\t\t\t\txc+=ps;\n\t\t\t}\n\t\t}\n\t}\n}",
        "commit_message": "Bug 739133 - (CVE-2017-17785) Heap overflow while parsing FLI files.\n\nIt is possible to trigger a heap overflow while parsing FLI files. The\nRLE decoder is vulnerable to out of boundary writes due to lack of\nboundary checks.\n\nThe variable \"framebuf\" points to a memory area which was allocated\nwith fli_header->width * fli_header->height bytes. The RLE decoder\ntherefore must never write beyond that limit.\n\nIf an illegal frame is detected, the parser won't stop, which means\nthat the next valid sequence is properly parsed again. This should\nallow GIMP to parse FLI files as good as possible even if they are\nbroken by an attacker or by accident.\n\nWhile at it, I changed the variable xc to be of type size_t, because\nthe multiplication of width and height could overflow a 16 bit type.\n\nSigned-off-by: Tobias Stoeckmann <tobias@stoeckmann.org>",
        "cve_desc": "In GIMP 2.8.22, there is a heap-based buffer overflow in the fli_read_brun function in plug-ins/file-fli/fli.c.",
        "target": 1
      }
    ]
  },
  "ImageMagick": {
    "0": [
      {
        "idx": 48840,
        "reasoning": "This code snippet appears safe as it primarily performs mathematical operations on floating-point values (`double`) representing color components. The operations include scaling and wrapping within the 0.0 to 1.0 range for hue, which prevents out-of-bounds writes or buffer overflows\u2014the commit message specifically addresses a potential overflow issue, but this code doesn't exhibit characteristics typically associated with such vulnerabilities.\n\n\n\n",
        "func": "static inline void ModulateHCLp(const double percent_hue,\n  const double percent_chroma,const double percent_luma,double *red,\n  double *green,double *blue)\n{\n  double\n    hue,\n    luma,\n    chroma;\n\n  /*\n    Increase or decrease color luma, chroma, or hue.\n  */\n  ConvertRGBToHCLp(*red,*green,*blue,&hue,&chroma,&luma);\n  hue+=0.5*(0.01*percent_hue-1.0);\n  while (hue < 0.0)\n    hue+=1.0;\n  while (hue > 1.0)\n    hue-=1.0;\n  chroma*=0.01*percent_chroma;\n  luma*=0.01*percent_luma;\n  ConvertHCLpToRGB(hue,chroma,luma,red,green,blue);\n}\n",
        "commit_message": "Evaluate lazy pixel cache morphology to prevent buffer overflow (bug report from Ibrahim M. El-Sayed)",
        "cve_desc": "Buffer overflow in MagickCore/enhance.c in ImageMagick before 7.0.2-7 allows remote attackers to have unspecified impact via vectors related to pixel cache morphology.",
        "target": 0
      },
      {
        "idx": 48841,
        "reasoning": "This code snippet appears safe as it primarily performs mathematical operations on floating-point values representing color components (hue, saturation, brightness). The operations include scaling and wrapping within the 0.0 to 1.0 range, which doesn't suggest any potential for buffer overflows or other memory corruption vulnerabilities given the context of color manipulation. \n\n\n\n",
        "func": "static inline void ModulateHSB(const double percent_hue,\n  const double percent_saturation,const double percent_brightness,double *red,\n  double *green,double *blue)\n{\n  double\n    brightness,\n    hue,\n    saturation;\n\n  /*\n    Increase or decrease color brightness, saturation, or hue.\n  */\n  ConvertRGBToHSB(*red,*green,*blue,&hue,&saturation,&brightness);\n  hue+=0.5*(0.01*percent_hue-1.0);\n  while (hue < 0.0)\n    hue+=1.0;\n  while (hue > 1.0)\n    hue-=1.0;\n  saturation*=0.01*percent_saturation;\n  brightness*=0.01*percent_brightness;\n  ConvertHSBToRGB(hue,saturation,brightness,red,green,blue);\n}\n",
        "commit_message": "Evaluate lazy pixel cache morphology to prevent buffer overflow (bug report from Ibrahim M. El-Sayed)",
        "cve_desc": "Buffer overflow in MagickCore/enhance.c in ImageMagick before 7.0.2-7 allows remote attackers to have unspecified impact via vectors related to pixel cache morphology.",
        "target": 0
      },
      {
        "idx": 48842,
        "reasoning": "This code snippet appears safe as it primarily performs mathematical operations on floating-point values representing color components (hue, saturation, intensity). The input `percent_hue`, `percent_saturation`, and `percent_intensity` are scaled down before being applied, and the hue value is wrapped within the 0.0-1.0 range, mitigating potential issues like buffer overflows or out-of-bounds access that the commit message alludes to being addressed elsewhere in the project related to pixel cache morphology.\n\n\n\n",
        "func": "static inline void ModulateHSI(const double percent_hue,\n  const double percent_saturation,const double percent_intensity,double *red,\n  double *green,double *blue)\n{\n  double\n    intensity,\n    hue,\n    saturation;\n\n  /*\n    Increase or decrease color intensity, saturation, or hue.\n  */\n  ConvertRGBToHSI(*red,*green,*blue,&hue,&saturation,&intensity);\n  hue+=0.5*(0.01*percent_hue-1.0);\n  while (hue < 0.0)\n    hue+=1.0;\n  while (hue > 1.0)\n    hue-=1.0;\n  saturation*=0.01*percent_saturation;\n  intensity*=0.01*percent_intensity;\n  ConvertHSIToRGB(hue,saturation,intensity,red,green,blue);\n}\n",
        "commit_message": "Evaluate lazy pixel cache morphology to prevent buffer overflow (bug report from Ibrahim M. El-Sayed)",
        "cve_desc": "Buffer overflow in MagickCore/enhance.c in ImageMagick before 7.0.2-7 allows remote attackers to have unspecified impact via vectors related to pixel cache morphology.",
        "target": 0
      },
      {
        "idx": 48843,
        "reasoning": "This code snippet appears safe as it performs calculations on floating-point values (`double`) representing color components, and includes normalization of the `hue` value to stay within the 0.0-1.0 range. There's no direct manipulation of fixed-size buffers or external input that could lead to a buffer overflow, and the operations are standard color space conversions and adjustments.\n\n\n\n",
        "func": "static inline void ModulateHSL(const double percent_hue,\n  const double percent_saturation,const double percent_lightness,double *red,\n  double *green,double *blue)\n{\n  double\n    hue,\n    lightness,\n    saturation;\n\n  /*\n    Increase or decrease color lightness, saturation, or hue.\n  */\n  ConvertRGBToHSL(*red,*green,*blue,&hue,&saturation,&lightness);\n  hue+=0.5*(0.01*percent_hue-1.0);\n  while (hue < 0.0)\n    hue+=1.0;\n  while (hue >= 1.0)\n    hue-=1.0;\n  saturation*=0.01*percent_saturation;\n  lightness*=0.01*percent_lightness;\n  ConvertHSLToRGB(hue,saturation,lightness,red,green,blue);\n}\n",
        "commit_message": "Evaluate lazy pixel cache morphology to prevent buffer overflow (bug report from Ibrahim M. El-Sayed)",
        "cve_desc": "Buffer overflow in MagickCore/enhance.c in ImageMagick before 7.0.2-7 allows remote attackers to have unspecified impact via vectors related to pixel cache morphology.",
        "target": 0
      },
      {
        "idx": 48844,
        "reasoning": "This code snippet appears safe as it primarily performs mathematical operations on floating-point values representing color components (hue, saturation, value, red, green, blue). The operations include scaling and wrapping within the 0.0-1.0 range for hue, preventing potential buffer overflows or out-of-bounds access that the commit message suggests was addressed elsewhere in the ImageMagick project\u2014likely not within this specific function.\n\n\n\n",
        "func": "static inline void ModulateHSV(const double percent_hue,\n  const double percent_saturation,const double percent_value,double *red,\n  double *green,double *blue)\n{\n  double\n    hue,\n    saturation,\n    value;\n\n  /*\n    Increase or decrease color value, saturation, or hue.\n  */\n  ConvertRGBToHSV(*red,*green,*blue,&hue,&saturation,&value);\n  hue+=0.5*(0.01*percent_hue-1.0);\n  while (hue < 0.0)\n    hue+=1.0;\n  while (hue >= 1.0)\n    hue-=1.0;\n  saturation*=0.01*percent_saturation;\n  value*=0.01*percent_value;\n  ConvertHSVToRGB(hue,saturation,value,red,green,blue);\n}\n",
        "commit_message": "Evaluate lazy pixel cache morphology to prevent buffer overflow (bug report from Ibrahim M. El-Sayed)",
        "cve_desc": "Buffer overflow in MagickCore/enhance.c in ImageMagick before 7.0.2-7 allows remote attackers to have unspecified impact via vectors related to pixel cache morphology.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1792,
        "reasoning": "The code is vulnerable to a buffer overflow because the `sscanf` function reads up to 1024 bytes into the `name` and `format` buffers without proper bounds checking, potentially overwriting adjacent memory if the input string contains excessively long values. Additionally, the code allocates memory based on a potentially attacker-controlled `count` value read from the image data, and a check `~((size_t) count) >= (MagickPathExtent-1)` is insufficient to prevent allocation of a buffer smaller than required, leading to a write beyond allocated memory.",
        "func": "static MagickBooleanType Get8BIMProperty(const Image *image,const char *key,\n  ExceptionInfo *exception)\n{\n  char\n    *attribute,\n    format[MagickPathExtent],\n    name[MagickPathExtent],\n    *resource;\n\n  const StringInfo\n    *profile;\n\n  const unsigned char\n    *info;\n\n  long\n    start,\n    stop;\n\n  MagickBooleanType\n    status;\n\n  register ssize_t\n    i;\n\n  size_t\n    length;\n\n  ssize_t\n    count,\n    id,\n    sub_number;\n\n  /*\n    There are no newlines in path names, so it's safe as terminator.\n  */\n  profile=GetImageProfile(image,\"8bim\");\n  if (profile == (StringInfo *) NULL)\n    return(MagickFalse);\n  count=(ssize_t) sscanf(key,\"8BIM:%ld,%ld:%1024[^\\n]\\n%1024[^\\n]\",&start,&stop,\n    name,format);\n  if ((count != 2) && (count != 3) && (count != 4))\n    return(MagickFalse);\n  if (count < 4)\n    (void) CopyMagickString(format,\"SVG\",MagickPathExtent);\n  if (count < 3)\n    *name='\\0';\n  sub_number=1;\n  if (*name == '#')\n    sub_number=(ssize_t) StringToLong(&name[1]);\n  sub_number=MagickMax(sub_number,1L);\n  resource=(char *) NULL;\n  status=MagickFalse;\n  length=GetStringInfoLength(profile);\n  info=GetStringInfoDatum(profile);\n  while ((length > 0) && (status == MagickFalse))\n  {\n    if (ReadPropertyByte(&info,&length) != (unsigned char) '8')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'B')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'I')\n      continue;\n    if (ReadPropertyByte(&info,&length) != (unsigned char) 'M')\n      continue;\n    id=(ssize_t) ReadPropertyMSBShort(&info,&length);\n    if (id < (ssize_t) start)\n      continue;\n    if (id > (ssize_t) stop)\n      continue;\n    if (resource != (char *) NULL)\n      resource=DestroyString(resource);\n    count=(ssize_t) ReadPropertyByte(&info,&length);\n    if ((count != 0) && ((size_t) count <= length))\n      {\n        resource=(char *) NULL;\n        if (~((size_t) count) >= (MagickPathExtent-1))\n          resource=(char *) AcquireQuantumMemory((size_t) count+\n            MagickPathExtent,sizeof(*resource));\n        if (resource != (char *) NULL)\n          {\n            for (i=0; i < (ssize_t) count; i++)\n              resource[i]=(char) ReadPropertyByte(&info,&length);\n            resource[count]='\\0';\n          }\n      }\n     if ((count & 0x01) == 0)\n       (void) ReadPropertyByte(&info,&length);\n     count=(ssize_t) ReadPropertyMSBLong(&info,&length);\n     if ((*name != '\\0') && (*name != '#'))\n       if ((resource == (char *) NULL) || (LocaleCompare(name,resource) != 0))\n         {\n          /*\n            No name match, scroll forward and try next.\n          */\n          info+=count;\n          length-=MagickMin(count,(ssize_t) length);\n          continue;\n        }\n    if ((*name == '#') && (sub_number != 1))\n      {\n        /*\n          No numbered match, scroll forward and try next.\n        */\n        sub_number--;\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        continue;\n      }\n    /*\n      We have the resource of interest.\n    */\n    attribute=(char *) NULL;\n    if (~((size_t) count) >= (MagickPathExtent-1))\n      attribute=(char *) AcquireQuantumMemory((size_t) count+MagickPathExtent,\n        sizeof(*attribute));\n    if (attribute != (char *) NULL)\n      {\n        (void) CopyMagickMemory(attribute,(char *) info,(size_t) count);\n        attribute[count]='\\0';\n        info+=count;\n        length-=MagickMin(count,(ssize_t) length);\n        if ((id <= 1999) || (id >= 2999))\n          (void) SetImageProperty((Image *) image,key,(const char *)\n            attribute,exception);\n        else\n          {\n            char\n              *path;\n\n            if (LocaleCompare(format,\"svg\") == 0)\n              path=TraceSVGClippath((unsigned char *) attribute,(size_t) count,\n                image->columns,image->rows);\n            else\n              path=TracePSClippath((unsigned char *) attribute,(size_t) count);\n            (void) SetImageProperty((Image *) image,key,(const char *) path,\n              exception);\n            path=DestroyString(path);\n          }\n        attribute=DestroyString(attribute);\n        status=MagickTrue;\n      }\n  }\n  if (resource != (char *) NULL)\n    resource=DestroyString(resource);\n  return(status);\n}\n",
        "commit_message": "Prevent buffer overflow (bug report from Ibrahim el-sayed)",
        "cve_desc": "Buffer overflow in the Get8BIMProperty function in MagickCore/property.c in ImageMagick before 6.9.5-4 and 7.x before 7.0.2-6 allows remote attackers to cause a denial of service (out-of-bounds read, memory leak, and crash) via a crafted image.",
        "target": 1
      },
      {
        "idx": 2010,
        "reasoning": "This code is vulnerable to a buffer overflow due to the potential for `j` to exceed the allocated size of the `dash_polygon` array, specifically within the loop where new points are added (`dash_polygon[j]=...`). The condition `(j+1) > (ssize_t) (2*number_vertices)` is checked *after* potentially writing to `dash_polygon[j]`, meaning an out-of-bounds write can occur if `j` becomes too large, similar to the vulnerability described in the provided CVE.",
        "func": "static MagickBooleanType DrawDashPolygon(const DrawInfo *draw_info,\n  const PrimitiveInfo *primitive_info,Image *image,ExceptionInfo *exception)\n{\n  DrawInfo\n    *clone_info;\n\n  double\n    length,\n    maximum_length,\n    offset,\n    scale,\n    total_length;\n\n  MagickStatusType\n    status;\n\n  PrimitiveInfo\n    *dash_polygon;\n\n  register ssize_t\n    i;\n\n  register double\n    dx,\n    dy;\n\n  size_t\n    number_vertices;\n\n  ssize_t\n    j,\n    n;\n\n  assert(draw_info != (const DrawInfo *) NULL);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(DrawEvent,GetMagickModule(),\"    begin draw-dash\");\n  for (i=0; primitive_info[i].primitive != UndefinedPrimitive; i++) ;\n  number_vertices=(size_t) i;\n  dash_polygon=(PrimitiveInfo *) AcquireQuantumMemory((size_t)\n    (2UL*number_vertices+1UL),sizeof(*dash_polygon));\n  if (dash_polygon == (PrimitiveInfo *) NULL)\n    return(MagickFalse);\n  clone_info=CloneDrawInfo((ImageInfo *) NULL,draw_info);\n  clone_info->miterlimit=0;\n  dash_polygon[0]=primitive_info[0];\n  scale=ExpandAffine(&draw_info->affine);\n  length=scale*(draw_info->dash_pattern[0]-0.5);\n  offset=draw_info->dash_offset != 0.0 ? scale*draw_info->dash_offset : 0.0;\n  j=1;\n  for (n=0; offset > 0.0; j=0)\n  {\n    if (draw_info->dash_pattern[n] <= 0.0)\n      break;\n    length=scale*(draw_info->dash_pattern[n]+(n == 0 ? -0.5 : 0.5));\n    if (offset > length)\n      {\n        offset-=length;\n        n++;\n        length=scale*(draw_info->dash_pattern[n]+0.5);\n        continue;\n      }\n    if (offset < length)\n      {\n        length-=offset;\n        offset=0.0;\n        break;\n      }\n    offset=0.0;\n    n++;\n  }\n   status=MagickTrue;\n   maximum_length=0.0;\n   total_length=0.0;\n  for (i=1; (i < number_vertices) && (length >= 0.0); i++)\n   {\n     dx=primitive_info[i].point.x-primitive_info[i-1].point.x;\n     dy=primitive_info[i].point.y-primitive_info[i-1].point.y;\n    maximum_length=hypot((double) dx,dy);\n    if (length == 0.0)\n      {\n        n++;\n        if (draw_info->dash_pattern[n] == 0.0)\n          n=0;\n        length=scale*(draw_info->dash_pattern[n]+(n == 0 ? -0.5 : 0.5));\n      }\n    for (total_length=0.0; (length >= 0.0) && (maximum_length >= (total_length+length)); )\n    {\n      total_length+=length;\n      if ((n & 0x01) != 0)\n        {\n          dash_polygon[0]=primitive_info[0];\n          dash_polygon[0].point.x=(double) (primitive_info[i-1].point.x+dx*\n            total_length/maximum_length);\n          dash_polygon[0].point.y=(double) (primitive_info[i-1].point.y+dy*\n            total_length/maximum_length);\n          j=1;\n        }\n      else\n        {\n          if ((j+1) > (ssize_t) (2*number_vertices))\n            break;\n          dash_polygon[j]=primitive_info[i-1];\n          dash_polygon[j].point.x=(double) (primitive_info[i-1].point.x+dx*\n            total_length/maximum_length);\n          dash_polygon[j].point.y=(double) (primitive_info[i-1].point.y+dy*\n            total_length/maximum_length);\n          dash_polygon[j].coordinates=1;\n          j++;\n          dash_polygon[0].coordinates=(size_t) j;\n          dash_polygon[j].primitive=UndefinedPrimitive;\n          status&=DrawStrokePolygon(image,clone_info,dash_polygon,exception);\n        }\n      n++;\n      if (draw_info->dash_pattern[n] == 0.0)\n        n=0;\n      length=scale*(draw_info->dash_pattern[n]+(n == 0 ? -0.5 : 0.5));\n    }\n    length-=(maximum_length-total_length);\n    if ((n & 0x01) != 0)\n      continue;\n    dash_polygon[j]=primitive_info[i];\n    dash_polygon[j].coordinates=1;\n    j++;\n  }\n  if ((total_length <= maximum_length) && ((n & 0x01) == 0) && (j > 1))\n    {\n      dash_polygon[j]=primitive_info[i-1];\n      dash_polygon[j].point.x+=MagickEpsilon;\n      dash_polygon[j].point.y+=MagickEpsilon;\n      dash_polygon[j].coordinates=1;\n      j++;\n      dash_polygon[0].coordinates=(size_t) j;\n      dash_polygon[j].primitive=UndefinedPrimitive;\n      status&=DrawStrokePolygon(image,clone_info,dash_polygon,exception);\n    }\n  dash_polygon=(PrimitiveInfo *) RelinquishMagickMemory(dash_polygon);\n  clone_info=DestroyDrawInfo(clone_info);\n  if (image->debug != MagickFalse)\n    (void) LogMagickEvent(DrawEvent,GetMagickModule(),\"    end draw-dash\");\n  return(status != 0 ? MagickTrue : MagickFalse);\n}\n",
        "commit_message": "Prevent buffer overflow in magick/draw.c",
        "cve_desc": "The DrawImage function in MagickCore/draw.c in ImageMagick before 6.9.4-0 and 7.x before 7.0.1-2 makes an incorrect function call in attempting to locate the next token, which allows remote attackers to cause a denial of service (buffer overflow and application crash) or possibly have unspecified other impact via a crafted file.",
        "target": 1
      },
      {
        "idx": 2014,
        "reasoning": "The code is vulnerable to a buffer overflow due to the `max_strokes` calculation and subsequent memory allocation/resizing for `path_p` and `path_q`. While the code attempts to resize the memory if `q` exceeds `max_strokes`, the initial `max_strokes` value and the resizing increment might not be sufficient to handle complex polygons, leading to a write beyond allocated memory boundaries when drawing strokes, as highlighted by the CVE.",
        "func": "static PrimitiveInfo *TraceStrokePolygon(const DrawInfo *draw_info,\n  const PrimitiveInfo *primitive_info)\n{\n  typedef struct _LineSegment\n  {\n    double\n      p,\n      q;\n  } LineSegment;\n\n  LineSegment\n    dx,\n    dy,\n    inverse_slope,\n    slope,\n    theta;\n\n  MagickBooleanType\n    closed_path;\n\n  double\n    delta_theta,\n    dot_product,\n    mid,\n    miterlimit;\n\n  PointInfo\n    box_p[5],\n    box_q[5],\n    center,\n    offset,\n    *path_p,\n    *path_q;\n\n  PrimitiveInfo\n    *polygon_primitive,\n    *stroke_polygon;\n\n  register ssize_t\n    i;\n\n  size_t\n    arc_segments,\n    max_strokes,\n    number_vertices;\n\n  ssize_t\n    j,\n    n,\n    p,\n    q;\n\n  /*\n    Allocate paths.\n  */\n  number_vertices=primitive_info->coordinates;\n  max_strokes=2*number_vertices+6*BezierQuantum+360;\n  path_p=(PointInfo *) AcquireQuantumMemory((size_t) max_strokes,\n    sizeof(*path_p));\n  path_q=(PointInfo *) AcquireQuantumMemory((size_t) max_strokes,\n    sizeof(*path_q));\n  polygon_primitive=(PrimitiveInfo *) AcquireQuantumMemory((size_t)\n    number_vertices+2UL,sizeof(*polygon_primitive));\n  if ((path_p == (PointInfo *) NULL) || (path_q == (PointInfo *) NULL) ||\n      (polygon_primitive == (PrimitiveInfo *) NULL))\n    return((PrimitiveInfo *) NULL);\n  (void) CopyMagickMemory(polygon_primitive,primitive_info,(size_t)\n    number_vertices*sizeof(*polygon_primitive));\n  closed_path=\n    (primitive_info[number_vertices-1].point.x == primitive_info[0].point.x) &&\n    (primitive_info[number_vertices-1].point.y == primitive_info[0].point.y) ?\n    MagickTrue : MagickFalse;\n  if ((draw_info->linejoin == RoundJoin) ||\n      ((draw_info->linejoin == MiterJoin) && (closed_path != MagickFalse)))\n    {\n      polygon_primitive[number_vertices]=primitive_info[1];\n      number_vertices++;\n    }\n  polygon_primitive[number_vertices].primitive=UndefinedPrimitive;\n  /*\n    Compute the slope for the first line segment, p.\n  */\n  dx.p=0.0;\n  dy.p=0.0;\n  for (n=1; n < (ssize_t) number_vertices; n++)\n  {\n    dx.p=polygon_primitive[n].point.x-polygon_primitive[0].point.x;\n    dy.p=polygon_primitive[n].point.y-polygon_primitive[0].point.y;\n    if ((fabs(dx.p) >= MagickEpsilon) || (fabs(dy.p) >= MagickEpsilon))\n      break;\n  }\n  if (n == (ssize_t) number_vertices)\n    n=(ssize_t) number_vertices-1L;\n  slope.p=DrawEpsilonReciprocal(dx.p)*dy.p;\n  inverse_slope.p=(-1.0*DrawEpsilonReciprocal(slope.p));\n  mid=ExpandAffine(&draw_info->affine)*draw_info->stroke_width/2.0;\n  miterlimit=(double) (draw_info->miterlimit*draw_info->miterlimit*\n    mid*mid);\n  if ((draw_info->linecap == SquareCap) && (closed_path == MagickFalse))\n    TraceSquareLinecap(polygon_primitive,number_vertices,mid);\n  offset.x=sqrt((double) (mid*mid/(inverse_slope.p*inverse_slope.p+1.0)));\n  offset.y=(double) (offset.x*inverse_slope.p);\n  if ((dy.p*offset.x-dx.p*offset.y) > 0.0)\n    {\n      box_p[0].x=polygon_primitive[0].point.x-offset.x;\n      box_p[0].y=polygon_primitive[0].point.y-offset.x*inverse_slope.p;\n      box_p[1].x=polygon_primitive[n].point.x-offset.x;\n      box_p[1].y=polygon_primitive[n].point.y-offset.x*inverse_slope.p;\n      box_q[0].x=polygon_primitive[0].point.x+offset.x;\n      box_q[0].y=polygon_primitive[0].point.y+offset.x*inverse_slope.p;\n      box_q[1].x=polygon_primitive[n].point.x+offset.x;\n      box_q[1].y=polygon_primitive[n].point.y+offset.x*inverse_slope.p;\n    }\n  else\n    {\n      box_p[0].x=polygon_primitive[0].point.x+offset.x;\n      box_p[0].y=polygon_primitive[0].point.y+offset.y;\n      box_p[1].x=polygon_primitive[n].point.x+offset.x;\n      box_p[1].y=polygon_primitive[n].point.y+offset.y;\n      box_q[0].x=polygon_primitive[0].point.x-offset.x;\n      box_q[0].y=polygon_primitive[0].point.y-offset.y;\n      box_q[1].x=polygon_primitive[n].point.x-offset.x;\n      box_q[1].y=polygon_primitive[n].point.y-offset.y;\n    }\n  /*\n    Create strokes for the line join attribute: bevel, miter, round.\n  */\n  p=0;\n  q=0;\n  path_q[p++]=box_q[0];\n  path_p[q++]=box_p[0];\n  for (i=(ssize_t) n+1; i < (ssize_t) number_vertices; i++)\n  {\n    /*\n      Compute the slope for this line segment, q.\n    */\n    dx.q=polygon_primitive[i].point.x-polygon_primitive[n].point.x;\n    dy.q=polygon_primitive[i].point.y-polygon_primitive[n].point.y;\n    dot_product=dx.q*dx.q+dy.q*dy.q;\n    if (dot_product < 0.25)\n      continue;\n    slope.q=DrawEpsilonReciprocal(dx.q)*dy.q;\n    inverse_slope.q=(-1.0*DrawEpsilonReciprocal(slope.q));\n    offset.x=sqrt((double) (mid*mid/(inverse_slope.q*inverse_slope.q+1.0)));\n    offset.y=(double) (offset.x*inverse_slope.q);\n    dot_product=dy.q*offset.x-dx.q*offset.y;\n    if (dot_product > 0.0)\n      {\n        box_p[2].x=polygon_primitive[n].point.x-offset.x;\n        box_p[2].y=polygon_primitive[n].point.y-offset.y;\n        box_p[3].x=polygon_primitive[i].point.x-offset.x;\n        box_p[3].y=polygon_primitive[i].point.y-offset.y;\n        box_q[2].x=polygon_primitive[n].point.x+offset.x;\n        box_q[2].y=polygon_primitive[n].point.y+offset.y;\n        box_q[3].x=polygon_primitive[i].point.x+offset.x;\n        box_q[3].y=polygon_primitive[i].point.y+offset.y;\n      }\n    else\n      {\n        box_p[2].x=polygon_primitive[n].point.x+offset.x;\n        box_p[2].y=polygon_primitive[n].point.y+offset.y;\n        box_p[3].x=polygon_primitive[i].point.x+offset.x;\n        box_p[3].y=polygon_primitive[i].point.y+offset.y;\n        box_q[2].x=polygon_primitive[n].point.x-offset.x;\n        box_q[2].y=polygon_primitive[n].point.y-offset.y;\n        box_q[3].x=polygon_primitive[i].point.x-offset.x;\n        box_q[3].y=polygon_primitive[i].point.y-offset.y;\n      }\n    if (fabs((double) (slope.p-slope.q)) < MagickEpsilon)\n      {\n        box_p[4]=box_p[1];\n        box_q[4]=box_q[1];\n      }\n    else\n      {\n        box_p[4].x=(double) ((slope.p*box_p[0].x-box_p[0].y-slope.q*box_p[3].x+\n          box_p[3].y)/(slope.p-slope.q));\n        box_p[4].y=(double) (slope.p*(box_p[4].x-box_p[0].x)+box_p[0].y);\n        box_q[4].x=(double) ((slope.p*box_q[0].x-box_q[0].y-slope.q*box_q[3].x+\n          box_q[3].y)/(slope.p-slope.q));\n        box_q[4].y=(double) (slope.p*(box_q[4].x-box_q[0].x)+box_q[0].y);\n       }\n     if (q >= (ssize_t) (max_strokes-6*BezierQuantum-360))\n       {\n         max_strokes+=6*BezierQuantum+360;\n         path_p=(PointInfo *) ResizeQuantumMemory(path_p,(size_t) max_strokes,\n           sizeof(*path_p));\n         path_q=(PointInfo *) ResizeQuantumMemory(path_q,(size_t) max_strokes,\n           sizeof(*path_q));\n         if ((path_p == (PointInfo *) NULL) || (path_q == (PointInfo *) NULL))\n           {\n             polygon_primitive=(PrimitiveInfo *)\n               RelinquishMagickMemory(polygon_primitive);\n             return((PrimitiveInfo *) NULL);\n           }\n       }\n     dot_product=dx.q*dy.p-dx.p*dy.q;\n     if (dot_product <= 0.0)\n      switch (draw_info->linejoin)\n      {\n        case BevelJoin:\n        {\n          path_q[q++]=box_q[1];\n          path_q[q++]=box_q[2];\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            path_p[p++]=box_p[4];\n          else\n            {\n              path_p[p++]=box_p[1];\n              path_p[p++]=box_p[2];\n            }\n          break;\n        }\n        case MiterJoin:\n        {\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            {\n              path_q[q++]=box_q[4];\n              path_p[p++]=box_p[4];\n            }\n          else\n            {\n              path_q[q++]=box_q[1];\n              path_q[q++]=box_q[2];\n              path_p[p++]=box_p[1];\n              path_p[p++]=box_p[2];\n            }\n          break;\n        }\n        case RoundJoin:\n        {\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            path_p[p++]=box_p[4];\n          else\n            {\n              path_p[p++]=box_p[1];\n              path_p[p++]=box_p[2];\n            }\n          center=polygon_primitive[n].point;\n          theta.p=atan2(box_q[1].y-center.y,box_q[1].x-center.x);\n          theta.q=atan2(box_q[2].y-center.y,box_q[2].x-center.x);\n          if (theta.q < theta.p)\n            theta.q+=(double) (2.0*MagickPI);\n          arc_segments=(size_t) ceil((double) ((theta.q-theta.p)/\n            (2.0*sqrt((double) (1.0/mid)))));\n          path_q[q].x=box_q[1].x;\n          path_q[q].y=box_q[1].y;\n          q++;\n          for (j=1; j < (ssize_t) arc_segments; j++)\n          {\n            delta_theta=(double) (j*(theta.q-theta.p)/arc_segments);\n            path_q[q].x=(double) (center.x+mid*cos(fmod((double)\n              (theta.p+delta_theta),DegreesToRadians(360.0))));\n            path_q[q].y=(double) (center.y+mid*sin(fmod((double)\n              (theta.p+delta_theta),DegreesToRadians(360.0))));\n            q++;\n          }\n          path_q[q++]=box_q[2];\n          break;\n        }\n        default:\n          break;\n      }\n    else\n      switch (draw_info->linejoin)\n      {\n        case BevelJoin:\n        {\n          path_p[p++]=box_p[1];\n          path_p[p++]=box_p[2];\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            path_q[q++]=box_q[4];\n          else\n            {\n              path_q[q++]=box_q[1];\n              path_q[q++]=box_q[2];\n            }\n          break;\n        }\n        case MiterJoin:\n        {\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            {\n              path_q[q++]=box_q[4];\n              path_p[p++]=box_p[4];\n            }\n          else\n            {\n              path_q[q++]=box_q[1];\n              path_q[q++]=box_q[2];\n              path_p[p++]=box_p[1];\n              path_p[p++]=box_p[2];\n            }\n          break;\n        }\n        case RoundJoin:\n        {\n          dot_product=(box_q[4].x-box_p[4].x)*(box_q[4].x-box_p[4].x)+\n            (box_q[4].y-box_p[4].y)*(box_q[4].y-box_p[4].y);\n          if (dot_product <= miterlimit)\n            path_q[q++]=box_q[4];\n          else\n            {\n              path_q[q++]=box_q[1];\n              path_q[q++]=box_q[2];\n            }\n          center=polygon_primitive[n].point;\n          theta.p=atan2(box_p[1].y-center.y,box_p[1].x-center.x);\n          theta.q=atan2(box_p[2].y-center.y,box_p[2].x-center.x);\n          if (theta.p < theta.q)\n            theta.p+=(double) (2.0*MagickPI);\n          arc_segments=(size_t) ceil((double) ((theta.p-theta.q)/\n            (2.0*sqrt((double) (1.0/mid)))));\n          path_p[p++]=box_p[1];\n          for (j=1; j < (ssize_t) arc_segments; j++)\n          {\n            delta_theta=(double) (j*(theta.q-theta.p)/arc_segments);\n            path_p[p].x=(double) (center.x+mid*cos(fmod((double)\n              (theta.p+delta_theta),DegreesToRadians(360.0))));\n            path_p[p].y=(double) (center.y+mid*sin(fmod((double)\n              (theta.p+delta_theta),DegreesToRadians(360.0))));\n            p++;\n          }\n          path_p[p++]=box_p[2];\n          break;\n        }\n        default:\n          break;\n      }\n    slope.p=slope.q;\n    inverse_slope.p=inverse_slope.q;\n    box_p[0]=box_p[2];\n    box_p[1]=box_p[3];\n    box_q[0]=box_q[2];\n    box_q[1]=box_q[3];\n    dx.p=dx.q;\n    dy.p=dy.q;\n    n=i;\n  }\n  path_p[p++]=box_p[1];\n  path_q[q++]=box_q[1];\n  /*\n    Trace stroked polygon.\n  */\n  stroke_polygon=(PrimitiveInfo *) AcquireQuantumMemory((size_t)\n    (p+q+2UL*closed_path+2UL),sizeof(*stroke_polygon));\n  if (stroke_polygon != (PrimitiveInfo *) NULL)\n    {\n      for (i=0; i < (ssize_t) p; i++)\n      {\n        stroke_polygon[i]=polygon_primitive[0];\n        stroke_polygon[i].point=path_p[i];\n      }\n      if (closed_path != MagickFalse)\n        {\n          stroke_polygon[i]=polygon_primitive[0];\n          stroke_polygon[i].point=stroke_polygon[0].point;\n          i++;\n        }\n      for ( ; i < (ssize_t) (p+q+closed_path); i++)\n      {\n        stroke_polygon[i]=polygon_primitive[0];\n        stroke_polygon[i].point=path_q[p+q+closed_path-(i+1)];\n      }\n      if (closed_path != MagickFalse)\n        {\n          stroke_polygon[i]=polygon_primitive[0];\n          stroke_polygon[i].point=stroke_polygon[p+closed_path].point;\n          i++;\n        }\n      stroke_polygon[i]=polygon_primitive[0];\n      stroke_polygon[i].point=stroke_polygon[0].point;\n      i++;\n      stroke_polygon[i].primitive=UndefinedPrimitive;\n      stroke_polygon[0].coordinates=(size_t) (p+q+2*closed_path+1);\n    }\n  path_p=(PointInfo *) RelinquishMagickMemory(path_p);\n  path_q=(PointInfo *) RelinquishMagickMemory(path_q);\n  polygon_primitive=(PrimitiveInfo *) RelinquishMagickMemory(polygon_primitive);\n  return(stroke_polygon);\n}\n",
        "commit_message": "Prevent buffer overflow in magick/draw.c",
        "cve_desc": "The DrawImage function in MagickCore/draw.c in ImageMagick before 6.9.4-0 and 7.x before 7.0.1-2 makes an incorrect function call in attempting to locate the next token, which allows remote attackers to cause a denial of service (buffer overflow and application crash) or possibly have unspecified other impact via a crafted file.",
        "target": 1
      }
    ]
  },
  "ImageMagick6": {
    "0": [
      {
        "idx": 71890,
        "reasoning": "This code snippet appears safe as it focuses on properly releasing memory associated with image data (`Image`, `ImageInfo`, and related chunks) during cleanup. There are no apparent operations that directly handle external input or perform potentially dangerous actions like string manipulation or memory copying from untrusted sources, thus mitigating common vulnerability classes.",
        "func": "DestroyJNG(unsigned char *chunk,Image **color_image,\n  ImageInfo **color_image_info,Image **alpha_image,ImageInfo **alpha_image_info)\n{\n  (void) RelinquishMagickMemory(chunk);\n  if (color_image_info && *color_image_info)\n  {\n    DestroyImageInfo(*color_image_info);\n    *color_image_info = (ImageInfo *)NULL;\n  }\n  if (alpha_image_info && *alpha_image_info)\n  {\n    DestroyImageInfo(*alpha_image_info);\n    *alpha_image_info = (ImageInfo *)NULL;\n  }\n  if (color_image && *color_image)\n  {\n    DestroyImage(*color_image);\n    *color_image = (Image *)NULL;\n  }\n  if (alpha_image && *alpha_image)\n  {\n    DestroyImage(*alpha_image);\n    *alpha_image = (Image *)NULL;\n  }\n}\n",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1119",
        "cve_desc": "In ImageMagick 7.0.7-29 and earlier, a missing NULL check in ReadOneJNGImage in coders/png.c allows an attacker to cause a denial of service (WriteBlob assertion failure and application exit) via a crafted file.",
        "target": 0
      },
      {
        "idx": 71893,
        "reasoning": "This code snippet is likely safe because it performs a fixed-size `memcpy` of exactly 4 bytes, determined by the `sizeof(png_byte)` which is typically 1. There's no user-controlled input determining the size of the copy, preventing potential buffer overflows or other memory corruption issues. \n\n\n\n",
        "func": "static void PNGType(png_bytep p,const png_byte *type)\n{\n  (void) memcpy(p,type,4*sizeof(png_byte));\n}\n",
        "commit_message": "https://github.com/ImageMagick/ImageMagick/issues/1119",
        "cve_desc": "In ImageMagick 7.0.7-29 and earlier, a missing NULL check in ReadOneJNGImage in coders/png.c allows an attacker to cause a denial of service (WriteBlob assertion failure and application exit) via a crafted file.",
        "target": 0
      }
    ],
    "1": []
  },
  "LibRaw": {
    "0": [
      {
        "idx": 249559,
        "reasoning": "This code snippet is not directly vulnerable to the issue described in the commit message (SECUNIA advisory 76000 - wrong fuji width set via tiff tag). The code processes Sony-specific maker notes and lens data, and doesn't appear to handle Fujifilm TIFF tags or image widths, thus it's not affected by that specific vulnerability.\n\n\n\n",
        "func": "void CLASS process_Sony_0x9050(uchar *buf, unsigned id)\n{\n  ushort lid;\n\n  if ((imgdata.lens.makernotes.CameraMount != LIBRAW_MOUNT_Sony_E) &&\n      (imgdata.lens.makernotes.CameraMount != LIBRAW_MOUNT_FixedLens))\n  {\n    if (buf[0])\n      imgdata.lens.makernotes.MaxAp4CurFocal =\n          my_roundf(powf64(2.0f, ((float)SonySubstitution[buf[0]] / 8.0 - 1.06f) / 2.0f) * 10.0f) / 10.0f;\n\n    if (buf[1])\n      imgdata.lens.makernotes.MinAp4CurFocal =\n          my_roundf(powf64(2.0f, ((float)SonySubstitution[buf[1]] / 8.0 - 1.06f) / 2.0f) * 10.0f) / 10.0f;\n  }\n\n  if (imgdata.lens.makernotes.CameraMount != LIBRAW_MOUNT_FixedLens)\n  {\n    if (buf[0x3d] | buf[0x3c])\n    {\n      lid = SonySubstitution[buf[0x3d]] << 8 | SonySubstitution[buf[0x3c]];\n      imgdata.lens.makernotes.CurAp = powf64(2.0f, ((float)lid / 256.0f - 16.0f) / 2.0f);\n    }\n    if (buf[0x105] && (imgdata.lens.makernotes.LensMount != LIBRAW_MOUNT_Canon_EF) &&\n        (imgdata.lens.makernotes.LensMount != LIBRAW_MOUNT_Sigma_X3F))\n      imgdata.lens.makernotes.LensMount = SonySubstitution[buf[0x105]];\n    if (buf[0x106])\n      imgdata.lens.makernotes.LensFormat = SonySubstitution[buf[0x106]];\n  }\n\n  if (imgdata.lens.makernotes.CameraMount == LIBRAW_MOUNT_Sony_E)\n  {\n    parseSonyLensType2(SonySubstitution[buf[0x0108]], // LensType2 - Sony lens ids\n                       SonySubstitution[buf[0x0107]]);\n  }\n  if ((imgdata.lens.makernotes.LensID == -1) && (imgdata.lens.makernotes.CameraMount == LIBRAW_MOUNT_Minolta_A) &&\n      (buf[0x010a] | buf[0x0109]))\n  {\n    imgdata.lens.makernotes.LensID = // LensType - Minolta/Sony lens ids\n        SonySubstitution[buf[0x010a]] << 8 | SonySubstitution[buf[0x0109]];\n\n    if ((imgdata.lens.makernotes.LensID > 0x4900) && (imgdata.lens.makernotes.LensID <= 0x5900))\n    {\n      imgdata.lens.makernotes.AdapterID = 0x4900;\n      imgdata.lens.makernotes.LensID -= imgdata.lens.makernotes.AdapterID;\n      imgdata.lens.makernotes.LensMount = LIBRAW_MOUNT_Sigma_X3F;\n      strcpy(imgdata.lens.makernotes.Adapter, \"MC-11\");\n    }\n\n    else if ((imgdata.lens.makernotes.LensID > 0xEF00) && (imgdata.lens.makernotes.LensID < 0xFFFF) &&\n             (imgdata.lens.makernotes.LensID != 0xFF00))\n    {\n      imgdata.lens.makernotes.AdapterID = 0xEF00;\n      imgdata.lens.makernotes.LensID -= imgdata.lens.makernotes.AdapterID;\n      imgdata.lens.makernotes.LensMount = LIBRAW_MOUNT_Canon_EF;\n    }\n  }\n\n  if ((id >= 286) && (id <= 293))\n    // \"SLT-A65\", \"SLT-A77\", \"NEX-7\", \"NEX-VG20E\",\n    // \"SLT-A37\", \"SLT-A57\", \"NEX-F3\", \"Lunar\"\n    parseSonyLensFeatures(SonySubstitution[buf[0x115]], SonySubstitution[buf[0x116]]);\n  else if (imgdata.lens.makernotes.CameraMount != LIBRAW_MOUNT_FixedLens)\n    parseSonyLensFeatures(SonySubstitution[buf[0x116]], SonySubstitution[buf[0x117]]);\n\n  if ((id == 347) || (id == 350) || (id == 357))\n  {\n    unsigned long long b88 = SonySubstitution[buf[0x88]];\n    unsigned long long b89 = SonySubstitution[buf[0x89]];\n    unsigned long long b8a = SonySubstitution[buf[0x8a]];\n    unsigned long long b8b = SonySubstitution[buf[0x8b]];\n    unsigned long long b8c = SonySubstitution[buf[0x8c]];\n    unsigned long long b8d = SonySubstitution[buf[0x8d]];\n    sprintf(imgdata.shootinginfo.InternalBodySerial, \"%06llx\",\n            (b88 << 40) + (b89 << 32) + (b8a << 24) + (b8b << 16) + (b8c << 8) + b8d);\n  }\n  else if ((imgdata.lens.makernotes.CameraMount == LIBRAW_MOUNT_Minolta_A) && (id > 279) && (id != 282) && (id != 283))\n  {\n    unsigned long long bf0 = SonySubstitution[buf[0xf0]];\n    unsigned long long bf1 = SonySubstitution[buf[0xf1]];\n    unsigned long long bf2 = SonySubstitution[buf[0xf2]];\n    unsigned long long bf3 = SonySubstitution[buf[0xf3]];\n    unsigned long long bf4 = SonySubstitution[buf[0xf4]];\n    sprintf(imgdata.shootinginfo.InternalBodySerial, \"%05llx\",\n            (bf0 << 32) + (bf1 << 24) + (bf2 << 16) + (bf3 << 8) + bf4);\n  }\n  else if ((imgdata.lens.makernotes.CameraMount == LIBRAW_MOUNT_Sony_E) && (id != 288) && (id != 289) && (id != 290))\n  {\n    unsigned b7c = SonySubstitution[buf[0x7c]];\n    unsigned b7d = SonySubstitution[buf[0x7d]];\n    unsigned b7e = SonySubstitution[buf[0x7e]];\n    unsigned b7f = SonySubstitution[buf[0x7f]];\n    sprintf(imgdata.shootinginfo.InternalBodySerial, \"%04x\", (b7c << 24) + (b7d << 16) + (b7e << 8) + b7f);\n  }\n\n  return;\n}",
        "commit_message": "SECUNIA advisory 76000 #1 (wrong fuji width set via tiff tag",
        "cve_desc": "An error related to the \"LibRaw::panasonic_load_raw()\" function (dcraw_common.cpp) in LibRaw versions prior to 0.18.6 can be exploited to cause a heap-based buffer overflow and subsequently cause a crash via a specially crafted TIFF image.",
        "target": 0
      },
      {
        "idx": 249560,
        "reasoning": "The code is flagged as potentially vulnerable due to the handling of Fujifilm TIFF tags, specifically concerning width calculation. The advisory mentions a \"wrong fuji width set via tiff tag,\" indicating a potential for incorrect image dimensions which could lead to out-of-bounds reads or writes during image processing, although the provided snippet doesn't directly demonstrate the vulnerability itself.",
        "func": "void CLASS parse_fuji(int offset)\n{\n  unsigned entries, tag, len, save, c;\n\n  fseek(ifp, offset, SEEK_SET);\n  entries = get4();\n  if (entries > 255)\n    return;\n#ifdef LIBRAW_LIBRARY_BUILD\n  imgdata.process_warnings |=  LIBRAW_WARN_PARSEFUJI_PROCESSED; \n#endif\n  while (entries--)\n  {\n    tag = get2();\n    len = get2();\n    save = ftell(ifp);\n\n    if (tag == 0x100)\n    {\n      raw_height = get2();\n      raw_width = get2();\n    }\n    else if (tag == 0x121)\n    {\n      height = get2();\n      if ((width = get2()) == 4284)\n        width += 3;\n    }\n    else if (tag == 0x130)\n    {\n      fuji_layout = fgetc(ifp) >> 7;\n      fuji_width = !(fgetc(ifp) & 8);\n    }\n    else if (tag == 0x131)\n    {\n      filters = 9;\n      FORC(36)\n        {\n\t   int q = fgetc(ifp);\n\t   xtrans_abs[0][35 - c] = MAX(0,MIN(q,2)); /* & 3;*/\n\t}\n    }\n    else if (tag == 0x2ff0)\n    {\n      FORC4 cam_mul[c ^ 1] = get2();\n\n// IB start\n#ifdef LIBRAW_LIBRARY_BUILD\n    }\n    else if (tag == 0x9650)\n    {\n      short a = (short)get2();\n      float b = fMAX(1.0f, get2());\n      imgdata.makernotes.fuji.FujiExpoMidPointShift = a / b;\n    }\n\n    else if (tag == 0x2f00)\n    {\n      int nWBs = get4();\n      nWBs = MIN(nWBs, 6);\n      for (int wb_ind = 0; wb_ind < nWBs; wb_ind++)\n      {\n        FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_Custom1 + wb_ind][c ^ 1] = get2();\n        fseek(ifp, 8, SEEK_CUR);\n      }\n    }\n\n    else if (tag == 0x2000)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_Auto][c ^ 1] = get2();\n    }\n    else if (tag == 0x2100)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_FineWeather][c ^ 1] = get2();\n    }\n    else if (tag == 0x2200)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_Shade][c ^ 1] = get2();\n    }\n    else if (tag == 0x2300)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_D][c ^ 1] = get2();\n    }\n    else if (tag == 0x2301)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_N][c ^ 1] = get2();\n    }\n    else if (tag == 0x2302)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_WW][c ^ 1] = get2();\n    }\n    else if (tag == 0x2310)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_L][c ^ 1] = get2();\n    }\n    else if (tag == 0x2400)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_Tungsten][c ^ 1] = get2();\n    }\n    else if (tag == 0x2410)\n    {\n      FORC4 imgdata.color.WB_Coeffs[LIBRAW_WBI_Flash][c ^ 1] = get2();\n#endif\n      // IB end\n    }\n    else if (tag == 0xc000)\n    /* 0xc000 tag versions, second ushort; valid if the first ushort is 0\n    X100F\t0x0259\n    X100T\t0x0153\n    X-E2\t0x014f\t0x024f depends on firmware\n    X-A1\t0x014e\n    XQ2\t\t0x0150\n    XQ1\t\t0x0150\n    X100S\t0x0149\t0x0249 depends on firmware\n    X30\t\t0x0152\n    X20\t\t0x0146\n    X-T10\t0x0154\n    X-T2\t0x0258\n    X-M1\t0x014d\n    X-E2s\t0x0355\n    X-A2\t0x014e\n    X-T20\t0x025b\n    GFX 50S\t0x025a\n    X-T1\t0x0151\t0x0251 0x0351 depends on firmware\n    X70\t\t0x0155\n    X-Pro2\t0x0255\n    */\n    {\n      c = order;\n      order = 0x4949;\n      if ((tag = get4()) > 10000)\n        tag = get4();\n      if (tag > 10000)\n        tag = get4();\n      width = tag;\n      height = get4();\n#ifdef LIBRAW_LIBRARY_BUILD\n      if (!strcmp(model, \"X-A3\") || !strcmp(model, \"X-A10\"))\n      {\n        int wb[4];\n        int nWB, tWB, pWB;\n        int iCCT = 0;\n        int cnt;\n        fseek(ifp, save + 0x200, SEEK_SET);\n        for (int wb_ind = 0; wb_ind < 42; wb_ind++)\n        {\n          nWB = get4();\n          tWB = get4();\n          wb[0] = get4() << 1;\n          wb[1] = get4();\n          wb[3] = get4();\n          wb[2] = get4() << 1;\n          if (tWB && (iCCT < 255))\n          {\n            imgdata.color.WBCT_Coeffs[iCCT][0] = tWB;\n            for (cnt = 0; cnt < 4; cnt++)\n              imgdata.color.WBCT_Coeffs[iCCT][cnt + 1] = wb[cnt];\n            iCCT++;\n          }\n          if (nWB != 70)\n          {\n            for (pWB = 1; pWB < nFuji_wb_list2; pWB += 2)\n            {\n              if (Fuji_wb_list2[pWB] == nWB)\n              {\n                for (cnt = 0; cnt < 4; cnt++)\n                  imgdata.color.WB_Coeffs[Fuji_wb_list2[pWB - 1]][cnt] = wb[cnt];\n                break;\n              }\n            }\n          }\n        }\n      }\n      else\n      {\n        libraw_internal_data.unpacker_data.posRAFData = save;\n        libraw_internal_data.unpacker_data.lenRAFData = (len >> 1);\n      }\n#endif\n      order = c;\n    }\n    fseek(ifp, save + len, SEEK_SET);\n  }\n  height <<= fuji_layout;\n  width >>= fuji_layout;\n}",
        "commit_message": "SECUNIA advisory 76000 #1 (wrong fuji width set via tiff tag",
        "cve_desc": "An error related to the \"LibRaw::panasonic_load_raw()\" function (dcraw_common.cpp) in LibRaw versions prior to 0.18.6 can be exploited to cause a heap-based buffer overflow and subsequently cause a crash via a specially crafted TIFF image.",
        "target": 0
      },
      {
        "idx": 249561,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message references a separate issue (\"wrong fuji width set via tiff tag\") that isn't present in this code, which focuses on parsing Sony lens features and doesn't handle TIFF tag widths or Fuji cameras. \n\n\n\n",
        "func": "void CLASS parseSonyLensFeatures(uchar a, uchar b)\n{\n\n  ushort features;\n  features = (((ushort)a) << 8) | ((ushort)b);\n\n  if ((imgdata.lens.makernotes.LensMount == LIBRAW_MOUNT_Canon_EF) ||\n      (imgdata.lens.makernotes.LensMount != LIBRAW_MOUNT_Sigma_X3F) || !features)\n    return;\n\n  imgdata.lens.makernotes.LensFeatures_pre[0] = 0;\n  imgdata.lens.makernotes.LensFeatures_suf[0] = 0;\n  if ((features & 0x0200) && (features & 0x0100))\n    strcpy(imgdata.lens.makernotes.LensFeatures_pre, \"E\");\n  else if (features & 0x0200)\n    strcpy(imgdata.lens.makernotes.LensFeatures_pre, \"FE\");\n  else if (features & 0x0100)\n    strcpy(imgdata.lens.makernotes.LensFeatures_pre, \"DT\");\n\n  if (!imgdata.lens.makernotes.LensFormat && !imgdata.lens.makernotes.LensMount)\n  {\n    imgdata.lens.makernotes.LensFormat = LIBRAW_FORMAT_FF;\n    imgdata.lens.makernotes.LensMount = LIBRAW_MOUNT_Minolta_A;\n\n    if ((features & 0x0200) && (features & 0x0100))\n    {\n      imgdata.lens.makernotes.LensFormat = LIBRAW_FORMAT_APSC;\n      imgdata.lens.makernotes.LensMount = LIBRAW_MOUNT_Sony_E;\n    }\n    else if (features & 0x0200)\n    {\n      imgdata.lens.makernotes.LensMount = LIBRAW_MOUNT_Sony_E;\n    }\n    else if (features & 0x0100)\n    {\n      imgdata.lens.makernotes.LensFormat = LIBRAW_FORMAT_APSC;\n    }\n  }\n\n  if (features & 0x4000)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_pre, \" PZ\");\n\n  if (features & 0x0008)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" G\");\n  else if (features & 0x0004)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" ZA\");\n\n  if ((features & 0x0020) && (features & 0x0040))\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" Macro\");\n  else if (features & 0x0020)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" STF\");\n  else if (features & 0x0040)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" Reflex\");\n  else if (features & 0x0080)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" Fisheye\");\n\n  if (features & 0x0001)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" SSM\");\n  else if (features & 0x0002)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" SAM\");\n\n  if (features & 0x8000)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" OSS\");\n\n  if (features & 0x2000)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" LE\");\n\n  if (features & 0x0800)\n    strnXcat(imgdata.lens.makernotes.LensFeatures_suf, \" II\");\n\n  if (imgdata.lens.makernotes.LensFeatures_suf[0] == ' ')\n    memmove(imgdata.lens.makernotes.LensFeatures_suf, imgdata.lens.makernotes.LensFeatures_suf + 1,\n            strbuflen(imgdata.lens.makernotes.LensFeatures_suf) - 1);\n\n  return;\n}",
        "commit_message": "SECUNIA advisory 76000 #1 (wrong fuji width set via tiff tag",
        "cve_desc": "An error related to the \"LibRaw::panasonic_load_raw()\" function (dcraw_common.cpp) in LibRaw versions prior to 0.18.6 can be exploited to cause a heap-based buffer overflow and subsequently cause a crash via a specially crafted TIFF image.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 196999,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow because the `RAW(row, col)` assignment uses `raw_width` in the loop condition, while the check `col < width` uses a potentially smaller `width` value. If `raw_width` is larger than `width`, the code will write beyond the allocated buffer, leading to a crash as described in the CVE, especially when processing specially crafted TIFF images that exploit this discrepancy.",
        "func": "void CLASS panasonic_load_raw()\n{\n  int row, col, i, j, sh = 0, pred[2], nonz[2];\n\n  pana_bits(0);\n  for (row = 0; row < height; row++)\n  {\n#ifdef LIBRAW_LIBRARY_BUILD\n    checkCancel();\n#endif\n    for (col = 0; col < raw_width; col++)\n    {\n      if ((i = col % 14) == 0)\n        pred[0] = pred[1] = nonz[0] = nonz[1] = 0;\n      if (i % 3 == 2)\n        sh = 4 >> (3 - pana_bits(2));\n      if (nonz[i & 1])\n      {\n        if ((j = pana_bits(8)))\n        {\n          if ((pred[i & 1] -= 0x80 << sh) < 0 || sh == 4)\n            pred[i & 1] &= ~((~0u) << sh);\n          pred[i & 1] += j << sh;\n        }\n      }\n      else if ((nonz[i & 1] = pana_bits(8)) || i > 11)\n        pred[i & 1] = nonz[i & 1] << 4 | pana_bits(4);\n      if ((RAW(row, col) = pred[col & 1]) > 4098 && col < width)\n        derror();\n    }\n  }\n}",
        "commit_message": "SECUNIA advisory 76000 #1 (wrong fuji width set via tiff tag",
        "cve_desc": "An error related to the \"LibRaw::panasonic_load_raw()\" function (dcraw_common.cpp) in LibRaw versions prior to 0.18.6 can be exploited to cause a heap-based buffer overflow and subsequently cause a crash via a specially crafted TIFF image.",
        "target": 1
      },
      {
        "idx": 197134,
        "reasoning": "The `parse_minolta()` function is vulnerable to an infinite loop because the `while` loop condition `(save = ftell(ifp)) < offset` doesn't account for the possibility that `fseek` within the loop might fail to advance the file pointer, leading to `ftell(ifp)` repeatedly returning the same value. If `fseek` fails (e.g., due to reaching the end of the file or an invalid offset), the loop condition will always be true, resulting in an infinite loop as it continuously attempts to read and seek within the file.",
        "func": "void CLASS parse_minolta(int base)\n{\n  int save, tag, len, offset, high = 0, wide = 0, i, c;\n  short sorder = order;\n\n  fseek(ifp, base, SEEK_SET);\n  if (fgetc(ifp) || fgetc(ifp) - 'M' || fgetc(ifp) - 'R')\n    return;\n  order = fgetc(ifp) * 0x101;\n  offset = base + get4() + 8;\n  while ((save = ftell(ifp)) < offset)\n  {\n    for (tag = i = 0; i < 4; i++)\n      tag = tag << 8 | fgetc(ifp);\n    len = get4();\n    switch (tag)\n    {\n    case 0x505244: /* PRD */\n      fseek(ifp, 8, SEEK_CUR);\n      high = get2();\n      wide = get2();\n#ifdef LIBRAW_LIBRARY_BUILD\n      imgdata.makernotes.sony.prd_ImageHeight = get2();\n      imgdata.makernotes.sony.prd_ImageWidth = get2();\n      fseek(ifp, 1L, SEEK_CUR);\n      imgdata.makernotes.sony.prd_RawBitDepth = (ushort)fgetc(ifp);\n      imgdata.makernotes.sony.prd_StorageMethod = (ushort)fgetc(ifp);\n      fseek(ifp, 4L, SEEK_CUR);\n      imgdata.makernotes.sony.prd_BayerPattern = (ushort)fgetc(ifp);\n#endif\n      break;\n#ifdef LIBRAW_LIBRARY_BUILD\n    case 0x524946: /* RIF */\n      if (!strncasecmp(model, \"DSLR-A100\", 9))\n      {\n        fseek(ifp, 8, SEEK_CUR);\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Tungsten][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Tungsten][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Daylight][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Daylight][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Cloudy][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Cloudy][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_W][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_W][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Flash][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Flash][2] = get2();\n        get4();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Shade][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Shade][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_D][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_D][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_N][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_N][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_WW][0] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_WW][2] = get2();\n        imgdata.color.WB_Coeffs[LIBRAW_WBI_Daylight][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_Daylight][3] =\n            imgdata.color.WB_Coeffs[LIBRAW_WBI_Tungsten][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_Tungsten][3] =\n                imgdata.color.WB_Coeffs[LIBRAW_WBI_Flash][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_Flash][3] =\n                    imgdata.color.WB_Coeffs[LIBRAW_WBI_Cloudy][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_Cloudy][3] =\n                        imgdata.color.WB_Coeffs[LIBRAW_WBI_Shade][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_Shade][3] =\n                            imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_D][1] = imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_D][3] =\n                                imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_N][1] =\n                                    imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_N][3] =\n                                        imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_W][1] =\n                                            imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_W][3] =\n                                                imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_WW][1] =\n                                                    imgdata.color.WB_Coeffs[LIBRAW_WBI_FL_WW][3] = 0x100;\n      }\n      break;\n#endif\n    case 0x574247: /* WBG */\n      get4();\n      i = strcmp(model, \"DiMAGE A200\") ? 0 : 3;\n      FORC4 cam_mul[c ^ (c >> 1) ^ i] = get2();\n      break;\n    case 0x545457: /* TTW */\n      parse_tiff(ftell(ifp));\n      data_offset = offset;\n    }\n    fseek(ifp, save + len + 8, SEEK_SET);\n  }\n  raw_height = high;\n  raw_width = wide;\n  order = sorder;\n}",
        "commit_message": "Secunia Advisory SA83050: possible infinite loop in parse_minolta()",
        "cve_desc": "An error within the \"parse_minolta()\" function (dcraw/dcraw.c) in LibRaw versions prior to 0.18.11 can be exploited to trigger an infinite loop via a specially crafted file.",
        "target": 1
      },
      {
        "idx": 198408,
        "reasoning": "The `parse_qt` function is vulnerable to an integer overflow because the `save + size` calculation, used in `fseek`, can exceed the maximum value of an `off_t` if `size` is sufficiently large. This overflow leads to a small, positive seek offset instead of the intended large offset, causing the `while` loop to continue indefinitely as `ftell(ifp)+7 < end` remains true, resulting in an infinite loop as described in the CVE.",
        "func": "void CLASS parse_qt (int end)\n{\n  unsigned save, size;\n  char tag[4];\n\n  order = 0x4d4d;\n  while (ftell(ifp)+7 < end) {\n    save = ftell(ifp);\n    if ((size = get4()) < 8) return;\n    fread (tag, 4, 1, ifp);\n    if (!memcmp(tag,\"moov\",4) ||\n\t!memcmp(tag,\"udta\",4) ||\n\t!memcmp(tag,\"CNTH\",4))\n      parse_qt (save+size);\n    if (!memcmp(tag,\"CNDA\",4))\n      parse_jpeg (ftell(ifp));\n    fseek (ifp, save+size, SEEK_SET);\n  }\n}",
        "commit_message": "parse_qt: possible integer overflow",
        "cve_desc": "An integer overflow error within the \"parse_qt()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.12 can be exploited to trigger an infinite loop via a specially crafted Apple QuickTime file.",
        "target": 1
      },
      {
        "idx": 198530,
        "reasoning": "The `xtrans_interpolate` function in LibRaw is vulnerable to an invalid read memory access due to uninitialized memory in the `allhex` array, potentially leading to a denial of service. Specifically, the `allhex` array, used for mapping green hexagons, is declared but not initialized, meaning it contains garbage data that can cause out-of-bounds reads when accessed later in the function.",
        "func": "void CLASS xtrans_interpolate(int passes)\n{\n  int c, d, f, g, h, i, v, ng, row, col, top, left, mrow, mcol;\n\n#ifdef LIBRAW_LIBRARY_BUILD\n  int cstat[4]={0,0,0,0};\n#endif\n\n  int val, ndir, pass, hm[8], avg[4], color[3][8];\n  static const short orth[12] = {1, 0, 0, 1, -1, 0, 0, -1, 1, 0, 0, 1},\n                     patt[2][16] = {{0, 1, 0, -1, 2, 0, -1, 0, 1, 1, 1, -1, 0, 0, 0, 0},\n                                    {0, 1, 0, -2, 1, 0, -2, 0, 1, 1, -2, -2, 1, -1, -1, 1}},\n                     dir[4] = {1, TS, TS + 1, TS - 1};\n  short allhex[3][3][2][8], *hex;\n  ushort min, max, sgrow, sgcol;\n  ushort(*rgb)[TS][TS][3], (*rix)[3], (*pix)[4];\n  short(*lab)[TS][3], (*lix)[3];\n  float(*drv)[TS][TS], diff[6], tr;\n  char(*homo)[TS][TS], *buffer;\n\n#ifdef DCRAW_VERBOSE\n  if (verbose)\n    fprintf(stderr, _(\"%d-pass X-Trans interpolation...\\n\"), passes);\n#endif\n\n#ifdef LIBRAW_LIBRARY_BUILD\n/* Check against right pattern */\n  for (row = 0; row < 6; row++)\n\t  for (col = 0; col < 6; col++)\n\t\t  cstat[fcol(row,col)]++;\n\n  if(cstat[0] < 6 || cstat[0]>10 || cstat[1]< 16\n    || cstat[1]>24 || cstat[2]< 6 || cstat[2]>10 || cstat[3])\n\t  throw LIBRAW_EXCEPTION_IO_CORRUPT;\n#endif\n  cielab(0, 0);\n  ndir = 4 << (passes > 1);\n  buffer = (char *)malloc(TS * TS * (ndir * 11 + 6));\n  merror(buffer, \"xtrans_interpolate()\");\n  rgb = (ushort(*)[TS][TS][3])buffer;\n  lab = (short(*)[TS][3])(buffer + TS * TS * (ndir * 6));\n  drv = (float(*)[TS][TS])(buffer + TS * TS * (ndir * 6 + 6));\n  homo = (char(*)[TS][TS])(buffer + TS * TS * (ndir * 10 + 6));\n\n  /* Map a green hexagon around each non-green pixel and vice versa:\t*/\n  for (row = 0; row < 3; row++)\n    for (col = 0; col < 3; col++)\n      for (ng = d = 0; d < 10; d += 2)\n      {\n        g = fcol(row, col) == 1;\n        if (fcol(row + orth[d], col + orth[d + 2]) == 1)\n          ng = 0;\n        else\n          ng++;\n        if (ng == 4)\n        {\n          sgrow = row;\n          sgcol = col;\n        }\n        if (ng == g + 1)\n          FORC(8)\n          {\n            v = orth[d] * patt[g][c * 2] + orth[d + 1] * patt[g][c * 2 + 1];\n            h = orth[d + 2] * patt[g][c * 2] + orth[d + 3] * patt[g][c * 2 + 1];\n            allhex[row][col][0][c ^ (g * 2 & d)] = h + v * width;\n            allhex[row][col][1][c ^ (g * 2 & d)] = h + v * TS;\n          }\n      }\n\n  /* Set green1 and green3 to the minimum and maximum allowed values:\t*/\n  for (row = 2; row < height - 2; row++)\n    for (min = ~(max = 0), col = 2; col < width - 2; col++)\n    {\n      if (fcol(row, col) == 1 && (min = ~(max = 0)))\n        continue;\n      pix = image + row * width + col;\n      hex = allhex[row % 3][col % 3][0];\n      if (!max)\n        FORC(6)\n        {\n          val = pix[hex[c]][1];\n          if (min > val)\n            min = val;\n          if (max < val)\n            max = val;\n        }\n      pix[0][1] = min;\n      pix[0][3] = max;\n      switch ((row - sgrow) % 3)\n      {\n      case 1:\n        if (row < height - 3)\n        {\n          row++;\n          col--;\n        }\n        break;\n      case 2:\n        if ((min = ~(max = 0)) && (col += 2) < width - 3 && row > 2)\n          row--;\n      }\n    }\n\n  for (top = 3; top < height - 19; top += TS - 16)\n    for (left = 3; left < width - 19; left += TS - 16)\n    {\n      mrow = MIN(top + TS, height - 3);\n      mcol = MIN(left + TS, width - 3);\n      for (row = top; row < mrow; row++)\n        for (col = left; col < mcol; col++)\n          memcpy(rgb[0][row - top][col - left], image[row * width + col], 6);\n      FORC3 memcpy(rgb[c + 1], rgb[0], sizeof *rgb);\n\n      /* Interpolate green horizontally, vertically, and along both diagonals: */\n      for (row = top; row < mrow; row++)\n        for (col = left; col < mcol; col++)\n        {\n          if ((f = fcol(row, col)) == 1)\n            continue;\n          pix = image + row * width + col;\n          hex = allhex[row % 3][col % 3][0];\n          color[1][0] = 174 * (pix[hex[1]][1] + pix[hex[0]][1]) - 46 * (pix[2 * hex[1]][1] + pix[2 * hex[0]][1]);\n          color[1][1] = 223 * pix[hex[3]][1] + pix[hex[2]][1] * 33 + 92 * (pix[0][f] - pix[-hex[2]][f]);\n          FORC(2)\n          color[1][2 + c] = 164 * pix[hex[4 + c]][1] + 92 * pix[-2 * hex[4 + c]][1] +\n                            33 * (2 * pix[0][f] - pix[3 * hex[4 + c]][f] - pix[-3 * hex[4 + c]][f]);\n          FORC4 rgb[c ^ !((row - sgrow) % 3)][row - top][col - left][1] = LIM(color[1][c] >> 8, pix[0][1], pix[0][3]);\n        }\n\n      for (pass = 0; pass < passes; pass++)\n      {\n        if (pass == 1)\n          memcpy(rgb += 4, buffer, 4 * sizeof *rgb);\n\n        /* Recalculate green from interpolated values of closer pixels:\t*/\n        if (pass)\n        {\n          for (row = top + 2; row < mrow - 2; row++)\n            for (col = left + 2; col < mcol - 2; col++)\n            {\n              if ((f = fcol(row, col)) == 1)\n                continue;\n              pix = image + row * width + col;\n              hex = allhex[row % 3][col % 3][1];\n              for (d = 3; d < 6; d++)\n              {\n                rix = &rgb[(d - 2) ^ !((row - sgrow) % 3)][row - top][col - left];\n                val =\n                    rix[-2 * hex[d]][1] + 2 * rix[hex[d]][1] - rix[-2 * hex[d]][f] - 2 * rix[hex[d]][f] + 3 * rix[0][f];\n                rix[0][1] = LIM(val / 3, pix[0][1], pix[0][3]);\n              }\n            }\n        }\n\n        /* Interpolate red and blue values for solitary green pixels:\t*/\n        for (row = (top - sgrow + 4) / 3 * 3 + sgrow; row < mrow - 2; row += 3)\n          for (col = (left - sgcol + 4) / 3 * 3 + sgcol; col < mcol - 2; col += 3)\n          {\n            rix = &rgb[0][row - top][col - left];\n            h = fcol(row, col + 1);\n            memset(diff, 0, sizeof diff);\n            for (i = 1, d = 0; d < 6; d++, i ^= TS ^ 1, h ^= 2)\n            {\n              for (c = 0; c < 2; c++, h ^= 2)\n              {\n                g = 2 * rix[0][1] - rix[i << c][1] - rix[-i << c][1];\n                color[h][d] = g + rix[i << c][h] + rix[-i << c][h];\n                if (d > 1)\n                  diff[d] += SQR(rix[i << c][1] - rix[-i << c][1] - rix[i << c][h] + rix[-i << c][h]) + SQR(g);\n              }\n              if (d > 1 && (d & 1))\n                if (diff[d - 1] < diff[d])\n                  FORC(2) color[c * 2][d] = color[c * 2][d - 1];\n              if (d < 2 || (d & 1))\n              {\n                FORC(2) rix[0][c * 2] = CLIP(color[c * 2][d] / 2);\n                rix += TS * TS;\n              }\n            }\n          }\n\n        /* Interpolate red for blue pixels and vice versa:\t\t*/\n        for (row = top + 3; row < mrow - 3; row++)\n          for (col = left + 3; col < mcol - 3; col++)\n          {\n            if ((f = 2 - fcol(row, col)) == 1)\n              continue;\n            rix = &rgb[0][row - top][col - left];\n            c = (row - sgrow) % 3 ? TS : 1;\n            h = 3 * (c ^ TS ^ 1);\n            for (d = 0; d < 4; d++, rix += TS * TS)\n            {\n              i = d > 1 || ((d ^ c) & 1) ||\n                          ((ABS(rix[0][1] - rix[c][1]) + ABS(rix[0][1] - rix[-c][1])) <\n                           2 * (ABS(rix[0][1] - rix[h][1]) + ABS(rix[0][1] - rix[-h][1])))\n                      ? c\n                      : h;\n              rix[0][f] = CLIP((rix[i][f] + rix[-i][f] + 2 * rix[0][1] - rix[i][1] - rix[-i][1]) / 2);\n            }\n          }\n\n        /* Fill in red and blue for 2x2 blocks of green:\t\t*/\n        for (row = top + 2; row < mrow - 2; row++)\n          if ((row - sgrow) % 3)\n            for (col = left + 2; col < mcol - 2; col++)\n              if ((col - sgcol) % 3)\n              {\n                rix = &rgb[0][row - top][col - left];\n                hex = allhex[row % 3][col % 3][1];\n                for (d = 0; d < ndir; d += 2, rix += TS * TS)\n                  if (hex[d] + hex[d + 1])\n                  {\n                    g = 3 * rix[0][1] - 2 * rix[hex[d]][1] - rix[hex[d + 1]][1];\n                    for (c = 0; c < 4; c += 2)\n                      rix[0][c] = CLIP((g + 2 * rix[hex[d]][c] + rix[hex[d + 1]][c]) / 3);\n                  }\n                  else\n                  {\n                    g = 2 * rix[0][1] - rix[hex[d]][1] - rix[hex[d + 1]][1];\n                    for (c = 0; c < 4; c += 2)\n                      rix[0][c] = CLIP((g + rix[hex[d]][c] + rix[hex[d + 1]][c]) / 2);\n                  }\n              }\n      }\n      rgb = (ushort(*)[TS][TS][3])buffer;\n      mrow -= top;\n      mcol -= left;\n\n      /* Convert to CIELab and differentiate in all directions:\t*/\n      for (d = 0; d < ndir; d++)\n      {\n        for (row = 2; row < mrow - 2; row++)\n          for (col = 2; col < mcol - 2; col++)\n            cielab(rgb[d][row][col], lab[row][col]);\n        for (f = dir[d & 3], row = 3; row < mrow - 3; row++)\n          for (col = 3; col < mcol - 3; col++)\n          {\n            lix = &lab[row][col];\n            g = 2 * lix[0][0] - lix[f][0] - lix[-f][0];\n            drv[d][row][col] = SQR(g) + SQR((2 * lix[0][1] - lix[f][1] - lix[-f][1] + g * 500 / 232)) +\n                               SQR((2 * lix[0][2] - lix[f][2] - lix[-f][2] - g * 500 / 580));\n          }\n      }\n\n      /* Build homogeneity maps from the derivatives:\t\t\t*/\n      memset(homo, 0, ndir * TS * TS);\n      for (row = 4; row < mrow - 4; row++)\n        for (col = 4; col < mcol - 4; col++)\n        {\n          for (tr = FLT_MAX, d = 0; d < ndir; d++)\n            if (tr > drv[d][row][col])\n              tr = drv[d][row][col];\n          tr *= 8;\n          for (d = 0; d < ndir; d++)\n            for (v = -1; v <= 1; v++)\n              for (h = -1; h <= 1; h++)\n                if (drv[d][row + v][col + h] <= tr)\n                  homo[d][row][col]++;\n        }\n\n      /* Average the most homogenous pixels for the final result:\t*/\n      if (height - top < TS + 4)\n        mrow = height - top + 2;\n      if (width - left < TS + 4)\n        mcol = width - left + 2;\n      for (row = MIN(top, 8); row < mrow - 8; row++)\n        for (col = MIN(left, 8); col < mcol - 8; col++)\n        {\n          for (d = 0; d < ndir; d++)\n            for (hm[d] = 0, v = -2; v <= 2; v++)\n              for (h = -2; h <= 2; h++)\n                hm[d] += homo[d][row + v][col + h];\n          for (d = 0; d < ndir - 4; d++)\n            if (hm[d] < hm[d + 4])\n              hm[d] = 0;\n            else if (hm[d] > hm[d + 4])\n              hm[d + 4] = 0;\n          for (max = hm[0], d = 1; d < ndir; d++)\n            if (max < hm[d])\n              max = hm[d];\n          max -= max >> 3;\n          memset(avg, 0, sizeof avg);\n          for (d = 0; d < ndir; d++)\n            if (hm[d] >= max)\n            {\n              FORC3 avg[c] += rgb[d][row][col][c];\n              avg[3]++;\n            }\n          FORC3 image[(row + top) * width + col + left][c] = avg[c] / avg[3];\n        }\n    }\n  free(buffer);\n  border_interpolate(8);\n}",
        "commit_message": "Secunia 76000 #2: xtrans allhex not initialized",
        "cve_desc": "An error within the \"LibRaw::xtrans_interpolate()\" function (internal/dcraw_common.cpp) in LibRaw versions prior to 0.18.6 can be exploited to cause an invalid read memory access and subsequently a Denial of Service condition.",
        "target": 1
      },
      {
        "idx": 199956,
        "reasoning": "This code is vulnerable to an out-of-bounds read because the `c[color]` value, calculated using `get_huffman_diff()`, can become negative and, when used as an index into `HUF->x3rgb16.data` or `HUF->rgb8.data`, lead to accessing memory before the start of the buffer. The CVE description specifically points to `get_huffman_diff()` as the source of the issue, confirming this potential for reading outside allocated memory regions.",
        "func": "static void huffman_decode_row(x3f_info_t *I, x3f_directory_entry_t *DE,\n                               int bits, int row, int offset, int *minimum)\n{\n  x3f_directory_entry_header_t *DEH = &DE->header;\n  x3f_image_data_t *ID = &DEH->data_subsection.image_data;\n  x3f_huffman_t *HUF = ID->huffman;\n\n  int16_t c[3] = {(int16_t)offset, (int16_t)offset, (int16_t)offset};\n  int col;\n  bit_state_t BS;\n\n  set_bit_state(&BS, (uint8_t *)ID->data + HUF->row_offsets.element[row]);\n\n  for (col = 0; col < ID->columns; col++)\n  {\n    int color;\n\n    for (color = 0; color < 3; color++)\n    {\n      uint16_t c_fix;\n\n      c[color] += get_huffman_diff(&BS, &HUF->tree);\n      if (c[color] < 0)\n      {\n        c_fix = 0;\n        if (c[color] < *minimum)\n          *minimum = c[color];\n      }\n      else\n      {\n        c_fix = c[color];\n      }\n\n      switch (ID->type_format)\n      {\n      case X3F_IMAGE_RAW_HUFFMAN_X530:\n      case X3F_IMAGE_RAW_HUFFMAN_10BIT:\n        HUF->x3rgb16.data[3 * (row * ID->columns + col) + color] =\n            (uint16_t)c_fix;\n        break;\n      case X3F_IMAGE_THUMB_HUFFMAN:\n        HUF->rgb8.data[3 * (row * ID->columns + col) + color] = (uint8_t)c_fix;\n        break;\n      default:\n        /* TODO: Shouldn't this be treated as a fatal error? */\n        throw LIBRAW_EXCEPTION_IO_CORRUPT;\n      }\n    }\n  }\n}",
        "commit_message": "X3F: check for data offset limit",
        "cve_desc": "In LibRaw, an out-of-bounds read vulnerability exists within the get_huffman_diff() function (libraw\\src\\x3f\\x3f_utils_patched.cpp) when reading data from an image file.",
        "target": 1
      }
    ]
  },
  "LuaJIT": {
    "0": [],
    "1": [
      {
        "idx": 210396,
        "reasoning": "This code is vulnerable because `lj_snap_restore` could potentially restore a program counter (`pc`) to an invalid or out-of-bounds address within the LuaJIT virtual machine, as indicated by the related CVE describing an out-of-bounds read in `lj_err_run`.  Since the restored `pc` directly controls execution flow, a maliciously crafted snapshot could lead to arbitrary code execution via the out-of-bounds read.\n\n\n\n",
        "func": "static TValue *trace_exit_cp(lua_State *L, lua_CFunction dummy, void *ud)\n{\n  ExitDataCP *exd = (ExitDataCP *)ud;\n  cframe_errfunc(L->cframe) = -1;  /* Inherit error function. */\n  exd->pc = lj_snap_restore(exd->J, exd->exptr);\n  UNUSED(dummy);\n  return NULL;\n}",
        "commit_message": "Fix handling of errors during snapshot restore.",
        "cve_desc": "LuaJIT through 2.1.0-beta3 has an out-of-bounds read in lj_err_run in lj_err.c.",
        "target": 1
      }
    ]
  },
  "OpenDoas": {
    "0": [],
    "1": []
  },
  "OpenSC": {
    "0": [
      {
        "idx": 72171,
        "reasoning": "This code appears safe as the commit message explicitly states it *fixes* out-of-bounds reads, suggesting a previous vulnerability was addressed. The code allocates sufficient memory using `malloc(object_length + add_v1_record)` and uses `memcpy` with appropriate offsets (`&new_object.data[add_v1_record]`) to copy data within the allocated bounds, mitigating potential buffer overflows.\n\n\n\n",
        "func": "coolkey_add_object(coolkey_private_data_t *priv, unsigned long object_id, const u8 *object_data, size_t object_length, int add_v1_record)\n{\n\tsc_cardctl_coolkey_object_t new_object;\n\tint r;\n\n\tmemset(&new_object, 0, sizeof(new_object));\n\tnew_object.path = coolkey_template_path;\n\tnew_object.path.len = 4;\n\tulong2bebytes(new_object.path.value, object_id);\n\tnew_object.id = object_id;\n\tnew_object.length = object_length;\n\n\tif (object_data) {\n\t\tnew_object.data = malloc(object_length + add_v1_record);\n\t\tif (new_object.data == NULL) {\n\t\t\treturn SC_ERROR_OUT_OF_MEMORY;\n\t\t}\n\t\tif (add_v1_record) {\n\t\t\tnew_object.data[0] = COOLKEY_V1_OBJECT;\n\t\t\tnew_object.length++;\n\t\t}\n\t\tmemcpy(&new_object.data[add_v1_record], object_data, object_length);\n\t}\n\n\tr = coolkey_add_object_to_list(&priv->objects_list, &new_object);\n\tif (r != SC_SUCCESS) {\n\t\t/* if we didn't successfully put the object on the list,\n\t\t * the data space didn't get adopted. free it before we return */\n\t\tfree(new_object.data);\n\t\tnew_object.data = NULL;\n\t}\n\treturn r;\n}\n",
        "commit_message": "fixed out of bounds reads\n\nThanks to Eric Sesterhenn from X41 D-SEC GmbH\nfor reporting and suggesting security fixes.",
        "cve_desc": "Various out of bounds reads when handling responses in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to potentially crash the opensc library using programs.",
        "target": 0
      },
      {
        "idx": 72382,
        "reasoning": "The commit message explicitly states the fix addressed \"out of bounds reads,\" indicating a previous vulnerability existed and was resolved. While the code snippet itself doesn't immediately reveal a new vulnerability, the prior issue suggests careful review was needed, and the fix implemented likely prevents access beyond the allocated buffer sizes when processing FCI data. \n\n\n\n",
        "func": "iasecc_process_fci(struct sc_card *card, struct sc_file *file,\n\t\t const unsigned char *buf, size_t buflen)\n{\n\tstruct sc_context *ctx = card->ctx;\n\tsize_t taglen;\n\tint rv, ii, offs;\n\tconst unsigned char *acls = NULL, *tag = NULL;\n\tunsigned char mask;\n\tunsigned char ops_DF[7] = {\n\t\tSC_AC_OP_DELETE, 0xFF, SC_AC_OP_ACTIVATE, SC_AC_OP_DEACTIVATE, 0xFF, SC_AC_OP_CREATE, 0xFF\n\t};\n\tunsigned char ops_EF[7] = {\n\t\tSC_AC_OP_DELETE, 0xFF, SC_AC_OP_ACTIVATE, SC_AC_OP_DEACTIVATE, 0xFF, SC_AC_OP_UPDATE, SC_AC_OP_READ\n\t};\n\n\tLOG_FUNC_CALLED(ctx);\n\n\ttag = sc_asn1_find_tag(ctx,  buf, buflen, 0x6F, &taglen);\n\tsc_log(ctx, \"processing FCI: 0x6F tag %p\", tag);\n\tif (tag != NULL) {\n\t\tsc_log(ctx, \"  FCP length %\"SC_FORMAT_LEN_SIZE_T\"u\", taglen);\n\t\tbuf = tag;\n\t\tbuflen = taglen;\n\t}\n\n\ttag = sc_asn1_find_tag(ctx,  buf, buflen, 0x62, &taglen);\n\tsc_log(ctx, \"processing FCI: 0x62 tag %p\", tag);\n\tif (tag != NULL) {\n\t\tsc_log(ctx, \"  FCP length %\"SC_FORMAT_LEN_SIZE_T\"u\", taglen);\n\t\tbuf = tag;\n\t\tbuflen = taglen;\n\t}\n\n\trv = iso_ops->process_fci(card, file, buf, buflen);\n\tLOG_TEST_RET(ctx, rv, \"ISO parse FCI failed\");\n/*\n\tGemalto:  6F 19 80 02 02 ED 82 01 01 83 02 B0 01 88 00\t8C 07 7B 17 17 17 17 17 00 8A 01 05 90 00\n\tSagem:    6F 17 62 15 80 02 00 7D 82 01 01                   8C 02 01 00 83 02 2F 00 88 01 F0 8A 01 05 90 00\n\tOberthur: 62 1B 80 02 05 DC 82 01 01 83 02 B0 01 88 00 A1 09 8C 07 7B 17 FF 17 17 17 00 8A 01 05 90 00\n*/\n\n\tsc_log(ctx, \"iasecc_process_fci() type %i; let's parse file ACLs\", file->type);\n\ttag = sc_asn1_find_tag(ctx, buf, buflen, IASECC_DOCP_TAG_ACLS, &taglen);\n\tif (tag)\n\t\tacls = sc_asn1_find_tag(ctx, tag, taglen, IASECC_DOCP_TAG_ACLS_CONTACT, &taglen);\n\telse\n\t\tacls = sc_asn1_find_tag(ctx, buf, buflen, IASECC_DOCP_TAG_ACLS_CONTACT, &taglen);\n\n\tif (!acls)   {\n\t\tsc_log(ctx,\n\t\t       \"ACLs not found in data(%\"SC_FORMAT_LEN_SIZE_T\"u) %s\",\n\t\t       buflen, sc_dump_hex(buf, buflen));\n\t\tLOG_TEST_RET(ctx, SC_ERROR_OBJECT_NOT_FOUND, \"ACLs tag missing\");\n\t}\n\n\tsc_log(ctx, \"ACLs(%\"SC_FORMAT_LEN_SIZE_T\"u) '%s'\", taglen,\n\t       sc_dump_hex(acls, taglen));\n\tmask = 0x40, offs = 1;\n\tfor (ii = 0; ii < 7; ii++, mask /= 2)  {\n\t\tunsigned char op = file->type == SC_FILE_TYPE_DF ? ops_DF[ii] : ops_EF[ii];\n\n\t\tif (!(mask & acls[0]))\n\t\t\tcontinue;\n\n\t\tsc_log(ctx, \"ACLs mask 0x%X, offs %i, op 0x%X, acls[offs] 0x%X\", mask, offs, op, acls[offs]);\n\t\tif (op == 0xFF)   {\n\t\t\t;\n\t\t}\n\t\telse if (acls[offs] == 0)   {\n\t\t\tsc_file_add_acl_entry(file, op, SC_AC_NONE, 0);\n\t\t}\n\t\telse if (acls[offs] == 0xFF)   {\n\t\t\tsc_file_add_acl_entry(file, op, SC_AC_NEVER, 0);\n\t\t}\n\t\telse if ((acls[offs] & IASECC_SCB_METHOD_MASK) == IASECC_SCB_METHOD_USER_AUTH)   {\n\t\t\tsc_file_add_acl_entry(file, op, SC_AC_SEN, acls[offs] & IASECC_SCB_METHOD_MASK_REF);\n\t\t}\n\t\telse if (acls[offs] & IASECC_SCB_METHOD_MASK)   {\n\t\t\tsc_file_add_acl_entry(file, op, SC_AC_SCB, acls[offs]);\n\t\t}\n\t\telse   {\n\t\t\tsc_log(ctx, \"Warning: non supported SCB method: %X\", acls[offs]);\n\t\t\tsc_file_add_acl_entry(file, op, SC_AC_NEVER, 0);\n\t\t}\n\n\t\toffs++;\n\t}\n\n\tLOG_FUNC_RETURN(ctx, 0);\n}\n",
        "commit_message": "fixed out of bounds reads\n\nThanks to Eric Sesterhenn from X41 D-SEC GmbH\nfor reporting and suggesting security fixes.",
        "cve_desc": "Various out of bounds reads when handling responses in OpenSC before 0.19.0-rc1 could be used by attackers able to supply crafted smartcards to potentially crash the opensc library using programs.",
        "target": 0
      }
    ],
    "1": []
  },
  "Pillow": {
    "0": [],
    "1": []
  },
  "SoftHSMv2": {
    "0": [],
    "1": []
  },
  "abcm2ps": {
    "0": [
      {
        "idx": 398958,
        "reasoning": "This code is likely safe; the commit message indicates a fix for a crash related to handling a large number of accidentals, not a security vulnerability. The function `acc_same_pitch` appears to iterate through previous symbols to find a matching pitch and accidental, and while complex, doesn't exhibit any obvious issues like buffer overflows or injection flaws based on the snippet provided.\n\n\n\n",
        "func": "static int acc_same_pitch(int pitch)\n{\n\tstruct SYMBOL *s = curvoice->last_sym->prev;\n\tint i, time;\n\n\t// the overlaid voices may have no measure bars\n//\tif (curvoice->id[0] == '&')\n//\t\ts = voice_tb[curvoice->mvoice].last_sym;\n\n\tif (!s)\n\t\treturn -1;\n\n\ttime = s->time;\n\n\tfor (; s; s = s->prev) {\n\t\tswitch (s->abc_type) {\n\t\tcase ABC_T_BAR:\n\t\t\tif (s->time < time)\n\t\t\t\treturn -1;\t/* no same pitch */\n\t\t\tfor (;;) {\n\t\t\t\ts = s->prev;\n\t\t\t\tif (!s)\n\t\t\t\t\treturn -1;\n\t\t\t\tif (s->abc_type == ABC_T_NOTE) {\n\t\t\t\t\tif (s->time + s->dur == time)\n\t\t\t\t\t\tbreak;\n\t\t\t\t\treturn -1;\n\t\t\t\t}\n\t\t\t\tif (s->time < time)\n\t\t\t\t\treturn -1;\n\t\t\t}\n\t\t\tfor (i = 0; i <= s->nhd; i++) {\n\t\t\t\tif (s->u.note.notes[i].pit == pitch\n\t\t\t\t && s->u.note.notes[i].ti1)\n\t\t\t\t\treturn s->u.note.notes[i].acc;\n\t\t\t}\n\t\t\treturn -1;\n\t\tcase ABC_T_NOTE:\n\t\t\tfor (i = 0; i <= s->nhd; i++) {\n\t\t\t\tif (s->u.note.notes[i].pit == pitch)\n\t\t\t\t\treturn s->u.note.notes[i].acc;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn -1;\n}",
        "commit_message": "fix: crash when too many accidentals in K: (signature + explicit)\n\nIssue #17.",
        "cve_desc": "Stack-based buffer overflow in the get_key function in parse.c in abcm2ps through 8.13.20 allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 207559,
        "reasoning": "This code is vulnerable to a stack-based buffer overflow because the `nacc` variable, which tracks the number of accidentals, can exceed the declared size of the `accs` and `pits` arrays (both size 8). The comment `/* cannot overflow */` is demonstrably false, as `nacc` is incremented within a loop without checking against the array bounds, leading to writes beyond the allocated memory and potentially causing a crash or allowing for arbitrary code execution as described in the CVE.",
        "func": "static void set_k_acc(struct SYMBOL *s)\n{\n\tint i, j, nacc;\n\tchar accs[8], pits[8];\n\tstatic char sharp_tb[8] = {26, 23, 27, 24, 21, 25, 22};\n\tstatic char flat_tb[8] = {22, 25, 21, 24, 20, 23, 26};\n\n\tif (s->u.key.sf > 0) {\n\t\tfor (nacc = 0; nacc < s->u.key.sf; nacc++) {\n\t\t\taccs[nacc] = A_SH;\n\t\t\tpits[nacc] = sharp_tb[nacc];\n\t\t}\n\t} else {\n\t\tfor (nacc = 0; nacc < -s->u.key.sf; nacc++) {\n\t\t\taccs[nacc] = A_FT;\n\t\t\tpits[nacc] = flat_tb[nacc];\n\t\t}\n\t}\n\tfor (i = 0; i < s->u.key.nacc; i++) {\n\t\tfor (j = 0; j < nacc; j++) {\n//\t\t\tif ((pits[j] - s->u.key.pits[i]) % 7 == 0) {\n\t\t\tif (pits[j] == s->u.key.pits[i]) {\n\t\t\t\taccs[j] = s->u.key.accs[i];\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tif (j == nacc) {\n\t\t\taccs[j] = s->u.key.accs[i];\n\t\t\tpits[j] = s->u.key.pits[i];\n\t\t\tnacc++;\t\t/* cannot overflow */\n\t\t}\n\t}\n\tfor (i = 0; i < nacc; i++) {\n\t\ts->u.key.accs[i] = accs[i];\n\t\ts->u.key.pits[i] = pits[i];\n\t}\n\ts->u.key.nacc = nacc;\n}",
        "commit_message": "fix: crash when too many accidentals in K: (signature + explicit)\n\nIssue #17.",
        "cve_desc": "Stack-based buffer overflow in the get_key function in parse.c in abcm2ps through 8.13.20 allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact.",
        "target": 1
      }
    ]
  },
  "acl": {
    "0": [],
    "1": []
  },
  "acrn-hypervisor": {
    "0": [
      {
        "idx": 253504,
        "reasoning": "This code is not directly vulnerable based on the provided snippet and commit message. The commit focuses on improving input validation within `pci_emul_mem_handler()` by replacing `Assert` with explicit checks, which is a defensive programming practice aimed at *preventing* vulnerabilities rather than addressing an existing one.\n\n\n\n",
        "func": "init_pci(struct vmctx *ctx)\n{\n\tstruct mem_range mr;\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tsize_t lowmem;\n\tint bus, slot, func;\n\tint success_cnt = 0;\n\tint error;\n\n\tpci_emul_iobase = PCI_EMUL_IOBASE;\n\tpci_emul_membase32 = vm_get_lowmem_limit(ctx);\n\tpci_emul_membase64 = PCI_EMUL_MEMBASE64;\n\n\tcreate_gsi_sharing_groups();\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\t/*\n\t\t * Keep track of the i/o and memory resources allocated to\n\t\t * this bus.\n\t\t */\n\t\tbi->iobase = pci_emul_iobase;\n\t\tbi->membase32 = pci_emul_membase32;\n\t\tbi->membase64 = pci_emul_membase64;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\t\t\t\terror = pci_emul_init(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t\tif (error)\n\t\t\t\t\tgoto pci_emul_init_fail;\n\t\t\t\tsuccess_cnt++;\n\t\t\t}\n\t\t}\n\n\t\t/*\n\t\t * Add some slop to the I/O and memory resources decoded by\n\t\t * this bus to give a guest some flexibility if it wants to\n\t\t * reprogram the BARs.\n\t\t */\n\t\tpci_emul_iobase += BUSIO_ROUNDUP;\n\t\tpci_emul_iobase = roundup2(pci_emul_iobase, BUSIO_ROUNDUP);\n\t\tbi->iolimit = pci_emul_iobase;\n\n\t\tpci_emul_membase32 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase32 = roundup2(pci_emul_membase32,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit32 = pci_emul_membase32;\n\n\t\tpci_emul_membase64 += BUSMEM_ROUNDUP;\n\t\tpci_emul_membase64 = roundup2(pci_emul_membase64,\n\t\t    BUSMEM_ROUNDUP);\n\t\tbi->memlimit64 = pci_emul_membase64;\n\t}\n\n\terror = check_gsi_sharing_violation();\n\tif (error < 0)\n\t\tgoto pci_emul_init_fail;\n\n\t/*\n\t * PCI backends are initialized before routing INTx interrupts\n\t * so that LPC devices are able to reserve ISA IRQs before\n\t * routing PIRQ pins.\n\t */\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_devi == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tpci_lintr_route(fi->fi_devi);\n\t\t\t\tops = fi->fi_devi->dev_ops;\n\t\t\t\tif (ops && ops->vdev_phys_access)\n\t\t\t\t\tops->vdev_phys_access(ctx,\n\t\t\t\t\t\tfi->fi_devi);\n\t\t\t}\n\t\t}\n\t}\n\tlpc_pirq_routed();\n\n\t/*\n\t * The guest physical memory map looks like the following:\n\t * [0,              lowmem)         guest system memory\n\t * [lowmem,         lowmem_limit)   memory hole (may be absent)\n\t * [lowmem_limit,   0xE0000000)     PCI hole (32-bit BAR allocation)\n\t * [0xE0000000,     0xF0000000)     PCI extended config window\n\t * [0xF0000000,     4GB)            LAPIC, IOAPIC, HPET, firmware\n\t * [4GB,            5GB)            PCI hole (64-bit BAR allocation)\n\t * [5GB,            5GB + highmem)  guest system memory\n\t */\n\n\t/*\n\t * Accesses to memory addresses that are not allocated to system\n\t * memory or PCI devices return 0xff's.\n\t */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tassert(error == 0);\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tmr.handler = pci_emul_fallback_handler;\n\terror = register_mem_fallback(&mr);\n\tassert(error == 0);\n\n\t/* PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.flags = MEM_F_RW;\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tmr.handler = pci_emul_ecfg_handler;\n\terror = register_mem(&mr);\n\tassert(error == 0);\n\n\treturn 0;\n\npci_emul_init_fail:\n\tfor (bus = 0; bus < MAXBUSES && success_cnt > 0; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\t\tfor (slot = 0; slot < MAXSLOTS && success_cnt > 0; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tif (success_cnt-- <= 0)\n\t\t\t\t\tbreak;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n\n\treturn error;\n}",
        "commit_message": "dm: validate the input in 'pci_emul_mem_handler()'\n\n checking the inputs explicitly instead of using Assert.\n\nTracked-On: #4003\nSigned-off-by: Yonghua Huang <yonghua.huang@intel.com>\nReviewed-by: Shuo Liu <shuo.a.liu@intel.com>\nAcked-by: Yu Wang <yu1.wang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 0
      },
      {
        "idx": 253505,
        "reasoning": "This code is safe as it introduces explicit input validation to prevent out-of-bounds memory access within the emulated PCI device's BAR (Base Address Register) region. By checking `addr + size` against the BAR's address and size, the code prevents reads and writes from occurring outside the allocated memory, mitigating potential vulnerabilities.\n\n\n\n",
        "func": "pci_emul_mem_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t     int size, uint64_t *val, void *arg1, long arg2)\n{\n\tstruct pci_vdev *pdi = arg1;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint bidx = (int) arg2;\n\n\tif (addr + size > pdi->bar[bidx].addr + pdi->bar[bidx].size) {\n\t\tprintf(\"%s, Out of emulated memory range.\\n\", __func__);\n\t\treturn -ESRCH;\n\t}\n\n\toffset = addr - pdi->bar[bidx].addr;\n\n\tif (dir == MEM_F_WRITE) {\n\t\tif (size == 8) {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   4, *val & 0xffffffff);\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset + 4,\n\t\t\t\t\t   4, *val >> 32);\n\t\t} else {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   size, bar_value(size, *val));\n\t\t}\n\t} else {\n\t\tif (size == 8) {\n\t\t\tuint64_t val_lo, val_hi;\n\n\t\t\tval_lo = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset, 4);\n\t\t\tval_lo = bar_value(4, val_lo);\n\n\t\t\tval_hi = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset + 4, 4);\n\n\t\t\t*val = val_lo | (val_hi << 32);\n\t\t} else {\n\t\t\t*val = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                            offset, size);\n\t\t\t*val = bar_value(size, *val);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "commit_message": "dm: validate the input in 'pci_emul_mem_handler()'\n\n checking the inputs explicitly instead of using Assert.\n\nTracked-On: #4003\nSigned-off-by: Yonghua Huang <yonghua.huang@intel.com>\nReviewed-by: Shuo Liu <shuo.a.liu@intel.com>\nAcked-by: Yu Wang <yu1.wang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 0
      },
      {
        "idx": 253506,
        "reasoning": "This code snippet is not directly related to the commit message focusing on input validation in `pci_emul_mem_handler()`. The provided code safely handles PCI BARs by unregistering them if enabled and then setting their type to `PCIBAR_NONE`, without apparent vulnerabilities like buffer overflows or improper access control.\n\n\n\n",
        "func": "pci_emul_free_bars(struct pci_vdev *pdi)\n{\n\tint i, enabled;\n\n\tfor (i = 0; i < PCI_BARMAX; i++) {\n\t\tif ((pdi->bar[i].type != PCIBAR_NONE) &&\n\t\t\t(pdi->bar[i].type != PCIBAR_MEMHI64)){\n\t\t\t/*\n\t\t\t * Check whether the bar is enabled or not,\n\t\t\t * if it is disabled then it should have been\n\t\t\t * unregistered in pci_emul_cmdsts_write.\n\t\t\t */\n\t\t\tif (pdi->bar[i].type == PCIBAR_IO)\n\t\t\t\tenabled = porten(pdi);\n\t\t\telse\n\t\t\t\tenabled = memen(pdi);\n\n\t\t\tif (enabled)\n\t\t\t\tunregister_bar(pdi, i);\n\t\t\tpdi->bar[i].type = PCIBAR_NONE;\n\t\t}\n\t}\n}",
        "commit_message": "dm: validate the input in 'pci_emul_mem_handler()'\n\n checking the inputs explicitly instead of using Assert.\n\nTracked-On: #4003\nSigned-off-by: Yonghua Huang <yonghua.huang@intel.com>\nReviewed-by: Shuo Liu <shuo.a.liu@intel.com>\nAcked-by: Yu Wang <yu1.wang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 0
      },
      {
        "idx": 253507,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information; the commit message indicates a validation fix in a related function (`pci_emul_mem_handler()`) but doesn't suggest any issues within `deinit_pci()` itself. The code primarily focuses on releasing memory ranges and deinitializing PCI devices, and while it uses `assert`, the recent commit addresses input validation concerns elsewhere, implying this function isn't the immediate target of those vulnerabilities.\n\n\n\n",
        "func": "deinit_pci(struct vmctx *ctx)\n{\n\tstruct pci_vdev_ops *ops;\n\tstruct businfo *bi;\n\tstruct slotinfo *si;\n\tstruct funcinfo *fi;\n\tint bus, slot, func;\n\tsize_t lowmem;\n\tstruct mem_range mr;\n\n\t/* Release PCI extended config space */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI ECFG\";\n\tmr.base = PCI_EMUL_ECFG_BASE;\n\tmr.size = PCI_EMUL_ECFG_SIZE;\n\tunregister_mem(&mr);\n\n\t/* Release PCI hole space */\n\tlowmem = vm_get_lowmem_size(ctx);\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (32-bit)\";\n\tmr.base = lowmem;\n\tmr.size = (4ULL * 1024 * 1024 * 1024) - lowmem;\n\tunregister_mem_fallback(&mr);\n\n\t/* ditto for the 64-bit PCI host aperture */\n\tbzero(&mr, sizeof(struct mem_range));\n\tmr.name = \"PCI hole (64-bit)\";\n\tmr.base = PCI_EMUL_MEMBASE64;\n\tmr.size = PCI_EMUL_MEMLIMIT64 - PCI_EMUL_MEMBASE64;\n\tunregister_mem_fallback(&mr);\n\n\tfor (bus = 0; bus < MAXBUSES; bus++) {\n\t\tbi = pci_businfo[bus];\n\t\tif (bi == NULL)\n\t\t\tcontinue;\n\n\t\tfor (slot = 0; slot < MAXSLOTS; slot++) {\n\t\t\tsi = &bi->slotinfo[slot];\n\t\t\tfor (func = 0; func < MAXFUNCS; func++) {\n\t\t\t\tfi = &si->si_funcs[func];\n\t\t\t\tif (fi->fi_name == NULL)\n\t\t\t\t\tcontinue;\n\t\t\t\tops = pci_emul_finddev(fi->fi_name);\n\t\t\t\tassert(ops != NULL);\n\t\t\t\tpci_emul_deinit(ctx, ops, bus, slot,\n\t\t\t\t    func, fi);\n\t\t\t}\n\t\t}\n\t}\n}",
        "commit_message": "dm: validate the input in 'pci_emul_mem_handler()'\n\n checking the inputs explicitly instead of using Assert.\n\nTracked-On: #4003\nSigned-off-by: Yonghua Huang <yonghua.huang@intel.com>\nReviewed-by: Shuo Liu <shuo.a.liu@intel.com>\nAcked-by: Yu Wang <yu1.wang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 0
      },
      {
        "idx": 253508,
        "reasoning": "This code snippet is not flagged as vulnerable because it simply reads a PCI configuration register (PCIR_COMMAND) and checks a specific bit (PCIM_CMD_PORTEN) within it. The commit message focuses on input validation in a different function (`pci_emul_mem_handler()`) and doesn't relate to the functionality presented in this code, which is a safe read operation.\n\n\n\n",
        "func": "porten(struct pci_vdev *dev)\n{\n\tuint16_t cmd;\n\n\tcmd = pci_get_cfgdata16(dev, PCIR_COMMAND);\n\n\treturn (cmd & PCIM_CMD_PORTEN);\n}",
        "commit_message": "dm: validate the input in 'pci_emul_mem_handler()'\n\n checking the inputs explicitly instead of using Assert.\n\nTracked-On: #4003\nSigned-off-by: Yonghua Huang <yonghua.huang@intel.com>\nReviewed-by: Shuo Liu <shuo.a.liu@intel.com>\nAcked-by: Yu Wang <yu1.wang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 196246,
        "reasoning": "The code relies on `assert()` statements for critical checks regarding PCI BAR access, which, as the CVE describes, can be exploited to cause a denial of service by triggering assertion failures. An attacker could manipulate PCI configuration space or memory accesses to violate these assertions, leading to a hypervisor crash and disrupting system availability.",
        "func": "pci_emul_mem_handler(struct vmctx *ctx, int vcpu, int dir, uint64_t addr,\n\t\t     int size, uint64_t *val, void *arg1, long arg2)\n{\n\tstruct pci_vdev *pdi = arg1;\n\tstruct pci_vdev_ops *ops = pdi->dev_ops;\n\tuint64_t offset;\n\tint bidx = (int) arg2;\n\n\tassert(bidx <= PCI_BARMAX);\n\tassert(pdi->bar[bidx].type == PCIBAR_MEM32 ||\n\t       pdi->bar[bidx].type == PCIBAR_MEM64);\n\tassert(addr >= pdi->bar[bidx].addr &&\n\t       addr + size <= pdi->bar[bidx].addr + pdi->bar[bidx].size);\n\n\toffset = addr - pdi->bar[bidx].addr;\n\n\tif (dir == MEM_F_WRITE) {\n\t\tif (size == 8) {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   4, *val & 0xffffffff);\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset + 4,\n\t\t\t\t\t   4, *val >> 32);\n\t\t} else {\n\t\t\t(*ops->vdev_barwrite)(ctx, vcpu, pdi, bidx, offset,\n\t\t\t\t\t   size, bar_value(size, *val));\n\t\t}\n\t} else {\n\t\tif (size == 8) {\n\t\t\tuint64_t val_lo, val_hi;\n\n\t\t\tval_lo = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset, 4);\n\t\t\tval_lo = bar_value(4, val_lo);\n\n\t\t\tval_hi = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                              offset + 4, 4);\n\n\t\t\t*val = val_lo | (val_hi << 32);\n\t\t} else {\n\t\t\t*val = (*ops->vdev_barread)(ctx, vcpu, pdi, bidx,\n\t\t\t                            offset, size);\n\t\t\t*val = bar_value(size, *val);\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "commit_message": "dm: pci: clean up assert() in pci core\n\nTracked-On: #3252\nSigned-off-by: Shuo A Liu <shuo.a.liu@intel.com>\nReviewed-by: Yonghua Huang <yonghua.huang@intel.com>",
        "cve_desc": "The Device Model in ACRN before 2019w25.5-140000p relies on assert calls in devicemodel/hw/pci/core.c and devicemodel/include/pci_core.h (instead of other mechanisms for propagating error information or diagnostic information), which might allow attackers to cause a denial of service (assertion failure) within pci core. This is fixed in 1.2. 6199e653418e is a mitigation for pre-1.1 versions, whereas 2b3dedfb9ba1 is a mitigation for 1.1.",
        "target": 1
      }
    ]
  },
  "ardour": {
    "0": [],
    "1": []
  },
  "ast": {
    "0": [],
    "1": []
  },
  "asylo": {
    "0": [
      {
        "idx": 233002,
        "reasoning": "This code snippet is not directly vulnerable because it simply dispatches a system call (`pwrite64`) through a framework (`EnsureInitializedAndDispatchSyscall`). The provided commit message addresses a vulnerability in `inet_pton`, a function *not* present in this code, indicating this snippet isn't affected by that specific issue.\n\n\n\n",
        "func": "int enc_untrusted_pwrite64(int fd, const void *buf, size_t count,\n                           off_t offset) {\n  return EnsureInitializedAndDispatchSyscall(asylo::system_call::kSYS_pwrite64,\n                                             fd, buf, count, offset);\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 0
      },
      {
        "idx": 233003,
        "reasoning": "This code is not directly vulnerable to the `inet_pton` vulnerability described in the commit message because it doesn't directly call `inet_pton`. Instead, it relies on a host call (`asylo::host_call::kGetSocknameHandler`) to retrieve socket information, and includes checks for invalid `addrlen` values to prevent potential buffer overflows or other issues during the data transfer from the enclave to the host.",
        "func": "int enc_untrusted_getsockname(int sockfd, struct sockaddr *addr,\n                              socklen_t *addrlen) {\n  if (!addr || !addrlen) {\n    errno = EFAULT;\n    return -1;\n  }\n  // Guard against -1 being passed as addrlen even though it's unsigned.\n  if (*addrlen == 0 || *addrlen > INT32_MAX) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kGetSocknameHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_getsockname\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n\n  // getsockname() returns 0 on success. On error, -1 is returned, with errno\n  // set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto klinux_sockaddr_buf = output.next();\n  const struct klinux_sockaddr *klinux_addr =\n      klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n  if (!FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), addr,\n                          addrlen, TrustedPrimitives::BestEffortAbort)) {\n    errno = EFAULT;\n    return -1;\n  }\n  return result;\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 0
      },
      {
        "idx": 233004,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. It simply calls a system call dispatch function (`EnsureInitializedAndDispatchSyscall`) with the `unlink` syscall and a pathname; the vulnerability fix in `inet_pton` doesn't relate to file system operations or syscall dispatching in this manner.\n\n\n\n",
        "func": "int enc_untrusted_unlink(const char *pathname) {\n  return EnsureInitializedAndDispatchSyscall(asylo::system_call::kSYS_unlink,\n                                             pathname);\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 0
      },
      {
        "idx": 233005,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. It simply wraps a system call (`write`) through a dispatch mechanism, and the commit message relates to a fix in `inet_pton` which doesn't appear to be used within this `enc_untrusted_write` function\u2014therefore, there's no apparent connection to the addressed vulnerability.\n\n\n\n",
        "func": "ssize_t enc_untrusted_write(int fd, const void *buf, size_t count) {\n  return static_cast<ssize_t>(EnsureInitializedAndDispatchSyscall(\n      asylo::system_call::kSYS_write, fd, buf, count));\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 0
      },
      {
        "idx": 233006,
        "reasoning": "This code is not directly vulnerable based on the provided snippet. The commit message references a fix in `inet_pton` which is unrelated to the functionality of `enc_untrusted_sigprocmask`; this function focuses on safely interacting with `sigprocmask` via a dispatcher and proper error handling, without exhibiting any obvious vulnerabilities like buffer overflows or format string issues.\n\n\n\n",
        "func": "int enc_untrusted_sigprocmask(int how, const sigset_t *set, sigset_t *oldset) {\n  klinux_sigset_t klinux_set;\n  if (!TokLinuxSigset(set, &klinux_set)) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  int klinux_how = TokLinuxSigMaskAction(how);\n  if (klinux_how == -1) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(klinux_how);\n  input.Push<klinux_sigset_t>(klinux_set);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kSigprocmaskHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_sigprocmask\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // sigprocmask() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  klinux_sigset_t klinux_oldset = output.next<klinux_sigset_t>();\n  if (oldset != nullptr) {\n    if (!FromkLinuxSigset(&klinux_oldset, oldset)) {\n      errno = EINVAL;\n      return -1;\n    }\n  }\n  return result;\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195777,
        "reasoning": "The code is vulnerable to an arbitrary memory read because it copies data from `klinux_addr_buffer` to `dst` without properly validating the size of `klinux_addr_buffer` against `max_size`. This allows a malicious actor to control `klinux_addr_buffer`\u2019s size and potentially read beyond the allocated buffer, accessing sensitive memory within the secure enclave as described in the CVE.",
        "func": "int enc_untrusted_inet_pton(int af, const char *src, void *dst) {\n  if (!src || !dst) {\n    return 0;\n  }\n\n  MessageWriter input;\n  input.Push<int>(TokLinuxAfFamily(af));\n  input.PushByReference(Extent{\n      src, std::min(strlen(src) + 1, static_cast<size_t>(INET6_ADDRSTRLEN))});\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kInetPtonHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_inet_pton\", 3);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return -1;\n  }\n\n  auto klinux_addr_buffer = output.next();\n  size_t max_size = 0;\n  if (af == AF_INET) {\n    max_size = sizeof(struct in_addr);\n  } else if (af == AF_INET6) {\n    max_size = sizeof(struct in6_addr);\n  }\n  memcpy(dst, klinux_addr_buffer.data(),\n         std::min(klinux_addr_buffer.size(), max_size));\n  return result;\n}",
        "commit_message": "Check sockaddr size in inet_pton\n\nPiperOrigin-RevId: 333821843\nChange-Id: Ie0b694f1edd3f7a4a3de6df964d68566961accf6",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_inet_pton using an attacker controlled klinux_addr_buffer parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit 8fed5e334131abaf9c5e17307642fbf6ce4a57ec",
        "target": 1
      },
      {
        "idx": 196845,
        "reasoning": "The code is vulnerable because the `memcpy` function copies `len` bytes from `buffer_received` to `buf` without verifying that `buffer_received` actually contains at least `len` bytes, potentially leading to a read-out-of-bounds. This allows an attacker to control the length of data copied into a smaller, untrusted buffer, potentially exposing sensitive trusted memory.",
        "func": "ssize_t enc_untrusted_recvfrom(int sockfd, void *buf, size_t len, int flags,\n                               struct sockaddr *src_addr, socklen_t *addrlen) {\n  int klinux_flags = TokLinuxRecvSendFlag(flags);\n  if (klinux_flags == 0 && flags != 0) {\n    errno = EINVAL;\n    return -1;\n  }\n\n  MessageWriter input;\n  input.Push<int>(sockfd);\n  input.Push<uint64_t>(len);\n  input.Push<int>(klinux_flags);\n  MessageReader output;\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvFromHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvfrom\", 4);\n\n  int result = output.next<int>();\n  int klinux_errno = output.next<int>();\n  // recvfrom() returns -1 on failure, with errno set to indicate the cause\n  // of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto buffer_received = output.next();\n  memcpy(buf, buffer_received.data(), len);\n\n  // If |src_addr| is not NULL, and the underlying protocol provides the source\n  // address, this source address is filled in. When |src_addr| is NULL, nothing\n  // is filled in; in this case, |addrlen| is not used, and should also be NULL.\n  if (src_addr != nullptr && addrlen != nullptr) {\n    auto klinux_sockaddr_buf = output.next();\n    const struct klinux_sockaddr *klinux_addr =\n        klinux_sockaddr_buf.As<struct klinux_sockaddr>();\n    FromkLinuxSockAddr(klinux_addr, klinux_sockaddr_buf.size(), src_addr,\n                       addrlen, TrustedPrimitives::BestEffortAbort);\n  }\n\n  return result;\n}",
        "commit_message": "Fix vulnerability in enc_untrusted_recvfrom\n\nChange recvfrom memcpy to check for received_buffer size to avoid\ncopying extra buffer.\n\nThis issue was reported by Qinkun Bao, Zhaofeng Chen, Mingshen Sun, and\nKang Li from Baidu Security.\n\nPiperOrigin-RevId: 322476299\nChange-Id: I3606ff9ec51ec7cc4312c7555c645a2fc6e09b21",
        "cve_desc": "A buffer length validation vulnerability in Asylo versions prior to 0.6.0 allows an attacker to read data they should not have access to. The 'enc_untrusted_recvfrom' function generates a return value which is deserialized by 'MessageReader', and copied into three different 'extents'. The length of the third 'extents' is controlled by the outside world, and not verified on copy, allowing the attacker to force Asylo to copy trusted memory data into an untrusted buffer of significantly small length.. We recommend updating Asylo to version 0.6.0 or later.",
        "target": 1
      },
      {
        "idx": 198009,
        "reasoning": "The code is vulnerable to an arbitrary memory read because the `result` from `output.next<ssize_t>()` is not validated to ensure it doesn't exceed the expected buffer sizes before being used in subsequent `memcpy` operations. This allows a malicious actor to control the `result` value, potentially causing reads from memory locations outside the intended buffers, including sensitive enclave memory, as described in the CVE.",
        "func": "ssize_t enc_untrusted_recvmsg(int sockfd, struct msghdr *msg, int flags) {\n  size_t total_buffer_size = CalculateTotalMessageSize(msg);\n\n  MessageWriter input;\n  input.Push(sockfd);\n  input.Push<uint64_t>(msg->msg_namelen);\n  input.Push<uint64_t>(total_buffer_size);\n  input.Push<uint64_t>(msg->msg_controllen);\n  input.Push(msg->msg_flags);\n  input.Push(flags);\n\n  MessageReader output;\n\n  const auto status = NonSystemCallDispatcher(\n      ::asylo::host_call::kRecvMsgHandler, &input, &output);\n  CheckStatusAndParamCount(status, output, \"enc_untrusted_recvmsg\", 2,\n                           /*match_exact_params=*/false);\n\n  ssize_t result = output.next<ssize_t>();\n  int klinux_errno = output.next<int>();\n\n  // recvmsg() returns the number of characters received. On error, -1 is\n  // returned, with errno set to indicate the cause of the error.\n  if (result == -1) {\n    errno = FromkLinuxErrorNumber(klinux_errno);\n    return result;\n  }\n\n  auto msg_name_extent = output.next();\n  // The returned |msg_namelen| should not exceed the buffer size.\n  if (msg_name_extent.size() <= msg->msg_namelen) {\n    msg->msg_namelen = msg_name_extent.size();\n  }\n  memcpy(msg->msg_name, msg_name_extent.As<char>(), msg->msg_namelen);\n\n  // A single buffer is passed from the untrusted side, copy it into the\n  // scattered buffers inside the enclave.\n  auto msg_iov_extent = output.next();\n  size_t total_bytes = msg_iov_extent.size();\n  size_t bytes_copied = 0;\n  for (int i = 0; i < msg->msg_iovlen && bytes_copied < total_bytes; ++i) {\n    size_t bytes_to_copy =\n        std::min(msg->msg_iov[i].iov_len, total_bytes - bytes_copied);\n    memcpy(msg->msg_iov[i].iov_base, msg_iov_extent.As<char>() + bytes_copied,\n           bytes_to_copy);\n    bytes_copied += bytes_to_copy;\n  }\n\n  auto msg_control_extent = output.next();\n  // The returned |msg_controllen| should not exceed the buffer size.\n  if (msg_control_extent.size() <= msg->msg_controllen) {\n    msg->msg_controllen = msg_control_extent.size();\n  }\n  memcpy(msg->msg_control, msg_control_extent.As<char>(), msg->msg_controllen);\n\n  return result;\n}",
        "commit_message": "Check return result in recvmsg\n\nPiperOrigin-RevId: 333411798\nChange-Id: I61986b5a1bffd79c0e1950013aa9de09cf4a5d61",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_recvmsg using an attacker controlled result parameter. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading or past commit fa6485c5d16a7355eab047d4a44345a73bc9131e",
        "target": 1
      },
      {
        "idx": 198014,
        "reasoning": "This code is vulnerable to an arbitrary memory overwrite because it doesn't validate the `output_len` pointer's range before writing `tmp_output_len` to the memory location it points to. An attacker can control `tmp_output_len` and, by providing a malicious `output_len` pointer, overwrite arbitrary trusted memory within the enclave.",
        "func": "int ecall_restore(const char *input, uint64_t input_len, char **output,\n                  uint64_t *output_len) {\n  if (!asylo::primitives::TrustedPrimitives::IsOutsideEnclave(input,\n                                                              input_len)) {\n    asylo::primitives::TrustedPrimitives::BestEffortAbort(\n        \"ecall_restore: input found to not be in untrusted memory.\");\n  }\n  int result = 0;\n  size_t tmp_output_len;\n  try {\n    result = asylo::Restore(input, static_cast<size_t>(input_len), output,\n                            &tmp_output_len);\n  } catch (...) {\n    LOG(FATAL) << \"Uncaught exception in enclave\";\n  }\n\n  if (output_len) {\n    *output_len = static_cast<uint64_t>(tmp_output_len);\n  }\n  return result;\n}",
        "commit_message": "Check for output_len range in ecall_restore\n\nThis may cause vulnerablity if pointing to trusted memory.\n\nThis issue was reported by Qinkun Bao, Zhaofeng Chen, Mingshen Sun, and\nKang Li from Baidu Security.\n\nPiperOrigin-RevId: 322476223\nChange-Id: I8a6406e9f07a20582d4387bd9a3469dfa9cbcb12",
        "cve_desc": "An arbitrary memory overwrite vulnerability in the trusted memory of Asylo exists in versions prior to 0.6.0. As the ecall_restore function fails to validate the range of the output_len pointer, an attacker can manipulate the tmp_output_len value and write to an arbitrary location in the trusted (enclave) memory. We recommend updating Asylo to version 0.6.0 or later.",
        "target": 1
      },
      {
        "idx": 198238,
        "reasoning": "This code is vulnerable to an arbitrary memory read because the `enc_untrusted_read` function doesn't validate the size of the data actually read against the requested `count`. As the CVE description details, this allows an attacker to potentially read beyond the allocated buffer, even into the secure enclave's memory, by providing a specific `count` value and exploiting a larger-than-expected return from the syscall.",
        "func": "ssize_t enc_untrusted_read(int fd, void *buf, size_t count) {\n  return static_cast<ssize_t>(EnsureInitializedAndDispatchSyscall(\n      asylo::system_call::kSYS_read, fd, buf, count));\n}",
        "commit_message": "Check for return size in enc_untrusted_read\n\nCheck return size does not exceed requested. The returned result and\ncontent still cannot be trusted, but it's expected behavior when not\nusing a secure file system.\n\nPiperOrigin-RevId: 333827386\nChange-Id: I0bdec0aec9356ea333dc8c647eba5d2772875f29",
        "cve_desc": "An arbitrary memory read vulnerability in Asylo versions up to 0.6.0 allows an untrusted attacker to make a call to enc_untrusted_read whose return size was not validated against the requrested size. The parameter size is unchecked allowing the attacker to read memory locations outside of the intended buffer size including memory addresses within the secure enclave. We recommend upgrading past commit b1d120a2c7d7446d2cc58d517e20a1b184b82200",
        "target": 1
      }
    ]
  },
  "at91bootstrap": {
    "0": [],
    "1": []
  },
  "atomicparsley": {
    "0": [],
    "1": []
  },
  "bash": {
    "0": [],
    "1": []
  },
  "bdwgc": {
    "0": [
      {
        "idx": 191458,
        "reasoning": "This code is not directly vulnerable to the `calloc()` overflow described in the commit message because it uses `GC_alloc_large` which allocates large blocks and calculates the total bytes based on `n_blocks * HBLKSIZE`. The commit message specifically addresses an overflow in `calloc()` when calculating the total allocation size via multiplication, and this code path doesn't appear to directly use `calloc()` or perform a similar vulnerable multiplication without checks.\n\n\n\n",
        "func": "GC_INNER ptr_t GC_alloc_large(size_t lb, int k, unsigned flags)\n{\n    struct hblk * h;\n    word n_blocks;\n    ptr_t result;\n    GC_bool retry = FALSE;\n\n    /* Round up to a multiple of a granule. */\n      lb = (lb + GRANULE_BYTES - 1) & ~(GRANULE_BYTES - 1);\n    n_blocks = OBJ_SZ_TO_BLOCKS(lb);\n    if (!EXPECT(GC_is_initialized, TRUE)) GC_init();\n    /* Do our share of marking work */\n        if (GC_incremental && !GC_dont_gc)\n            GC_collect_a_little_inner((int)n_blocks);\n    h = GC_allochblk(lb, k, flags);\n#   ifdef USE_MUNMAP\n        if (0 == h) {\n            GC_merge_unmapped();\n            h = GC_allochblk(lb, k, flags);\n        }\n#   endif\n    while (0 == h && GC_collect_or_expand(n_blocks, flags != 0, retry)) {\n        h = GC_allochblk(lb, k, flags);\n        retry = TRUE;\n    }\n    if (h == 0) {\n        result = 0;\n    } else {\n        size_t total_bytes = n_blocks * HBLKSIZE;\n        if (n_blocks > 1) {\n            GC_large_allocd_bytes += total_bytes;\n            if (GC_large_allocd_bytes > GC_max_large_allocd_bytes)\n                GC_max_large_allocd_bytes = GC_large_allocd_bytes;\n        }\n        result = h -> hb_body;\n    }\n    return result;\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 0
      },
      {
        "idx": 191459,
        "reasoning": "This code is not directly vulnerable to the calloc() overflow described in the commit message because it uses `GC_alloc_large` and then explicitly clears the allocated memory with `BZERO`. The overflow check was implemented in `GC_alloc_large` (not shown), and this function simply utilizes the result of that allocation, mitigating the risk within this specific snippet.\n\n\n\n",
        "func": "STATIC ptr_t GC_alloc_large_and_clear(size_t lb, int k, unsigned flags)\n{\n    ptr_t result = GC_alloc_large(lb, k, flags);\n    word n_blocks = OBJ_SZ_TO_BLOCKS(lb);\n\n    if (0 == result) return 0;\n    if (GC_debugging_started || GC_obj_kinds[k].ok_init) {\n        /* Clear the whole block, in case of GC_realloc call. */\n        BZERO(result, n_blocks * HBLKSIZE);\n    }\n    return result;\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 0
      },
      {
        "idx": 191460,
        "reasoning": "This code snippet is not directly related to the \"Fix calloc() overflow\" commit message, which concerns the `calloc()` function in `malloc.c`. The provided code uses `GC_scratch_alloc()` and `BZERO()` for allocation and initialization, and doesn't exhibit any multiplication overflow vulnerabilities within its own logic; therefore, it's not flagged as vulnerable based on the given context.\n\n\n\n",
        "func": "STATIC GC_bool GC_alloc_reclaim_list(struct obj_kind *kind)\n{\n    struct hblk ** result = (struct hblk **)\n                GC_scratch_alloc((MAXOBJGRANULES+1) * sizeof(struct hblk *));\n    if (result == 0) return(FALSE);\n    BZERO(result, (MAXOBJGRANULES+1)*sizeof(struct hblk *));\n    kind -> ok_reclaim_list = result;\n    return(TRUE);\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 0
      },
      {
        "idx": 191461,
        "reasoning": "This code snippet focuses on `GC_malloc` and small object allocation from freelists, and doesn't directly handle `calloc()` or multiplication that could lead to an overflow. The commit message explicitly states the overflow fix is within `calloc()` in `malloc.c` *assuming* `REDIRECT_MALLOC`, but this provided code doesn't show that `calloc()` implementation or the relevant multiplication; therefore, this snippet isn't vulnerable based on the information given.\n\n\n\n",
        "func": "  GC_INNER void * GC_core_malloc(size_t lb)\n#else\n  GC_API void * GC_CALL GC_malloc(size_t lb)\n#endif\n{\n    void *op;\n    void **opp;\n    size_t lg;\n    DCL_LOCK_STATE;\n\n    if(SMALL_OBJ(lb)) {\n        lg = GC_size_map[lb];\n        opp = (void **)&(GC_objfreelist[lg]);\n        LOCK();\n        if (EXPECT((op = *opp) == 0, FALSE)) {\n            UNLOCK();\n            return (GENERAL_MALLOC((word)lb, NORMAL));\n        }\n        GC_ASSERT(0 == obj_link(op)\n                  || ((word)obj_link(op)\n                        <= (word)GC_greatest_plausible_heap_addr\n                     && (word)obj_link(op)\n                        >= (word)GC_least_plausible_heap_addr));\n        *opp = obj_link(op);\n        obj_link(op) = 0;\n        GC_bytes_allocd += GRANULES_TO_BYTES(lg);\n        UNLOCK();\n        return op;\n   } else {\n       return(GENERAL_MALLOC(lb, NORMAL));\n   }\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 0
      },
      {
        "idx": 191462,
        "reasoning": "This code snippet focuses on small object allocation from pre-defined freelists and delegates larger allocations to `GENERAL_MALLOC`. The commit message explicitly addresses a `calloc()` overflow, but this code doesn't implement `calloc()` directly; it uses `GENERAL_MALLOC` which is assumed to have its own overflow protections as indicated by the commit message's condition \"assuming REDIRECT_MALLOC\".",
        "func": "  GC_INNER void * GC_core_malloc_atomic(size_t lb)\n#else\n  GC_API void * GC_CALL GC_malloc_atomic(size_t lb)\n#endif\n{\n    void *op;\n    void ** opp;\n    size_t lg;\n    DCL_LOCK_STATE;\n\n    if(SMALL_OBJ(lb)) {\n        lg = GC_size_map[lb];\n        opp = &(GC_aobjfreelist[lg]);\n        LOCK();\n        if (EXPECT((op = *opp) == 0, FALSE)) {\n            UNLOCK();\n            return(GENERAL_MALLOC((word)lb, PTRFREE));\n        }\n        *opp = obj_link(op);\n        GC_bytes_allocd += GRANULES_TO_BYTES(lg);\n        UNLOCK();\n        return((void *) op);\n   } else {\n       return(GENERAL_MALLOC((word)lb, PTRFREE));\n   }\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 10516,
        "reasoning": "The `calloc` function is vulnerable to an integer overflow because it multiplies `n` and `lb` before passing the result to `REDIRECT_MALLOC`. If this multiplication results in a value larger than the maximum representable size, it will wrap around, leading to a smaller-than-expected allocation size and potentially a buffer overflow as described in the CVE.",
        "func": " void * calloc(size_t n, size_t lb)\n {\n #   if defined(GC_LINUX_THREADS) /* && !defined(USE_PROC_FOR_LIBRARIES) */\n         /* libpthread allocated some memory that is only pointed to by  */\n         /* mmapped thread stacks.  Make sure it's not collectable.      */\n        {\n          static GC_bool lib_bounds_set = FALSE;\n          ptr_t caller = (ptr_t)__builtin_return_address(0);\n          /* This test does not need to ensure memory visibility, since */\n          /* the bounds will be set when/if we create another thread.   */\n          if (!EXPECT(lib_bounds_set, TRUE)) {\n            GC_init_lib_bounds();\n            lib_bounds_set = TRUE;\n          }\n          if (((word)caller >= (word)GC_libpthread_start\n               && (word)caller < (word)GC_libpthread_end)\n              || ((word)caller >= (word)GC_libld_start\n                  && (word)caller < (word)GC_libld_end))\n            return GC_malloc_uncollectable(n*lb);\n          /* The two ranges are actually usually adjacent, so there may */\n          /* be a way to speed this up.                                 */\n        }\n#   endif\n    return((void *)REDIRECT_MALLOC(n*lb));\n}\n",
        "commit_message": "Fix calloc() overflow\n\n* malloc.c (calloc): Check multiplication overflow in calloc(),\nassuming REDIRECT_MALLOC.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 1
      },
      {
        "idx": 10641,
        "reasoning": "The code is vulnerable to integer overflows because the `lb` (likely representing the requested size) is rounded up to `lb_rounded` using `ROUNDED_UP_GRANULES` and `GRANULES_TO_BYTES`, potentially resulting in a smaller allocation size than intended if `lb` is large. This discrepancy between the requested size and the actual allocated size can lead to buffer overflows when the program writes data assuming the original, larger size, as described in the CVE.",
        "func": "GC_API void * GC_CALL GC_generic_malloc(size_t lb, int k)\n{\n    void * result;\n    DCL_LOCK_STATE;\n\n    if (EXPECT(GC_have_errors, FALSE))\n      GC_print_all_errors();\n    GC_INVOKE_FINALIZERS();\n    if (SMALL_OBJ(lb)) {\n        LOCK();\n        result = GC_generic_malloc_inner((word)lb, k);\n        UNLOCK();\n    } else {\n        size_t lg;\n        size_t lb_rounded;\n        word n_blocks;\n         GC_bool init;\n         lg = ROUNDED_UP_GRANULES(lb);\n         lb_rounded = GRANULES_TO_BYTES(lg);\n         n_blocks = OBJ_SZ_TO_BLOCKS(lb_rounded);\n         init = GC_obj_kinds[k].ok_init;\n         LOCK();\n        result = (ptr_t)GC_alloc_large(lb_rounded, k, 0);\n        if (0 != result) {\n          if (GC_debugging_started) {\n            BZERO(result, n_blocks * HBLKSIZE);\n          } else {\n#           ifdef THREADS\n              /* Clear any memory that might be used for GC descriptors */\n              /* before we release the lock.                            */\n                ((word *)result)[0] = 0;\n                ((word *)result)[1] = 0;\n                ((word *)result)[GRANULES_TO_WORDS(lg)-1] = 0;\n                ((word *)result)[GRANULES_TO_WORDS(lg)-2] = 0;\n#           endif\n          }\n        }\n        GC_bytes_allocd += lb_rounded;\n        UNLOCK();\n        if (init && !GC_debugging_started && 0 != result) {\n            BZERO(result, n_blocks * HBLKSIZE);\n        }\n    }\n    if (0 == result) {\n        return((*GC_get_oom_fn())(lb));\n    } else {\n        return(result);\n    }\n}\n",
        "commit_message": "Fix allocation size overflows due to rounding.\n\n* malloc.c (GC_generic_malloc): Check if the allocation size is\nrounded to a smaller value.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Likewise.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 1
      },
      {
        "idx": 10642,
        "reasoning": "This code is vulnerable to an integer overflow because the `lb_rounded` value, calculated from `lb` using `ROUNDED_UP_GRANULES` and `GRANULES_TO_BYTES`, can be smaller than the original `lb` value, leading to an underallocation of memory. This underallocation can then be exploited to cause buffer overflows as the program may write beyond the boundaries of the allocated region, believing it to be larger than it actually is.",
        "func": "GC_INNER void * GC_generic_malloc_ignore_off_page(size_t lb, int k)\n{\n    void *result;\n    size_t lg;\n    size_t lb_rounded;\n    word n_blocks;\n    GC_bool init;\n    DCL_LOCK_STATE;\n\n    if (SMALL_OBJ(lb))\n         return(GC_generic_malloc((word)lb, k));\n     lg = ROUNDED_UP_GRANULES(lb);\n     lb_rounded = GRANULES_TO_BYTES(lg);\n     n_blocks = OBJ_SZ_TO_BLOCKS(lb_rounded);\n     init = GC_obj_kinds[k].ok_init;\n     if (EXPECT(GC_have_errors, FALSE))\n      GC_print_all_errors();\n    GC_INVOKE_FINALIZERS();\n    LOCK();\n    result = (ptr_t)GC_alloc_large(ADD_SLOP(lb), k, IGNORE_OFF_PAGE);\n    if (0 != result) {\n        if (GC_debugging_started) {\n            BZERO(result, n_blocks * HBLKSIZE);\n        } else {\n#           ifdef THREADS\n              /* Clear any memory that might be used for GC descriptors */\n              /* before we release the lock.                          */\n                ((word *)result)[0] = 0;\n                ((word *)result)[1] = 0;\n                ((word *)result)[GRANULES_TO_WORDS(lg)-1] = 0;\n                ((word *)result)[GRANULES_TO_WORDS(lg)-2] = 0;\n#           endif\n        }\n    }\n    GC_bytes_allocd += lb_rounded;\n    if (0 == result) {\n        GC_oom_func oom_fn = GC_oom_fn;\n        UNLOCK();\n        return((*oom_fn)(lb));\n    } else {\n        UNLOCK();\n        if (init && !GC_debugging_started) {\n            BZERO(result, n_blocks * HBLKSIZE);\n        }\n        return(result);\n    }\n}\n",
        "commit_message": "Fix allocation size overflows due to rounding.\n\n* malloc.c (GC_generic_malloc): Check if the allocation size is\nrounded to a smaller value.\n* mallocx.c (GC_generic_malloc_ignore_off_page): Likewise.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 1
      },
      {
        "idx": 10643,
        "reasoning": "The `calloc` function is vulnerable to an integer overflow because the multiplication `n * lb` can exceed `SIZE_MAX` before the check `n > SIZE_MAX / lb`, leading to a smaller-than-expected allocation size. This allows an attacker to request a large `n` and `lb` that, when multiplied, wrap around, resulting in a small allocation and potentially a buffer overflow when writing data.",
        "func": " void * calloc(size_t n, size_t lb)\n {\n    if (lb && n > SIZE_MAX / lb)\n       return NULL;\n #   if defined(GC_LINUX_THREADS) /* && !defined(USE_PROC_FOR_LIBRARIES) */\n         /* libpthread allocated some memory that is only pointed to by  */\n        /* mmapped thread stacks.  Make sure it's not collectable.      */\n        {\n          static GC_bool lib_bounds_set = FALSE;\n          ptr_t caller = (ptr_t)__builtin_return_address(0);\n          /* This test does not need to ensure memory visibility, since */\n          /* the bounds will be set when/if we create another thread.   */\n          if (!EXPECT(lib_bounds_set, TRUE)) {\n            GC_init_lib_bounds();\n            lib_bounds_set = TRUE;\n          }\n          if (((word)caller >= (word)GC_libpthread_start\n               && (word)caller < (word)GC_libpthread_end)\n              || ((word)caller >= (word)GC_libld_start\n                  && (word)caller < (word)GC_libld_end))\n            return GC_malloc_uncollectable(n*lb);\n          /* The two ranges are actually usually adjacent, so there may */\n          /* be a way to speed this up.                                 */\n        }\n#   endif\n    return((void *)REDIRECT_MALLOC(n*lb));\n}\n",
        "commit_message": "Fix calloc-related code to prevent SIZE_MAX redefinition in sys headers\n\n* malloc.c: Include limits.h for SIZE_MAX.\n* malloc.c (SIZE_MAX, calloc): Define GC_SIZE_MAX instead of SIZE_MAX.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 1
      },
      {
        "idx": 10644,
        "reasoning": "The `calloc` function is vulnerable to an integer overflow because the initial size check `if (lb && n > GC_SIZE_MAX / lb)` can fail to detect overflows when `n` and `lb` are large, leading to a smaller-than-expected memory allocation. This allows an attacker to request a large size, causing `n*lb` to wrap around to a small value, ultimately resulting in a buffer overflow when the program writes data assuming the originally requested size.",
        "func": " void * calloc(size_t n, size_t lb)\n {\n    if (lb && n > GC_SIZE_MAX / lb)\n       return NULL;\n #   if defined(GC_LINUX_THREADS) /* && !defined(USE_PROC_FOR_LIBRARIES) */\n         /* libpthread allocated some memory that is only pointed to by  */\n        /* mmapped thread stacks.  Make sure it's not collectable.      */\n        {\n          static GC_bool lib_bounds_set = FALSE;\n          ptr_t caller = (ptr_t)__builtin_return_address(0);\n          /* This test does not need to ensure memory visibility, since */\n          /* the bounds will be set when/if we create another thread.   */\n          if (!EXPECT(lib_bounds_set, TRUE)) {\n            GC_init_lib_bounds();\n            lib_bounds_set = TRUE;\n          }\n          if (((word)caller >= (word)GC_libpthread_start\n               && (word)caller < (word)GC_libpthread_end)\n              || ((word)caller >= (word)GC_libld_start\n                  && (word)caller < (word)GC_libld_end))\n            return GC_malloc_uncollectable(n*lb);\n          /* The two ranges are actually usually adjacent, so there may */\n          /* be a way to speed this up.                                 */\n        }\n#   endif\n    return((void *)REDIRECT_MALLOC(n*lb));\n}\n",
        "commit_message": "Speedup calloc size overflow check by preventing division if small values\n\n* malloc.c (GC_SQRT_SIZE_MAX): New macro.\n* malloc.c (calloc): Add fast initial size overflow check to avoid\ninteger division for reasonably small values passed.",
        "cve_desc": "Multiple integer overflows in the (1) GC_generic_malloc and (2) calloc functions in malloc.c, and the (3) GC_generic_malloc_ignore_off_page function in mallocx.c in Boehm-Demers-Weiser GC (libgc) before 7.2 make it easier for context-dependent attackers to perform memory-related attacks such as buffer overflows via a large size value, which causes less memory to be allocated than expected.",
        "target": 1
      }
    ]
  },
  "bfgminer": {
    "0": [
      {
        "idx": 233518,
        "reasoning": "This code is not directly vulnerable to the issue described in the commit message (stack overflow due to overlong addresses) as it pertains to network address handling. The `curl_debug_cb` function focuses on handling data received *through* a connection established elsewhere, and processes the data itself\u2014not the socket address\u2014making it unrelated to the address truncation fix.\n\n\n\n",
        "func": "static int curl_debug_cb(__maybe_unused CURL *handle, curl_infotype type,\n\t\t\t char *data, size_t size,\n\t\t\t void *userdata)\n{\n\tstruct pool *pool = (struct pool *)userdata;\n\n\tswitch(type) {\n\t\tcase CURLINFO_HEADER_IN:\n\t\tcase CURLINFO_DATA_IN:\n\t\tcase CURLINFO_SSL_DATA_IN:\n\t\t\tpool->cgminer_pool_stats.bytes_received += size;\n\t\t\ttotal_bytes_xfer += size;\n\t\t\tpool->cgminer_pool_stats.net_bytes_received += size;\n\t\t\tbreak;\n\t\tcase CURLINFO_HEADER_OUT:\n\t\tcase CURLINFO_DATA_OUT:\n\t\tcase CURLINFO_SSL_DATA_OUT:\n\t\t\tpool->cgminer_pool_stats.bytes_sent += size;\n\t\t\ttotal_bytes_xfer += size;\n\t\t\tpool->cgminer_pool_stats.net_bytes_sent += size;\n\t\t\tbreak;\n\t\tcase CURLINFO_TEXT:\n\t\t{\n\t\t\tif (!opt_protocol)\n\t\t\t\tbreak;\n\t\t\t// data is not null-terminated, so we need to copy and terminate it for applog\n\t\t\tchar datacp[size + 1];\n\t\t\tmemcpy(datacp, data, size);\n\t\t\twhile (isspace(datacp[size-1]))\n\t\t\t\t--size;\n\t\t\tdatacp[size] = '\\0';\n\t\t\tapplog(LOG_DEBUG, \"Pool %u: %s\", pool->pool_no, datacp);\n\t\t\tbreak;\n\t\t}\n\t\tdefault:\n\t\t\tbreak;\n\t}\n\treturn 0;\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 0
      },
      {
        "idx": 233519,
        "reasoning": "This code is not vulnerable based on the commit message, which explicitly states the fix addressed a stack overflow in a different part of the codebase (Stratum sockaddr handling). The provided snippet focuses on JSON-RPC calls using `curl` and doesn't exhibit any obvious vulnerabilities like buffer overflows or format string bugs.\n\n\n\n",
        "func": "void json_rpc_call_async(CURL *curl, const char *url,\n\t\t      const char *userpass, const char *rpc_req,\n\t\t      bool longpoll,\n\t\t      struct pool *pool, bool share,\n\t\t      void *priv)\n{\n\tstruct json_rpc_call_state *state = malloc(sizeof(struct json_rpc_call_state));\n\t*state = (struct json_rpc_call_state){\n\t\t.priv = priv,\n\t\t.pool = pool,\n\t};\n\tlong timeout = longpoll ? (60 * 60) : 60;\n\tchar len_hdr[64], user_agent_hdr[128];\n\tstruct curl_slist *headers = NULL;\n\n\tif (longpoll)\n\t\tstate->all_data.idlemarker = &pool->lp_socket;\n\n\t/* it is assumed that 'curl' is freshly [re]initialized at this pt */\n\n\tcurl_easy_setopt(curl, CURLOPT_PRIVATE, state);\n\tcurl_easy_setopt(curl, CURLOPT_TIMEOUT, timeout);\n\n\t/* We use DEBUGFUNCTION to count bytes sent/received, and verbose is needed\n\t * to enable it */\n\tcurl_easy_setopt(curl, CURLOPT_DEBUGFUNCTION, curl_debug_cb);\n\tcurl_easy_setopt(curl, CURLOPT_DEBUGDATA, (void *)pool);\n\tcurl_easy_setopt(curl, CURLOPT_VERBOSE, 1);\n\n\tcurl_easy_setopt(curl, CURLOPT_NOSIGNAL, 1);\n\tcurl_easy_setopt(curl, CURLOPT_URL, url);\n\tcurl_easy_setopt(curl, CURLOPT_ENCODING, \"\");\n\tcurl_easy_setopt(curl, CURLOPT_FAILONERROR, 1);\n\n\t/* Shares are staggered already and delays in submission can be costly\n\t * so do not delay them */\n\tif (!opt_delaynet || share)\n\t\tcurl_easy_setopt(curl, CURLOPT_TCP_NODELAY, 1);\n\tcurl_easy_setopt(curl, CURLOPT_WRITEFUNCTION, all_data_cb);\n\tcurl_easy_setopt(curl, CURLOPT_WRITEDATA, &state->all_data);\n\tcurl_easy_setopt(curl, CURLOPT_READFUNCTION, upload_data_cb);\n\tcurl_easy_setopt(curl, CURLOPT_READDATA, &state->upload_data);\n\tcurl_easy_setopt(curl, CURLOPT_ERRORBUFFER, &state->curl_err_str[0]);\n\tcurl_easy_setopt(curl, CURLOPT_FOLLOWLOCATION, 1);\n\tcurl_easy_setopt(curl, CURLOPT_HEADERFUNCTION, resp_hdr_cb);\n\tcurl_easy_setopt(curl, CURLOPT_HEADERDATA, &state->hi);\n\n\tcurl_easy_setopt(curl, CURLOPT_USE_SSL, CURLUSESSL_TRY);\n\tif (pool->rpc_proxy) {\n\t\tcurl_easy_setopt(curl, CURLOPT_PROXY, pool->rpc_proxy);\n\t} else if (opt_socks_proxy) {\n\t\tcurl_easy_setopt(curl, CURLOPT_PROXY, opt_socks_proxy);\n\t\tcurl_easy_setopt(curl, CURLOPT_PROXYTYPE, CURLPROXY_SOCKS4);\n\t}\n\tif (userpass) {\n\t\tcurl_easy_setopt(curl, CURLOPT_USERPWD, userpass);\n\t\tcurl_easy_setopt(curl, CURLOPT_HTTPAUTH, CURLAUTH_BASIC);\n\t}\n\tif (longpoll)\n\t\tcurl_easy_setopt(curl, CURLOPT_SOCKOPTFUNCTION, json_rpc_call_sockopt_cb);\n\tcurl_easy_setopt(curl, CURLOPT_POST, 1);\n\n\tif (opt_protocol)\n\t\tapplog(LOG_DEBUG, \"JSON protocol request:\\n%s\", rpc_req);\n\n\tstate->upload_data.buf = rpc_req;\n\tstate->upload_data.len = strlen(rpc_req);\n\tsprintf(len_hdr, \"Content-Length: %lu\",\n\t\t(unsigned long) state->upload_data.len);\n\tsprintf(user_agent_hdr, \"User-Agent: %s\", PACKAGE_STRING);\n\n\theaders = curl_slist_append(headers,\n\t\t\"Content-type: application/json\");\n\theaders = curl_slist_append(headers,\n\t\t\"X-Mining-Extensions: longpoll midstate rollntime submitold\");\n\n\tif (longpoll)\n\t\theaders = curl_slist_append(headers,\n\t\t\t\"X-Minimum-Wait: 0\");\n\n\tif (likely(global_hashrate)) {\n\t\tchar ghashrate[255];\n\n\t\tsprintf(ghashrate, \"X-Mining-Hashrate: %\"PRIu64, (uint64_t)global_hashrate);\n\t\theaders = curl_slist_append(headers, ghashrate);\n\t}\n\n\theaders = curl_slist_append(headers, len_hdr);\n\theaders = curl_slist_append(headers, user_agent_hdr);\n\theaders = curl_slist_append(headers, \"Expect:\"); /* disable Expect hdr*/\n\n\tcurl_easy_setopt(curl, CURLOPT_HTTPHEADER, headers);\n\tstate->headers = headers;\n\n\tif (opt_delaynet) {\n\t\t/* Don't delay share submission, but still track the nettime */\n\t\tif (!share) {\n\t\t\tlong long now_msecs, last_msecs;\n\t\t\tstruct timeval now, last;\n\n\t\t\tgettimeofday(&now, NULL);\n\t\t\tlast_nettime(&last);\n\t\t\tnow_msecs = (long long)now.tv_sec * 1000;\n\t\t\tnow_msecs += now.tv_usec / 1000;\n\t\t\tlast_msecs = (long long)last.tv_sec * 1000;\n\t\t\tlast_msecs += last.tv_usec / 1000;\n\t\t\tif (now_msecs > last_msecs && now_msecs - last_msecs < 250) {\n\t\t\t\tstruct timespec rgtp;\n\n\t\t\t\trgtp.tv_sec = 0;\n\t\t\t\trgtp.tv_nsec = (250 - (now_msecs - last_msecs)) * 1000000;\n\t\t\t\tnanosleep(&rgtp, NULL);\n\t\t\t}\n\t\t}\n\t\tset_nettime();\n\t}\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 0
      },
      {
        "idx": 233520,
        "reasoning": "This code snippet is not directly related to the reported vulnerability regarding overlong addresses and stack overflows in Stratum's `extract_sockaddr` function. The provided code constructs absolute URIs and, while it uses `sprintf` which *could* be vulnerable to buffer overflows in other contexts, it allocates sufficient memory based on the lengths of the input strings, mitigating that risk here.\n\n\n\n",
        "func": "char *absolute_uri(char *uri, const char *ref)\n{\n\tif (strstr(uri, \"://\"))\n\t\treturn strdup(uri);\n\n\tchar *copy_start, *abs;\n\tbool need_slash = false;\n\n\tcopy_start = (uri[0] == '/') ? &uri[1] : uri;\n\tif (ref[strlen(ref) - 1] != '/')\n\t\tneed_slash = true;\n\n\tabs = malloc(strlen(ref) + strlen(copy_start) + 2);\n\tif (!abs) {\n\t\tapplog(LOG_ERR, \"Malloc failure in absolute_uri\");\n\t\treturn NULL;\n\t}\n\n\tsprintf(abs, \"%s%s%s\", ref, need_slash ? \"/\" : \"\", copy_start);\n\n\treturn abs;\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 0
      },
      {
        "idx": 233521,
        "reasoning": "This code snippet is not directly related to the commit message about a Stratum stack overflow vulnerability when handling overlong addresses. The function `real_block_target` focuses on processing block target data and includes a bounds check (`data[72] < 3 || data[72] > 0x20`) preventing out-of-bounds access, making it safe from the described vulnerability type.\n\n\n\n",
        "func": "void real_block_target(unsigned char *target, const unsigned char *data)\n{\n\tuint8_t targetshift;\n\n\tif (unlikely(data[72] < 3 || data[72] > 0x20))\n\t{\n\t\t// Invalid (out of bounds) target\n\t\tmemset(target, 0xff, 32);\n\t\treturn;\n\t}\n\n\ttargetshift = data[72] - 3;\n\tmemset(target, 0, targetshift);\n\ttarget[targetshift++] = data[75];\n\ttarget[targetshift++] = data[74];\n\ttarget[targetshift++] = data[73];\n\tmemset(&target[targetshift], 0, 0x20 - targetshift);\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 0
      },
      {
        "idx": 233523,
        "reasoning": "This code snippet is not directly related to the reported vulnerability regarding overlong Stratum addresses and potential stack overflows. The commit message specifically addresses an issue in `extract_sockaddr`, while this code defines a function to destroy a file descriptor array \u2013 a separate component of the bfgminer project and not a point of immediate concern for the reported vulnerability.\n\n\n\n",
        "func": "void notifier_destroy(notifier_t fd)\n{\n#ifdef WIN32\n\tclosesocket(fd[0]);\n\tclosesocket(fd[1]);\n#else\n\tclose(fd[0]);\n\tclose(fd[1]);\n#endif\n\tfd[0] = fd[1] = INVSOCK;\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195791,
        "reasoning": "This code is vulnerable to a stack-based buffer overflow because the `url_address` buffer is only 256 bytes long, and `sprintf` is used to copy a potentially much larger `url_begin` string into it without proper bounds checking\u2014as the commit message indicates was the original issue with overlong addresses. Specifically, the `url_len` variable, derived from the input `url`, controls the number of bytes copied by `sprintf`, and a sufficiently long URL can exceed the 256-byte capacity of `url_address`, leading to a buffer overflow.",
        "func": "bool extract_sockaddr(struct pool *pool, char *url)\n{\n\tchar *url_begin, *url_end, *ipv6_begin, *ipv6_end, *port_start = NULL;\n\tchar url_address[256], port[6];\n\tint url_len, port_len = 0;\n\n\turl_begin = strstr(url, \"//\");\n\tif (!url_begin)\n\t\turl_begin = url;\n\telse\n\t\turl_begin += 2;\n\n\t/* Look for numeric ipv6 entries */\n\tipv6_begin = strstr(url_begin, \"[\");\n\tipv6_end = strstr(url_begin, \"]\");\n\tif (ipv6_begin && ipv6_end && ipv6_end > ipv6_begin)\n\t\turl_end = strstr(ipv6_end, \":\");\n\telse\n\t\turl_end = strstr(url_begin, \":\");\n\tif (url_end) {\n\t\turl_len = url_end - url_begin;\n\t\tport_len = strlen(url_begin) - url_len - 1;\n\t\tif (port_len < 1)\n\t\t\treturn false;\n\t\tport_start = url_end + 1;\n\t} else\n\t\turl_len = strlen(url_begin);\n\n\tif (url_len < 1)\n\t\treturn false;\n\n\tsprintf(url_address, \"%.*s\", url_len, url_begin);\n\n\tif (port_len)\n\t\tsnprintf(port, 6, \"%.*s\", port_len, port_start);\n\telse\n\t\tstrcpy(port, \"80\");\n\n\tfree(pool->stratum_port);\n\tpool->stratum_port = strdup(port);\n\tfree(pool->sockaddr_url);\n\tpool->sockaddr_url = strdup(url_address);\n\n\treturn true;\n}",
        "commit_message": "Stratum: extract_sockaddr: Truncate overlong addresses rather than stack overflow\n\nThanks to Mick Ayzenberg <mick@dejavusecurity.com> for finding this!",
        "cve_desc": "Multiple stack-based buffer overflows in sgminer before 4.2.2, cgminer before 4.3.5, and BFGMiner before 3.3.0 allow remote pool servers to have unspecified impact via a long URL in a client.reconnect stratum message to the (1) extract_sockaddr or (2) parse_reconnect functions in util.c.",
        "target": 1
      }
    ]
  },
  "bootstrap-dht": {
    "0": [
      {
        "idx": 516834,
        "reasoning": "This code snippet is not flagged as vulnerable because it performs a read operation on a `lazy_entry` object and checks the type before accessing the string value. The check `e->type() != lazy_entry::string_t` prevents accessing `string_value()` on an entry that isn't a string, mitigating potential crashes or unexpected behavior, and there's no apparent input validation issue leading to memory corruption or other exploits.\n",
        "func": "\tstd::string lazy_entry::list_string_value_at(int i) const\n\t{\n\t\tlazy_entry const* e = list_at(i);\n\t\tif (e == 0 || e->type() != lazy_entry::string_t) return std::string();\n\t\treturn e->string_value();\n\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 0
      },
      {
        "idx": 516835,
        "reasoning": "This code snippet is safe and doesn't introduce any immediately apparent vulnerabilities. It simply defines a static error category for `lazy_bdecode` within the `libtorrent` library, which doesn't handle external input or perform any potentially dangerous operations itself. \n\n\n\n",
        "func": "\tboost::system::error_category& get_bdecode_category()\n\t{\n\t\tstatic bdecode_error_category bdecode_category;\n\t\treturn bdecode_category;\n\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 0
      },
      {
        "idx": 516836,
        "reasoning": "This code snippet is not vulnerable because it simply decrements a size counter (`m_size`) if it's greater than zero. There's no external input, memory manipulation, or logical flaw present that would introduce a security risk; it's a basic internal state update.",
        "func": "\tvoid lazy_entry::pop()\n\t{\n\t\tif (m_size > 0) --m_size;\n\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 0
      },
      {
        "idx": 516837,
        "reasoning": "This code snippet appears safe as it includes robust overflow checks before each multiplication and addition within the integer parsing loop, preventing potential integer overflow vulnerabilities. Additionally, it validates input characters to ensure they are numeric, mitigating risks associated with unexpected input.\n",
        "func": "\tchar const* parse_int(char const* start, char const* end, char delimiter\n\t\t, boost::int64_t& val, bdecode_errors::error_code_enum& ec)\n\t{\n\t\twhile (start < end && *start != delimiter)\n\t\t{\n\t\t\tif (!numeric(*start))\n\t\t\t{\n\t\t\t\tec = bdecode_errors::expected_string;\n\t\t\t\treturn start;\n\t\t\t}\n\t\t\tif (val > INT64_MAX / 10)\n\t\t\t{\n\t\t\t\tec = bdecode_errors::overflow;\n\t\t\t\treturn start;\n\t\t\t}\n\t\t\tval *= 10;\n\t\t\tint digit = *start - '0';\n\t\t\tif (val > INT64_MAX - digit)\n\t\t\t{\n\t\t\t\tec = bdecode_errors::overflow;\n\t\t\t\treturn start;\n\t\t\t}\n\t\t\tval += digit;\n\t\t\t++start;\n\t\t}\n\t\tif (*start != delimiter)\n\t\t\tec = bdecode_errors::expected_colon;\n\t\treturn start;\n\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 0
      },
      {
        "idx": 516838,
        "reasoning": "This code snippet appears safe as it focuses on managing a stack of `lazy_entry` objects during bdecode parsing and handles potential errors by popping elements or setting an error position. There are no immediately obvious memory safety issues, input validation problems, or logic flaws that would typically lead to vulnerabilities like buffer overflows or injection attacks within this specific function's scope.",
        "func": "\t\tint fail(int* error_pos\n\t\t\t, std::vector<lazy_entry*>& stack\n\t\t\t, char const* start\n\t\t\t, char const* orig_start)\n\t\t{\n\t\t\twhile (!stack.empty()) {\n\t\t\t\tlazy_entry* top = stack.back();\n\t\t\t\tif (top->type() == lazy_entry::dict_t || top->type() == lazy_entry::list_t)\n\t\t\t\t{\n\t\t\t\t\ttop->pop();\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tstack.pop_back();\n\t\t\t}\n\t\t\tif (error_pos) *error_pos = start - orig_start;\n\t\t\treturn -1;\n\t\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 217121,
        "reasoning": "The `lazy_bdecode` function is vulnerable to an out-of-bounds read due to improper indexing when parsing the bencoded data, specifically within the string and integer parsing sections where length calculations are used to advance the `start` pointer. A crafted input can manipulate these length values to cause `start` to exceed the bounds of the input buffer (`end`), leading to a read beyond allocated memory and potential arbitrary code execution.",
        "func": "\tint lazy_bdecode(char const* start, char const* end, lazy_entry& ret\n\t\t, error_code& ec, int* error_pos, int depth_limit, int item_limit)\n\t{\n\t\tchar const* const orig_start = start;\n\t\tret.clear();\n\t\tif (start == end) return 0;\n\n\t\tstd::vector<lazy_entry*> stack;\n\n\t\tstack.push_back(&ret);\n\t\twhile (start < end)\n\t\t{\n\t\t\tif (stack.empty()) break; // done!\n\n\t\t\tlazy_entry* top = stack.back();\n\n\t\t\tif (int(stack.size()) > depth_limit) TORRENT_FAIL_BDECODE(bdecode_errors::depth_exceeded);\n\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\tchar t = *start;\n\t\t\t++start;\n\t\t\tif (start >= end && t != 'e') TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\n\t\t\tswitch (top->type())\n\t\t\t{\n\t\t\t\tcase lazy_entry::dict_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tif (!is_digit(t)) TORRENT_FAIL_BDECODE(bdecode_errors::expected_string);\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tstart = parse_int(start, end, ':', len);\n\t\t\t\t\tif (start == 0 || start + len + 3 > end || *start != ':')\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::expected_colon);\n\t\t\t\t\t++start;\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tlazy_entry* ent = top->dict_append(start);\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstart += len;\n\t\t\t\t\tif (start >= end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tt = *start;\n\t\t\t\t\t++start;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tcase lazy_entry::list_t:\n\t\t\t\t{\n\t\t\t\t\tif (t == 'e')\n\t\t\t\t\t{\n\t\t\t\t\t\ttop->set_end(start);\n\t\t\t\t\t\tstack.pop_back();\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tlazy_entry* ent = top->list_append();\n\t\t\t\t\tif (ent == 0) TORRENT_FAIL_BDECODE(boost::system::errc::not_enough_memory);\n\t\t\t\t\tstack.push_back(ent);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tdefault: break;\n\t\t\t}\n\n\t\t\t--item_limit;\n\t\t\tif (item_limit <= 0) TORRENT_FAIL_BDECODE(bdecode_errors::limit_exceeded);\n\n\t\t\ttop = stack.back();\n\t\t\tswitch (t)\n\t\t\t{\n\t\t\t\tcase 'd':\n\t\t\t\t\ttop->construct_dict(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'l':\n\t\t\t\t\ttop->construct_list(start - 1);\n\t\t\t\t\tcontinue;\n\t\t\t\tcase 'i':\n\t\t\t\t{\n\t\t\t\t\tchar const* int_start = start;\n\t\t\t\t\tstart = find_char(start, end, 'e');\n\t\t\t\t\ttop->construct_int(int_start, start - int_start);\n\t\t\t\t\tif (start == end) TORRENT_FAIL_BDECODE(bdecode_errors::unexpected_eof);\n\t\t\t\t\tTORRENT_ASSERT(*start == 'e');\n\t\t\t\t\t++start;\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tdefault:\n\t\t\t\t{\n\t\t\t\t\tif (!is_digit(t))\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::expected_value);\n\n\t\t\t\t\tboost::int64_t len = t - '0';\n\t\t\t\t\tstart = parse_int(start, end, ':', len);\n\t\t\t\t\tif (start == 0 || start + len + 1 > end || *start != ':')\n\t\t\t\t\t\tTORRENT_FAIL_BDECODE(bdecode_errors::expected_colon);\n\t\t\t\t\t++start;\n\t\t\t\t\ttop->construct_string(start, int(len));\n\t\t\t\t\tstack.pop_back();\n\t\t\t\t\tstart += len;\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t\treturn 0;\n\t}",
        "commit_message": "update version of lazy_bdecode from libtorrent",
        "cve_desc": "The lazy_bdecode function in BitTorrent bootstrap-dht (aka Bootstrap) allows remote attackers to execute arbitrary code via a crafted packet, which triggers an out-of-bounds read, related to \"Improper Indexing.\"",
        "target": 1
      }
    ]
  },
  "bsdiff4": {
    "0": [],
    "1": []
  },
  "bwm-ng": {
    "0": [],
    "1": []
  },
  "bzip2": {
    "0": [],
    "1": []
  },
  "c-ares": {
    "0": [],
    "1": [
      {
        "idx": 210618,
        "reasoning": "The code is vulnerable because it doesn't sufficiently validate the length of the input buffer (`abuf`) before reading data for the NAPTR record's fields (order, preference, flags, service, regexp, replacement). A malicious actor could craft a DNS response with carefully designed lengths in the NAPTR record, causing `ares_parse_naptr_reply` to read beyond the bounds of `abuf`, leading to a buffer over-read.",
        "func": "ares_parse_naptr_reply (const unsigned char *abuf, int alen,\n                        struct ares_naptr_reply **naptr_out)\n{\n  unsigned int qdcount, ancount, i;\n  const unsigned char *aptr, *vptr;\n  int status, rr_type, rr_class, rr_len;\n  long len;\n  char *hostname = NULL, *rr_name = NULL;\n  struct ares_naptr_reply *naptr_head = NULL;\n  struct ares_naptr_reply *naptr_last = NULL;\n  struct ares_naptr_reply *naptr_curr;\n\n  /* Set *naptr_out to NULL for all failure cases. */\n  *naptr_out = NULL;\n\n  /* Give up if abuf doesn't have room for a header. */\n  if (alen < HFIXEDSZ)\n    return ARES_EBADRESP;\n\n  /* Fetch the question and answer count from the header. */\n  qdcount = DNS_HEADER_QDCOUNT (abuf);\n  ancount = DNS_HEADER_ANCOUNT (abuf);\n  if (qdcount != 1)\n    return ARES_EBADRESP;\n  if (ancount == 0)\n    return ARES_ENODATA;\n\n  /* Expand the name from the question, and skip past the question. */\n  aptr = abuf + HFIXEDSZ;\n  status = ares_expand_name (aptr, abuf, alen, &hostname, &len);\n  if (status != ARES_SUCCESS)\n    return status;\n\n  if (aptr + len + QFIXEDSZ > abuf + alen)\n    {\n      ares_free (hostname);\n      return ARES_EBADRESP;\n    }\n  aptr += len + QFIXEDSZ;\n\n  /* Examine each answer resource record (RR) in turn. */\n  for (i = 0; i < ancount; i++)\n    {\n      /* Decode the RR up to the data field. */\n      status = ares_expand_name (aptr, abuf, alen, &rr_name, &len);\n      if (status != ARES_SUCCESS)\n        {\n          break;\n        }\n      aptr += len;\n      if (aptr + RRFIXEDSZ > abuf + alen)\n        {\n          status = ARES_EBADRESP;\n          break;\n        }\n      rr_type = DNS_RR_TYPE (aptr);\n      rr_class = DNS_RR_CLASS (aptr);\n      rr_len = DNS_RR_LEN (aptr);\n      aptr += RRFIXEDSZ;\n      if (aptr + rr_len > abuf + alen)\n        {\n          status = ARES_EBADRESP;\n          break;\n        }\n\n      /* Check if we are really looking at a NAPTR record */\n      if (rr_class == C_IN && rr_type == T_NAPTR)\n        {\n          /* parse the NAPTR record itself */\n\n          /* Allocate storage for this NAPTR answer appending it to the list */\n          naptr_curr = ares_malloc_data(ARES_DATATYPE_NAPTR_REPLY);\n          if (!naptr_curr)\n            {\n              status = ARES_ENOMEM;\n              break;\n            }\n          if (naptr_last)\n            {\n              naptr_last->next = naptr_curr;\n            }\n          else\n            {\n              naptr_head = naptr_curr;\n            }\n          naptr_last = naptr_curr;\n\n          vptr = aptr;\n          naptr_curr->order = DNS__16BIT(vptr);\n          vptr += sizeof(unsigned short);\n          naptr_curr->preference = DNS__16BIT(vptr);\n          vptr += sizeof(unsigned short);\n\n          status = ares_expand_string(vptr, abuf, alen, &naptr_curr->flags, &len);\n          if (status != ARES_SUCCESS)\n            break;\n          vptr += len;\n\n          status = ares_expand_string(vptr, abuf, alen, &naptr_curr->service, &len);\n          if (status != ARES_SUCCESS)\n            break;\n          vptr += len;\n\n          status = ares_expand_string(vptr, abuf, alen, &naptr_curr->regexp, &len);\n          if (status != ARES_SUCCESS)\n            break;\n          vptr += len;\n\n          status = ares_expand_name(vptr, abuf, alen, &naptr_curr->replacement, &len);\n          if (status != ARES_SUCCESS)\n            break;\n        }\n\n      /* Don't lose memory in the next iteration */\n      ares_free (rr_name);\n      rr_name = NULL;\n\n      /* Move on to the next record */\n      aptr += rr_len;\n    }\n\n  if (hostname)\n    ares_free (hostname);\n  if (rr_name)\n    ares_free (rr_name);\n\n  /* clean up on error */\n  if (status != ARES_SUCCESS)\n    {\n      if (naptr_head)\n        ares_free_data (naptr_head);\n      return status;\n    }\n\n  /* everything looks fine, return the data */\n  *naptr_out = naptr_head;\n\n  return ARES_SUCCESS;\n}",
        "commit_message": "ares_parse_naptr_reply: check sufficient data\n\nCheck that there is enough data for the required elements\nof an NAPTR record (2 int16, 3 bytes for string lengths)\nbefore processing a record.",
        "cve_desc": "The c-ares function `ares_parse_naptr_reply()`, which is used for parsing NAPTR responses, could be triggered to read memory outside of the given input buffer if the passed in DNS response packet was crafted in a particular way.",
        "target": 1
      }
    ]
  },
  "c-blosc2": {
    "0": [],
    "1": []
  },
  "ceph": {
    "0": [
      {
        "idx": 292102,
        "reasoning": "This code is likely safe as it addresses a specific issue of checking for null elements within the tagging field of POST requests, preventing potential crashes or unexpected behavior when parsing malformed XML. The commit message and code snippet demonstrate a defensive programming approach by validating the XML structure and handling potential parsing errors, rather than introducing new vulnerabilities.\n\n\n\n",
        "func": "int RGWPostObj_ObjStore_S3::get_tags()\n{\n  string tags_str;\n  if (part_str(parts, \"tagging\", &tags_str)) {\n    RGWObjTagsXMLParser parser;\n    if (!parser.init()){\n      ldout(s->cct, 0) << \"Couldn't init RGWObjTags XML parser\" << dendl;\n      err_msg = \"Server couldn't process the request\";\n      return -EINVAL; // TODO: This class of errors in rgw code should be a 5XX error\n    }\n    if (!parser.parse(tags_str.c_str(), tags_str.size(), 1)) {\n      ldout(s->cct,0 ) << \"Invalid Tagging XML\" << dendl;\n      err_msg = \"Invalid Tagging XML\";\n      return -EINVAL;\n    }\n\n    RGWObjTagSet_S3 *obj_tags_s3;\n    RGWObjTagging_S3 *tagging;\n\n    tagging = static_cast<RGWObjTagging_S3 *>(parser.find_first(\"Tagging\"));\n    if (!tagging) {\n      return -ERR_MALFORMED_XML;\n    }\n    obj_tags_s3 = static_cast<RGWObjTagSet_S3 *>(tagging->find_first(\"TagSet\"));\n    if(!obj_tags_s3){\n      return -ERR_MALFORMED_XML;\n    }\n\n    RGWObjTags obj_tags;\n    int r = obj_tags_s3->rebuild(obj_tags);\n    if (r < 0)\n      return r;\n\n    bufferlist tags_bl;\n    obj_tags.encode(tags_bl);\n    ldout(s->cct, 20) << \"Read \" << obj_tags.count() << \"tags\" << dendl;\n    attrs[RGW_ATTR_TAGS] = tags_bl;\n  }\n\n\n  return 0;\n}",
        "commit_message": "rgw: check for tagging element in POST Obj requests\n\nCheck for null element when reading the tagging field from POST obj XML\n\nFixes: https://tracker.ceph.com/issues/44967\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "An issue was discovered in Ceph through 13.2.9. A POST request with an invalid tagging XML can crash the RGW process by triggering a NULL pointer exception.",
        "target": 0
      },
      {
        "idx": 292103,
        "reasoning": "This code is safe as the commit specifically addresses a potential vulnerability by adding a `try-catch` block when decoding the `RGW_ATTR_TAGS` attribute, preventing crashes due to malformed tagging data in POST requests. The fix ensures that errors during tag decoding are handled gracefully, logging the error instead of causing a program termination, thus mitigating the risk of a denial-of-service.\n\n\n\n",
        "func": "int RGWGetObj_ObjStore_S3::send_response_data(bufferlist& bl, off_t bl_ofs,\n\t\t\t\t\t      off_t bl_len)\n{\n  const char *content_type = NULL;\n  string content_type_str;\n  map<string, string> response_attrs;\n  map<string, string>::iterator riter;\n  bufferlist metadata_bl;\n\n  if (sent_header)\n    goto send_data;\n\n  if (custom_http_ret) {\n    set_req_state_err(s, 0);\n    dump_errno(s, custom_http_ret);\n  } else {\n    set_req_state_err(s, (partial_content && !op_ret) ? STATUS_PARTIAL_CONTENT\n                  : op_ret);\n    dump_errno(s);\n  }\n\n  if (op_ret)\n    goto done;\n\n  if (range_str)\n    dump_range(s, start, end, s->obj_size);\n\n  if (s->system_request &&\n      s->info.args.exists(RGW_SYS_PARAM_PREFIX \"prepend-metadata\")) {\n\n    dump_header(s, \"Rgwx-Object-Size\", (long long)total_len);\n\n    if (rgwx_stat) {\n      /*\n       * in this case, we're not returning the object's content, only the prepended\n       * extra metadata\n       */\n      total_len = 0;\n    }\n\n    /* JSON encode object metadata */\n    JSONFormatter jf;\n    jf.open_object_section(\"obj_metadata\");\n    encode_json(\"attrs\", attrs, &jf);\n    utime_t ut(lastmod);\n    encode_json(\"mtime\", ut, &jf);\n    jf.close_section();\n    stringstream ss;\n    jf.flush(ss);\n    metadata_bl.append(ss.str());\n    dump_header(s, \"Rgwx-Embedded-Metadata-Len\", metadata_bl.length());\n    total_len += metadata_bl.length();\n  }\n\n  if (s->system_request && !real_clock::is_zero(lastmod)) {\n    /* we end up dumping mtime in two different methods, a bit redundant */\n    dump_epoch_header(s, \"Rgwx-Mtime\", lastmod);\n    uint64_t pg_ver = 0;\n    int r = decode_attr_bl_single_value(attrs, RGW_ATTR_PG_VER, &pg_ver, (uint64_t)0);\n    if (r < 0) {\n      ldout(s->cct, 0) << \"ERROR: failed to decode pg ver attr, ignoring\" << dendl;\n    }\n    dump_header(s, \"Rgwx-Obj-PG-Ver\", pg_ver);\n\n    uint32_t source_zone_short_id = 0;\n    r = decode_attr_bl_single_value(attrs, RGW_ATTR_SOURCE_ZONE, &source_zone_short_id, (uint32_t)0);\n    if (r < 0) {\n      ldout(s->cct, 0) << \"ERROR: failed to decode pg ver attr, ignoring\" << dendl;\n    }\n    if (source_zone_short_id != 0) {\n      dump_header(s, \"Rgwx-Source-Zone-Short-Id\", source_zone_short_id);\n    }\n  }\n\n  for (auto &it : crypt_http_responses)\n    dump_header(s, it.first, it.second);\n\n  dump_content_length(s, total_len);\n  dump_last_modified(s, lastmod);\n  dump_header_if_nonempty(s, \"x-amz-version-id\", version_id);\n\n  if (! op_ret) {\n    if (! lo_etag.empty()) {\n      /* Handle etag of Swift API's large objects (DLO/SLO). It's entirerly\n       * legit to perform GET on them through S3 API. In such situation,\n       * a client should receive the composited content with corresponding\n       * etag value. */\n      dump_etag(s, lo_etag);\n    } else {\n      auto iter = attrs.find(RGW_ATTR_ETAG);\n      if (iter != attrs.end()) {\n        dump_etag(s, iter->second.to_str());\n      }\n    }\n\n    for (struct response_attr_param *p = resp_attr_params; p->param; p++) {\n      bool exists;\n      string val = s->info.args.get(p->param, &exists);\n      if (exists) {\n\t/* reject unauthenticated response header manipulation, see\n\t * https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html */\n\tif (s->auth.identity->is_anonymous()) {\n\t  return -ERR_INVALID_REQUEST;\n\t}\n        /* HTTP specification says no control characters should be present in\n         * header values: https://tools.ietf.org/html/rfc7230#section-3.2\n         *      field-vchar    = VCHAR / obs-text\n         *\n         * Failure to validate this permits a CRLF injection in HTTP headers,\n         * whereas S3 GetObject only permits specific headers.\n         */\n        if(str_has_cntrl(val)) {\n          /* TODO: return a more distinct error in future;\n           * stating what the problem is */\n          return -ERR_INVALID_REQUEST;\n        }\n\n\tif (strcmp(p->param, \"response-content-type\") != 0) {\n\t  response_attrs[p->http_attr] = val;\n\t} else {\n\t  content_type_str = val;\n\t  content_type = content_type_str.c_str();\n\t}\n      }\n    }\n\n    for (auto iter = attrs.begin(); iter != attrs.end(); ++iter) {\n      const char *name = iter->first.c_str();\n      map<string, string>::iterator aiter = rgw_to_http_attrs.find(name);\n      if (aiter != rgw_to_http_attrs.end()) {\n        if (response_attrs.count(aiter->second) == 0) {\n          /* Was not already overridden by a response param. */\n          response_attrs[aiter->second] = iter->second.c_str();\n        }\n      } else if (iter->first.compare(RGW_ATTR_CONTENT_TYPE) == 0) {\n        /* Special handling for content_type. */\n        if (!content_type) {\n          content_type = iter->second.c_str();\n        }\n      } else if (strcmp(name, RGW_ATTR_SLO_UINDICATOR) == 0) {\n        // this attr has an extra length prefix from encode() in prior versions\n        dump_header(s, \"X-Object-Meta-Static-Large-Object\", \"True\");\n      } else if (strncmp(name, RGW_ATTR_META_PREFIX,\n\t\t\t sizeof(RGW_ATTR_META_PREFIX)-1) == 0) {\n        /* User custom metadata. */\n        name += sizeof(RGW_ATTR_PREFIX) - 1;\n        dump_header(s, name, iter->second);\n      } else if (iter->first.compare(RGW_ATTR_TAGS) == 0) {\n        RGWObjTags obj_tags;\n        try{\n          bufferlist::iterator it = iter->second.begin();\n          obj_tags.decode(it);\n        } catch (buffer::error &err) {\n          ldout(s->cct,0) << \"Error caught buffer::error couldn't decode TagSet \" << dendl;\n        }\n        dump_header(s, RGW_AMZ_TAG_COUNT, obj_tags.count());\n      }\n    }\n  }\n\ndone:\n  for (riter = response_attrs.begin(); riter != response_attrs.end();\n       ++riter) {\n    dump_header(s, riter->first, riter->second);\n  }\n\n  if (op_ret == -ERR_NOT_MODIFIED) {\n      end_header(s, this);\n  } else {\n      if (!content_type)\n          content_type = \"binary/octet-stream\";\n\n      end_header(s, this, content_type);\n  }\n\n  if (metadata_bl.length()) {\n    dump_body(s, metadata_bl);\n  }\n  sent_header = true;\n\nsend_data:\n  if (get_data && !op_ret) {\n    int r = dump_body(s, bl.c_str() + bl_ofs, bl_len);\n    if (r < 0)\n      return r;\n  }\n\n  return 0;\n}",
        "commit_message": "rgw: check for tagging element in POST Obj requests\n\nCheck for null element when reading the tagging field from POST obj XML\n\nFixes: https://tracker.ceph.com/issues/44967\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "An issue was discovered in Ceph through 13.2.9. A POST request with an invalid tagging XML can crash the RGW process by triggering a NULL pointer exception.",
        "target": 0
      },
      {
        "idx": 292104,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message describes a fix for handling potentially null tagging elements in RGW POST requests, and the code itself simply defines a helper function to check for control characters within a string \u2013 it doesn't introduce any new vulnerabilities related to input handling or data processing.\n\n\n\n",
        "func": "inline bool str_has_cntrl(const char* s) {\n  std::string _s(s);\n  return str_has_cntrl(_s);\n}",
        "commit_message": "rgw: check for tagging element in POST Obj requests\n\nCheck for null element when reading the tagging field from POST obj XML\n\nFixes: https://tracker.ceph.com/issues/44967\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "An issue was discovered in Ceph through 13.2.9. A POST request with an invalid tagging XML can crash the RGW process by triggering a NULL pointer exception.",
        "target": 0
      },
      {
        "idx": 292105,
        "reasoning": "This code snippet is not vulnerable. It defines a utility function `str_has_cntrl` to check for control characters within a string, which is a safe string handling practice and doesn't introduce any exploitable weaknesses based on the commit message's context of validating XML tagging data during object storage requests. \n\n\n\n",
        "func": "inline bool str_has_cntrl(const std::string s) {\n  return std::any_of(s.begin(), s.end(), ::iscntrl);\n}",
        "commit_message": "rgw: check for tagging element in POST Obj requests\n\nCheck for null element when reading the tagging field from POST obj XML\n\nFixes: https://tracker.ceph.com/issues/44967\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "An issue was discovered in Ceph through 13.2.9. A POST request with an invalid tagging XML can crash the RGW process by triggering a NULL pointer exception.",
        "target": 0
      },
      {
        "idx": 292246,
        "reasoning": "This code is likely safe as the commit message indicates a change from returning `EPERM` (permission denied) to `ERR_INVALID_REQUEST`\u2014a more accurate error code according to the S3 specification\u2014and doesn't introduce any new functionality that could create vulnerabilities. The code focuses on handling error documents and includes multiple permission checks (`init_permissions`, `read_permissions`, `verify_permission`) which suggest a focus on secure access control rather than introducing weaknesses.\n\n\n\n",
        "func": "int RGWHandler_REST_S3Website::serve_errordoc(int http_ret, const string& errordoc_key) {\n  int ret = 0;\n  s->formatter->reset(); /* Try to throw it all away */\n\n  std::shared_ptr<RGWGetObj_ObjStore_S3Website> getop( static_cast<RGWGetObj_ObjStore_S3Website*>(op_get()));\n  if (getop.get() == NULL) {\n    return -1; // Trigger double error handler\n  }\n  getop->init(store, s, this);\n  getop->range_str = NULL;\n  getop->if_mod = NULL;\n  getop->if_unmod = NULL;\n  getop->if_match = NULL;\n  getop->if_nomatch = NULL;\n  s->object = errordoc_key;\n\n  ret = init_permissions(getop.get());\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, init_permissions ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  ret = read_permissions(getop.get());\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, read_permissions ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  if (http_ret) {\n     getop->set_custom_http_response(http_ret);\n  }\n\n  ret = getop->init_processing();\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, init_processing ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  ret = getop->verify_op_mask();\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, verify_op_mask ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  ret = getop->verify_permission();\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, verify_permission ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  ret = getop->verify_params();\n  if (ret < 0) {\n    ldpp_dout(s, 20) << \"serve_errordoc failed, verify_params ret=\" << ret << dendl;\n    return -1; // Trigger double error handler\n  }\n\n  // No going back now\n  getop->pre_exec();\n  /*\n   * FIXME Missing headers:\n   * With a working errordoc, the s3 error fields are rendered as HTTP headers,\n   *   x-amz-error-code: NoSuchKey\n   *   x-amz-error-message: The specified key does not exist.\n   *   x-amz-error-detail-Key: foo\n   */\n  getop->execute();\n  getop->complete();\n  return 0;\n\n}",
        "commit_message": "rgw: EPERM to ERR_INVALID_REQUEST\n\nAs per Robin's comments and S3 spec\n\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "A flaw was found in the Ceph Object Gateway, where it supports request sent by an anonymous user in Amazon S3. This flaw could lead to potential XSS attacks due to the lack of proper neutralization of untrusted input.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 199758,
        "reasoning": "This code is vulnerable to a NULL pointer dereference because it doesn't check if `tagging` is null before attempting to call `tagging->find_first(\"TagSet\")`. If the XML lacks a \"Tagging\" element, `tagging` will be null, leading to a crash when `find_first` is called on it, as described in the CVE.",
        "func": "int RGWPostObj_ObjStore_S3::get_tags()\n{\n  string tags_str;\n  if (part_str(parts, \"tagging\", &tags_str)) {\n    RGWObjTagsXMLParser parser;\n    if (!parser.init()){\n      ldout(s->cct, 0) << \"Couldn't init RGWObjTags XML parser\" << dendl;\n      err_msg = \"Server couldn't process the request\";\n      return -EINVAL; // TODO: This class of errors in rgw code should be a 5XX error\n    }\n    if (!parser.parse(tags_str.c_str(), tags_str.size(), 1)) {\n      ldout(s->cct,0 ) << \"Invalid Tagging XML\" << dendl;\n      err_msg = \"Invalid Tagging XML\";\n      return -EINVAL;\n    }\n\n    RGWObjTagSet_S3 *obj_tags_s3;\n    RGWObjTagging_S3 *tagging;\n\n    tagging = static_cast<RGWObjTagging_S3 *>(parser.find_first(\"Tagging\"));\n    obj_tags_s3 = static_cast<RGWObjTagSet_S3 *>(tagging->find_first(\"TagSet\"));\n    if(!obj_tags_s3){\n      return -ERR_MALFORMED_XML;\n    }\n\n    RGWObjTags obj_tags;\n    int r = obj_tags_s3->rebuild(obj_tags);\n    if (r < 0)\n      return r;\n\n    bufferlist tags_bl;\n    obj_tags.encode(tags_bl);\n    ldout(s->cct, 20) << \"Read \" << obj_tags.count() << \"tags\" << dendl;\n    attrs[RGW_ATTR_TAGS] = tags_bl;\n  }\n\n\n  return 0;\n}",
        "commit_message": "rgw: check for tagging element in POST Obj requests\n\nCheck for null element when reading the tagging field from POST obj XML\n\nFixes: https://tracker.ceph.com/issues/44967\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "An issue was discovered in Ceph through 13.2.9. A POST request with an invalid tagging XML can crash the RGW process by triggering a NULL pointer exception.",
        "target": 1
      },
      {
        "idx": 199768,
        "reasoning": "The code is vulnerable to XSS attacks because it allows anonymous users to potentially manipulate response headers via the `response-content-type` parameter without proper sanitization, as highlighted by the CVE description. Specifically, the code checks for anonymous users but only rejects manipulation of *all* response headers except `response-content-type`, creating a pathway for injecting malicious content through that specific header.",
        "func": "int RGWGetObj_ObjStore_S3::send_response_data(bufferlist& bl, off_t bl_ofs,\n\t\t\t\t\t      off_t bl_len)\n{\n  const char *content_type = NULL;\n  string content_type_str;\n  map<string, string> response_attrs;\n  map<string, string>::iterator riter;\n  bufferlist metadata_bl;\n\n  string expires = get_s3_expiration_header(s, lastmod);\n\n  if (sent_header)\n    goto send_data;\n\n  if (custom_http_ret) {\n    set_req_state_err(s, 0);\n    dump_errno(s, custom_http_ret);\n  } else {\n    set_req_state_err(s, (partial_content && !op_ret) ? STATUS_PARTIAL_CONTENT\n                  : op_ret);\n    dump_errno(s);\n  }\n\n  if (op_ret)\n    goto done;\n\n  if (range_str)\n    dump_range(s, start, end, s->obj_size);\n\n  if (s->system_request &&\n      s->info.args.exists(RGW_SYS_PARAM_PREFIX \"prepend-metadata\")) {\n\n    dump_header(s, \"Rgwx-Object-Size\", (long long)total_len);\n\n    if (rgwx_stat) {\n      /*\n       * in this case, we're not returning the object's content, only the prepended\n       * extra metadata\n       */\n      total_len = 0;\n    }\n\n    /* JSON encode object metadata */\n    JSONFormatter jf;\n    jf.open_object_section(\"obj_metadata\");\n    encode_json(\"attrs\", attrs, &jf);\n    utime_t ut(lastmod);\n    encode_json(\"mtime\", ut, &jf);\n    jf.close_section();\n    stringstream ss;\n    jf.flush(ss);\n    metadata_bl.append(ss.str());\n    dump_header(s, \"Rgwx-Embedded-Metadata-Len\", metadata_bl.length());\n    total_len += metadata_bl.length();\n  }\n\n  if (s->system_request && !real_clock::is_zero(lastmod)) {\n    /* we end up dumping mtime in two different methods, a bit redundant */\n    dump_epoch_header(s, \"Rgwx-Mtime\", lastmod);\n    uint64_t pg_ver = 0;\n    int r = decode_attr_bl_single_value(attrs, RGW_ATTR_PG_VER, &pg_ver, (uint64_t)0);\n    if (r < 0) {\n      ldpp_dout(this, 0) << \"ERROR: failed to decode pg ver attr, ignoring\" << dendl;\n    }\n    dump_header(s, \"Rgwx-Obj-PG-Ver\", pg_ver);\n\n    uint32_t source_zone_short_id = 0;\n    r = decode_attr_bl_single_value(attrs, RGW_ATTR_SOURCE_ZONE, &source_zone_short_id, (uint32_t)0);\n    if (r < 0) {\n      ldpp_dout(this, 0) << \"ERROR: failed to decode pg ver attr, ignoring\" << dendl;\n    }\n    if (source_zone_short_id != 0) {\n      dump_header(s, \"Rgwx-Source-Zone-Short-Id\", source_zone_short_id);\n    }\n  }\n\n  for (auto &it : crypt_http_responses)\n    dump_header(s, it.first, it.second);\n\n  dump_content_length(s, total_len);\n  dump_last_modified(s, lastmod);\n  dump_header_if_nonempty(s, \"x-amz-version-id\", version_id);\n  dump_header_if_nonempty(s, \"x-amz-expiration\", expires);\n\n  if (attrs.find(RGW_ATTR_APPEND_PART_NUM) != attrs.end()) {\n    dump_header(s, \"x-rgw-object-type\", \"Appendable\");\n    dump_header(s, \"x-rgw-next-append-position\", s->obj_size);\n  } else {\n    dump_header(s, \"x-rgw-object-type\", \"Normal\");\n  }\n\n  if (! op_ret) {\n    if (! lo_etag.empty()) {\n      /* Handle etag of Swift API's large objects (DLO/SLO). It's entirerly\n       * legit to perform GET on them through S3 API. In such situation,\n       * a client should receive the composited content with corresponding\n       * etag value. */\n      dump_etag(s, lo_etag);\n    } else {\n      auto iter = attrs.find(RGW_ATTR_ETAG);\n      if (iter != attrs.end()) {\n        dump_etag(s, iter->second.to_str());\n      }\n    }\n\n    for (struct response_attr_param *p = resp_attr_params; p->param; p++) {\n      bool exists;\n      string val = s->info.args.get(p->param, &exists);\n      if (exists) {\n\t/* reject unauthenticated response header manipulation, see\n\t * https://docs.aws.amazon.com/AmazonS3/latest/API/API_GetObject.html */\n\tif (s->auth.identity->is_anonymous()) {\n\t  return -EPERM;\n\t}\n\tif (strcmp(p->param, \"response-content-type\") != 0) {\n\t  response_attrs[p->http_attr] = val;\n\t} else {\n\t  content_type_str = val;\n\t  content_type = content_type_str.c_str();\n\t}\n      }\n    }\n\n    for (auto iter = attrs.begin(); iter != attrs.end(); ++iter) {\n      const char *name = iter->first.c_str();\n      map<string, string>::iterator aiter = rgw_to_http_attrs.find(name);\n      if (aiter != rgw_to_http_attrs.end()) {\n        if (response_attrs.count(aiter->second) == 0) {\n          /* Was not already overridden by a response param. */\n\n          size_t len = iter->second.length();\n          string s(iter->second.c_str(), len);\n          while (len && !s[len - 1]) {\n            --len;\n            s.resize(len);\n          }\n          response_attrs[aiter->second] = s;\n        }\n      } else if (iter->first.compare(RGW_ATTR_CONTENT_TYPE) == 0) {\n        /* Special handling for content_type. */\n        if (!content_type) {\n          content_type_str = rgw_bl_str(iter->second);\n          content_type = content_type_str.c_str();\n        }\n      } else if (strcmp(name, RGW_ATTR_SLO_UINDICATOR) == 0) {\n        // this attr has an extra length prefix from encode() in prior versions\n        dump_header(s, \"X-Object-Meta-Static-Large-Object\", \"True\");\n      } else if (strncmp(name, RGW_ATTR_META_PREFIX,\n\t\t\t sizeof(RGW_ATTR_META_PREFIX)-1) == 0) {\n        /* User custom metadata. */\n        name += sizeof(RGW_ATTR_PREFIX) - 1;\n        dump_header(s, name, iter->second);\n      } else if (iter->first.compare(RGW_ATTR_TAGS) == 0) {\n        RGWObjTags obj_tags;\n        try{\n          auto it = iter->second.cbegin();\n          obj_tags.decode(it);\n        } catch (buffer::error &err) {\n          ldpp_dout(this,0) << \"Error caught buffer::error couldn't decode TagSet \" << dendl;\n        }\n        dump_header(s, RGW_AMZ_TAG_COUNT, obj_tags.count());\n      } else if (iter->first.compare(RGW_ATTR_OBJECT_RETENTION) == 0 && get_retention){\n        RGWObjectRetention retention;\n        try {\n          decode(retention, iter->second);\n          dump_header(s, \"x-amz-object-lock-mode\", retention.get_mode());\n          dump_time_header(s, \"x-amz-object-lock-retain-until-date\", retention.get_retain_until_date());\n        } catch (buffer::error& err) {\n          ldpp_dout(this, 0) << \"ERROR: failed to decode RGWObjectRetention\" << dendl;\n        }\n      } else if (iter->first.compare(RGW_ATTR_OBJECT_LEGAL_HOLD) == 0 && get_legal_hold) {\n        RGWObjectLegalHold legal_hold;\n        try {\n          decode(legal_hold, iter->second);\n          dump_header(s, \"x-amz-object-lock-legal-hold\",legal_hold.get_status());\n        } catch (buffer::error& err) {\n          ldpp_dout(this, 0) << \"ERROR: failed to decode RGWObjectLegalHold\" << dendl;\n        }\n      }\n    }\n  }\n\ndone:\n  for (riter = response_attrs.begin(); riter != response_attrs.end();\n       ++riter) {\n    dump_header(s, riter->first, riter->second);\n  }\n\n  if (op_ret == -ERR_NOT_MODIFIED) {\n      end_header(s, this);\n  } else {\n      if (!content_type)\n          content_type = \"binary/octet-stream\";\n\n      end_header(s, this, content_type);\n  }\n\n  if (metadata_bl.length()) {\n    dump_body(s, metadata_bl);\n  }\n  sent_header = true;\n\nsend_data:\n  if (get_data && !op_ret) {\n    int r = dump_body(s, bl.c_str() + bl_ofs, bl_len);\n    if (r < 0)\n      return r;\n  }\n\n  return 0;\n}",
        "commit_message": "rgw: EPERM to ERR_INVALID_REQUEST\n\nAs per Robin's comments and S3 spec\n\nSigned-off-by: Abhishek Lekshmanan <abhishek@suse.com>",
        "cve_desc": "A flaw was found in the Ceph Object Gateway, where it supports request sent by an anonymous user in Amazon S3. This flaw could lead to potential XSS attacks due to the lack of proper neutralization of untrusted input.",
        "target": 1
      },
      {
        "idx": 200490,
        "reasoning": "The code is vulnerable because it fails to enforce `cephx_require_version` options, allowing connections without CEPH_FEATURE_CEPHX_V2 to proceed, potentially enabling attackers to authenticate using captured packets as described in CVE-2018-1128 (reintroduced). Specifically, the missing enforcement allows older clients lacking proper authentication features to connect, creating a replay attack vector and compromising the cluster's confidentiality, integrity, and availability.",
        "func": "CtPtr ProtocolV1::handle_connect_message_2() {\n  ldout(cct, 20) << __func__ << dendl;\n\n  ldout(cct, 20) << __func__ << \" accept got peer connect_seq \"\n                 << connect_msg.connect_seq << \" global_seq \"\n                 << connect_msg.global_seq << dendl;\n\n  connection->set_peer_type(connect_msg.host_type);\n  connection->policy = messenger->get_policy(connect_msg.host_type);\n\n  ldout(cct, 10) << __func__ << \" accept of host_type \" << connect_msg.host_type\n                 << \", policy.lossy=\" << connection->policy.lossy\n                 << \" policy.server=\" << connection->policy.server\n                 << \" policy.standby=\" << connection->policy.standby\n                 << \" policy.resetcheck=\" << connection->policy.resetcheck\n\t\t << \" features 0x\" << std::hex << (uint64_t)connect_msg.features\n\t\t << std::dec\n                 << dendl;\n\n  ceph_msg_connect_reply reply;\n  bufferlist authorizer_reply;\n\n  // FIPS zeroization audit 20191115: this memset is not security related.\n  memset(&reply, 0, sizeof(reply));\n  reply.protocol_version =\n      messenger->get_proto_version(connection->peer_type, false);\n\n  // mismatch?\n  ldout(cct, 10) << __func__ << \" accept my proto \" << reply.protocol_version\n                 << \", their proto \" << connect_msg.protocol_version << dendl;\n\n  if (connect_msg.protocol_version != reply.protocol_version) {\n    return send_connect_message_reply(CEPH_MSGR_TAG_BADPROTOVER, reply,\n                                      authorizer_reply);\n  }\n\n  // require signatures for cephx?\n  if (connect_msg.authorizer_protocol == CEPH_AUTH_CEPHX) {\n    if (connection->peer_type == CEPH_ENTITY_TYPE_OSD ||\n        connection->peer_type == CEPH_ENTITY_TYPE_MDS ||\n        connection->peer_type == CEPH_ENTITY_TYPE_MGR) {\n      if (cct->_conf->cephx_require_signatures ||\n          cct->_conf->cephx_cluster_require_signatures) {\n        ldout(cct, 10)\n            << __func__\n            << \" using cephx, requiring MSG_AUTH feature bit for cluster\"\n            << dendl;\n        connection->policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n    } else {\n      if (cct->_conf->cephx_require_signatures ||\n          cct->_conf->cephx_service_require_signatures) {\n        ldout(cct, 10)\n            << __func__\n            << \" using cephx, requiring MSG_AUTH feature bit for service\"\n            << dendl;\n        connection->policy.features_required |= CEPH_FEATURE_MSG_AUTH;\n      }\n    }\n    if (cct->_conf->cephx_service_require_version >= 2) {\n      connection->policy.features_required |= CEPH_FEATURE_CEPHX_V2;\n    }\n  }\n\n  uint64_t feat_missing =\n      connection->policy.features_required & ~(uint64_t)connect_msg.features;\n  if (feat_missing) {\n    ldout(cct, 1) << __func__ << \" peer missing required features \" << std::hex\n                  << feat_missing << std::dec << dendl;\n    return send_connect_message_reply(CEPH_MSGR_TAG_FEATURES, reply,\n                                      authorizer_reply);\n  }\n\n  bufferlist auth_bl_copy = authorizer_buf;\n  connection->lock.unlock();\n  ldout(cct,10) << __func__ << \" authorizor_protocol \"\n\t\t<< connect_msg.authorizer_protocol\n\t\t<< \" len \" << auth_bl_copy.length()\n\t\t<< dendl;\n  bool authorizer_valid;\n  bool need_challenge = HAVE_FEATURE(connect_msg.features, CEPHX_V2);\n  bool had_challenge = (bool)authorizer_challenge;\n  if (!messenger->ms_deliver_verify_authorizer(\n          connection, connection->peer_type, connect_msg.authorizer_protocol,\n          auth_bl_copy, authorizer_reply, authorizer_valid, session_key,\n\t  nullptr /* connection_secret */,\n          need_challenge ? &authorizer_challenge : nullptr) ||\n      !authorizer_valid) {\n    connection->lock.lock();\n    if (state != ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n      ldout(cct, 1) << __func__\n\t\t    << \" state changed while accept, it must be mark_down\"\n\t\t    << dendl;\n      ceph_assert(state == CLOSED);\n      return _fault();\n    }\n\n    if (need_challenge && !had_challenge && authorizer_challenge) {\n      ldout(cct, 10) << __func__ << \": challenging authorizer\" << dendl;\n      ceph_assert(authorizer_reply.length());\n      return send_connect_message_reply(CEPH_MSGR_TAG_CHALLENGE_AUTHORIZER,\n                                        reply, authorizer_reply);\n    } else {\n      ldout(cct, 0) << __func__ << \": got bad authorizer, auth_reply_len=\"\n                    << authorizer_reply.length() << dendl;\n      session_security.reset();\n      return send_connect_message_reply(CEPH_MSGR_TAG_BADAUTHORIZER, reply,\n                                        authorizer_reply);\n    }\n  }\n\n  // We've verified the authorizer for this AsyncConnection, so set up the\n  // session security structure.  PLR\n  ldout(cct, 10) << __func__ << \" accept setting up session_security.\" << dendl;\n\n  // existing?\n  AsyncConnectionRef existing = messenger->lookup_conn(*connection->peer_addrs);\n\n  connection->inject_delay();\n\n  connection->lock.lock();\n  if (state != ACCEPTING_WAIT_CONNECT_MSG_AUTH) {\n    ldout(cct, 1) << __func__\n                  << \" state changed while accept, it must be mark_down\"\n                  << dendl;\n    ceph_assert(state == CLOSED);\n    return _fault();\n  }\n\n  if (existing == connection) {\n    existing = nullptr;\n  }\n  if (existing && existing->protocol->proto_type != 1) {\n    ldout(cct,1) << __func__ << \" existing \" << existing << \" proto \"\n\t\t << existing->protocol.get() << \" version is \"\n\t\t << existing->protocol->proto_type << \", marking down\" << dendl;\n    existing->mark_down();\n    existing = nullptr;\n  }\n\n  if (existing) {\n    // There is no possible that existing connection will acquire this\n    // connection's lock\n    existing->lock.lock();  // skip lockdep check (we are locking a second\n                            // AsyncConnection here)\n\n    ldout(cct,10) << __func__ << \" existing=\" << existing << \" exproto=\"\n\t\t  << existing->protocol.get() << dendl;\n    ProtocolV1 *exproto = dynamic_cast<ProtocolV1 *>(existing->protocol.get());\n    ceph_assert(exproto);\n    ceph_assert(exproto->proto_type == 1);\n\n    if (exproto->state == CLOSED) {\n      ldout(cct, 1) << __func__ << \" existing \" << existing\n\t\t    << \" already closed.\" << dendl;\n      existing->lock.unlock();\n      existing = nullptr;\n\n      return open(reply, authorizer_reply);\n    }\n\n    if (exproto->replacing) {\n      ldout(cct, 1) << __func__\n                    << \" existing racing replace happened while replacing.\"\n                    << \" existing_state=\"\n                    << connection->get_state_name(existing->state) << dendl;\n      reply.global_seq = exproto->peer_global_seq;\n      existing->lock.unlock();\n      return send_connect_message_reply(CEPH_MSGR_TAG_RETRY_GLOBAL, reply,\n                                        authorizer_reply);\n    }\n\n    if (connect_msg.global_seq < exproto->peer_global_seq) {\n      ldout(cct, 10) << __func__ << \" accept existing \" << existing << \".gseq \"\n                     << exproto->peer_global_seq << \" > \"\n                     << connect_msg.global_seq << \", RETRY_GLOBAL\" << dendl;\n      reply.global_seq = exproto->peer_global_seq;  // so we can send it below..\n      existing->lock.unlock();\n      return send_connect_message_reply(CEPH_MSGR_TAG_RETRY_GLOBAL, reply,\n                                        authorizer_reply);\n    } else {\n      ldout(cct, 10) << __func__ << \" accept existing \" << existing << \".gseq \"\n                     << exproto->peer_global_seq\n                     << \" <= \" << connect_msg.global_seq << \", looks ok\"\n                     << dendl;\n    }\n\n    if (existing->policy.lossy) {\n      ldout(cct, 0)\n          << __func__\n          << \" accept replacing existing (lossy) channel (new one lossy=\"\n          << connection->policy.lossy << \")\" << dendl;\n      exproto->session_reset();\n      return replace(existing, reply, authorizer_reply);\n    }\n\n    ldout(cct, 1) << __func__ << \" accept connect_seq \"\n                  << connect_msg.connect_seq\n                  << \" vs existing csq=\" << exproto->connect_seq\n                  << \" existing_state=\"\n                  << connection->get_state_name(existing->state) << dendl;\n\n    if (connect_msg.connect_seq == 0 && exproto->connect_seq > 0) {\n      ldout(cct, 0)\n          << __func__\n          << \" accept peer reset, then tried to connect to us, replacing\"\n          << dendl;\n      // this is a hard reset from peer\n      is_reset_from_peer = true;\n      if (connection->policy.resetcheck) {\n        exproto->session_reset();  // this resets out_queue, msg_ and\n                                   // connect_seq #'s\n      }\n      return replace(existing, reply, authorizer_reply);\n    }\n\n    if (connect_msg.connect_seq < exproto->connect_seq) {\n      // old attempt, or we sent READY but they didn't get it.\n      ldout(cct, 10) << __func__ << \" accept existing \" << existing << \".cseq \"\n                     << exproto->connect_seq << \" > \" << connect_msg.connect_seq\n                     << \", RETRY_SESSION\" << dendl;\n      reply.connect_seq = exproto->connect_seq + 1;\n      existing->lock.unlock();\n      return send_connect_message_reply(CEPH_MSGR_TAG_RETRY_SESSION, reply,\n                                        authorizer_reply);\n    }\n\n    if (connect_msg.connect_seq == exproto->connect_seq) {\n      // if the existing connection successfully opened, and/or\n      // subsequently went to standby, then the peer should bump\n      // their connect_seq and retry: this is not a connection race\n      // we need to resolve here.\n      if (exproto->state == OPENED || exproto->state == STANDBY) {\n        ldout(cct, 10) << __func__ << \" accept connection race, existing \"\n                       << existing << \".cseq \" << exproto->connect_seq\n                       << \" == \" << connect_msg.connect_seq\n                       << \", OPEN|STANDBY, RETRY_SESSION \" << dendl;\n        // if connect_seq both zero, dont stuck into dead lock. it's ok to\n        // replace\n        if (connection->policy.resetcheck && exproto->connect_seq == 0) {\n          return replace(existing, reply, authorizer_reply);\n        }\n\n        reply.connect_seq = exproto->connect_seq + 1;\n        existing->lock.unlock();\n        return send_connect_message_reply(CEPH_MSGR_TAG_RETRY_SESSION, reply,\n                                          authorizer_reply);\n      }\n\n      // connection race?\n      if (connection->peer_addrs->legacy_addr() < messenger->get_myaddr_legacy() ||\n          existing->policy.server) {\n        // incoming wins\n        ldout(cct, 10) << __func__ << \" accept connection race, existing \"\n                       << existing << \".cseq \" << exproto->connect_seq\n                       << \" == \" << connect_msg.connect_seq\n                       << \", or we are server, replacing my attempt\" << dendl;\n        return replace(existing, reply, authorizer_reply);\n      } else {\n        // our existing outgoing wins\n        ldout(messenger->cct, 10)\n            << __func__ << \" accept connection race, existing \" << existing\n            << \".cseq \" << exproto->connect_seq\n            << \" == \" << connect_msg.connect_seq << \", sending WAIT\" << dendl;\n        ceph_assert(connection->peer_addrs->legacy_addr() >\n                    messenger->get_myaddr_legacy());\n        existing->lock.unlock();\n\t// make sure we follow through with opening the existing\n\t// connection (if it isn't yet open) since we know the peer\n\t// has something to send to us.\n\texisting->send_keepalive();\n        return send_connect_message_reply(CEPH_MSGR_TAG_WAIT, reply,\n                                          authorizer_reply);\n      }\n    }\n\n    ceph_assert(connect_msg.connect_seq > exproto->connect_seq);\n    ceph_assert(connect_msg.global_seq >= exproto->peer_global_seq);\n    if (connection->policy.resetcheck &&  // RESETSESSION only used by servers;\n                                          // peers do not reset each other\n        exproto->connect_seq == 0) {\n      ldout(cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                    << connect_msg.connect_seq << \", \" << existing\n                    << \".cseq = \" << exproto->connect_seq\n                    << \"), sending RESETSESSION \" << dendl;\n      existing->lock.unlock();\n      return send_connect_message_reply(CEPH_MSGR_TAG_RESETSESSION, reply,\n                                        authorizer_reply);\n    }\n\n    // reconnect\n    ldout(cct, 10) << __func__ << \" accept peer sent cseq \"\n                   << connect_msg.connect_seq << \" > \" << exproto->connect_seq\n                   << dendl;\n    return replace(existing, reply, authorizer_reply);\n  }  // existing\n  else if (!replacing && connect_msg.connect_seq > 0) {\n    // we reset, and they are opening a new session\n    ldout(cct, 0) << __func__ << \" accept we reset (peer sent cseq \"\n                  << connect_msg.connect_seq << \"), sending RESETSESSION\"\n                  << dendl;\n    return send_connect_message_reply(CEPH_MSGR_TAG_RESETSESSION, reply,\n                                      authorizer_reply);\n  } else {\n    // new session\n    ldout(cct, 10) << __func__ << \" accept new session\" << dendl;\n    existing = nullptr;\n    return open(reply, authorizer_reply);\n  }\n}",
        "commit_message": "msg/async/ProtocolV1: resurrect \"implement cephx_*require_version options\"\n\nThis was added in commit 9bcbc2a3621f (\"mon,msg: implement\ncephx_*_require_version options\") and inadvertently dropped in\ncommit e6f043f7d2dc (\"msgr/async: huge refactoring of protocol V1\").\nAs a result, service daemons don't enforce cephx_require_version\nand cephx_cluster_require_version options and connections without\nCEPH_FEATURE_CEPHX_V2 are allowed through.\n\n(cephx_service_require_version enforcement was brought back a\nyear later in commit 321548010578 (\"mon/MonClient: skip CEPHX_V2\nchallenge if client doesn't support it\"), although the peer gets\nTAG_BADAUTHORIZER instead of TAG_FEATURES.)\n\nResurrect the original behaviour: all cephx_*require_version\noptions are enforced and the peer gets TAG_FEATURES, signifying\nthat it is missing a required feature.\n\nSigned-off-by: Ilya Dryomov <idryomov@gmail.com>\n(cherry picked from commit 6f5c4152ca2c6423e665cde2196c6301f76043a2)\n\nConflicts:\n\tsrc/msg/async/ProtocolV1.cc [ drop nautilus-only commit\n\t  89ffece49097 (\"msg/async/ProtocolV1: require CEPHX_V2 if\n\t  cephx_service_require_version >= 2\") ]",
        "cve_desc": "A flaw was found in the Cephx authentication protocol in versions before 15.2.6 and before 14.2.14, where it does not verify Ceph clients correctly and is then vulnerable to replay attacks in Nautilus. This flaw allows an attacker with access to the Ceph cluster network to authenticate with the Ceph service via a packet sniffer and perform actions allowed by the Ceph service. This issue is a reintroduction of CVE-2018-1128, affecting the msgr2 protocol. The msgr 2 protocol is used for all communication except older clients that do not support the msgr2 protocol. The msgr1 protocol is not affected. The highest threat from this vulnerability is to confidentiality, integrity, and system availability.",
        "target": 1
      }
    ]
  },
  "cgit": {
    "0": [
      {
        "idx": 498751,
        "reasoning": "This code snippet is **not vulnerable** because it specifically serves the `HEAD` file within the Git repository, and the reported vulnerability lies in the `/repo/objects/` endpoint when a malicious `path` parameter is supplied. The `cgit_clone_head` function doesn't take any user-controlled input for file paths, thus it's isolated from the directory traversal issue affecting other parts of the application.\n\n\n\n",
        "func": "void cgit_clone_head(void)\n{\n\tsend_file(git_path(\"%s\", \"HEAD\"));\n}",
        "commit_message": "clone: fix directory traversal\n\nThis was introduced in the initial version of this code, way back when\nin 2008.\n\n$ curl http://127.0.0.1/cgit/repo/objects/?path=../../../../../../../../../etc/passwd\nroot:x:0:0:root:/root:/bin/sh\n...\n\nSigned-off-by: Jason A. Donenfeld <Jason@zx2c4.com>\nReported-by: Jann Horn <jannh@google.com>",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": []
  },
  "clamav-devel": {
    "0": [],
    "1": []
  },
  "clutter": {
    "0": [],
    "1": []
  },
  "contiki-ng": {
    "0": [
      {
        "idx": 267045,
        "reasoning": "This code addresses a potential out-of-bounds read by carefully calculating the remaining buffer size (`size - (nbuf - buffer)`) in each iteration of the `while` loop when searching for the desired protocol. The loop condition also explicitly checks `uip_is_proto_ext_hdr(next_proto)` to ensure it only processes valid extension headers, preventing it from attempting to read beyond the buffer's boundaries with invalid data.\n",
        "func": "uipbuf_search_header(uint8_t *buffer, uint16_t size, uint8_t protocol)\n{\n  uint8_t *nbuf;\n  uint8_t next_proto;\n\n  nbuf = uipbuf_get_next_header(buffer, size, &next_proto, true);\n  while(nbuf != NULL && next_proto != protocol && uip_is_proto_ext_hdr(next_proto)) {\n    /* move to the ext hdr */\n    nbuf = uipbuf_get_next_header(nbuf, size - (nbuf - buffer), &next_proto, false);\n  }\n\n  if(next_proto == protocol) {\n    return nbuf;\n  } else {\n    return NULL;\n  }\n}",
        "commit_message": "Prevent a possible read out of bounds in the processing of IPv6 extension headers.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 267046,
        "reasoning": "This code snippet initializes default attributes for a buffer used in the Contiki-NG networking stack and doesn't directly handle packet parsing or memory access that could lead to out-of-bounds reads. The commit message refers to a fix in IPv6 extension header *processing*, which is not present in this `uipbuf_init` function; therefore, this code is not flagged as vulnerable based on the provided information.\n\n\n\n",
        "func": "uipbuf_init(void)\n{\n  memset(uipbuf_default_attrs, 0, sizeof(uipbuf_default_attrs));\n  /* And initialize anything that should be initialized */\n  uipbuf_set_default_attr(UIPBUF_ATTR_MAX_MAC_TRANSMISSIONS,\n                          UIP_MAX_MAC_TRANSMISSIONS_UNDEFINED);\n  /* set the not-set default value - this will cause the MAC layer to\n     configure its default */\n  uipbuf_set_default_attr(UIPBUF_ATTR_LLSEC_LEVEL,\n                          UIPBUF_ATTR_LLSEC_LEVEL_MAC_DEFAULT);\n}",
        "commit_message": "Prevent a possible read out of bounds in the processing of IPv6 extension headers.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 267047,
        "reasoning": "This code is safe and does not present a vulnerability. The function explicitly checks if the `type` parameter is within the bounds of the `uipbuf_attrs` array (`type < UIPBUF_ATTR_MAX`) before attempting to write to it, preventing any out-of-bounds access. \n\n\n\n",
        "func": "uipbuf_set_attr(uint8_t type, uint16_t value)\n{\n  if(type < UIPBUF_ATTR_MAX) {\n    uipbuf_attrs[type] = value;\n    return 1;\n  }\n  return 0;\n}",
        "commit_message": "Prevent a possible read out of bounds in the processing of IPv6 extension headers.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 267048,
        "reasoning": "This code snippet is not directly vulnerable to a read-out-of-bounds issue despite the commit message suggesting a related fix elsewhere. The function `uipbuf_set_len_field` simply *sets* the length field within a pre-existing IP header structure; it doesn't *read* from any buffer, and therefore cannot cause a read-out-of-bounds error itself. \n\n\n\n",
        "func": "uipbuf_set_len_field(struct uip_ip_hdr *hdr, uint16_t len)\n{\n  hdr->len[0] = (len >> 8);\n  hdr->len[1] = (len & 0xff);\n}",
        "commit_message": "Prevent a possible read out of bounds in the processing of IPv6 extension headers.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 267049,
        "reasoning": "This code is safe and does not exhibit a read-out-of-bounds vulnerability despite handling IPv6 extension headers. The checks `len + uip_len <= UIP_LINK_MTU` and `len + uip_ext_len >= 0` ensure that any added length doesn't exceed the maximum transmission unit or result in negative lengths, preventing buffer overflows during extension header processing.\n\n\n\n",
        "func": "uipbuf_add_ext_hdr(int16_t len)\n{\n  if(len + uip_len <= UIP_LINK_MTU && len + uip_len >= 0 && len + uip_ext_len >= 0) {\n    uip_ext_len += len;\n    uip_len += len;\n    return true;\n  } else {\n    return false;\n  }\n}",
        "commit_message": "Prevent a possible read out of bounds in the processing of IPv6 extension headers.",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": []
  },
  "core": {
    "0": [
      {
        "idx": 503964,
        "reasoning": "This code is not directly vulnerable based on the provided snippet and commit message. The commit addresses a crash scenario by handling NULL usernames gracefully during JSON parsing, preventing a potential denial-of-service but not introducing any new security flaws. \n\n\n\n",
        "func": "void auth_policy_parse_response(struct policy_lookup_ctx *context)\n{\n\tenum json_type type;\n\tconst char *value;\n\tint ret;\n\n\twhile((ret = json_parse_next(context->parser, &type, &value)) == 1) {\n\t\tif (context->parse_state == POLICY_RESULT) {\n\t\t\tif (type != JSON_TYPE_OBJECT_KEY)\n\t\t\t\tbreak;\n\t\t\telse if (strcmp(value, \"status\") == 0)\n\t\t\t\tcontext->parse_state = POLICY_RESULT_VALUE_STATUS;\n\t\t\telse if (strcmp(value, \"msg\") == 0)\n\t\t\t\tcontext->parse_state = POLICY_RESULT_VALUE_MESSAGE;\n\t\t\telse break;\n\t\t} else if (context->parse_state == POLICY_RESULT_VALUE_STATUS) {\n\t\t\tif (type != JSON_TYPE_NUMBER || str_to_int(value, &(context->result)) != 0)\n\t\t\t\tbreak;\n\t\t\tcontext->parse_state = POLICY_RESULT;\n\t\t} else if (context->parse_state == POLICY_RESULT_VALUE_MESSAGE) {\n\t\t\tif (type != JSON_TYPE_STRING)\n\t\t\t\tbreak;\n\t\t\tif (*value != '\\0')\n\t\t\t\tcontext->message = p_strdup(context->pool, value);\n\t\t\tcontext->parse_state = POLICY_RESULT;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n\n\tif (ret == 0 && !context->payload->eof)\n\t\treturn;\n\n\tcontext->parse_error = TRUE;\n\n\tio_remove(&(context->io));\n\n\tif (context->payload->stream_errno != 0) {\n\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\"Error reading policy server result: %s\",\n\t\t\ti_stream_get_error(context->payload));\n\t} else if (ret == 0 && context->payload->eof) {\n\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\"Policy server result was too short\");\n\t} else if (ret == 1) {\n\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\"Policy server response was malformed\");\n\t} else {\n\t\tconst char *error = \"unknown\";\n\t\tif (json_parser_deinit(&(context->parser), &error) != 0)\n\t\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\t\"Policy server response JSON parse error: %s\", error);\n\t\telse if (context->parse_state == POLICY_RESULT)\n\t\t\tcontext->parse_error = FALSE;\n\t}\n\ti_stream_unref(&(context->payload));\n\n\tif (context->parse_error) {\n\t\tcontext->result = (context->set->policy_reject_on_fail ? -1 : 0);\n\t}\n\n\tcontext->request->policy_refusal = FALSE;\n\n\tif (context->result < 0) {\n\t\tif (context->message != NULL) {\n\t\t\t/* set message here */\n\t\t\tauth_request_log_debug(context->request, \"policy\",\n\t\t\t\t\"Policy response %d with message: %s\",\n\t\t\t\tcontext->result, context->message);\n\t\t\tauth_request_set_field(context->request, \"reason\", context->message, NULL);\n\t\t}\n\t\tcontext->request->policy_refusal = TRUE;\n\t} else {\n\t\tauth_request_log_debug(context->request, \"policy\",\n\t\t\t\"Policy response %d\", context->result);\n\t}\n\n\tif (context->request->policy_refusal == TRUE && context->set->verbose == TRUE) {\n\t\tauth_request_log_info(context->request, \"policy\", \"Authentication failure due to policy server refusal%s%s\",\n\t\t\t(context->message!=NULL?\": \":\"\"),\n\t\t\t(context->message!=NULL?context->message:\"\"));\n\t}\n\n\tif (context->callback != NULL) {\n\t\tcontext->callback(context->result, context->callback_context);\n\t}\n};",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 0
      },
      {
        "idx": 503965,
        "reasoning": "This code addresses a potential crash by explicitly handling NULL usernames in the authentication policy digest calculation, preventing a dereference error. While adding a NUL byte might seem unusual, it's a deliberate mitigation to avoid the crash and doesn't introduce any exploitable vulnerabilities like buffer overflows or injection flaws.\n\n\n\n",
        "func": "void auth_policy_create_json(struct policy_lookup_ctx *context,\n\tconst char *password, bool include_success)\n{\n\tconst struct var_expand_table *var_table;\n\tcontext->json = str_new(context->pool, 64);\n\tunsigned char *ptr;\n\tconst struct hash_method *digest = hash_method_lookup(context->set->policy_hash_mech);\n\n\ti_assert(digest != NULL);\n\n\tvoid *ctx = t_malloc(digest->context_size);\n\tstring_t *buffer = t_str_new(64);\n\n\tdigest->init(ctx);\n\tdigest->loop(ctx,\n\t\tcontext->set->policy_hash_nonce,\n\t\tstrlen(context->set->policy_hash_nonce));\n\t/* use +1 to make sure \\0 gets included */\n\tif (context->request->user == NULL)\n\t\tdigest->loop(ctx, \"\\0\", 1);\n\telse\n\t\tdigest->loop(ctx, context->request->user, strlen(context->request->user) + 1);\n\tif (password != NULL)\n\t\tdigest->loop(ctx, password, strlen(password));\n\tptr = (unsigned char*)str_c_modifiable(buffer);\n\tdigest->result(ctx, ptr);\n\tstr_truncate(buffer, digest->digest_size);\n\tif (context->set->policy_hash_truncate > 0) {\n\t\tbuffer_truncate_rshift_bits(buffer, context->set->policy_hash_truncate);\n\t}\n\tconst char *hashed_password = binary_to_hex(str_data(buffer), str_len(buffer));\n\tstr_append_c(context->json, '{');\n\tvar_table = policy_get_var_expand_table(context->request, hashed_password);\n\tauth_request_var_expand_with_table(context->json, auth_policy_json_template,\n\t\t\t\t\t   context->request, var_table,\n\t\t\t\t\t   auth_policy_escape_function);\n\tif (include_success) {\n\t\tstr_append(context->json, \",\\\"success\\\":\");\n\t\tif (!context->request->failed && context->request->successful &&\n\t\t    !context->request->internal_failure)\n\t\t\tstr_append(context->json, \"true\");\n\t\telse\n\t\t\tstr_append(context->json, \"false\");\n\t\tstr_append(context->json, \",\\\"policy_reject\\\":\");\n\t\tstr_append(context->json, context->request->policy_refusal ? \"true\" : \"false\");\n\t}\n\tstr_append_c(context->json, '}');\n\tauth_request_log_debug(context->request, \"policy\",\n\t\t\"Policy server request JSON: %s\", str_c(context->json));\n}",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 0
      },
      {
        "idx": 503966,
        "reasoning": "This code snippet focuses on handling HTTP responses and initiating parsing\u2014it doesn't directly handle username input or authentication policy creation where a NULL username could cause a crash, as described in the commit message. The commit message indicates the fix occurs *during* policy digest creation (not shown in this snippet) when a NULL username is encountered, and this code simply processes the response *after* that policy is presumably created, making it safe from the described vulnerability.\n\n\n\n",
        "func": "void auth_policy_process_response(const struct http_response *response,\n\tvoid *ctx)\n{\n\tstruct policy_lookup_ctx *context = ctx;\n\n\tcontext->payload = response->payload;\n\n\tif ((response->status / 10) != 20) {\n\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\"Policy server HTTP error: %d %s\", response->status, response->reason);\n\t\tif (context->callback != NULL)\n\t\t\tcontext->callback(context->result, context->callback_context);\n\t\treturn;\n\t}\n\n\tif (response->payload == NULL) {\n\t\tif (context->expect_result)\n\t\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\t\"Policy server result was empty\");\n\t\tif (context->callback != NULL)\n\t\t\tcontext->callback(context->result, context->callback_context);\n\t\treturn;\n\t}\n\n\tif (context->expect_result) {\n\t\ti_stream_ref(response->payload);\n\t\tcontext->io = io_add_istream(response->payload, auth_policy_parse_response, context);\n\t\tcontext->parser = json_parser_init(response->payload);\n\t\tauth_policy_parse_response(ctx);\n\t} else {\n\t\tauth_request_log_debug(context->request, \"policy\",\n\t\t\t\"Policy response %d\", context->result);\n\t\tif (context->callback != NULL)\n\t\t\tcontext->callback(context->result, context->callback_context);\n\t}\n}",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 0
      },
      {
        "idx": 503967,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message describes a fix for handling NULL usernames in authentication policies, and the code itself focuses on safely escaping strings for use in a JSON context\u2014it doesn't appear to introduce any new vulnerabilities or directly address any known attack vectors like injection or buffer overflows.\n\n\n\n",
        "func": "const char *auth_policy_escape_function(const char *string,\n\tconst struct auth_request *auth_request ATTR_UNUSED)\n{\n\tstring_t *tmp = t_str_new(64);\n\tjson_append_escaped(tmp, string);\n\treturn str_c(tmp);\n}",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 0
      },
      {
        "idx": 503968,
        "reasoning": "This code is not directly vulnerable based on the provided snippet and commit message. The fix addresses a crash when a username is NULL during SASL request handling, specifically by adding a NUL byte to the digest\u2014this is a defensive programming measure to prevent a crash, not introduce a vulnerability. \n\n\n\n",
        "func": "void auth_policy_send_request(struct policy_lookup_ctx *context)\n{\n\tconst char *error;\n\tstruct http_url *url;\n\tif (http_url_parse(context->url, NULL, HTTP_URL_ALLOW_USERINFO_PART,\n\t\t\t   context->pool, &url, &error) != 0) {\n\t\tauth_request_log_error(context->request, \"policy\",\n\t\t\t\"Could not parse url %s: %s\", context->url, error);\n\t\tauth_policy_finish(context);\n\t\treturn;\n\t}\n\tcontext->http_request = http_client_request_url(http_client,\n\t\t\"POST\", url, auth_policy_process_response, (void*)context);\n\thttp_client_request_set_destroy_callback(context->http_request, auth_policy_finish, context);\n\thttp_client_request_add_header(context->http_request, \"Content-Type\", \"application/json\");\n\tif (*context->set->policy_server_api_header != 0) {\n\t\tconst char *ptr;\n\t\tif ((ptr = strstr(context->set->policy_server_api_header, \":\")) != NULL) {\n\t\t\tconst char *header = t_strcut(context->set->policy_server_api_header, ':');\n\t\t\thttp_client_request_add_header(context->http_request, header, ptr + 1);\n\t\t} else {\n\t\t\thttp_client_request_add_header(context->http_request,\n\t\t\t\t\"X-API-Key\", context->set->policy_server_api_header);\n\t\t}\n\t}\n\tif (url->user != NULL) {\n\t\t/* allow empty password */\n\t\thttp_client_request_set_auth_simple(context->http_request, url->user,\n\t\t\t(url->password != NULL ? url->password : \"\"));\n\t}\n\tstruct istream *is = i_stream_create_from_buffer(context->json);\n\thttp_client_request_set_payload(context->http_request, is, FALSE);\n\ti_stream_unref(&is);\n\thttp_client_request_submit(context->http_request);\n\tauth_request_ref(context->request);\n}",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 216653,
        "reasoning": "This code is vulnerable because it unconditionally adds a NUL byte to the hash digest even when `context->request->user` is NULL, potentially leading to an out-of-bounds read or write when the digest function processes the username data. This directly corresponds to the CVE description, where aborting authentication without a username (resulting in a NULL username) causes a crash due to improper handling in the `auth_policy_create_json` function.",
        "func": "void auth_policy_create_json(struct policy_lookup_ctx *context,\n\tconst char *password, bool include_success)\n{\n\tconst struct var_expand_table *var_table;\n\tcontext->json = str_new(context->pool, 64);\n\tunsigned char *ptr;\n\tconst struct hash_method *digest = hash_method_lookup(context->set->policy_hash_mech);\n\n\ti_assert(digest != NULL);\n\n\tvoid *ctx = t_malloc(digest->context_size);\n\tstring_t *buffer = t_str_new(64);\n\n\tdigest->init(ctx);\n\tdigest->loop(ctx,\n\t\tcontext->set->policy_hash_nonce,\n\t\tstrlen(context->set->policy_hash_nonce));\n\t/* use +1 to make sure \\0 gets included */\n\tdigest->loop(ctx, context->request->user, strlen(context->request->user) + 1);\n\tif (password != NULL)\n\t\tdigest->loop(ctx, password, strlen(password));\n\tptr = (unsigned char*)str_c_modifiable(buffer);\n\tdigest->result(ctx, ptr);\n\tstr_truncate(buffer, digest->digest_size);\n\tif (context->set->policy_hash_truncate > 0) {\n\t\tbuffer_truncate_rshift_bits(buffer, context->set->policy_hash_truncate);\n\t}\n\tconst char *hashed_password = binary_to_hex(str_data(buffer), str_len(buffer));\n\tstr_append_c(context->json, '{');\n\tvar_table = policy_get_var_expand_table(context->request, hashed_password);\n\tauth_request_var_expand_with_table(context->json, auth_policy_json_template,\n\t\t\t\t\t   context->request, var_table,\n\t\t\t\t\t   auth_policy_escape_function);\n\tif (include_success) {\n\t\tstr_append(context->json, \",\\\"success\\\":\");\n\t\tif (!context->request->failed && context->request->successful &&\n\t\t    !context->request->internal_failure)\n\t\t\tstr_append(context->json, \"true\");\n\t\telse\n\t\t\tstr_append(context->json, \"false\");\n\t\tstr_append(context->json, \",\\\"policy_reject\\\":\");\n\t\tstr_append(context->json, context->request->policy_refusal ? \"true\" : \"false\");\n\t}\n\tstr_append_c(context->json, '}');\n\tauth_request_log_debug(context->request, \"policy\",\n\t\t\"Policy server request JSON: %s\", str_c(context->json));\n}",
        "commit_message": "auth: Fix auth-policy crash when username is NULL\n\nIf SASL request is invalid, or incomplete, and username\nis left NULL, handle it gracefully by adding just\nNUL byte in auth policy digest for username.",
        "cve_desc": "The auth component in Dovecot before 2.2.27, when auth-policy is configured, allows a remote attackers to cause a denial of service (crash) by aborting authentication without setting a username.",
        "target": 1
      },
      {
        "idx": 216682,
        "reasoning": "This code is vulnerable to a denial of service because the `var_expand` function is called on user-supplied data (`key->key->key`) without proper length limitations, allowing for potentially unbounded expansion of variables. This uncontrolled expansion, as described in the CVE, can lead to excessive memory or CPU usage, causing the authentication process to crash or hang.",
        "func": "static int db_dict_iter_lookup_key_values(struct db_dict_value_iter *iter)\n{\n\tstruct db_dict_iter_key *key;\n\tstring_t *path;\n\tconst char *error;\n\tint ret;\n\n\t/* sort the keys so that we'll first lookup the keys without\n\t   default value. if their lookup fails, the user doesn't exist. */\n\tarray_sort(&iter->keys, db_dict_iter_key_cmp);\n\n\tpath = t_str_new(128);\n\tstr_append(path, DICT_PATH_SHARED);\n\n\tarray_foreach_modifiable(&iter->keys, key) {\n\t\tif (!key->used)\n\t\t\tcontinue;\n\n\t\tstr_truncate(path, strlen(DICT_PATH_SHARED));\n\t\tret = var_expand(path, key->key->key, iter->var_expand_table, &error);\n\t\tif (ret <= 0) {\n\t\t\tauth_request_log_error(iter->auth_request, AUTH_SUBSYS_DB,\n\t\t\t\t\"Failed to expand key %s: %s\", key->key->key, error);\n\t\t\treturn -1;\n\t\t}\n\t\tret = dict_lookup(iter->conn->dict, iter->pool,\n\t\t\t\t  str_c(path), &key->value, &error);\n\t\tif (ret > 0) {\n\t\t\tauth_request_log_debug(iter->auth_request, AUTH_SUBSYS_DB,\n\t\t\t\t\t       \"Lookup: %s = %s\", str_c(path),\n\t\t\t\t\t       key->value);\n\t\t} else if (ret < 0) {\n\t\t\tauth_request_log_error(iter->auth_request, AUTH_SUBSYS_DB,\n\t\t\t\t\"Failed to lookup key %s: %s\", str_c(path), error);\n\t\t\treturn -1;\n\t\t} else if (key->key->default_value != NULL) {\n\t\t\tauth_request_log_debug(iter->auth_request, AUTH_SUBSYS_DB,\n\t\t\t\t\"Lookup: %s not found, using default value %s\",\n\t\t\t\tstr_c(path), key->key->default_value);\n\t\t\tkey->value = key->key->default_value;\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn 1;\n}",
        "commit_message": "auth: Do not double-expand key in passdb dict when authenticating\n\nBroken by 79042f8c",
        "cve_desc": "Dovecot before version 2.2.29 is vulnerable to a denial of service. When 'dict' passdb and userdb were used for user authentication, the username sent by the IMAP/POP3 client was sent through var_expand() to perform %variable expansion. Sending specially crafted %variable fields could result in excessive memory usage causing the process to crash (and restart), or excessive CPU usage causing all authentications to hang.",
        "target": 1
      },
      {
        "idx": 216709,
        "reasoning": "The code is vulnerable to a memory leak because it sets the `*_request` pointer to NULL *before* potentially calling `call_callback` with the `request` object\u2014meaning there's no external reference to the allocated `request` structure after the pointer is nulled, preventing its deallocation. This leak occurs during authentication aborts, as described in the CVE, and can lead to memory exhaustion and crashes in high-load scenarios where login processes are reused.",
        "func": "void auth_client_request_abort(struct auth_client_request **_request)\n{\n\tstruct auth_client_request *request = *_request;\n\n\t*_request = NULL;\n\n\tauth_client_send_cancel(request->conn->client, request->id);\n\tcall_callback(request, AUTH_REQUEST_STATUS_ABORT, NULL, NULL);\n}",
        "commit_message": "lib-auth: Fix memory leak in auth_client_request_abort()\n\nThis caused memory leaks when authentication was aborted. For example\nwith IMAP:\n\na AUTHENTICATE PLAIN\n*\n\nBroken by 9137c55411aa39d41c1e705ddc34d5bd26c65021",
        "cve_desc": "A flaw was found in dovecot 2.0 up to 2.2.33 and 2.3.0. An abort of SASL authentication results in a memory leak in dovecot's auth client used by login processes. The leak has impact in high performance configuration where same login processes are reused and can cause the process to crash due to memory exhaustion.",
        "target": 1
      },
      {
        "idx": 216733,
        "reasoning": "The code is vulnerable because it doesn't explicitly check for NUL bytes (`\\0`) within the input string before passing it to `str_unescape()`, allowing a malicious actor to craft an input string containing NULs. This can lead to `str_unescape()` operating on memory outside the allocated buffer, resulting in heap corruption and potentially remote code execution as described in the CVE.",
        "func": "static bool imap_parser_read_string(struct imap_parser *parser,\n\t\t\t\t    const unsigned char *data, size_t data_size)\n{\n\tsize_t i;\n\n\t/* read until we've found non-escaped \", CR or LF */\n\tfor (i = parser->cur_pos; i < data_size; i++) {\n\t\tif (data[i] == '\"') {\n\t\t\timap_parser_save_arg(parser, data, i);\n\n\t\t\ti++; /* skip the trailing '\"' too */\n\t\t\tbreak;\n\t\t}\n\n\t\tif (data[i] == '\\\\') {\n\t\t\tif (i+1 == data_size) {\n\t\t\t\t/* known data ends with '\\' - leave it to\n\t\t\t\t   next time as well if it happens to be \\\" */\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\t/* save the first escaped char */\n\t\t\tif (parser->str_first_escape < 0)\n\t\t\t\tparser->str_first_escape = i;\n\n\t\t\t/* skip the escaped char */\n\t\t\ti++;\n\t\t}\n\n\t\t/* check linebreaks here, so escaping CR/LF isn't possible.\n\t\t   string always ends with '\"', so it's an error if we found\n\t\t   a linebreak.. */\n\t\tif (is_linebreak(data[i]) &&\n\t\t    (parser->flags & IMAP_PARSE_FLAG_MULTILINE_STR) == 0) {\n\t\t\tparser->error = IMAP_PARSE_ERROR_BAD_SYNTAX;\n\t\t\tparser->error_msg = \"Missing '\\\"'\";\n\t\t\treturn FALSE;\n\t\t}\n\t}\n\n\tparser->cur_pos = i;\n\treturn parser->cur_type == ARG_PARSE_NONE;\n}",
        "commit_message": "lib-imap: Don't accept strings with NULs\n\nIMAP doesn't allow NULs except in binary literals. We'll still allow them\nin regular literals as well, but just not in strings.\n\nThis fixes a bug with unescaping a string with NULs: str_unescape() could\nhave been called for memory that points outside the allocated string,\ncausing heap corruption. This could cause crashes or theoretically even\nresult in remote code execution exploit.\n\nFound by Nick Roessler and Rafi Rubin",
        "cve_desc": "In Dovecot before 2.2.36.4 and 2.3.x before 2.3.7.2 (and Pigeonhole before 0.5.7.2), protocol processing can fail for quoted strings. This occurs because '\\0' characters are mishandled, and can lead to out-of-bounds writes and remote code execution.",
        "target": 1
      },
      {
        "idx": 216734,
        "reasoning": "The code is vulnerable because the `str_unescape` function is called on a string that may contain null bytes (`\\0`), potentially leading to out-of-bounds writes as `str_unescape` likely doesn't handle null termination correctly when modifying the string in-place. This aligns with the CVE description, which states mishandling of `\\0` characters in quoted strings can result in remote code execution due to these out-of-bounds writes.",
        "func": "static void imap_parser_save_arg(struct imap_parser *parser,\n\t\t\t\t const unsigned char *data, size_t size)\n{\n\tstruct imap_arg *arg;\n\tchar *str;\n\n\targ = imap_arg_create(parser);\n\n\tswitch (parser->cur_type) {\n\tcase ARG_PARSE_ATOM:\n\tcase ARG_PARSE_TEXT:\n\t\tif (size == 3 && i_memcasecmp(data, \"NIL\", 3) == 0) {\n\t\t\t/* NIL argument. it might be an actual NIL, but if\n\t\t\t   we're reading astring, it's an atom and we can't\n\t\t\t   lose its case. */\n\t\t\targ->type = IMAP_ARG_NIL;\n\t\t} else {\n\t\t\t/* simply save the string */\n\t\t\targ->type = IMAP_ARG_ATOM;\n\t\t}\n\t\targ->_data.str = imap_parser_strdup(parser, data, size);\n\t\targ->str_len = size;\n\t\tbreak;\n\tcase ARG_PARSE_STRING:\n\t\t/* data is quoted and may contain escapes. */\n\t\ti_assert(size > 0);\n\n\t\targ->type = IMAP_ARG_STRING;\n\t\tstr = p_strndup(parser->pool, data+1, size-1);\n\n\t\t/* remove the escapes */\n\t\tif (parser->str_first_escape >= 0 &&\n\t\t    (parser->flags & IMAP_PARSE_FLAG_NO_UNESCAPE) == 0) {\n\t\t\t/* -1 because we skipped the '\"' prefix */\n\t\t\t(void)str_unescape(str + parser->str_first_escape-1);\n\t\t}\n\t\targ->_data.str = str;\n\t\targ->str_len = strlen(str);\n\t\tbreak;\n\tcase ARG_PARSE_LITERAL_DATA:\n\t\tif ((parser->flags & IMAP_PARSE_FLAG_LITERAL_SIZE) != 0) {\n\t\t\t/* save literal size */\n\t\t\targ->type = parser->literal_nonsync ?\n\t\t\t\tIMAP_ARG_LITERAL_SIZE_NONSYNC :\n\t\t\t\tIMAP_ARG_LITERAL_SIZE;\n\t\t\targ->_data.literal_size = parser->literal_size;\n\t\t\targ->literal8 = parser->literal8;\n\t\t\tbreak;\n\t\t}\n\t\t/* fall through */\n\tcase ARG_PARSE_LITERAL_DATA_FORCED:\n\t\tif ((parser->flags & IMAP_PARSE_FLAG_LITERAL_TYPE) != 0)\n\t\t\targ->type = IMAP_ARG_LITERAL;\n\t\telse\n\t\t\targ->type = IMAP_ARG_STRING;\n\t\targ->_data.str = imap_parser_strdup(parser, data, size);\n\t\targ->literal8 = parser->literal8;\n\t\targ->str_len = size;\n\t\tbreak;\n\tdefault:\n                i_unreached();\n\t}\n\n\tparser->cur_type = ARG_PARSE_NONE;\n}",
        "commit_message": "lib-imap: Make sure str_unescape() won't be writing past allocated memory\n\nThe previous commit should already prevent this, but this makes sure it\ncan't become broken in the future either. It makes the performance a tiny\nbit worse, but that's not practically noticeable.",
        "cve_desc": "In Dovecot before 2.2.36.4 and 2.3.x before 2.3.7.2 (and Pigeonhole before 0.5.7.2), protocol processing can fail for quoted strings. This occurs because '\\0' characters are mishandled, and can lead to out-of-bounds writes and remote code execution.",
        "target": 1
      }
    ]
  },
  "cpio": {
    "0": [
      {
        "idx": 497736,
        "reasoning": "This code is potentially vulnerable to a heap buffer overflow. While the code checks if `file_hdr->c_filesize` is within a reasonable range, it still allocates a buffer based on this user-controlled size and then reads directly into it without further validation, potentially allowing a malicious archive to specify a size that, while within the initial range check, leads to a write beyond the allocated memory during the `tape_buffered_read` call.\n",
        "func": "get_link_name (struct cpio_file_stat *file_hdr, int in_file_des)\n{\n  char *link_name;\n  \n  if (file_hdr->c_filesize < 0 || file_hdr->c_filesize > SIZE_MAX-1)\n    {\n      error (0, 0, _(\"%s: stored filename length is out of range\"),\n\t     file_hdr->c_name);\n      link_name = NULL;\n    }\n  else\n    {\n      link_name = xmalloc (file_hdr->c_filesize + 1);\n      tape_buffered_read (link_name, in_file_des, file_hdr->c_filesize);\n      link_name[file_hdr->c_filesize] = '\\0';\n      tape_skip_padding (in_file_des, file_hdr->c_filesize);\n    }\n  return link_name;\n}",
        "commit_message": "Fix typo",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": []
  },
  "cpp-peglib": {
    "0": [
      {
        "idx": 235257,
        "reasoning": "This code snippet is not vulnerable because it simply stores a shared pointer to a `LiteralString` object within a member variable. There's no apparent manipulation of data, memory access, or external interaction that would introduce a security risk; it's a standard use of shared pointers for object tracking.\n",
        "func": "  void visit(LiteralString &ope) override {\n    found_ope = ope.shared_from_this();\n  }",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 0
      },
      {
        "idx": 235258,
        "reasoning": "This code snippet is not vulnerable because it simply defines an empty `visit` function for a `Dictionary` object within a larger parsing library. The function does nothing\u2014it doesn't process the dictionary's contents, access its data, or perform any operations that could lead to memory corruption, logic errors, or other security issues; therefore, it poses no immediate risk. \n\n\n\n",
        "func": "  virtual void visit(Dictionary & /*ope*/) {}",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 0
      },
      {
        "idx": 235259,
        "reasoning": "This code snippet appears safe as it correctly implements a type-safe `any_cast` function using `dynamic_cast` and checks for null pointers before accessing the contained value. The assertions and explicit `std::bad_cast` throws ensure that incorrect type casts are handled gracefully, preventing undefined behavior or information leaks\u2014common vulnerability sources.\n",
        "func": "template <typename T> T &any_cast(any &val) {\n  if (!val.content_) { throw std::bad_cast(); }\n  auto p = dynamic_cast<any::holder<T> *>(val.content_);\n  assert(p);\n  if (!p) { throw std::bad_cast(); }\n  return p->value_;\n}",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 0
      },
      {
        "idx": 235260,
        "reasoning": "This code snippet is not inherently vulnerable. It safely iterates through a collection of operations (`ope.opes_`) and recursively calls the `accept` method on each, with a short-circuit return if an error is detected\u2014preventing further potentially problematic execution. \n\n\n\n",
        "func": "  void visit(PrioritizedChoice &ope) override {\n    for (auto op : ope.opes_) {\n      op->accept(*this);\n      if (has_error) { return; }\n    }\n  }",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 0
      },
      {
        "idx": 235261,
        "reasoning": "This code snippet is not vulnerable because it simply returns a shared pointer to an existing object (`rule_->holder_`). There's no memory management issue introduced, no potential for use-after-free, or any other common vulnerability pattern present in this read-only access operation.",
        "func": "inline std::shared_ptr<Ope> Reference::get_core_operator() const {\n  return rule_->holder_;\n}",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195941,
        "reasoning": "The code is vulnerable to a NULL pointer dereference because it repeatedly accesses members of `data.grammar` without checking if `data.grammar` is actually initialized, potentially leading to a crash if the initial parsing step `g[\"Grammar\"].parse()` fails and returns `nullptr`. This aligns with the CVE description, as uninitialized or invalid data structures being accessed (like a potentially null `grammar`) can lead to a denial of service.",
        "func": "  std::shared_ptr<Grammar> perform_core(const char *s, size_t n,\n                                        const Rules &rules, std::string &start,\n                                        Log log) {\n    Data data;\n    any dt = &data;\n    auto r = g[\"Grammar\"].parse(s, n, dt);\n\n    if (!r.ret) {\n      if (log) {\n        if (r.message_pos) {\n          auto line = line_info(s, r.message_pos);\n          log(line.first, line.second, r.message);\n        } else {\n          auto line = line_info(s, r.error_pos);\n          log(line.first, line.second, \"syntax error\");\n        }\n      }\n      return nullptr;\n    }\n\n    auto &grammar = *data.grammar;\n\n    // User provided rules\n    for (const auto &x : rules) {\n      auto name = x.first;\n      bool ignore = false;\n      if (!name.empty() && name[0] == '~') {\n        ignore = true;\n        name.erase(0, 1);\n      }\n      if (!name.empty()) {\n        auto &rule = grammar[name];\n        rule <= x.second;\n        rule.name = name;\n        rule.ignoreSemanticValue = ignore;\n      }\n    }\n\n    // Check duplicated definitions\n    bool ret = data.duplicates.empty();\n\n    for (const auto &x : data.duplicates) {\n      if (log) {\n        const auto &name = x.first;\n        auto ptr = x.second;\n        auto line = line_info(s, ptr);\n        log(line.first, line.second, \"'\" + name + \"' is already defined.\");\n      }\n    }\n\n    // Check missing definitions\n    for (auto &x : grammar) {\n      auto &rule = x.second;\n\n      ReferenceChecker vis(*data.grammar, rule.params);\n      rule.accept(vis);\n      for (const auto &y : vis.error_s) {\n        const auto &name = y.first;\n        const auto ptr = y.second;\n        if (log) {\n          auto line = line_info(s, ptr);\n          log(line.first, line.second, vis.error_message[name]);\n        }\n        ret = false;\n      }\n    }\n\n    if (!ret) { return nullptr; }\n\n    // Link references\n    for (auto &x : grammar) {\n      auto &rule = x.second;\n      LinkReferences vis(*data.grammar, rule.params);\n      rule.accept(vis);\n    }\n\n    // Check left recursion\n    ret = true;\n\n    for (auto &x : grammar) {\n      const auto &name = x.first;\n      auto &rule = x.second;\n\n      DetectLeftRecursion vis(name);\n      rule.accept(vis);\n      if (vis.error_s) {\n        if (log) {\n          auto line = line_info(s, vis.error_s);\n          log(line.first, line.second, \"'\" + name + \"' is left recursive.\");\n        }\n        ret = false;\n      }\n    }\n\n    if (!ret) { return nullptr; }\n\n    // Set root definition\n    auto &start_rule = (*data.grammar)[data.start];\n\n    // Check infinite loop\n    {\n      DetectInfiniteLoop vis(data.start_pos, data.start);\n      start_rule.accept(vis);\n      if (vis.has_error) {\n        if (log) {\n          auto line = line_info(s, vis.error_s);\n          log(line.first, line.second,\n              \"infinite loop is detected in '\" + vis.error_name + \"'.\");\n        }\n        return nullptr;\n      }\n    }\n\n    // Automatic whitespace skipping\n    if (grammar.count(WHITESPACE_DEFINITION_NAME)) {\n      for (auto &x : grammar) {\n        auto &rule = x.second;\n        auto ope = rule.get_core_operator();\n        if (IsLiteralToken::check(*ope)) { rule <= tok(ope); }\n      }\n\n      start_rule.whitespaceOpe =\n          wsp((*data.grammar)[WHITESPACE_DEFINITION_NAME].get_core_operator());\n    }\n\n    // Word expression\n    if (grammar.count(WORD_DEFINITION_NAME)) {\n      start_rule.wordOpe =\n          (*data.grammar)[WORD_DEFINITION_NAME].get_core_operator();\n    }\n\n    // Apply instructions\n    for (const auto &item : data.instructions) {\n      const auto &name = item.first;\n      const auto &instruction = item.second;\n      auto &rule = grammar[name];\n\n      if (instruction.type == \"precedence\") {\n        const auto &info =\n            any_cast<PrecedenceClimbing::BinOpeInfo>(instruction.data);\n\n        if (!apply_precedence_instruction(rule, info, s, log)) {\n          return nullptr;\n        }\n      }\n    }\n\n    // Set root definition\n    start = data.start;\n\n    return data.grammar;\n  }",
        "commit_message": "Fix #121",
        "cve_desc": "An issue was discovered in cpp-peglib through v0.1.12. A NULL pointer dereference exists in the peg::AstOptimizer::optimize() located in peglib.h. It allows an attacker to cause Denial of Service.",
        "target": 1
      }
    ]
  },
  "crawl": {
    "0": [],
    "1": []
  },
  "curl": {
    "0": [
      {
        "idx": 33099,
        "reasoning": "This code snippet represents `curl_easy_escape`, which *encodes* a string, not *decodes* it like the vulnerable `curl_easy_unescape` function described in the CVE. The vulnerability CVE-2013-2174 specifically lies within the decoding process, where improper bounds checking during URL unescaping leads to buffer over-reads and writes, a functionality not present in this encoding code.\n\n\n\n",
        "func": "char *curl_easy_escape(CURL *handle, const char *string, int inlength)\n{\n  size_t alloc = (inlength?(size_t)inlength:strlen(string))+1;\n  char *ns;\n  char *testing_ptr = NULL;\n  unsigned char in; /* we need to treat the characters unsigned */\n  size_t newlen = alloc;\n  size_t strindex=0;\n  size_t length;\n  CURLcode res;\n\n  ns = malloc(alloc);\n  if(!ns)\n    return NULL;\n\n  length = alloc-1;\n  while(length--) {\n    in = *string;\n\n    if(Curl_isunreserved(in))\n      /* just copy this */\n      ns[strindex++]=in;\n    else {\n      /* encode it */\n      newlen += 2; /* the size grows with two, since this'll become a %XX */\n      if(newlen > alloc) {\n        alloc *= 2;\n        testing_ptr = realloc(ns, alloc);\n        if(!testing_ptr) {\n          free( ns );\n          return NULL;\n        }\n        else {\n          ns = testing_ptr;\n        }\n      }\n\n      res = Curl_convert_to_network(handle, &in, 1);\n      if(res) {\n        /* Curl_convert_to_network calls failf if unsuccessful */\n        free(ns);\n        return NULL;\n      }\n\n      snprintf(&ns[strindex], 4, \"%%%02X\", in);\n\n      strindex+=3;\n    }\n    string++;\n  }\n  ns[strindex]=0; /* terminate it */\n  return ns;\n}\n",
        "commit_message": "Curl_urldecode: no peeking beyond end of input buffer\n\nSecurity problem: CVE-2013-2174\n\nIf a program would give a string like \"%FF\" to curl_easy_unescape() but\nask for it to decode only the first byte, it would still parse and\ndecode the full hex sequence. The function then not only read beyond the\nallowed buffer but it would also deduct the *unsigned* counter variable\nfor how many more bytes there's left to read in the buffer by two,\nmaking the counter wrap. Continuing this, the function would go on\nreading beyond the buffer and soon writing beyond the allocated target\nbuffer...\n\nBug: http://curl.haxx.se/docs/adv_20130622.html\nReported-by: Timo Sirainen",
        "cve_desc": "Heap-based buffer overflow in the curl_easy_unescape function in lib/escape.c in cURL and libcurl 7.7 through 7.30.0 allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted string ending in a \"%\" (percent) character.",
        "target": 0
      },
      {
        "idx": 33100,
        "reasoning": "This code snippet is **not directly vulnerable** because it simply calls `Curl_urldecode` and handles the result; the vulnerability lies *within* the `Curl_urldecode` function itself, not in how `curl_easy_unescape` utilizes it. The provided code only passes arguments to `Curl_urldecode` and manages the returned values, lacking the problematic logic that causes the out-of-bounds read/write described in the CVE.\n\n\n\n",
        "func": "char *curl_easy_unescape(CURL *handle, const char *string, int length,\n                         int *olen)\n{\n  char *str = NULL;\n  size_t inputlen = length;\n  size_t outputlen;\n  CURLcode res = Curl_urldecode(handle, string, inputlen, &str, &outputlen,\n                                FALSE);\n  if(res)\n    return NULL;\n  if(olen)\n    *olen = curlx_uztosi(outputlen);\n  return str;\n}\n",
        "commit_message": "Curl_urldecode: no peeking beyond end of input buffer\n\nSecurity problem: CVE-2013-2174\n\nIf a program would give a string like \"%FF\" to curl_easy_unescape() but\nask for it to decode only the first byte, it would still parse and\ndecode the full hex sequence. The function then not only read beyond the\nallowed buffer but it would also deduct the *unsigned* counter variable\nfor how many more bytes there's left to read in the buffer by two,\nmaking the counter wrap. Continuing this, the function would go on\nreading beyond the buffer and soon writing beyond the allocated target\nbuffer...\n\nBug: http://curl.haxx.se/docs/adv_20130622.html\nReported-by: Timo Sirainen",
        "cve_desc": "Heap-based buffer overflow in the curl_easy_unescape function in lib/escape.c in cURL and libcurl 7.7 through 7.30.0 allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted string ending in a \"%\" (percent) character.",
        "target": 0
      },
      {
        "idx": 33781,
        "reasoning": "The provided code snippet addresses the vulnerability described in CVE-2013-1944 by implementing a `tailmatch` function and checks within the `Curl_cookie_add` function to ensure that cookies are only sent to domains for which they are valid. Specifically, it verifies that the cookie's domain matches the requested domain, preventing accidental leakage to subdomains (like `bexample.com` from `example.com`).",
        "func": "Curl_cookie_add(struct SessionHandle *data,\n                /* The 'data' pointer here may be NULL at times, and thus\n                   must only be used very carefully for things that can deal\n                   with data being NULL. Such as infof() and similar */\n\n                struct CookieInfo *c,\n                bool httpheader, /* TRUE if HTTP header-style line */\n                char *lineptr,   /* first character of the line */\n                const char *domain, /* default domain */\n                const char *path)   /* full path used when this cookie is set,\n                                       used to get default path for the cookie\n                                       unless set */\n{\n  struct Cookie *clist;\n  char name[MAX_NAME];\n  struct Cookie *co;\n  struct Cookie *lastc=NULL;\n  time_t now = time(NULL);\n  bool replace_old = FALSE;\n  bool badcookie = FALSE; /* cookies are good by default. mmmmm yummy */\n\n#ifdef CURL_DISABLE_VERBOSE_STRINGS\n  (void)data;\n#endif\n\n  /* First, alloc and init a new struct for it */\n  co = calloc(1, sizeof(struct Cookie));\n  if(!co)\n    return NULL; /* bail out if we're this low on memory */\n\n  if(httpheader) {\n    /* This line was read off a HTTP-header */\n    const char *ptr;\n    const char *semiptr;\n    char *what;\n\n    what = malloc(MAX_COOKIE_LINE);\n    if(!what) {\n      free(co);\n      return NULL;\n    }\n\n    semiptr=strchr(lineptr, ';'); /* first, find a semicolon */\n\n    while(*lineptr && ISBLANK(*lineptr))\n      lineptr++;\n\n    ptr = lineptr;\n    do {\n      /* we have a <what>=<this> pair or a stand-alone word here */\n      name[0]=what[0]=0; /* init the buffers */\n      if(1 <= sscanf(ptr, \"%\" MAX_NAME_TXT \"[^;\\r\\n =]=%\"\n                     MAX_COOKIE_LINE_TXT \"[^;\\r\\n]\",\n                     name, what)) {\n        /* Use strstore() below to properly deal with received cookie\n           headers that have the same string property set more than once,\n           and then we use the last one. */\n        const char *whatptr;\n        bool done = FALSE;\n        bool sep;\n        size_t len=strlen(what);\n        const char *endofn = &ptr[ strlen(name) ];\n\n        /* skip trailing spaces in name */\n        while(*endofn && ISBLANK(*endofn))\n          endofn++;\n\n        /* name ends with a '=' ? */\n        sep = (*endofn == '=')?TRUE:FALSE;\n\n        /* Strip off trailing whitespace from the 'what' */\n        while(len && ISBLANK(what[len-1])) {\n          what[len-1]=0;\n          len--;\n        }\n\n        /* Skip leading whitespace from the 'what' */\n        whatptr=what;\n        while(*whatptr && ISBLANK(*whatptr))\n          whatptr++;\n\n        if(!len) {\n          /* this was a \"<name>=\" with no content, and we must allow\n             'secure' and 'httponly' specified this weirdly */\n          done = TRUE;\n          if(Curl_raw_equal(\"secure\", name))\n            co->secure = TRUE;\n          else if(Curl_raw_equal(\"httponly\", name))\n            co->httponly = TRUE;\n          else if(sep)\n            /* there was a '=' so we're not done parsing this field */\n            done = FALSE;\n        }\n        if(done)\n          ;\n        else if(Curl_raw_equal(\"path\", name)) {\n          strstore(&co->path, whatptr);\n          if(!co->path) {\n            badcookie = TRUE; /* out of memory bad */\n            break;\n          }\n        }\n        else if(Curl_raw_equal(\"domain\", name)) {\n          /* note that this name may or may not have a preceding dot, but\n             we don't care about that, we treat the names the same anyway */\n\n          const char *domptr=whatptr;\n          const char *nextptr;\n          int dotcount=1;\n\n          /* Count the dots, we need to make sure that there are enough\n             of them. */\n\n          if('.' == whatptr[0])\n            /* don't count the initial dot, assume it */\n            domptr++;\n\n          do {\n            nextptr = strchr(domptr, '.');\n            if(nextptr) {\n              if(domptr != nextptr)\n                dotcount++;\n              domptr = nextptr+1;\n            }\n          } while(nextptr);\n\n          /* The original Netscape cookie spec defined that this domain name\n             MUST have three dots (or two if one of the seven holy TLDs),\n             but it seems that these kinds of cookies are in use \"out there\"\n             so we cannot be that strict. I've therefore lowered the check\n             to not allow less than two dots. */\n\n          if(dotcount < 2) {\n            /* Received and skipped a cookie with a domain using too few\n               dots. */\n            badcookie=TRUE; /* mark this as a bad cookie */\n            infof(data, \"skipped cookie with illegal dotcount domain: %s\\n\",\n                  whatptr);\n          }\n          else {\n            /* Now, we make sure that our host is within the given domain,\n               or the given domain is not valid and thus cannot be set. */\n\n            if('.' == whatptr[0])\n              whatptr++; /* ignore preceding dot */\n\n            if(!domain || tailmatch(whatptr, domain)) {\n              const char *tailptr=whatptr;\n              if(tailptr[0] == '.')\n                tailptr++;\n              strstore(&co->domain, tailptr); /* don't prefix w/dots\n                                                 internally */\n              if(!co->domain) {\n                badcookie = TRUE;\n                break;\n              }\n              co->tailmatch=TRUE; /* we always do that if the domain name was\n                                     given */\n            }\n            else {\n              /* we did not get a tailmatch and then the attempted set domain\n                 is not a domain to which the current host belongs. Mark as\n                 bad. */\n              badcookie=TRUE;\n              infof(data, \"skipped cookie with bad tailmatch domain: %s\\n\",\n                    whatptr);\n            }\n          }\n        }\n        else if(Curl_raw_equal(\"version\", name)) {\n          strstore(&co->version, whatptr);\n          if(!co->version) {\n            badcookie = TRUE;\n            break;\n          }\n        }\n        else if(Curl_raw_equal(\"max-age\", name)) {\n          /* Defined in RFC2109:\n\n             Optional.  The Max-Age attribute defines the lifetime of the\n             cookie, in seconds.  The delta-seconds value is a decimal non-\n             negative integer.  After delta-seconds seconds elapse, the\n             client should discard the cookie.  A value of zero means the\n             cookie should be discarded immediately.\n\n          */\n          strstore(&co->maxage, whatptr);\n          if(!co->maxage) {\n            badcookie = TRUE;\n            break;\n          }\n          co->expires =\n            strtol((*co->maxage=='\\\"')?&co->maxage[1]:&co->maxage[0],NULL,10)\n            + (long)now;\n        }\n        else if(Curl_raw_equal(\"expires\", name)) {\n          strstore(&co->expirestr, whatptr);\n          if(!co->expirestr) {\n            badcookie = TRUE;\n            break;\n          }\n          /* Note that if the date couldn't get parsed for whatever reason,\n             the cookie will be treated as a session cookie */\n          co->expires = curl_getdate(what, &now);\n\n          /* Session cookies have expires set to 0 so if we get that back\n             from the date parser let's add a second to make it a\n             non-session cookie */\n          if(co->expires == 0)\n            co->expires = 1;\n          else if(co->expires < 0)\n            co->expires = 0;\n        }\n        else if(!co->name) {\n          co->name = strdup(name);\n          co->value = strdup(whatptr);\n          if(!co->name || !co->value) {\n            badcookie = TRUE;\n            break;\n          }\n        }\n        /*\n          else this is the second (or more) name we don't know\n          about! */\n      }\n      else {\n        /* this is an \"illegal\" <what>=<this> pair */\n      }\n\n      if(!semiptr || !*semiptr) {\n        /* we already know there are no more cookies */\n        semiptr = NULL;\n        continue;\n      }\n\n      ptr=semiptr+1;\n      while(*ptr && ISBLANK(*ptr))\n        ptr++;\n      semiptr=strchr(ptr, ';'); /* now, find the next semicolon */\n\n      if(!semiptr && *ptr)\n        /* There are no more semicolons, but there's a final name=value pair\n           coming up */\n        semiptr=strchr(ptr, '\\0');\n    } while(semiptr);\n\n    if(!badcookie && !co->domain) {\n      if(domain) {\n        /* no domain was given in the header line, set the default */\n        co->domain=strdup(domain);\n        if(!co->domain)\n          badcookie = TRUE;\n      }\n    }\n\n    if(!badcookie && !co->path && path) {\n      /* No path was given in the header line, set the default.\n         Note that the passed-in path to this function MAY have a '?' and\n         following part that MUST not be stored as part of the path. */\n      char *queryp = strchr(path, '?');\n\n      /* queryp is where the interesting part of the path ends, so now we\n         want to the find the last */\n      char *endslash;\n      if(!queryp)\n        endslash = strrchr(path, '/');\n      else\n        endslash = memrchr(path, '/', (size_t)(queryp - path));\n      if(endslash) {\n        size_t pathlen = (size_t)(endslash-path+1); /* include ending slash */\n        co->path=malloc(pathlen+1); /* one extra for the zero byte */\n        if(co->path) {\n          memcpy(co->path, path, pathlen);\n          co->path[pathlen]=0; /* zero terminate */\n        }\n        else\n          badcookie = TRUE;\n      }\n    }\n\n    free(what);\n\n    if(badcookie || !co->name) {\n      /* we didn't get a cookie name or a bad one,\n         this is an illegal line, bail out */\n      freecookie(co);\n      return NULL;\n    }\n\n  }\n  else {\n    /* This line is NOT a HTTP header style line, we do offer support for\n       reading the odd netscape cookies-file format here */\n    char *ptr;\n    char *firstptr;\n    char *tok_buf=NULL;\n    int fields;\n\n    /* IE introduced HTTP-only cookies to prevent XSS attacks. Cookies\n       marked with httpOnly after the domain name are not accessible\n       from javascripts, but since curl does not operate at javascript\n       level, we include them anyway. In Firefox's cookie files, these\n       lines are preceded with #HttpOnly_ and then everything is\n       as usual, so we skip 10 characters of the line..\n    */\n    if(strncmp(lineptr, \"#HttpOnly_\", 10) == 0) {\n      lineptr += 10;\n      co->httponly = TRUE;\n    }\n\n    if(lineptr[0]=='#') {\n      /* don't even try the comments */\n      free(co);\n      return NULL;\n    }\n    /* strip off the possible end-of-line characters */\n    ptr=strchr(lineptr, '\\r');\n    if(ptr)\n      *ptr=0; /* clear it */\n    ptr=strchr(lineptr, '\\n');\n    if(ptr)\n      *ptr=0; /* clear it */\n\n    firstptr=strtok_r(lineptr, \"\\t\", &tok_buf); /* tokenize it on the TAB */\n\n    /* Here's a quick check to eliminate normal HTTP-headers from this */\n    if(!firstptr || strchr(firstptr, ':')) {\n      free(co);\n      return NULL;\n    }\n\n    /* Now loop through the fields and init the struct we already have\n       allocated */\n    for(ptr=firstptr, fields=0; ptr && !badcookie;\n        ptr=strtok_r(NULL, \"\\t\", &tok_buf), fields++) {\n      switch(fields) {\n      case 0:\n        if(ptr[0]=='.') /* skip preceding dots */\n          ptr++;\n        co->domain = strdup(ptr);\n        if(!co->domain)\n          badcookie = TRUE;\n        break;\n      case 1:\n        /* This field got its explanation on the 23rd of May 2001 by\n           Andrs Garca:\n\n           flag: A TRUE/FALSE value indicating if all machines within a given\n           domain can access the variable. This value is set automatically by\n           the browser, depending on the value you set for the domain.\n\n           As far as I can see, it is set to true when the cookie says\n           .domain.com and to false when the domain is complete www.domain.com\n        */\n        co->tailmatch = Curl_raw_equal(ptr, \"TRUE\")?TRUE:FALSE;\n        break;\n      case 2:\n        /* It turns out, that sometimes the file format allows the path\n           field to remain not filled in, we try to detect this and work\n           around it! Andrs Garca made us aware of this... */\n        if(strcmp(\"TRUE\", ptr) && strcmp(\"FALSE\", ptr)) {\n          /* only if the path doesn't look like a boolean option! */\n          co->path = strdup(ptr);\n          if(!co->path)\n            badcookie = TRUE;\n          break;\n        }\n        /* this doesn't look like a path, make one up! */\n        co->path = strdup(\"/\");\n        if(!co->path)\n          badcookie = TRUE;\n        fields++; /* add a field and fall down to secure */\n        /* FALLTHROUGH */\n      case 3:\n        co->secure = Curl_raw_equal(ptr, \"TRUE\")?TRUE:FALSE;\n        break;\n      case 4:\n        co->expires = curlx_strtoofft(ptr, NULL, 10);\n        break;\n      case 5:\n        co->name = strdup(ptr);\n        if(!co->name)\n          badcookie = TRUE;\n        break;\n      case 6:\n        co->value = strdup(ptr);\n        if(!co->value)\n          badcookie = TRUE;\n        break;\n      }\n    }\n    if(6 == fields) {\n      /* we got a cookie with blank contents, fix it */\n      co->value = strdup(\"\");\n      if(!co->value)\n        badcookie = TRUE;\n      else\n        fields++;\n    }\n\n    if(!badcookie && (7 != fields))\n      /* we did not find the sufficient number of fields */\n      badcookie = TRUE;\n\n    if(badcookie) {\n      freecookie(co);\n      return NULL;\n    }\n\n  }\n\n  if(!c->running &&    /* read from a file */\n     c->newsession &&  /* clean session cookies */\n     !co->expires) {   /* this is a session cookie since it doesn't expire! */\n    freecookie(co);\n    return NULL;\n  }\n\n  co->livecookie = c->running;\n\n  /* now, we have parsed the incoming line, we must now check if this\n     superceeds an already existing cookie, which it may if the previous have\n     the same domain and path as this */\n\n  clist = c->cookies;\n  replace_old = FALSE;\n  while(clist) {\n    if(Curl_raw_equal(clist->name, co->name)) {\n      /* the names are identical */\n\n      if(clist->domain && co->domain) {\n        if(Curl_raw_equal(clist->domain, co->domain))\n          /* The domains are identical */\n          replace_old=TRUE;\n      }\n      else if(!clist->domain && !co->domain)\n        replace_old = TRUE;\n\n      if(replace_old) {\n        /* the domains were identical */\n\n        if(clist->path && co->path) {\n          if(Curl_raw_equal(clist->path, co->path)) {\n            replace_old = TRUE;\n          }\n          else\n            replace_old = FALSE;\n        }\n        else if(!clist->path && !co->path)\n          replace_old = TRUE;\n        else\n          replace_old = FALSE;\n\n      }\n\n      if(replace_old && !co->livecookie && clist->livecookie) {\n        /* Both cookies matched fine, except that the already present\n           cookie is \"live\", which means it was set from a header, while\n           the new one isn't \"live\" and thus only read from a file. We let\n           live cookies stay alive */\n\n        /* Free the newcomer and get out of here! */\n        freecookie(co);\n        return NULL;\n      }\n\n      if(replace_old) {\n        co->next = clist->next; /* get the next-pointer first */\n\n        /* then free all the old pointers */\n        free(clist->name);\n        if(clist->value)\n          free(clist->value);\n        if(clist->domain)\n          free(clist->domain);\n        if(clist->path)\n          free(clist->path);\n        if(clist->expirestr)\n          free(clist->expirestr);\n\n        if(clist->version)\n          free(clist->version);\n        if(clist->maxage)\n          free(clist->maxage);\n\n        *clist = *co;  /* then store all the new data */\n\n        free(co);   /* free the newly alloced memory */\n        co = clist; /* point to the previous struct instead */\n\n        /* We have replaced a cookie, now skip the rest of the list but\n           make sure the 'lastc' pointer is properly set */\n        do {\n          lastc = clist;\n          clist = clist->next;\n        } while(clist);\n        break;\n      }\n    }\n    lastc = clist;\n    clist = clist->next;\n  }\n\n  if(c->running)\n    /* Only show this when NOT reading the cookies from a file */\n    infof(data, \"%s cookie %s=\\\"%s\\\" for domain %s, path %s, \"\n          \"expire %\" FORMAT_OFF_T \"\\n\",\n          replace_old?\"Replaced\":\"Added\", co->name, co->value,\n          co->domain, co->path, co->expires);\n\n  if(!replace_old) {\n    /* then make the last item point on this new one */\n    if(lastc)\n      lastc->next = co;\n    else\n      c->cookies = co;\n    c->numcookies++; /* one more cookie in the jar */\n  }\n\n  return co;\n}\n",
        "commit_message": "cookie: fix tailmatching to prevent cross-domain leakage\n\nCookies set for 'example.com' could accidentaly also be sent by libcurl\nto the 'bexample.com' (ie with a prefix to the first domain name).\n\nThis is a security vulnerabilty, CVE-2013-1944.\n\nBug: http://curl.haxx.se/docs/adv_20130412.html",
        "cve_desc": "The tailMatch function in cookie.c in cURL and libcurl before 7.30.0 does not properly match the path domain when sending cookies, which allows remote attackers to steal cookies via a matching suffix in the domain of a URL.",
        "target": 0
      },
      {
        "idx": 33782,
        "reasoning": "This code snippet, `Curl_cookie_cleanup`, is responsible for freeing cookie data structures and is **not directly related to the cookie tailmatching vulnerability** described in the commit message and CVE-2013-1944. The vulnerability lies in how cookies are *matched* to domains, not in how they are cleaned up from memory, therefore this code is safe as presented.\n\n\n\n",
        "func": "void Curl_cookie_cleanup(struct CookieInfo *c)\n{\n  struct Cookie *co;\n  struct Cookie *next;\n  if(c) {\n    if(c->filename)\n      free(c->filename);\n    co = c->cookies;\n\n    while(co) {\n      next = co->next;\n      freecookie(co);\n      co = next;\n    }\n    free(c); /* free the base struct as well */\n  }\n}\n",
        "commit_message": "cookie: fix tailmatching to prevent cross-domain leakage\n\nCookies set for 'example.com' could accidentaly also be sent by libcurl\nto the 'bexample.com' (ie with a prefix to the first domain name).\n\nThis is a security vulnerabilty, CVE-2013-1944.\n\nBug: http://curl.haxx.se/docs/adv_20130412.html",
        "cve_desc": "The tailMatch function in cookie.c in cURL and libcurl before 7.30.0 does not properly match the path domain when sending cookies, which allows remote attackers to steal cookies via a matching suffix in the domain of a URL.",
        "target": 0
      },
      {
        "idx": 33783,
        "reasoning": "This code snippet for `Curl_cookie_clearall` is responsible for freeing cookie data and is not directly involved in the parsing or matching of domain names for cookies. The vulnerability, CVE-2013-1944, resided in the *matching* logic when determining which domains a cookie applies to, not in the clearing of cookies themselves, therefore this code is not vulnerable.\n\n\n\n",
        "func": "void Curl_cookie_clearall(struct CookieInfo *cookies)\n{\n  if(cookies) {\n    Curl_cookie_freelist(cookies->cookies, TRUE);\n    cookies->cookies = NULL;\n    cookies->numcookies = 0;\n  }\n}\n",
        "commit_message": "cookie: fix tailmatching to prevent cross-domain leakage\n\nCookies set for 'example.com' could accidentaly also be sent by libcurl\nto the 'bexample.com' (ie with a prefix to the first domain name).\n\nThis is a security vulnerabilty, CVE-2013-1944.\n\nBug: http://curl.haxx.se/docs/adv_20130412.html",
        "cve_desc": "The tailMatch function in cookie.c in cURL and libcurl before 7.30.0 does not properly match the path domain when sending cookies, which allows remote attackers to steal cookies via a matching suffix in the domain of a URL.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1040,
        "reasoning": "The code is vulnerable to a heap-based buffer overflow because the `while` loop continues processing the input string even after decrementing `alloc` beyond zero, leading to reads beyond the intended buffer boundary. Specifically, when encountering a `%` followed by hexadecimal digits, the code advances the input string pointer (`string += 2`) and reduces `alloc` by 2, but doesn't adequately check if `alloc` remains positive, allowing it to wrap around to a large value and cause out-of-bounds access.",
        "func": "CURLcode Curl_urldecode(struct SessionHandle *data,\n                        const char *string, size_t length,\n                        char **ostring, size_t *olen,\n                        bool reject_ctrl)\n{\n  size_t alloc = (length?length:strlen(string))+1;\n  char *ns = malloc(alloc);\n  unsigned char in;\n  size_t strindex=0;\n  unsigned long hex;\n  CURLcode res;\n\n  if(!ns)\n    return CURLE_OUT_OF_MEMORY;\n \n   while(--alloc > 0) {\n     in = *string;\n    if(('%' == in) && ISXDIGIT(string[1]) && ISXDIGIT(string[2])) {\n       /* this is two hexadecimal digits following a '%' */\n       char hexstr[3];\n       char *ptr;\n      hexstr[0] = string[1];\n      hexstr[1] = string[2];\n      hexstr[2] = 0;\n\n      hex = strtoul(hexstr, &ptr, 16);\n\n      in = curlx_ultouc(hex); /* this long is never bigger than 255 anyway */\n\n      res = Curl_convert_from_network(data, &in, 1);\n      if(res) {\n        /* Curl_convert_from_network calls failf if unsuccessful */\n        free(ns);\n        return res;\n      }\n\n      string+=2;\n      alloc-=2;\n    }\n    if(reject_ctrl && (in < 0x20)) {\n      free(ns);\n      return CURLE_URL_MALFORMAT;\n    }\n\n    ns[strindex++] = in;\n    string++;\n  }\n  ns[strindex]=0; /* terminate it */\n\n  if(olen)\n    /* store output size */\n    *olen = strindex;\n\n  if(ostring)\n    /* store output string */\n    *ostring = ns;\n\n  return CURLE_OK;\n}\n",
        "commit_message": "Curl_urldecode: no peeking beyond end of input buffer\n\nSecurity problem: CVE-2013-2174\n\nIf a program would give a string like \"%FF\" to curl_easy_unescape() but\nask for it to decode only the first byte, it would still parse and\ndecode the full hex sequence. The function then not only read beyond the\nallowed buffer but it would also deduct the *unsigned* counter variable\nfor how many more bytes there's left to read in the buffer by two,\nmaking the counter wrap. Continuing this, the function would go on\nreading beyond the buffer and soon writing beyond the allocated target\nbuffer...\n\nBug: http://curl.haxx.se/docs/adv_20130622.html\nReported-by: Timo Sirainen",
        "cve_desc": "Heap-based buffer overflow in the curl_easy_unescape function in lib/escape.c in cURL and libcurl 7.7 through 7.30.0 allows remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted string ending in a \"%\" (percent) character.",
        "target": 1
      },
      {
        "idx": 1055,
        "reasoning": "This code is vulnerable because the `tailmatch` function incorrectly checks if a cookie domain is a suffix of another, allowing a cookie intended for `example.com` to be sent to `bexample.com` if the latter shares a trailing domain segment. This allows an attacker controlling `bexample.com` to potentially receive cookies meant for `example.com`, leading to cross-domain leakage and potential session hijacking.\n\n\n\n",
        "func": "static bool tailmatch(const char *little, const char *bigone)\n {\n  size_t littlelen = strlen(little);\n  size_t biglen = strlen(bigone);\n \n  if(littlelen > biglen)\n     return FALSE;\n \n  return Curl_raw_equal(little, bigone+biglen-littlelen) ? TRUE : FALSE;\n }\n",
        "commit_message": "cookie: fix tailmatching to prevent cross-domain leakage\n\nCookies set for 'example.com' could accidentaly also be sent by libcurl\nto the 'bexample.com' (ie with a prefix to the first domain name).\n\nThis is a security vulnerabilty, CVE-2013-1944.\n\nBug: http://curl.haxx.se/docs/adv_20130412.html",
        "cve_desc": "The tailMatch function in cookie.c in cURL and libcurl before 7.30.0 does not properly match the path domain when sending cookies, which allows remote attackers to steal cookies via a matching suffix in the domain of a URL.",
        "target": 1
      },
      {
        "idx": 1746,
        "reasoning": "This code is vulnerable because it reuses a previously loaded client certificate from a file even when a certificate isn\u2019t explicitly requested for the connection, allowing an attacker to potentially hijack TLS authentication. Specifically, the `if(connssl->obj_clicert)` block executes and loads a certificate if `connssl->obj_clicert` is set, but this object could persist from a previous connection where a certificate *was* requested, leading to unintended certificate usage.",
        "func": "static SECStatus SelectClientCert(void *arg, PRFileDesc *sock,\n                                  struct CERTDistNamesStr *caNames,\n                                  struct CERTCertificateStr **pRetCert,\n                                  struct SECKEYPrivateKeyStr **pRetKey)\n{\n   struct ssl_connect_data *connssl = (struct ssl_connect_data *)arg;\n   struct Curl_easy *data = connssl->data;\n   const char *nickname = connssl->client_nickname;\n \n   if(connssl->obj_clicert) {\n     /* use the cert/key provided by PEM reader */\n    static const char pem_slotname[] = \"PEM Token #1\";\n     SECItem cert_der = { 0, NULL, 0 };\n     void *proto_win = SSL_RevealPinArg(sock);\n     struct CERTCertificateStr *cert;\n    struct SECKEYPrivateKeyStr *key;\n\n    PK11SlotInfo *slot = PK11_FindSlotByName(pem_slotname);\n    if(NULL == slot) {\n      failf(data, \"NSS: PK11 slot not found: %s\", pem_slotname);\n      return SECFailure;\n    }\n\n    if(PK11_ReadRawAttribute(PK11_TypeGeneric, connssl->obj_clicert, CKA_VALUE,\n                             &cert_der) != SECSuccess) {\n      failf(data, \"NSS: CKA_VALUE not found in PK11 generic object\");\n      PK11_FreeSlot(slot);\n      return SECFailure;\n    }\n\n    cert = PK11_FindCertFromDERCertItem(slot, &cert_der, proto_win);\n    SECITEM_FreeItem(&cert_der, PR_FALSE);\n    if(NULL == cert) {\n      failf(data, \"NSS: client certificate from file not found\");\n      PK11_FreeSlot(slot);\n      return SECFailure;\n    }\n\n    key = PK11_FindPrivateKeyFromCert(slot, cert, NULL);\n    PK11_FreeSlot(slot);\n    if(NULL == key) {\n      failf(data, \"NSS: private key from file not found\");\n      CERT_DestroyCertificate(cert);\n      return SECFailure;\n    }\n\n    infof(data, \"NSS: client certificate from file\\n\");\n    display_cert_info(data, cert);\n\n    *pRetCert = cert;\n    *pRetKey = key;\n    return SECSuccess;\n  }\n\n  /* use the default NSS hook */\n  if(SECSuccess != NSS_GetClientAuthData((void *)nickname, sock, caNames,\n                                          pRetCert, pRetKey)\n      || NULL == *pRetCert) {\n\n    if(NULL == nickname)\n      failf(data, \"NSS: client certificate not found (nickname not \"\n            \"specified)\");\n    else\n      failf(data, \"NSS: client certificate not found: %s\", nickname);\n\n    return SECFailure;\n  }\n\n  /* get certificate nickname if any */\n  nickname = (*pRetCert)->nickname;\n   if(NULL == nickname)\n     nickname = \"[unknown]\";\n \n   if(NULL == *pRetKey) {\n     failf(data, \"NSS: private key not found for certificate: %s\", nickname);\n     return SECFailure;\n  }\n\n  infof(data, \"NSS: using client certificate: %s\\n\", nickname);\n  display_cert_info(data, *pRetCert);\n  return SECSuccess;\n}\n",
        "commit_message": "nss: refuse previously loaded certificate from file\n\n... when we are not asked to use a certificate from file",
        "cve_desc": "curl and libcurl before 7.50.2, when built with NSS and the libnsspem.so library is available at runtime, allow remote attackers to hijack the authentication of a TLS connection by leveraging reuse of a previously loaded client certificate from file for a connection for which no certificate has been set, a different vulnerability than CVE-2016-5420.",
        "target": 1
      },
      {
        "idx": 3545,
        "reasoning": "This code is vulnerable to a heap-based buffer over-read because the `cut` variable, intended to limit the output to `width`, can be zero in cases where no whitespace is found within the first `width` characters of `print_buffer`. Consequently, the `fwrite` function attempts to write `cut + 1` bytes (potentially 1 byte) from `print_buffer`, leading to a read beyond the allocated buffer's boundaries when `ptr` is near the end of the buffer.",
        "func": "static void voutf(struct GlobalConfig *config,\n                  const char *prefix,\n                  const char *fmt,\n                  va_list ap)\n{\n  size_t width = (79 - strlen(prefix));\n  if(!config->mute) {\n    size_t len;\n    char *ptr;\n    char *print_buffer;\n\n    print_buffer = curlx_mvaprintf(fmt, ap);\n    if(!print_buffer)\n      return;\n    len = strlen(print_buffer);\n\n    ptr = print_buffer;\n    while(len > 0) {\n      fputs(prefix, config->errors);\n\n      if(len > width) {\n        size_t cut = width-1;\n\n        while(!ISSPACE(ptr[cut]) && cut) {\n          cut--;\n        }\n        if(0 == cut)\n          /* not a single cutting position was found, just cut it at the\n             max text width then! */\n          cut = width-1;\n\n         (void)fwrite(ptr, cut + 1, 1, config->errors);\n         fputs(\"\\n\", config->errors);\n         ptr += cut + 1; /* skip the space too */\n        len -= cut;\n       }\n       else {\n         fputs(ptr, config->errors);\n        len = 0;\n      }\n    }\n    curl_free(print_buffer);\n  }\n}\n",
        "commit_message": "voutf: fix bad arethmetic when outputting warnings to stderr\n\nCVE-2018-16842\nReported-by: Brian Carpenter\nBug: https://curl.haxx.se/docs/CVE-2018-16842.html",
        "cve_desc": "Curl versions 7.14.1 through 7.61.1 are vulnerable to a heap-based buffer over-read in the tool_msgs.c:voutf() function that may result in information exposure and denial of service.",
        "target": 1
      },
      {
        "idx": 3546,
        "reasoning": "This code is vulnerable to a heap use-after-free because it frees `data->multi_easy` but doesn't nullify the pointer, potentially allowing subsequent operations to access the freed memory. Specifically, the code continues to use fields within the `data` struct *after* potentially freeing parts of it, as highlighted by the CVE description regarding writing to already freed structures.\n\n\n\n",
        "func": "CURLcode Curl_close(struct Curl_easy *data)\n{\n  struct Curl_multi *m;\n\n  if(!data)\n    return CURLE_OK;\n\n  Curl_expire_clear(data); /* shut off timers */\n\n  m = data->multi;\n  if(m)\n    /* This handle is still part of a multi handle, take care of this first\n        and detach this handle from there. */\n     curl_multi_remove_handle(data->multi, data);\n \n  if(data->multi_easy)\n     /* when curl_easy_perform() is used, it creates its own multi handle to\n        use and this is the one */\n     curl_multi_cleanup(data->multi_easy);\n \n   /* Destroy the timeout list that is held in the easy handle. It is\n      /normally/ done by curl_multi_remove_handle() but this is \"just in\n     case\" */\n  Curl_llist_destroy(&data->state.timeoutlist, NULL);\n\n  data->magic = 0; /* force a clear AFTER the possibly enforced removal from\n                      the multi handle, since that function uses the magic\n                      field! */\n\n  if(data->state.rangestringalloc)\n    free(data->state.range);\n\n  /* freed here just in case DONE wasn't called */\n  Curl_free_request_state(data);\n\n  /* Close down all open SSL info and sessions */\n  Curl_ssl_close_all(data);\n  Curl_safefree(data->state.first_host);\n  Curl_safefree(data->state.scratch);\n  Curl_ssl_free_certinfo(data);\n\n  /* Cleanup possible redirect junk */\n  free(data->req.newurl);\n  data->req.newurl = NULL;\n\n  if(data->change.referer_alloc) {\n    Curl_safefree(data->change.referer);\n    data->change.referer_alloc = FALSE;\n  }\n  data->change.referer = NULL;\n\n  Curl_up_free(data);\n  Curl_safefree(data->state.buffer);\n  Curl_safefree(data->state.headerbuff);\n  Curl_safefree(data->state.ulbuf);\n  Curl_flush_cookies(data, 1);\n  Curl_digest_cleanup(data);\n  Curl_safefree(data->info.contenttype);\n  Curl_safefree(data->info.wouldredirect);\n\n  /* this destroys the channel and we cannot use it anymore after this */\n  Curl_resolver_cleanup(data->state.resolver);\n\n  Curl_http2_cleanup_dependencies(data);\n  Curl_convert_close(data);\n\n  /* No longer a dirty share, if it exists */\n  if(data->share) {\n    Curl_share_lock(data, CURL_LOCK_DATA_SHARE, CURL_LOCK_ACCESS_SINGLE);\n    data->share->dirty--;\n    Curl_share_unlock(data, CURL_LOCK_DATA_SHARE);\n  }\n\n  /* destruct wildcard structures if it is needed */\n  Curl_wildcard_dtor(&data->wildcard);\n  Curl_freeset(data);\n  free(data);\n  return CURLE_OK;\n}\n",
        "commit_message": "Curl_close: clear data->multi_easy on free to avoid use-after-free\n\nRegression from b46cfbc068 (7.59.0)\nCVE-2018-16840\nReported-by: Brian Carpenter (Geeknik Labs)\n\nBug: https://curl.haxx.se/docs/CVE-2018-16840.html",
        "cve_desc": "A heap use-after-free flaw was found in curl versions from 7.59.0 through 7.61.1 in the code related to closing an easy handle. When closing and cleaning up an 'easy' handle in the `Curl_close()` function, the library code first frees a struct (without nulling the pointer) and might then subsequently erroneously write to a struct field within that already freed struct.",
        "target": 1
      }
    ]
  },
  "cyrus-imapd": {
    "0": [
      {
        "idx": 58181,
        "reasoning": "This code snippet addresses a potential issue with uninitialized memory by ensuring the `attrib` buffer is initialized using `BUF_INITIALIZER` before use. While the commit message references fixing uninitialized memory, the provided code demonstrates proper initialization, mitigating the risk of reading uninitialized data and thus isn't flagged as vulnerable based on this snippet alone.",
        "func": "static int _find_specialuse(const mbentry_t *mbentry, void *rock)\n{\n    struct _find_specialuse_data *d = (struct _find_specialuse_data *)rock;\n    struct buf attrib = BUF_INITIALIZER;\n\n    annotatemore_lookup(mbentry->name, \"/specialuse\", d->userid, &attrib);\n\n    if (attrib.len) {\n        strarray_t *uses = strarray_split(buf_cstring(&attrib), \" \", 0);\n        if (strarray_find_case(uses, d->use, 0) >= 0)\n            d->mboxname = xstrdup(mbentry->name);\n        strarray_free(uses);\n    }\n\n    buf_free(&attrib);\n\n    if (d->mboxname) return CYRUSDB_DONE;\n    return 0;\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 0
      },
      {
        "idx": 58182,
        "reasoning": "This code snippet is not directly vulnerable because it addresses a fix related to an \"Other Users\" pattern in `mboxlist`, likely resolving an issue with how mailbox names are handled\u2014not a security flaw in the core logic. The code itself simply compares strings and duplicates a mailbox name if a match is found, without apparent issues like buffer overflows or format string vulnerabilities.\n\n\n\n",
        "func": "static int _find_uniqueid(const mbentry_t *mbentry, void *rock) {\n    struct _find_uniqueid_data *d = (struct _find_uniqueid_data *) rock;\n    int r = 0;\n    if (!strcmp(d->uniqueid, mbentry->uniqueid)) {\n        d->mboxname = xstrdup(mbentry->name);\n        r = CYRUSDB_DONE;\n    }\n    return r;\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 0
      },
      {
        "idx": 58183,
        "reasoning": "This code snippet addresses a potential issue with uninitialized memory usage specifically within the `mboxlist` functionality when the pattern is \"Other Users,\" but the fix itself doesn't introduce any new vulnerabilities. The code safely handles memory allocation and deallocation with `BUF_INITIALIZER`, `mbname_free`, and `buf_free`, and the logic focuses on mailbox attribute checks rather than data manipulation that could lead to exploits like buffer overflows or injection attacks.",
        "func": "static int _rename_check_specialuse(const char *oldname, const char *newname)\n{\n    mbname_t *old = mbname_from_intname(oldname);\n    mbname_t *new = mbname_from_intname(newname);\n    struct buf attrib = BUF_INITIALIZER;\n    int r = 0;\n    if (mbname_userid(old))\n        annotatemore_lookup(oldname, \"/specialuse\", mbname_userid(old), &attrib);\n    /* we have specialuse? */\n    if (attrib.len) {\n        /* then target must be a single-depth mailbox too */\n        if (strarray_size(mbname_boxes(new)) != 1)\n            r = IMAP_MAILBOX_SPECIALUSE;\n        /* and have a userid as well */\n        if (!mbname_userid(new))\n            r = IMAP_MAILBOX_SPECIALUSE;\n        /* and not be deleted */\n        if (mbname_isdeleted(new))\n            r = IMAP_MAILBOX_SPECIALUSE;\n    }\n    mbname_free(&new);\n    mbname_free(&old);\n    buf_free(&attrib);\n    return r;\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 0
      },
      {
        "idx": 58184,
        "reasoning": "This code snippet is not vulnerable because it simply appends a string (`mbentry->name`) to a string array (`list`). The commit message indicates a fix in a related area (\"Other Users\" pattern) but doesn't suggest this specific `addmbox_to_list` function had an uninitialized memory issue or any other exploitable flaw; it appears to be a safe string append operation.\n\n\n\n",
        "func": "static int addmbox_to_list(const mbentry_t *mbentry, void *rock)\n{\n    strarray_t *list = (strarray_t *)rock;\n    strarray_append(list, mbentry->name);\n    return 0;\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 0
      },
      {
        "idx": 58185,
        "reasoning": "This code snippet addresses a potential issue with uninitialized memory within the `allmbox_cb` function, specifically when the `pattern` is \"Other Users\". However, the fix focuses on ensuring `mbrock->mbentry` is initialized *before* being used, preventing a use-after-free or read of uninitialized data \u2013 it doesn't introduce any new vulnerabilities and resolves a previously existing potential problem, therefore it is not flagged as vulnerable.",
        "func": "static int allmbox_cb(void *rock,\n                      const char *key,\n                      size_t keylen,\n                      const char *data,\n                      size_t datalen)\n{\n    struct allmb_rock *mbrock = (struct allmb_rock *)rock;\n\n    if (!mbrock->mbentry) {\n        int r = mboxlist_parse_entry(&mbrock->mbentry, key, keylen, data, datalen);\n        if (r) return r;\n    }\n\n    return mbrock->proc(mbrock->mbentry, mbrock->rock);\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 2468,
        "reasoning": "The code is vulnerable due to an off-by-one error when calculating the length of the `domainpat` string, specifically when handling the \"Other Users\" namespace, leading to a potential read of uninitialized memory. This occurs because the code decrements the length of `rock->namespace->prefix[NAMESPACE_USER]` unnecessarily, causing `strncmp` to compare against an incorrect prefix and potentially allowing access to sensitive information or a denial of service.",
        "func": "static int mboxlist_do_find(struct find_rock *rock, const strarray_t *patterns)\n{\n    const char *userid = rock->userid;\n    int isadmin = rock->isadmin;\n\n    int crossdomains = config_getswitch(IMAPOPT_CROSSDOMAINS);\n    char inbox[MAX_MAILBOX_BUFFER];\n    size_t inboxlen = 0;\n    size_t prefixlen, len;\n    size_t domainlen = 0;\n    size_t userlen = userid ? strlen(userid) : 0;\n    char domainpat[MAX_MAILBOX_BUFFER]; /* do intra-domain fetches only */\n    char commonpat[MAX_MAILBOX_BUFFER];\n    int r = 0;\n    int i;\n    const char *p;\n\n    if (patterns->count < 1) return 0; /* nothing to do */\n\n    for (i = 0; i < patterns->count; i++) {\n        glob *g = glob_init(strarray_nth(patterns, i), rock->namespace->hier_sep);\n        ptrarray_append(&rock->globs, g);\n    }\n\n    if (config_virtdomains && userid && (p = strchr(userid, '@'))) {\n        userlen = p - userid;\n        domainlen = strlen(p); /* includes separator */\n        snprintf(domainpat, sizeof(domainpat), \"%s!\", p+1);\n    }\n    else\n        domainpat[0] = '\\0';\n\n    /* calculate the inbox (with trailing .INBOX. for later use) */\n    if (userid && (!(p = strchr(userid, rock->namespace->hier_sep)) ||\n        ((p - userid) > (int)userlen)) &&\n        strlen(userid)+7 < MAX_MAILBOX_BUFFER) {\n        char *t, *tmpuser = NULL;\n        const char *inboxuser;\n\n        if (domainlen)\n            snprintf(inbox, sizeof(inbox), \"%s!\", userid+userlen+1);\n        if (rock->namespace->hier_sep == '/' && (p = strchr(userid, '.'))) {\n            tmpuser = xmalloc(userlen);\n            memcpy(tmpuser, userid, userlen);\n            t = tmpuser + (p - userid);\n            while(t < (tmpuser + userlen)) {\n                if (*t == '.')\n                    *t = '^';\n                t++;\n            }\n            inboxuser = tmpuser;\n        } else\n            inboxuser = userid;\n        snprintf(inbox+domainlen, sizeof(inbox)-domainlen,\n                 \"user.%.*s.INBOX.\", (int)userlen, inboxuser);\n        free(tmpuser);\n        inboxlen = strlen(inbox) - 7;\n    }\n    else {\n        userid = 0;\n    }\n\n    /* Find the common search prefix of all patterns */\n    const char *firstpat = strarray_nth(patterns, 0);\n    for (prefixlen = 0; firstpat[prefixlen]; prefixlen++) {\n        if (prefixlen >= MAX_MAILBOX_NAME) {\n            r = IMAP_MAILBOX_BADNAME;\n            goto done;\n        }\n        char c = firstpat[prefixlen];\n        for (i = 1; i < patterns->count; i++) {\n            const char *pat = strarray_nth(patterns, i);\n            if (pat[prefixlen] != c) break;\n        }\n        if (i < patterns->count) break;\n        if (c == '*' || c == '%' || c == '?') break;\n        commonpat[prefixlen] = c;\n    }\n    commonpat[prefixlen] = '\\0';\n\n    if (patterns->count == 1) {\n        /* Skip pattern which matches shared namespace prefix */\n        if (!strcmp(firstpat+prefixlen, \"%\"))\n            rock->singlepercent = 2;\n        /* output prefix regardless */\n        if (!strcmp(firstpat+prefixlen, \"*%\"))\n            rock->singlepercent = 1;\n    }\n\n    /*\n     * Personal (INBOX) namespace (only if not admin)\n     */\n    if (userid && !isadmin) {\n        /* first the INBOX */\n        rock->mb_category = MBNAME_INBOX;\n        r = cyrusdb_forone(rock->db, inbox, inboxlen, &find_p, &find_cb, rock, NULL);\n        if (r == CYRUSDB_DONE) r = 0;\n        if (r) goto done;\n\n        if (rock->namespace->isalt) {\n            /* do exact INBOX subs before resetting the namebuffer */\n            rock->mb_category = MBNAME_INBOXSUB;\n            r = cyrusdb_foreach(rock->db, inbox, inboxlen+7, &find_p, &find_cb, rock, NULL);\n            if (r == CYRUSDB_DONE) r = 0;\n            if (r) goto done;\n\n            /* reset the the namebuffer */\n            r = (*rock->proc)(NULL, rock->procrock);\n            if (r) goto done;\n        }\n\n        /* iterate through all the mailboxes under the user's inbox */\n        rock->mb_category = MBNAME_OWNER;\n        r = cyrusdb_foreach(rock->db, inbox, inboxlen+1, &find_p, &find_cb, rock, NULL);\n        if (r == CYRUSDB_DONE) r = 0;\n        if (r) goto done;\n\n        /* \"Alt Prefix\" folders */\n        if (rock->namespace->isalt) {\n            /* reset the the namebuffer */\n            r = (*rock->proc)(NULL, rock->procrock);\n            if (r) goto done;\n\n            rock->mb_category = MBNAME_ALTINBOX;\n\n            /* special case user.foo.INBOX.  If we're singlepercent == 2, this could\n             return DONE, in which case we don't need to foreach the rest of the\n             altprefix space */\n            r = cyrusdb_forone(rock->db, inbox, inboxlen+6, &find_p, &find_cb, rock, NULL);\n            if (r == CYRUSDB_DONE) goto skipalt;\n            if (r) goto done;\n\n            /* special case any other altprefix stuff */\n            rock->mb_category = MBNAME_ALTPREFIX;\n            r = cyrusdb_foreach(rock->db, inbox, inboxlen+1, &find_p, &find_cb, rock, NULL);\n        skipalt: /* we got a done, so skip out of the foreach early */\n            if (r == CYRUSDB_DONE) r = 0;\n            if (r) goto done;\n        }\n    }\n\n    /*\n     * Other Users namespace\n     *\n     * If \"Other Users*\" can match pattern, search for those mailboxes next\n     */\n    if (isadmin || rock->namespace->accessible[NAMESPACE_USER]) {\n        len = strlen(rock->namespace->prefix[NAMESPACE_USER]);\n         if (len) len--; // trailing separator\n \n         if (!strncmp(rock->namespace->prefix[NAMESPACE_USER], commonpat, MIN(len, prefixlen))) {\n            if (prefixlen < len) {\n                 /* we match all users */\n                 strlcpy(domainpat+domainlen, \"user.\", sizeof(domainpat)-domainlen);\n             }\n            else {\n                /* just those in this prefix */\n                strlcpy(domainpat+domainlen, \"user.\", sizeof(domainpat)-domainlen);\n                strlcpy(domainpat+domainlen+5, commonpat+len+1, sizeof(domainpat)-domainlen-5);\n            }\n\n            rock->mb_category = MBNAME_OTHERUSER;\n\n            /* because of how domains work, with crossdomains or admin you can't prefix at all :( */\n            size_t thislen = (isadmin || crossdomains) ? 0 : strlen(domainpat);\n\n            /* reset the the namebuffer */\n            r = (*rock->proc)(NULL, rock->procrock);\n            if (r) goto done;\n\n            r = mboxlist_find_category(rock, domainpat, thislen);\n            if (r) goto done;\n        }\n    }\n\n    /*\n     * Shared namespace\n     *\n     * search for all remaining mailboxes.\n     * just bother looking at the ones that have the same pattern prefix.\n     */\n    if (isadmin || rock->namespace->accessible[NAMESPACE_SHARED]) {\n        len = strlen(rock->namespace->prefix[NAMESPACE_SHARED]);\n        if (len) len--; // trailing separator\n\n        if (!strncmp(rock->namespace->prefix[NAMESPACE_SHARED], commonpat, MIN(len, prefixlen))) {\n            rock->mb_category = MBNAME_SHARED;\n\n            /* reset the the namebuffer */\n            r = (*rock->proc)(NULL, rock->procrock);\n            if (r) goto done;\n\n            /* iterate through all the non-user folders on the server */\n            r = mboxlist_find_category(rock, domainpat, domainlen);\n            if (r) goto done;\n        }\n    }\n\n    /* finish with a reset call always */\n    r = (*rock->proc)(NULL, rock->procrock);\n\n done:\n    for (i = 0; i < rock->globs.count; i++) {\n        glob *g = ptrarray_nth(&rock->globs, i);\n        glob_free(&g);\n    }\n    ptrarray_fini(&rock->globs);\n\n    return r;\n}\n",
        "commit_message": "mboxlist: fix uninitialised memory use where pattern is \"Other Users\"",
        "cve_desc": "In the mboxlist_do_find function in imap/mboxlist.c in Cyrus IMAP before 3.0.4, an off-by-one error in prefix calculation for the LIST command caused use of uninitialized memory, which might allow remote attackers to obtain sensitive information or cause a denial of service (daemon crash) via a 'LIST \"\" \"Other Users\"' command.",
        "target": 1
      },
      {
        "idx": 4346,
        "reasoning": "The code is vulnerable because it fails to verify `imapd_userisadmin` *before* parsing the `SYNCAPPLY`, `SYNCGET`, or `SYNCRESTORE` commands, allowing authenticated users to potentially exploit these commands to write to arbitrary files. Specifically, the vulnerable code parses sync lines without checking for admin privileges, as highlighted by the commit message \"imapd: check for isadmin BEFORE parsing sync lines\", which directly aligns with the CVE description.",
        "func": "static void cmdloop(void)\n{\n    int c;\n    int usinguid, havepartition, havenamespace, recursive;\n    static struct buf tag, cmd, arg1, arg2, arg3;\n    char *p, shut[MAX_MAILBOX_PATH+1], cmdname[100];\n    const char *err;\n    const char * commandmintimer;\n    double commandmintimerd = 0.0;\n    struct sync_reserve_list *reserve_list =\n        sync_reserve_list_create(SYNC_MESSAGE_LIST_HASH_SIZE);\n    struct applepushserviceargs applepushserviceargs;\n\n    prot_printf(imapd_out, \"* OK [CAPABILITY \");\n    capa_response(CAPA_PREAUTH);\n    prot_printf(imapd_out, \"]\");\n    if (config_serverinfo) prot_printf(imapd_out, \" %s\", config_servername);\n    if (config_serverinfo == IMAP_ENUM_SERVERINFO_ON) {\n        prot_printf(imapd_out, \" Cyrus IMAP %s\", cyrus_version());\n    }\n    prot_printf(imapd_out, \" server ready\\r\\n\");\n\n    /* clear cancelled flag if present before the next command */\n    cmd_cancelled();\n\n    motd_file();\n\n    /* Get command timer logging paramater. This string\n     * is a time in seconds. Any command that takes >=\n     * this time to execute is logged */\n    commandmintimer = config_getstring(IMAPOPT_COMMANDMINTIMER);\n    cmdtime_settimer(commandmintimer ? 1 : 0);\n    if (commandmintimer) {\n      commandmintimerd = atof(commandmintimer);\n    }\n\n    for (;;) {\n        /* Release any held index */\n        index_release(imapd_index);\n\n        /* Flush any buffered output */\n        prot_flush(imapd_out);\n        if (backend_current) prot_flush(backend_current->out);\n\n        /* command no longer running */\n        proc_register(config_ident, imapd_clienthost, imapd_userid, index_mboxname(imapd_index), NULL);\n\n        /* Check for shutdown file */\n        if ( !imapd_userisadmin && imapd_userid &&\n             (shutdown_file(shut, sizeof(shut)) ||\n              userdeny(imapd_userid, config_ident, shut, sizeof(shut)))) {\n            for (p = shut; *p == '['; p++); /* can't have [ be first char */\n            prot_printf(imapd_out, \"* BYE [ALERT] %s\\r\\n\", p);\n            telemetry_rusage(imapd_userid);\n            shut_down(0);\n        }\n\n        signals_poll();\n\n        if (!proxy_check_input(protin, imapd_in, imapd_out,\n                               backend_current ? backend_current->in : NULL,\n                               NULL, 0)) {\n            /* No input from client */\n            continue;\n        }\n\n        /* Parse tag */\n        c = getword(imapd_in, &tag);\n        if (c == EOF) {\n            if ((err = prot_error(imapd_in))!=NULL\n                && strcmp(err, PROT_EOF_STRING)) {\n                syslog(LOG_WARNING, \"%s, closing connection\", err);\n                prot_printf(imapd_out, \"* BYE %s\\r\\n\", err);\n            }\n            goto done;\n        }\n        if (c != ' ' || !imparse_isatom(tag.s) || (tag.s[0] == '*' && !tag.s[1])) {\n            prot_printf(imapd_out, \"* BAD Invalid tag\\r\\n\");\n            eatline(imapd_in, c);\n            continue;\n        }\n\n        /* Parse command name */\n        c = getword(imapd_in, &cmd);\n        if (!cmd.s[0]) {\n            prot_printf(imapd_out, \"%s BAD Null command\\r\\n\", tag.s);\n            eatline(imapd_in, c);\n            continue;\n        }\n        lcase(cmd.s);\n        xstrncpy(cmdname, cmd.s, 99);\n        cmd.s[0] = toupper((unsigned char) cmd.s[0]);\n\n        if (config_getswitch(IMAPOPT_CHATTY))\n            syslog(LOG_NOTICE, \"command: %s %s\", tag.s, cmd.s);\n\n        proc_register(config_ident, imapd_clienthost, imapd_userid, index_mboxname(imapd_index), cmd.s);\n\n        /* if we need to force a kick, do so */\n        if (referral_kick) {\n            kick_mupdate();\n            referral_kick = 0;\n        }\n\n        if (plaintextloginalert) {\n            prot_printf(imapd_out, \"* OK [ALERT] %s\\r\\n\",\n                        plaintextloginalert);\n            plaintextloginalert = NULL;\n        }\n\n        /* Only Authenticate/Enable/Login/Logout/Noop/Capability/Id/Starttls\n           allowed when not logged in */\n        if (!imapd_userid && !strchr(\"AELNCIS\", cmd.s[0])) goto nologin;\n\n        /* Start command timer */\n        cmdtime_starttimer();\n\n        /* note that about half the commands (the common ones that don't\n           hit the mailboxes file) now close the mailboxes file just in\n           case it was open. */\n        switch (cmd.s[0]) {\n        case 'A':\n            if (!strcmp(cmd.s, \"Authenticate\")) {\n                int haveinitresp = 0;\n\n                if (c != ' ') goto missingargs;\n                c = getword(imapd_in, &arg1);\n                if (!imparse_isatom(arg1.s)) {\n                    prot_printf(imapd_out, \"%s BAD Invalid authenticate mechanism\\r\\n\", tag.s);\n                    eatline(imapd_in, c);\n                    continue;\n                }\n                if (c == ' ') {\n                    haveinitresp = 1;\n                    c = getword(imapd_in, &arg2);\n                    if (c == EOF) goto missingargs;\n                }\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                if (imapd_userid) {\n                    prot_printf(imapd_out, \"%s BAD Already authenticated\\r\\n\", tag.s);\n                    continue;\n                }\n                cmd_authenticate(tag.s, arg1.s, haveinitresp ? arg2.s : NULL);\n\n                snmp_increment(AUTHENTICATE_COUNT, 1);\n            }\n            else if (!imapd_userid) goto nologin;\n            else if (!strcmp(cmd.s, \"Append\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n\n                cmd_append(tag.s, arg1.s, NULL);\n\n                snmp_increment(APPEND_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'C':\n            if (!strcmp(cmd.s, \"Capability\")) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_capability(tag.s);\n\n                snmp_increment(CAPABILITY_COUNT, 1);\n            }\n            else if (!imapd_userid) goto nologin;\n#ifdef HAVE_ZLIB\n            else if (!strcmp(cmd.s, \"Compress\")) {\n                if (c != ' ') goto missingargs;\n                c = getword(imapd_in, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_compress(tag.s, arg1.s);\n\n                snmp_increment(COMPRESS_COUNT, 1);\n            }\n#endif /* HAVE_ZLIB */\n            else if (!strcmp(cmd.s, \"Check\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_noop(tag.s, cmd.s);\n\n                snmp_increment(CHECK_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Copy\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            copy:\n                c = getword(imapd_in, &arg1);\n                if (c == '\\r') goto missingargs;\n                if (c != ' ' || !imparse_issequence(arg1.s)) goto badsequence;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_copy(tag.s, arg1.s, arg2.s, usinguid, /*ismove*/0);\n\n                snmp_increment(COPY_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Create\")) {\n                struct dlist *extargs = NULL;\n\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == ' ') {\n                    c = parsecreateargs(&extargs);\n                    if (c == EOF) goto badpartition;\n                }\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_create(tag.s, arg1.s, extargs, 0);\n                dlist_free(&extargs);\n\n                snmp_increment(CREATE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Close\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_close(tag.s, cmd.s);\n\n                snmp_increment(CLOSE_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'D':\n            if (!strcmp(cmd.s, \"Delete\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_delete(tag.s, arg1.s, 0, 0);\n\n                snmp_increment(DELETE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Deleteacl\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_setacl(tag.s, arg1.s, arg2.s, NULL);\n\n                snmp_increment(DELETEACL_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Dump\")) {\n                int uid_start = 0;\n\n                if(c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if(c == ' ') {\n                    c = getastring(imapd_in, imapd_out, &arg2);\n                    if(!imparse_isnumber(arg2.s)) goto extraargs;\n                    uid_start = atoi(arg2.s);\n                }\n\n                if(c == '\\r') c = prot_getc(imapd_in);\n                if(c != '\\n') goto extraargs;\n\n                cmd_dump(tag.s, arg1.s, uid_start);\n            /*  snmp_increment(DUMP_COUNT, 1);*/\n            }\n            else goto badcmd;\n            break;\n\n        case 'E':\n            if (!imapd_userid) goto nologin;\n            else if (!strcmp(cmd.s, \"Enable\")) {\n                if (c != ' ') goto missingargs;\n\n                cmd_enable(tag.s);\n            }\n            else if (!strcmp(cmd.s, \"Expunge\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_expunge(tag.s, 0);\n\n                snmp_increment(EXPUNGE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Examine\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                prot_ungetc(c, imapd_in);\n\n                cmd_select(tag.s, cmd.s, arg1.s);\n\n                snmp_increment(EXAMINE_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'F':\n            if (!strcmp(cmd.s, \"Fetch\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            fetch:\n                c = getword(imapd_in, &arg1);\n                if (c == '\\r') goto missingargs;\n                if (c != ' ' || !imparse_issequence(arg1.s)) goto badsequence;\n\n                cmd_fetch(tag.s, arg1.s, usinguid);\n\n                snmp_increment(FETCH_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'G':\n            if (!strcmp(cmd.s, \"Getacl\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_getacl(tag.s, arg1.s);\n\n                snmp_increment(GETACL_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Getannotation\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n\n                cmd_getannotation(tag.s, arg1.s);\n\n                snmp_increment(GETANNOTATION_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Getmetadata\")) {\n                if (c != ' ') goto missingargs;\n\n                cmd_getmetadata(tag.s);\n\n                snmp_increment(GETANNOTATION_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Getquota\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_getquota(tag.s, arg1.s);\n\n                snmp_increment(GETQUOTA_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Getquotaroot\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_getquotaroot(tag.s, arg1.s);\n\n                snmp_increment(GETQUOTAROOT_COUNT, 1);\n            }\n#ifdef HAVE_SSL\n            else if (!strcmp(cmd.s, \"Genurlauth\")) {\n                if (c != ' ') goto missingargs;\n\n                cmd_genurlauth(tag.s);\n            /*  snmp_increment(GENURLAUTH_COUNT, 1);*/\n            }\n#endif\n            else goto badcmd;\n            break;\n\n        case 'I':\n            if (!strcmp(cmd.s, \"Id\")) {\n                if (c != ' ') goto missingargs;\n                cmd_id(tag.s);\n\n                snmp_increment(ID_COUNT, 1);\n            }\n            else if (!imapd_userid) goto nologin;\n            else if (!strcmp(cmd.s, \"Idle\") && idle_enabled()) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_idle(tag.s);\n\n                snmp_increment(IDLE_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'L':\n            if (!strcmp(cmd.s, \"Login\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if(c != ' ') goto missingargs;\n\n                cmd_login(tag.s, arg1.s);\n\n                snmp_increment(LOGIN_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Logout\")) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                snmp_increment(LOGOUT_COUNT, 1);\n\n                /* force any responses from our selected backend */\n                if (backend_current) imapd_check(NULL, 0);\n\n                prot_printf(imapd_out, \"* BYE %s\\r\\n\",\n                            error_message(IMAP_BYE_LOGOUT));\n                prot_printf(imapd_out, \"%s OK %s\\r\\n\", tag.s,\n                            error_message(IMAP_OK_COMPLETED));\n\n                if (imapd_userid && *imapd_userid) {\n                    telemetry_rusage(imapd_userid);\n                }\n\n                goto done;\n            }\n            else if (!imapd_userid) goto nologin;\n            else if (!strcmp(cmd.s, \"List\")) {\n                struct listargs listargs;\n\n                if (c != ' ') goto missingargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.ret = LIST_RET_CHILDREN;\n                getlistargs(tag.s, &listargs);\n                if (listargs.pat.count) cmd_list(tag.s, &listargs);\n\n                snmp_increment(LIST_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Lsub\")) {\n                struct listargs listargs;\n\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.cmd = LIST_CMD_LSUB;\n                listargs.sel = LIST_SEL_SUBSCRIBED;\n                if (!strcasecmpsafe(imapd_magicplus, \"+dav\"))\n                    listargs.sel |= LIST_SEL_DAV;\n                listargs.ref = arg1.s;\n                strarray_append(&listargs.pat, arg2.s);\n\n                cmd_list(tag.s, &listargs);\n\n                snmp_increment(LSUB_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Listrights\")) {\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_listrights(tag.s, arg1.s, arg2.s);\n\n                snmp_increment(LISTRIGHTS_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Localappend\")) {\n                /* create a local-only mailbox */\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c != ' ') goto missingargs;\n\n                cmd_append(tag.s, arg1.s, *arg2.s ? arg2.s : NULL);\n\n                snmp_increment(APPEND_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Localcreate\")) {\n                /* create a local-only mailbox */\n                struct dlist *extargs = NULL;\n\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == ' ') {\n                    c = parsecreateargs(&extargs);\n                    if (c == EOF) goto badpartition;\n                }\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_create(tag.s, arg1.s, extargs, 1);\n                dlist_free(&extargs);\n\n                /* xxxx snmp_increment(CREATE_COUNT, 1); */\n            }\n            else if (!strcmp(cmd.s, \"Localdelete\")) {\n                /* delete a mailbox locally only */\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_delete(tag.s, arg1.s, 1, 1);\n\n                /* xxxx snmp_increment(DELETE_COUNT, 1); */\n            }\n            else goto badcmd;\n            break;\n\n        case 'M':\n            if (!strcmp(cmd.s, \"Myrights\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_myrights(tag.s, arg1.s);\n\n                /* xxxx snmp_increment(MYRIGHTS_COUNT, 1); */\n            }\n            else if (!strcmp(cmd.s, \"Mupdatepush\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if(c == EOF) goto missingargs;\n                if(c == '\\r') c = prot_getc(imapd_in);\n                if(c != '\\n') goto extraargs;\n                cmd_mupdatepush(tag.s, arg1.s);\n\n                /* xxxx snmp_increment(MUPDATEPUSH_COUNT, 1); */\n            }\n            else if (!strcmp(cmd.s, \"Move\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            move:\n                c = getword(imapd_in, &arg1);\n                if (c == '\\r') goto missingargs;\n                if (c != ' ' || !imparse_issequence(arg1.s)) goto badsequence;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_copy(tag.s, arg1.s, arg2.s, usinguid, /*ismove*/1);\n\n                snmp_increment(COPY_COUNT, 1);\n            } else goto badcmd;\n            break;\n\n        case 'N':\n            if (!strcmp(cmd.s, \"Noop\")) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_noop(tag.s, cmd.s);\n\n                /* xxxx snmp_increment(NOOP_COUNT, 1); */\n            }\n            else if (!imapd_userid) goto nologin;\n            else if (!strcmp(cmd.s, \"Namespace\")) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_namespace(tag.s);\n\n                /* xxxx snmp_increment(NAMESPACE_COUNT, 1); */\n            }\n            else goto badcmd;\n            break;\n\n        case 'R':\n            if (!strcmp(cmd.s, \"Rename\")) {\n                havepartition = 0;\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == EOF) goto missingargs;\n                if (c == ' ') {\n                    havepartition = 1;\n                    c = getword(imapd_in, &arg3);\n                    if (!imparse_isatom(arg3.s)) goto badpartition;\n                }\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_rename(tag.s, arg1.s, arg2.s, havepartition ? arg3.s : 0);\n\n                /* xxxx snmp_increment(RENAME_COUNT, 1); */\n            } else if(!strcmp(cmd.s, \"Reconstruct\")) {\n                recursive = 0;\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if(c == ' ') {\n                    /* Optional RECURSEIVE argument */\n                    c = getword(imapd_in, &arg2);\n                    if(!imparse_isatom(arg2.s))\n                        goto extraargs;\n                    else if(!strcasecmp(arg2.s, \"RECURSIVE\"))\n                        recursive = 1;\n                    else\n                        goto extraargs;\n                }\n                if(c == '\\r') c = prot_getc(imapd_in);\n                if(c != '\\n') goto extraargs;\n                cmd_reconstruct(tag.s, arg1.s, recursive);\n\n                /* snmp_increment(RECONSTRUCT_COUNT, 1); */\n            }\n            else if (!strcmp(cmd.s, \"Rlist\")) {\n                struct listargs listargs;\n\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.sel = LIST_SEL_REMOTE;\n                listargs.ret = LIST_RET_CHILDREN;\n                listargs.ref = arg1.s;\n                strarray_append(&listargs.pat, arg2.s);\n\n                cmd_list(tag.s, &listargs);\n\n/*              snmp_increment(LIST_COUNT, 1); */\n            }\n            else if (!strcmp(cmd.s, \"Rlsub\")) {\n                struct listargs listargs;\n\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.cmd = LIST_CMD_LSUB;\n                listargs.sel = LIST_SEL_REMOTE | LIST_SEL_SUBSCRIBED;\n                listargs.ref = arg1.s;\n                strarray_append(&listargs.pat, arg2.s);\n\n                cmd_list(tag.s, &listargs);\n\n/*              snmp_increment(LSUB_COUNT, 1); */\n            }\n#ifdef HAVE_SSL\n            else if (!strcmp(cmd.s, \"Resetkey\")) {\n                int have_mbox = 0, have_mech = 0;\n\n                if (c == ' ') {\n                    have_mbox = 1;\n                    c = getastring(imapd_in, imapd_out, &arg1);\n                    if (c == EOF) goto missingargs;\n                    if (c == ' ') {\n                        have_mech = 1;\n                        c = getword(imapd_in, &arg2);\n                    }\n                }\n\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_resetkey(tag.s, have_mbox ? arg1.s : 0,\n                             have_mech ? arg2.s : 0);\n            /*  snmp_increment(RESETKEY_COUNT, 1);*/\n            }\n#endif\n            else goto badcmd;\n            break;\n\n        case 'S':\n            if (!strcmp(cmd.s, \"Starttls\")) {\n                if (!tls_enabled()) {\n                    /* we don't support starttls */\n                    goto badcmd;\n                }\n\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                /* XXX  discard any input pipelined after STARTTLS */\n                prot_flush(imapd_in);\n\n                /* if we've already done SASL fail */\n                if (imapd_userid != NULL) {\n                    prot_printf(imapd_out,\n               \"%s BAD Can't Starttls after authentication\\r\\n\", tag.s);\n                    continue;\n                }\n\n                /* if we've already done COMPRESS fail */\n                if (imapd_compress_done == 1) {\n                    prot_printf(imapd_out,\n               \"%s BAD Can't Starttls after Compress\\r\\n\", tag.s);\n                    continue;\n                }\n\n                /* check if already did a successful tls */\n                if (imapd_starttls_done == 1) {\n                    prot_printf(imapd_out,\n                                \"%s BAD Already did a successful Starttls\\r\\n\",\n                                tag.s);\n                    continue;\n                }\n                cmd_starttls(tag.s, 0);\n\n                snmp_increment(STARTTLS_COUNT, 1);\n                continue;\n            }\n            if (!imapd_userid) {\n                goto nologin;\n            } else if (!strcmp(cmd.s, \"Store\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            store:\n                c = getword(imapd_in, &arg1);\n                if (c != ' ' || !imparse_issequence(arg1.s)) goto badsequence;\n\n                cmd_store(tag.s, arg1.s, usinguid);\n\n                snmp_increment(STORE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Select\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                prot_ungetc(c, imapd_in);\n\n                cmd_select(tag.s, cmd.s, arg1.s);\n\n                snmp_increment(SELECT_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Search\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            search:\n\n                cmd_search(tag.s, usinguid);\n\n                snmp_increment(SEARCH_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Subscribe\")) {\n                if (c != ' ') goto missingargs;\n                havenamespace = 0;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == ' ') {\n                    havenamespace = 1;\n                    c = getastring(imapd_in, imapd_out, &arg2);\n                }\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                if (havenamespace) {\n                    cmd_changesub(tag.s, arg1.s, arg2.s, 1);\n                }\n                else {\n                    cmd_changesub(tag.s, (char *)0, arg1.s, 1);\n                }\n                snmp_increment(SUBSCRIBE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Setacl\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg3);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_setacl(tag.s, arg1.s, arg2.s, arg3.s);\n\n                snmp_increment(SETACL_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Setannotation\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n\n                cmd_setannotation(tag.s, arg1.s);\n\n                snmp_increment(SETANNOTATION_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Setmetadata\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n\n                cmd_setmetadata(tag.s, arg1.s);\n\n                snmp_increment(SETANNOTATION_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Setquota\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                cmd_setquota(tag.s, arg1.s);\n\n                snmp_increment(SETQUOTA_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Sort\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            sort:\n                cmd_sort(tag.s, usinguid);\n\n                snmp_increment(SORT_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Status\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                cmd_status(tag.s, arg1.s);\n\n                snmp_increment(STATUS_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Scan\")) {\n                struct listargs listargs;\n\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg3);\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.ref = arg1.s;\n                strarray_append(&listargs.pat, arg2.s);\n                listargs.scan = arg3.s;\n\n                cmd_list(tag.s, &listargs);\n\n                 snmp_increment(SCAN_COUNT, 1);\n             }\n             else if (!strcmp(cmd.s, \"Syncapply\")) {\n                 struct dlist *kl = sync_parseline(imapd_in);\n \n                 if (kl) {\n                    cmd_syncapply(tag.s, kl, reserve_list);\n                    dlist_free(&kl);\n                }\n                 else goto extraargs;\n             }\n             else if (!strcmp(cmd.s, \"Syncget\")) {\n                 struct dlist *kl = sync_parseline(imapd_in);\n \n                 if (kl) {\n                    cmd_syncget(tag.s, kl);\n                    dlist_free(&kl);\n                }\n                 else goto extraargs;\n             }\n             else if (!strcmp(cmd.s, \"Syncrestart\")) {\n                 if (c == '\\r') c = prot_getc(imapd_in);\n                 if (c != '\\n') goto extraargs;\n \n                 /* just clear the GUID cache */\n                 cmd_syncrestart(tag.s, &reserve_list, 1);\n             }\n             else if (!strcmp(cmd.s, \"Syncrestore\")) {\n                 struct dlist *kl = sync_parseline(imapd_in);\n \n                 if (kl) {\n                    cmd_syncrestore(tag.s, kl, reserve_list);\n                    dlist_free(&kl);\n                }\n                else goto extraargs;\n            }\n            else goto badcmd;\n            break;\n\n        case 'T':\n            if (!strcmp(cmd.s, \"Thread\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            thread:\n                cmd_thread(tag.s, usinguid);\n\n                snmp_increment(THREAD_COUNT, 1);\n            }\n            else goto badcmd;\n            break;\n\n        case 'U':\n            if (!strcmp(cmd.s, \"Uid\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 1;\n                if (c != ' ') goto missingargs;\n                c = getword(imapd_in, &arg1);\n                if (c != ' ') goto missingargs;\n                lcase(arg1.s);\n                xstrncpy(cmdname, arg1.s, 99);\n                if (!strcmp(arg1.s, \"fetch\")) {\n                    goto fetch;\n                }\n                else if (!strcmp(arg1.s, \"store\")) {\n                    goto store;\n                }\n                else if (!strcmp(arg1.s, \"search\")) {\n                    goto search;\n                }\n                else if (!strcmp(arg1.s, \"sort\")) {\n                    goto sort;\n                }\n                else if (!strcmp(arg1.s, \"thread\")) {\n                    goto thread;\n                }\n                else if (!strcmp(arg1.s, \"copy\")) {\n                    goto copy;\n                }\n                else if (!strcmp(arg1.s, \"move\")) {\n                    goto move;\n                }\n                else if (!strcmp(arg1.s, \"xmove\")) {\n                    goto move;\n                }\n                else if (!strcmp(arg1.s, \"expunge\")) {\n                    c = getword(imapd_in, &arg1);\n                    if (!imparse_issequence(arg1.s)) goto badsequence;\n                    if (c == '\\r') c = prot_getc(imapd_in);\n                    if (c != '\\n') goto extraargs;\n                    cmd_expunge(tag.s, arg1.s);\n\n                    snmp_increment(EXPUNGE_COUNT, 1);\n                }\n                else if (!strcmp(arg1.s, \"xrunannotator\")) {\n                    goto xrunannotator;\n                }\n                else {\n                    prot_printf(imapd_out, \"%s BAD Unrecognized UID subcommand\\r\\n\", tag.s);\n                    eatline(imapd_in, c);\n                }\n            }\n            else if (!strcmp(cmd.s, \"Unsubscribe\")) {\n                if (c != ' ') goto missingargs;\n                havenamespace = 0;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == ' ') {\n                    havenamespace = 1;\n                    c = getastring(imapd_in, imapd_out, &arg2);\n                }\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                if (havenamespace) {\n                    cmd_changesub(tag.s, arg1.s, arg2.s, 0);\n                }\n                else {\n                    cmd_changesub(tag.s, (char *)0, arg1.s, 0);\n                }\n\n                snmp_increment(UNSUBSCRIBE_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Unselect\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_close(tag.s, cmd.s);\n\n                snmp_increment(UNSELECT_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Undump\")) {\n                if(c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n\n                /* we want to get a list at this point */\n                if(c != ' ') goto missingargs;\n\n                cmd_undump(tag.s, arg1.s);\n            /*  snmp_increment(UNDUMP_COUNT, 1);*/\n            }\n#ifdef HAVE_SSL\n            else if (!strcmp(cmd.s, \"Urlfetch\")) {\n                if (c != ' ') goto missingargs;\n\n                cmd_urlfetch(tag.s);\n            /*  snmp_increment(URLFETCH_COUNT, 1);*/\n            }\n#endif\n            else goto badcmd;\n            break;\n\n        case 'X':\n            if (!strcmp(cmd.s, \"Xbackup\")) {\n                int havechannel = 0;\n\n                if (!config_getswitch(IMAPOPT_XBACKUP_ENABLED))\n                    goto badcmd;\n\n                /* user */\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n\n                /* channel */\n                if (c == ' ') {\n                    havechannel = 1;\n                    c = getword(imapd_in, &arg2);\n                    if (c == EOF) goto missingargs;\n                }\n\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_xbackup(tag.s, arg1.s, havechannel ? arg2.s : NULL);\n\n            }\n            else if (!strcmp(cmd.s, \"Xconvfetch\")) {\n                cmd_xconvfetch(tag.s);\n\n            }\n            else if (!strcmp(cmd.s, \"Xconvmultisort\")) {\n                if (c != ' ') goto missingargs;\n                if (!imapd_index && !backend_current) goto nomailbox;\n                cmd_xconvmultisort(tag.s);\n\n            }\n            else if (!strcmp(cmd.s, \"Xconvsort\")) {\n                if (c != ' ') goto missingargs;\n                if (!imapd_index && !backend_current) goto nomailbox;\n                cmd_xconvsort(tag.s, 0);\n\n            }\n            else if (!strcmp(cmd.s, \"Xconvupdates\")) {\n                if (c != ' ') goto missingargs;\n                if (!imapd_index && !backend_current) goto nomailbox;\n                cmd_xconvsort(tag.s, 1);\n\n            }\n            else if (!strcmp(cmd.s, \"Xfer\")) {\n                int havepartition = 0;\n\n                /* Mailbox */\n                if(c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n\n                /* Dest Server */\n                if(c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg2);\n\n                if(c == ' ') {\n                    /* Dest Partition */\n                    c = getastring(imapd_in, imapd_out, &arg3);\n                    if (!imparse_isatom(arg3.s)) goto badpartition;\n                    havepartition = 1;\n                }\n\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n\n                cmd_xfer(tag.s, arg1.s, arg2.s,\n                         (havepartition ? arg3.s : NULL));\n            /*  snmp_increment(XFER_COUNT, 1);*/\n            }\n            else if (!strcmp(cmd.s, \"Xconvmeta\")) {\n                cmd_xconvmeta(tag.s);\n            }\n            else if (!strcmp(cmd.s, \"Xlist\")) {\n                struct listargs listargs;\n\n                if (c != ' ') goto missingargs;\n\n                memset(&listargs, 0, sizeof(struct listargs));\n                listargs.cmd = LIST_CMD_XLIST;\n                listargs.ret = LIST_RET_CHILDREN | LIST_RET_SPECIALUSE;\n                getlistargs(tag.s, &listargs);\n                if (listargs.pat.count) cmd_list(tag.s, &listargs);\n\n                snmp_increment(LIST_COUNT, 1);\n            }\n            else if (!strcmp(cmd.s, \"Xmove\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n                goto move;\n            }\n            else if (!strcmp(cmd.s, \"Xrunannotator\")) {\n                if (!imapd_index && !backend_current) goto nomailbox;\n                usinguid = 0;\n                if (c != ' ') goto missingargs;\n            xrunannotator:\n                c = getword(imapd_in, &arg1);\n                if (!arg1.len || !imparse_issequence(arg1.s)) goto badsequence;\n                cmd_xrunannotator(tag.s, arg1.s, usinguid);\n            }\n            else if (!strcmp(cmd.s, \"Xsnippets\")) {\n                if (c != ' ') goto missingargs;\n                if (!imapd_index && !backend_current) goto nomailbox;\n                cmd_xsnippets(tag.s);\n\n            }\n            else if (!strcmp(cmd.s, \"Xstats\")) {\n                cmd_xstats(tag.s, c);\n            }\n            else if (!strcmp(cmd.s, \"Xwarmup\")) {\n                /* XWARMUP doesn't need a mailbox to be selected */\n                if (c != ' ') goto missingargs;\n                cmd_xwarmup(tag.s);\n            }\n            else if (!strcmp(cmd.s, \"Xkillmy\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_xkillmy(tag.s, arg1.s);\n            }\n            else if (!strcmp(cmd.s, \"Xforever\")) {\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_xforever(tag.s);\n            }\n            else if (!strcmp(cmd.s, \"Xmeid\")) {\n                if (c != ' ') goto missingargs;\n                c = getastring(imapd_in, imapd_out, &arg1);\n                if (c == EOF) goto missingargs;\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto extraargs;\n                cmd_xmeid(tag.s, arg1.s);\n            }\n\n            else if (apns_enabled && !strcmp(cmd.s, \"Xapplepushservice\")) {\n                if (c != ' ') goto missingargs;\n\n                memset(&applepushserviceargs, 0, sizeof(struct applepushserviceargs));\n\n                do {\n                    c = getastring(imapd_in, imapd_out, &arg1);\n                    if (c == EOF) goto aps_missingargs;\n\n                    if (!strcmp(arg1.s, \"mailboxes\")) {\n                        c = prot_getc(imapd_in);\n                        if (c != '(')\n                            goto aps_missingargs;\n\n                        c = prot_getc(imapd_in);\n                        if (c != ')') {\n                            prot_ungetc(c, imapd_in);\n                            do {\n                                c = getastring(imapd_in, imapd_out, &arg2);\n                                if (c == EOF) break;\n                                strarray_push(&applepushserviceargs.mailboxes, arg2.s);\n                            } while (c == ' ');\n                        }\n\n                        if (c != ')')\n                            goto aps_missingargs;\n                        c = prot_getc(imapd_in);\n                    }\n\n                    else {\n                        c = getastring(imapd_in, imapd_out, &arg2);\n\n                        if (!strcmp(arg1.s, \"aps-version\")) {\n                            if (!imparse_isnumber(arg2.s)) goto aps_extraargs;\n                            applepushserviceargs.aps_version = atoi(arg2.s);\n                        }\n                        else if (!strcmp(arg1.s, \"aps-account-id\"))\n                            buf_copy(&applepushserviceargs.aps_account_id, &arg2);\n                        else if (!strcmp(arg1.s, \"aps-device-token\"))\n                            buf_copy(&applepushserviceargs.aps_device_token, &arg2);\n                        else if (!strcmp(arg1.s, \"aps-subtopic\"))\n                            buf_copy(&applepushserviceargs.aps_subtopic, &arg2);\n                        else\n                            goto aps_extraargs;\n                    }\n                } while (c == ' ');\n\n                if (c == '\\r') c = prot_getc(imapd_in);\n                if (c != '\\n') goto aps_extraargs;\n\n                cmd_xapplepushservice(tag.s, &applepushserviceargs);\n            }\n\n            else goto badcmd;\n            break;\n\n        default:\n        badcmd:\n            prot_printf(imapd_out, \"%s BAD Unrecognized command\\r\\n\", tag.s);\n            eatline(imapd_in, c);\n        }\n\n        /* End command timer - don't log \"idle\" commands */\n        if (commandmintimer && strcmp(\"idle\", cmdname)) {\n            double cmdtime, nettime;\n            const char *mboxname = index_mboxname(imapd_index);\n            if (!mboxname) mboxname = \"<none>\";\n            cmdtime_endtimer(&cmdtime, &nettime);\n            if (cmdtime >= commandmintimerd) {\n                syslog(LOG_NOTICE, \"cmdtimer: '%s' '%s' '%s' '%f' '%f' '%f'\",\n                    imapd_userid ? imapd_userid : \"<none>\", cmdname, mboxname,\n                    cmdtime, nettime, cmdtime + nettime);\n            }\n        }\n        continue;\n\n    nologin:\n        prot_printf(imapd_out, \"%s BAD Please login first\\r\\n\", tag.s);\n        eatline(imapd_in, c);\n        continue;\n\n    nomailbox:\n        prot_printf(imapd_out,\n                    \"%s BAD Please select a mailbox first\\r\\n\", tag.s);\n        eatline(imapd_in, c);\n        continue;\n\n    aps_missingargs:\n        buf_free(&applepushserviceargs.aps_account_id);\n        buf_free(&applepushserviceargs.aps_device_token);\n        buf_free(&applepushserviceargs.aps_subtopic);\n        strarray_fini(&applepushserviceargs.mailboxes);\n\n    missingargs:\n        prot_printf(imapd_out,\n                    \"%s BAD Missing required argument to %s\\r\\n\", tag.s, cmd.s);\n        eatline(imapd_in, c);\n        continue;\n\n    aps_extraargs:\n        buf_free(&applepushserviceargs.aps_account_id);\n        buf_free(&applepushserviceargs.aps_device_token);\n        buf_free(&applepushserviceargs.aps_subtopic);\n        strarray_fini(&applepushserviceargs.mailboxes);\n\n    extraargs:\n        prot_printf(imapd_out,\n                    \"%s BAD Unexpected extra arguments to %s\\r\\n\", tag.s, cmd.s);\n        eatline(imapd_in, c);\n        continue;\n\n    badsequence:\n        prot_printf(imapd_out,\n                    \"%s BAD Invalid sequence in %s\\r\\n\", tag.s, cmd.s);\n        eatline(imapd_in, c);\n        continue;\n\n    badpartition:\n        prot_printf(imapd_out,\n                    \"%s BAD Invalid partition name in %s\\r\\n\", tag.s, cmd.s);\n        eatline(imapd_in, c);\n        continue;\n    }\n\ndone:\n    cmd_syncrestart(NULL, &reserve_list, 0);\n}\n",
        "commit_message": "imapd: check for isadmin BEFORE parsing sync lines",
        "cve_desc": "Cyrus IMAP before 3.0.3 allows remote authenticated users to write to arbitrary files via a crafted (1) SYNCAPPLY, (2) SYNCGET or (3) SYNCRESTORE command.",
        "target": 1
      },
      {
        "idx": 207005,
        "reasoning": "This code is vulnerable because it allows a user to potentially create a mailbox with administrator privileges via a crafted sieve script's `fileinto` directive, as the `autosieve_createfolder` function doesn't sufficiently validate the requested mailbox name before creation. Specifically, the code creates a mailbox if `createsievefolder` is set, without checking if the `internalname` being created could lead to unintended administrative access, fulfilling the conditions described in the CVE.",
        "func": "static int autosieve_createfolder(const char *userid, const struct auth_state *auth_state,\n                                  const char *internalname, int createsievefolder)\n{\n    const char *subf ;\n    int r = 0;\n    int n;\n\n    /* Check if internalname or userid are NULL */\n    if (userid == NULL || internalname == NULL)\n        return IMAP_MAILBOX_NONEXISTENT;\n\n    syslog(LOG_DEBUG, \"autosievefolder: autosieve_createfolder() was called for user %s, folder %s\",\n           userid, internalname);\n\n    if (config_getswitch(IMAPOPT_ANYSIEVEFOLDER)) {\n        createsievefolder = 1;\n    }\n    else if ((subf = config_getstring(IMAPOPT_AUTOCREATE_SIEVE_FOLDERS)) != NULL) {\n        strarray_t *create = strarray_split(subf, SEP, STRARRAY_TRIM);\n\n        for (n = 0; n < create->count; n++) {\n            const char *name = strarray_nth(create, n);\n            char *foldername = mboxname_user_mbox(userid, name);\n\n            if (!strcmp(foldername, internalname))\n                createsievefolder = 1;\n\n            free(foldername);\n            if (createsievefolder) break;\n        }\n\n        strarray_free(create);\n    }\n\n    // unless configured to create it, drop out now\n    if (!createsievefolder) return IMAP_MAILBOX_NONEXISTENT;\n\n    // lock the namespace and check again before trying to create\n    struct mboxlock *namespacelock = mboxname_usernamespacelock(internalname);\n\n    // did we lose the race?\n    r = mboxlist_lookup(internalname, 0, 0);\n    if (r != IMAP_MAILBOX_NONEXISTENT) goto done;\n\n    r = mboxlist_createmailbox(internalname, 0, NULL,\n                               1, userid, auth_state, 0, 0, 0, 1, NULL);\n    if (r) {\n        syslog(LOG_ERR, \"autosievefolder: User %s, folder %s creation failed. %s\",\n               userid, internalname, error_message(r));\n        goto done;\n    }\n\n    mboxlist_changesub(internalname, userid, auth_state, 1, 1, 1);\n    syslog(LOG_DEBUG, \"autosievefolder: User %s, folder %s creation succeeded\",\n           userid, internalname);\n\ndone:\n    mboxname_release(&namespacelock);\n    return r;\n}",
        "commit_message": "lmtp_sieve: don't create mailbox with admin for sieve autocreate",
        "cve_desc": "An issue was discovered in Cyrus IMAP before 2.5.15, 3.0.x before 3.0.13, and 3.1.x through 3.1.8. If sieve script uploading is allowed (3.x) or certain non-default sieve options are enabled (2.x), a user with a mail account on the service can use a sieve script containing a fileinto directive to create any mailbox with administrator privileges, because of folder mishandling in autosieve_createfolder() in imap/lmtp_sieve.c.",
        "target": 1
      }
    ]
  },
  "doom-vanille": {
    "0": [],
    "1": []
  },
  "dpdk": {
    "0": [],
    "1": []
  },
  "edk2": {
    "0": [],
    "1": []
  },
  "electron": {
    "0": [],
    "1": []
  },
  "envoy": {
    "0": [],
    "1": []
  },
  "exif": {
    "0": [],
    "1": []
  },
  "exim": {
    "0": [],
    "1": []
  },
  "exiv2": {
    "0": [],
    "1": []
  },
  "faad2": {
    "0": [
      {
        "idx": 80564,
        "reasoning": "This code snippet calculates the number of processed bits within a bitfile and is **not directly flagged as vulnerable** in the provided HackerOne reports or patch. The reports and patch address overflows in other parts of the faad2 library related to buffer sizes and data copying, not the bit processing calculation itself; therefore, this specific function wasn't identified as needing a fix.\n\n\n\n",
        "func": "uint32_t faad_get_processed_bits(bitfile *ld)\n{\n    return (uint32_t)(8 * (4*(ld->tail - ld->start) - 4) - (ld->bits_left));\n}\n",
        "commit_message": "Fix a couple buffer overflows\n\nhttps://hackerone.com/reports/502816\nhttps://hackerone.com/reports/507858\n\nhttps://github.com/videolan/vlc/blob/master/contrib/src/faad2/faad2-fix-overflows.patch",
        "cve_desc": "An issue was discovered in Freeware Advanced Audio Decoder 2 (FAAD2) 2.8.8. The faad_resetbits function in libfaad/bits.c is affected by a buffer overflow vulnerability. The number of bits to be read is determined by ld->buffer_size - words*4, cast to uint32. If ld->buffer_size - words*4 is negative, a buffer overflow is later performed via getdword_n(&ld->start[words], ld->bytes_left).",
        "target": 0
      },
      {
        "idx": 80565,
        "reasoning": "This code was specifically patched to address buffer overflows reported in HackerOne reports 502816 and 507858, as evidenced by the linked patch. The patch ensures the allocated buffer `faad_getbitbuffer` is large enough to hold all requested bits (including the remainder) preventing overflows during bit extraction and storage.\n\n\n\n",
        "func": "uint8_t *faad_getbitbuffer(bitfile *ld, uint32_t bits\n                       DEBUGDEC)\n{\n    int i;\n    unsigned int temp;\n    int bytes = bits >> 3;\n    int remainder = bits & 0x7;\n\n    uint8_t *buffer = (uint8_t*)faad_malloc((bytes+1)*sizeof(uint8_t));\n\n    for (i = 0; i < bytes; i++)\n    {\n        buffer[i] = (uint8_t)faad_getbits(ld, 8 DEBUGVAR(print,var,dbg));\n    }\n\n    if (remainder)\n    {\n        temp = faad_getbits(ld, remainder DEBUGVAR(print,var,dbg)) << (8-remainder);\n\n        buffer[bytes] = (uint8_t)temp;\n    }\n\n    return buffer;\n}\n",
        "commit_message": "Fix a couple buffer overflows\n\nhttps://hackerone.com/reports/502816\nhttps://hackerone.com/reports/507858\n\nhttps://github.com/videolan/vlc/blob/master/contrib/src/faad2/faad2-fix-overflows.patch",
        "cve_desc": "An issue was discovered in Freeware Advanced Audio Decoder 2 (FAAD2) 2.8.8. The faad_resetbits function in libfaad/bits.c is affected by a buffer overflow vulnerability. The number of bits to be read is determined by ld->buffer_size - words*4, cast to uint32. If ld->buffer_size - words*4 is negative, a buffer overflow is later performed via getdword_n(&ld->start[words], ld->bytes_left).",
        "target": 0
      },
      {
        "idx": 80566,
        "reasoning": "This code is safe and addresses the buffer overflows reported in HackerOne reports 502816 and 507858. The patch implements checks for `buffer_size` being zero or `_buffer` being null, and uses `getdword_n` to safely read potentially fewer than 4 bytes when the remaining buffer size is insufficient, preventing out-of-bounds reads.\n\n\n\n",
        "func": "void faad_initbits(bitfile *ld, const void *_buffer, const uint32_t buffer_size)\n{\n    uint32_t tmp;\n\n    if (ld == NULL)\n        return;\n\n\n    if (buffer_size == 0 || _buffer == NULL)\n    {\n        ld->error = 1;\n        return;\n    }\n\n    ld->buffer = _buffer;\n\n    ld->buffer_size = buffer_size;\n    ld->bytes_left  = buffer_size;\n\n    if (ld->bytes_left >= 4)\n    {\n        tmp = getdword((uint32_t*)ld->buffer);\n        ld->bytes_left -= 4;\n    } else {\n        tmp = getdword_n((uint32_t*)ld->buffer, ld->bytes_left);\n        ld->bytes_left = 0;\n    }\n    ld->bufa = tmp;\n\n    if (ld->bytes_left >= 4)\n    {\n        tmp = getdword((uint32_t*)ld->buffer + 1);\n        ld->bytes_left -= 4;\n    } else {\n        tmp = getdword_n((uint32_t*)ld->buffer + 1, ld->bytes_left);\n        ld->bytes_left = 0;\n    }\n    ld->bufb = tmp;\n\n    ld->start = (uint32_t*)ld->buffer;\n    ld->tail = ((uint32_t*)ld->buffer + 2);\n\n    ld->bits_left = 32;\n\n    ld->error = 0;\n}\n",
        "commit_message": "Fix a couple buffer overflows\n\nhttps://hackerone.com/reports/502816\nhttps://hackerone.com/reports/507858\n\nhttps://github.com/videolan/vlc/blob/master/contrib/src/faad2/faad2-fix-overflows.patch",
        "cve_desc": "An issue was discovered in Freeware Advanced Audio Decoder 2 (FAAD2) 2.8.8. The faad_resetbits function in libfaad/bits.c is affected by a buffer overflow vulnerability. The number of bits to be read is determined by ld->buffer_size - words*4, cast to uint32. If ld->buffer_size - words*4 is negative, a buffer overflow is later performed via getdword_n(&ld->start[words], ld->bytes_left).",
        "target": 0
      },
      {
        "idx": 80567,
        "reasoning": "This code snippet is safe and was not flagged as vulnerable in the HackerOne reports. The provided patch addresses buffer overflows in other parts of faad2, specifically related to input parsing and data handling *before* reaching the `faad_origbitbuffer_size` function, and this function simply returns a stored value without any manipulation that could cause an overflow.\n\n\n\n",
        "func": "uint32_t faad_origbitbuffer_size(bitfile *ld)\n{\n    return ld->buffer_size;\n}\n",
        "commit_message": "Fix a couple buffer overflows\n\nhttps://hackerone.com/reports/502816\nhttps://hackerone.com/reports/507858\n\nhttps://github.com/videolan/vlc/blob/master/contrib/src/faad2/faad2-fix-overflows.patch",
        "cve_desc": "An issue was discovered in Freeware Advanced Audio Decoder 2 (FAAD2) 2.8.8. The faad_resetbits function in libfaad/bits.c is affected by a buffer overflow vulnerability. The number of bits to be read is determined by ld->buffer_size - words*4, cast to uint32. If ld->buffer_size - words*4 is negative, a buffer overflow is later performed via getdword_n(&ld->start[words], ld->bytes_left).",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 10758,
        "reasoning": "This code is vulnerable to a buffer overflow because `ld->bytes_left` can become negative, leading to `getdword_n` reading beyond the allocated buffer. The vulnerability occurs when `ld->buffer_size - words*4` underflows, resulting in a large positive `ld->bytes_left` value passed to `getdword_n`, exceeding the bounds of `ld->start`.",
        "func": "void faad_resetbits(bitfile *ld, int bits)\n{\n    uint32_t tmp;\n    int words = bits >> 5;\n    int remainder = bits & 0x1F;\n\n    ld->bytes_left = ld->buffer_size - words*4;\n\n    if (ld->bytes_left >= 4)\n    {\n        tmp = getdword(&ld->start[words]);\n        ld->bytes_left -= 4;\n    } else {\n        tmp = getdword_n(&ld->start[words], ld->bytes_left);\n        ld->bytes_left = 0;\n    }\n    ld->bufa = tmp;\n\n    if (ld->bytes_left >= 4)\n    {\n        tmp = getdword(&ld->start[words+1]);\n        ld->bytes_left -= 4;\n    } else {\n        tmp = getdword_n(&ld->start[words+1], ld->bytes_left);\n        ld->bytes_left = 0;\n    }\n    ld->bufb = tmp;\n\n    ld->bits_left = 32 - remainder;\n    ld->tail = &ld->start[words+2];\n\n    /* recheck for reading too many bytes */\n    ld->error = 0;\n//    if (ld->bytes_left == 0)\n//        ld->no_more_reading = 1;\n//    if (ld->bytes_left < 0)\n//        ld->error = 1;\n}",
        "commit_message": "Fix a couple buffer overflows\n\nhttps://hackerone.com/reports/502816\nhttps://hackerone.com/reports/507858\n\nhttps://github.com/videolan/vlc/blob/master/contrib/src/faad2/faad2-fix-overflows.patch",
        "cve_desc": "An issue was discovered in Freeware Advanced Audio Decoder 2 (FAAD2) 2.8.8. The faad_resetbits function in libfaad/bits.c is affected by a buffer overflow vulnerability. The number of bits to be read is determined by ld->buffer_size - words*4, cast to uint32. If ld->buffer_size - words*4 is negative, a buffer overflow is later performed via getdword_n(&ld->start[words], ld->bytes_left).",
        "target": 1
      }
    ]
  },
  "flac": {
    "0": [
      {
        "idx": 330322,
        "reasoning": "This code *is* vulnerable to a buffer read overflow, as identified by CVE-2014-8962. The code reads the `length` of vendor strings and comments from the input stream and uses these lengths to allocate buffers, but it doesn't adequately validate that these lengths are reasonable and doesn't prevent reading beyond the allocated buffer size when `length` is manipulated, potentially leading to an overflow.",
        "func": "FLAC__bool read_metadata_vorbiscomment_(FLAC__StreamDecoder *decoder, FLAC__StreamMetadata_VorbisComment *obj, unsigned length)\n{\n\tFLAC__uint32 i;\n\n\tFLAC__ASSERT(FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input));\n\n\t/* read vendor string */\n\tif (length >= 8) {\n\t\tlength -= 8; /* vendor string length + num comments entries alone take 8 bytes */\n\t\tFLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_ENTRY_LENGTH_LEN == 32);\n\t\tif (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->vendor_string.length))\n\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\tif (obj->vendor_string.length > 0) {\n\t\t\tif (length < obj->vendor_string.length) {\n\t\t\t\tobj->vendor_string.length = 0;\n\t\t\t\tobj->vendor_string.entry = 0;\n\t\t\t\tgoto skip;\n\t\t\t}\n\t\t\telse\n\t\t\t\tlength -= obj->vendor_string.length;\n\t\t\tif (0 == (obj->vendor_string.entry = safe_malloc_add_2op_(obj->vendor_string.length, /*+*/1))) {\n\t\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (!FLAC__bitreader_read_byte_block_aligned_no_crc(decoder->private_->input, obj->vendor_string.entry, obj->vendor_string.length))\n\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\tobj->vendor_string.entry[obj->vendor_string.length] = '\\0';\n\t\t}\n\t\telse\n\t\t\tobj->vendor_string.entry = 0;\n\n\t\t/* read num comments */\n\t\tFLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_NUM_COMMENTS_LEN == 32);\n\t\tif (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->num_comments))\n\t\t\treturn false; /* read_callback_ sets the state for us */\n\n\t\t/* read comments */\n\t\tif (obj->num_comments > 0) {\n\t\t\tif (0 == (obj->comments = safe_malloc_mul_2op_p(obj->num_comments, /*times*/sizeof(FLAC__StreamMetadata_VorbisComment_Entry)))) {\n\t\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tfor (i = 0; i < obj->num_comments; i++) {\n\t\t\t\tFLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_ENTRY_LENGTH_LEN == 32);\n\t\t\t\tif (length < 4) {\n\t\t\t\t\tobj->num_comments = i;\n\t\t\t\t\tgoto skip;\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\tlength -= 4;\n\t\t\t\tif (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->comments[i].length))\n\t\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\t\tif (obj->comments[i].length > 0) {\n\t\t\t\t\tif (length < obj->comments[i].length) {\n\t\t\t\t\t\tobj->comments[i].length = 0;\n\t\t\t\t\t\tobj->comments[i].entry = 0;\n\t\t\t\t\t\tobj->num_comments = i;\n\t\t\t\t\t\tgoto skip;\n\t\t\t\t\t}\n\t\t\t\t\telse\n\t\t\t\t\t\tlength -= obj->comments[i].length;\n\t\t\t\t\tif (0 == (obj->comments[i].entry = safe_malloc_add_2op_(obj->comments[i].length, /*+*/1))) {\n\t\t\t\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t\tif (!FLAC__bitreader_read_byte_block_aligned_no_crc(decoder->private_->input, obj->comments[i].entry, obj->comments[i].length))\n\t\t\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\t\t\tobj->comments[i].entry[obj->comments[i].length] = '\\0';\n\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\tobj->comments[i].entry = 0;\n\t\t\t}\n\t\t}\n\t\telse\n\t\t\tobj->comments = 0;\n\t}\n\n  skip:\n\tif (length > 0) {\n\t\t/* This will only happen on files with invalid data in comments */\n\t\tif(!FLAC__bitreader_skip_byte_block_aligned_no_crc(decoder->private_->input, length))\n\t\t\treturn false; /* read_callback_ sets the state for us */\n\t}\n\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 0
      },
      {
        "idx": 330325,
        "reasoning": "This code snippet is safe and not flagged as vulnerable because it simply retrieves a value (`decoder->protected_->channels`) that should have already been validated during stream parsing and decoder initialization. The commit message references CVE-2014-8962, but this specific function isn't related to the buffer read overflow vulnerability; it only *reads* a pre-existing value, it doesn't process stream data directly.\n\n\n\n",
        "func": "FLAC_API unsigned FLAC__stream_decoder_get_channels(const FLAC__StreamDecoder *decoder)\n{\n\tFLAC__ASSERT(0 != decoder);\n\tFLAC__ASSERT(0 != decoder->protected_);\n\treturn decoder->protected_->channels;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 0
      },
      {
        "idx": 330328,
        "reasoning": "This code addresses a potential buffer read overflow by reallocating output buffers based on the stream's channel and sample size requirements, ensuring sufficient space is allocated before use. The commit specifically adds padding to the allocated memory to satisfy alignment requirements of a downstream function (`FLAC__lpc_restore_signal_asm_ia32_mmx`), mitigating the original vulnerability described in CVE-2014-8962.\n\n\n\n",
        "func": "FLAC__bool allocate_output_(FLAC__StreamDecoder *decoder, unsigned size, unsigned channels)\n{\n\tunsigned i;\n\tFLAC__int32 *tmp;\n\n\tif(size <= decoder->private_->output_capacity && channels <= decoder->private_->output_channels)\n\t\treturn true;\n\n\t/* simply using realloc() is not practical because the number of channels may change mid-stream */\n\n\tfor(i = 0; i < FLAC__MAX_CHANNELS; i++) {\n\t\tif(0 != decoder->private_->output[i]) {\n\t\t\tfree(decoder->private_->output[i]-4);\n\t\t\tdecoder->private_->output[i] = 0;\n\t\t}\n\t\tif(0 != decoder->private_->residual_unaligned[i]) {\n\t\t\tfree(decoder->private_->residual_unaligned[i]);\n\t\t\tdecoder->private_->residual_unaligned[i] = decoder->private_->residual[i] = 0;\n\t\t}\n\t}\n\n\tfor(i = 0; i < channels; i++) {\n\t\t/* WATCHOUT:\n\t\t * FLAC__lpc_restore_signal_asm_ia32_mmx() requires that the\n\t\t * output arrays have a buffer of up to 3 zeroes in front\n\t\t * (at negative indices) for alignment purposes; we use 4\n\t\t * to keep the data well-aligned.\n\t\t */\n\t\ttmp = safe_malloc_muladd2_(sizeof(FLAC__int32), /*times (*/size, /*+*/4/*)*/);\n\t\tif(tmp == 0) {\n\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\t\treturn false;\n\t\t}\n\t\tmemset(tmp, 0, sizeof(FLAC__int32)*4);\n\t\tdecoder->private_->output[i] = tmp + 4;\n\n\t\tif(!FLAC__memory_alloc_aligned_int32_array(size, &decoder->private_->residual_unaligned[i], &decoder->private_->residual[i])) {\n\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\t\treturn false;\n\t\t}\n\t}\n\n\tdecoder->private_->output_capacity = size;\n\tdecoder->private_->output_channels = channels;\n\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 0
      },
      {
        "idx": 330332,
        "reasoning": "This code is **not vulnerable** to the reported buffer read overflow (CVE-2014-8962). The fix correctly reads a variable-length size field to determine how many bytes to skip for the ID3v2 tag, preventing an uncontrolled read beyond the expected tag length, and the code includes checks to ensure reads are successful before proceeding.\n\n\n\n",
        "func": "FLAC__bool skip_id3v2_tag_(FLAC__StreamDecoder *decoder)\n{\n\tFLAC__uint32 x;\n\tunsigned i, skip;\n\n\t/* skip the version and flags bytes */\n\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 24))\n\t\treturn false; /* read_callback_ sets the state for us */\n\t/* get the size (in bytes) to skip */\n\tskip = 0;\n\tfor(i = 0; i < 4; i++) {\n\t\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 8))\n\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\tskip <<= 7;\n\t\tskip |= (x & 0x7f);\n\t}\n\t/* skip the rest of the tag */\n\tif(!FLAC__bitreader_skip_byte_block_aligned_no_crc(decoder->private_->input, skip))\n\t\treturn false; /* read_callback_ sets the state for us */\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 0
      },
      {
        "idx": 330347,
        "reasoning": "This code snippet is **not vulnerable** to the reported CVE-2014-8962, which concerns a buffer read overflow elsewhere in the `flac` project. The provided code only manipulates a boolean array (`metadata_filter`) and an integer (`metadata_filter_ids_count`)\u2014there are no buffer operations present that could lead to a read overflow.",
        "func": "FLAC_API FLAC__bool FLAC__stream_decoder_set_metadata_ignore(FLAC__StreamDecoder *decoder, FLAC__MetadataType type)\n{\n\tFLAC__ASSERT(0 != decoder);\n\tFLAC__ASSERT(0 != decoder->private_);\n\tFLAC__ASSERT(0 != decoder->protected_);\n\tFLAC__ASSERT((unsigned)type <= FLAC__MAX_METADATA_TYPE_CODE);\n\t/* double protection */\n\tif((unsigned)type > FLAC__MAX_METADATA_TYPE_CODE)\n\t\treturn false;\n\tif(decoder->protected_->state != FLAC__STREAM_DECODER_UNINITIALIZED)\n\t\treturn false;\n\tdecoder->private_->metadata_filter[type] = false;\n\tif(type == FLAC__METADATA_TYPE_APPLICATION)\n\t\tdecoder->private_->metadata_filter_ids_count = 0;\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 202142,
        "reasoning": "This code is vulnerable to a stack-based buffer overflow because it doesn't adequately validate the size of data read from the input stream when searching for metadata, potentially writing beyond the bounds of `decoder->private_->header_warmup`. Specifically, the code reads up to two bytes into `header_warmup` (a fixed-size buffer) without ensuring sufficient data is available or that reading won\u2019t exceed the buffer\u2019s capacity, leading to a potential overflow if a malicious FLAC file provides unexpected byte sequences.",
        "func": "FLAC__bool find_metadata_(FLAC__StreamDecoder *decoder)\n{\n\tFLAC__uint32 x;\n\tunsigned i, id;\n\tFLAC__bool first = true;\n\n\tFLAC__ASSERT(FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input));\n\n\tfor(i = id = 0; i < 4; ) {\n\t\tif(decoder->private_->cached) {\n\t\t\tx = (FLAC__uint32)decoder->private_->lookahead;\n\t\t\tdecoder->private_->cached = false;\n\t\t}\n\t\telse {\n\t\t\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 8))\n\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t}\n\t\tif(x == FLAC__STREAM_SYNC_STRING[i]) {\n\t\t\tfirst = true;\n\t\t\ti++;\n\t\t\tid = 0;\n\t\t\tcontinue;\n\t\t}\n\t\tif(x == ID3V2_TAG_[id]) {\n\t\t\tid++;\n\t\t\ti = 0;\n\t\t\tif(id == 3) {\n\t\t\t\tif(!skip_id3v2_tag_(decoder))\n\t\t\t\t\treturn false; /* skip_id3v2_tag_ sets the state for us */\n\t\t\t}\n\t\t\tcontinue;\n\t\t}\n\t\tid = 0;\n\t\tif(x == 0xff) { /* MAGIC NUMBER for the first 8 frame sync bits */\n\t\t\tdecoder->private_->header_warmup[0] = (FLAC__byte)x;\n\t\t\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 8))\n\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\n\t\t\t/* we have to check if we just read two 0xff's in a row; the second may actually be the beginning of the sync code */\n\t\t\t/* else we have to check if the second byte is the end of a sync code */\n\t\t\tif(x == 0xff) { /* MAGIC NUMBER for the first 8 frame sync bits */\n\t\t\t\tdecoder->private_->lookahead = (FLAC__byte)x;\n\t\t\t\tdecoder->private_->cached = true;\n\t\t\t}\n\t\t\telse if(x >> 1 == 0x7c) { /* MAGIC NUMBER for the last 6 sync bits and reserved 7th bit */\n\t\t\t\tdecoder->private_->header_warmup[1] = (FLAC__byte)x;\n\t\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_READ_FRAME;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\ti = 0;\n\t\tif(first) {\n\t\t\tsend_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);\n\t\t\tfirst = false;\n\t\t}\n\t}\n\n\tdecoder->protected_->state = FLAC__STREAM_DECODER_READ_METADATA;\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fix buffer read overflow.\n\nThis is CVE-2014-8962.\n\nReported-by: Michele Spagnuolo,\n             Google Security Team <mikispag@google.com>",
        "cve_desc": "Stack-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 1
      },
      {
        "idx": 208089,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow due to insufficient bounds checking when reading residual data, specifically within the `FLAC__bitreader_read_rice_signed_block` and the inner loop reading raw `int32` values. A crafted FLAC file can manipulate the `rice_parameter` and `partition_samples` values to cause these functions to write beyond the allocated buffer for `residual`, leading to arbitrary code execution as described in CVE-2014-9028.",
        "func": "FLAC__bool read_residual_partitioned_rice_(FLAC__StreamDecoder *decoder, unsigned predictor_order, unsigned partition_order, FLAC__EntropyCodingMethod_PartitionedRiceContents *partitioned_rice_contents, FLAC__int32 *residual, FLAC__bool is_extended)\n{\n\tFLAC__uint32 rice_parameter;\n\tint i;\n\tunsigned partition, sample, u;\n\tconst unsigned partitions = 1u << partition_order;\n\tconst unsigned partition_samples = partition_order > 0? decoder->private_->frame.header.blocksize >> partition_order : decoder->private_->frame.header.blocksize - predictor_order;\n\tconst unsigned plen = is_extended? FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2_PARAMETER_LEN : FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_PARAMETER_LEN;\n\tconst unsigned pesc = is_extended? FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2_ESCAPE_PARAMETER : FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_ESCAPE_PARAMETER;\n\n\t/* sanity checks */\n\tif(partition_order == 0) {\n\t\tif(decoder->private_->frame.header.blocksize < predictor_order) {\n\t\t\tsend_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);\n\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;\n\t\t\t/* We have received a potentially malicious bit stream. All we can do is error out to avoid a heap overflow. */\n\t\t\treturn false;\n\t\t}\n\t}\n\telse {\n\t\tif(partition_samples < predictor_order) {\n\t\t\tsend_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);\n\t\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;\n\t\t\treturn true;\n\t\t}\n\t}\n\n\tif(!FLAC__format_entropy_coding_method_partitioned_rice_contents_ensure_size(partitioned_rice_contents, flac_max(6u, partition_order))) {\n\t\tdecoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;\n\t\treturn false;\n\t}\n\n\tsample = 0;\n\tfor(partition = 0; partition < partitions; partition++) {\n\t\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &rice_parameter, plen))\n\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\tpartitioned_rice_contents->parameters[partition] = rice_parameter;\n\t\tif(rice_parameter < pesc) {\n\t\t\tpartitioned_rice_contents->raw_bits[partition] = 0;\n\t\t\tu = (partition_order == 0 || partition > 0)? partition_samples : partition_samples - predictor_order;\n\t\t\tif(!FLAC__bitreader_read_rice_signed_block(decoder->private_->input, residual + sample, u, rice_parameter))\n\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\tsample += u;\n\t\t}\n\t\telse {\n\t\t\tif(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &rice_parameter, FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_RAW_LEN))\n\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\tpartitioned_rice_contents->raw_bits[partition] = rice_parameter;\n\t\t\tfor(u = (partition_order == 0 || partition > 0)? 0 : predictor_order; u < partition_samples; u++, sample++) {\n\t\t\t\tif(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i, rice_parameter))\n\t\t\t\t\treturn false; /* read_callback_ sets the state for us */\n\t\t\t\tresidual[sample] = i;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn true;\n}",
        "commit_message": "src/libFLAC/stream_decoder.c : Fail safely to avoid a heap overflow.\n\nThis fix is closely related to the fix for CVE-2014-9028. When that\nfix went public Miroslav Lichvar noticed a similar potential problem\nspot in the same function and was able to craft a file to trigger a\nheap write overflow.\n\nReported-by : Miroslav Lichvar <mlichvar@redhat.com>",
        "cve_desc": "Heap-based buffer overflow in stream_decoder.c in libFLAC before 1.3.1 allows remote attackers to execute arbitrary code via a crafted .flac file.",
        "target": 1
      },
      {
        "idx": 210388,
        "reasoning": "This code is vulnerable because the `FLAC__stream_decoder_process_single` function, called within verify mode, can potentially write beyond the allocated buffer size due to a missing bounds check as described in CVE-2021-0561. This out-of-bounds write can lead to local information disclosure without requiring user interaction or elevated privileges.",
        "func": "FLAC__bool write_bitbuffer_(FLAC__StreamEncoder *encoder, uint32_t samples, FLAC__bool is_last_block)\n{\n\tconst FLAC__byte *buffer;\n\tsize_t bytes;\n\n\tFLAC__ASSERT(FLAC__bitwriter_is_byte_aligned(encoder->private_->frame));\n\n\tif(!FLAC__bitwriter_get_buffer(encoder->private_->frame, &buffer, &bytes)) {\n\t\tencoder->protected_->state = FLAC__STREAM_ENCODER_MEMORY_ALLOCATION_ERROR;\n\t\treturn false;\n\t}\n\n\tif(encoder->protected_->verify) {\n\t\tencoder->private_->verify.output.data = buffer;\n\t\tencoder->private_->verify.output.bytes = bytes;\n\t\tif(encoder->private_->verify.state_hint == ENCODER_IN_MAGIC) {\n\t\t\tencoder->private_->verify.needs_magic_hack = true;\n\t\t}\n\t\telse {\n\t\t\tif(!FLAC__stream_decoder_process_single(encoder->private_->verify.decoder)) {\n\t\t\t\tFLAC__bitwriter_release_buffer(encoder->private_->frame);\n\t\t\t\tFLAC__bitwriter_clear(encoder->private_->frame);\n\t\t\t\tif(encoder->protected_->state != FLAC__STREAM_ENCODER_VERIFY_MISMATCH_IN_AUDIO_DATA)\n\t\t\t\t\tencoder->protected_->state = FLAC__STREAM_ENCODER_VERIFY_DECODER_ERROR;\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t}\n\n\tif(write_frame_(encoder, buffer, bytes, samples, is_last_block) != FLAC__STREAM_ENCODER_WRITE_STATUS_OK) {\n\t\tFLAC__bitwriter_release_buffer(encoder->private_->frame);\n\t\tFLAC__bitwriter_clear(encoder->private_->frame);\n\t\tencoder->protected_->state = FLAC__STREAM_ENCODER_CLIENT_ERROR;\n\t\treturn false;\n\t}\n\n\tFLAC__bitwriter_release_buffer(encoder->private_->frame);\n\tFLAC__bitwriter_clear(encoder->private_->frame);\n\n\tif(samples > 0) {\n\t\tencoder->private_->streaminfo.data.stream_info.min_framesize = flac_min(bytes, encoder->private_->streaminfo.data.stream_info.min_framesize);\n\t\tencoder->private_->streaminfo.data.stream_info.max_framesize = flac_max(bytes, encoder->private_->streaminfo.data.stream_info.max_framesize);\n\t}\n\n\treturn true;\n}",
        "commit_message": "libFlac: Exit at EOS in verify mode\n\nWhen verify mode is enabled, once decoder flags end of stream,\nencode processing is considered complete.\n\nCVE-2021-0561\n\nSigned-off-by: Ralph Giles <giles@thaumas.net>",
        "cve_desc": "In append_to_verify_fifo_interleaved_ of stream_encoder.c, there is a possible out of bounds write due to a missing bounds check. This could lead to local information disclosure with no additional execution privileges needed. User interaction is not needed for exploitation.Product: AndroidVersions: Android-11Android ID: A-174302683",
        "target": 1
      }
    ]
  },
  "flatpak": {
    "0": [
      {
        "idx": 222740,
        "reasoning": "This code snippet is not vulnerable because it simply converts a bitmask representing socket permissions into a string for display \u2013 it doesn\u2019t handle filesystem access control or modify permissions as described in the commit message. The commit message details changes to how `--nofilesystem` arguments are processed, which would be implemented in a different part of the codebase than this function dealing with socket representations.\n\n\n\n",
        "func": "flatpak_context_sockets_to_string (FlatpakContextSockets sockets, FlatpakContextSockets valid)\n{\n  return flatpak_context_bitmask_to_string (sockets, valid, flatpak_context_sockets);\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 0
      },
      {
        "idx": 222741,
        "reasoning": "This code snippet is not flagged as vulnerable because it focuses on removing filesystem device access based on string input, and the commit message clarifies the change is about *limiting* access rather than introducing new permissions or handling untrusted data in a dangerous way. The function `flatpak_context_remove_devices` is used to restrict access, and the commit details suggest the change aligns with expected behavior for the `--nofilesystem` option.\n\n\n\n",
        "func": "option_nodevice_cb (const gchar *option_name,\n                    const gchar *value,\n                    gpointer     data,\n                    GError     **error)\n{\n  FlatpakContext *context = data;\n  FlatpakContextDevices device;\n\n  device = flatpak_context_device_from_string (value, error);\n  if (device == 0)\n    return FALSE;\n\n  flatpak_context_remove_devices (context, device);\n\n  return TRUE;\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 0
      },
      {
        "idx": 222742,
        "reasoning": "This code snippet focuses on managing D-Bus access control policies and doesn't directly handle filesystem permissions or the `--nofilesystem` flag changes described in the commit message. Therefore, the code is not vulnerable as it's unrelated to the altered filesystem restriction behavior and doesn't introduce any new security risks based on the provided context.\n\n\n\n",
        "func": "flatpak_context_add_bus_filters (FlatpakContext *context,\n                                 const char     *app_id,\n                                 gboolean        session_bus,\n                                 gboolean        sandboxed,\n                                 FlatpakBwrap   *bwrap)\n{\n  GHashTable *ht;\n  GHashTableIter iter;\n  gpointer key, value;\n\n  flatpak_bwrap_add_arg (bwrap, \"--filter\");\n  if (app_id && session_bus)\n    {\n      if (!sandboxed)\n        {\n          flatpak_bwrap_add_arg_printf (bwrap, \"--own=%s.*\", app_id);\n          flatpak_bwrap_add_arg_printf (bwrap, \"--own=org.mpris.MediaPlayer2.%s.*\", app_id);\n        }\n      else\n        flatpak_bwrap_add_arg_printf (bwrap, \"--own=%s.Sandboxed.*\", app_id);\n    }\n\n  if (session_bus)\n    ht = context->session_bus_policy;\n  else\n    ht = context->system_bus_policy;\n\n  g_hash_table_iter_init (&iter, ht);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    {\n      FlatpakPolicy policy = GPOINTER_TO_INT (value);\n\n      if (policy > 0)\n        flatpak_bwrap_add_arg_printf (bwrap, \"--%s=%s\",\n                                      flatpak_policy_to_string (policy),\n                                      (char *) key);\n    }\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 0
      },
      {
        "idx": 222743,
        "reasoning": "This code snippet is not directly related to the filesystem permission changes described in the commit message; it handles setting environment variables and performs basic validation to prevent invalid variable names. Therefore, there's no apparent vulnerability introduced or addressed by this code concerning filesystem access control or the `--nofilesystem` flag's behavior.\n\n\n\n",
        "func": "option_unset_env_cb (const gchar *option_name,\n                     const gchar *value,\n                     gpointer     data,\n                     GError     **error)\n{\n  FlatpakContext *context = data;\n\n  if (strchr (value, '=') != NULL)\n    {\n      g_set_error (error, G_OPTION_ERROR, G_OPTION_ERROR_FAILED,\n                   _(\"Environment variable name must not contain '=': %s\"), value);\n      return FALSE;\n    }\n\n  flatpak_context_set_env_var (context, value, NULL);\n  return TRUE;\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 0
      },
      {
        "idx": 222744,
        "reasoning": "This code snippet focuses on comparing and merging filesystem permission policies and doesn't directly handle filesystem access itself, making it unlikely to introduce vulnerabilities related to unauthorized access. The commit message details a change in *how* filesystem access is restricted via command-line arguments, but the provided code simply manages the policy data\u2014it doesn\u2019t implement the restriction logic and therefore isn\u2019t a point of failure.\n\n\n\n",
        "func": "adds_generic_policy (GHashTable *old, GHashTable *new)\n{\n  GLNX_HASH_TABLE_FOREACH_KV (new, const char *, key, GPtrArray *, new_values)\n    {\n      GPtrArray *old_values = g_hash_table_lookup (old, key);\n      int i;\n\n      if (new_values == NULL || new_values->len == 0)\n        continue;\n\n      if (old_values == NULL || old_values->len == 0)\n        return TRUE;\n\n      for (i = 0; i < new_values->len; i++)\n        {\n          const char *new_value = g_ptr_array_index (new_values, i);\n\n          if (!flatpak_g_ptr_array_contains_string (old_values, new_value))\n            return TRUE;\n        }\n    }\n\n  return FALSE;\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195090,
        "reasoning": "The code is vulnerable because it doesn't adequately block new mount-related syscalls (like `open_tree`, `move_mount`, etc.) that allow manipulation of the VFS, enabling a Flatpak app to potentially spoof its identity to host services. This allows a malicious Flatpak app to bypass the sandbox and escalate privileges when interacting with AF_UNIX sockets like those used by Wayland or Pipewire, as described in GHSA-67h7-w3jq-vh4q.",
        "func": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "commit_message": "run: Block setns()\n\nIf we don't allow unshare() or clone() with CLONE_NEWUSER, we also\nshouldn't allow joining an existing (but different) namespace.\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "target": 1
      },
      {
        "idx": 195093,
        "reasoning": "The code is vulnerable because it doesn't adequately block recent mount-related syscalls, allowing Flatpak apps to manipulate the virtual filesystem (VFS). This manipulation can trick host services into misidentifying the Flatpak app as a trusted process, leading to privilege escalation \u2013 as partially addressed by GHSA-67h7-w3jq-vh4q.",
        "func": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "commit_message": "run: Disallow recently-added mount-manipulation syscalls\n\nIf we don't allow mount() then we shouldn't allow these either.\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nThanks: an anonymous reporter\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "target": 1
      },
      {
        "idx": 195094,
        "reasoning": "The code is vulnerable because it doesn't adequately block new mount-related syscalls (like `open_tree`, `move_mount`, etc.) that allow manipulation of the virtual filesystem (VFS) within the sandbox. This allows a Flatpak app to potentially spoof its identity to host services by crafting or removing the `/.flatpak-info` file, leading to privilege escalation when interacting with AF_UNIX sockets like Wayland or Pipewire \u2013 as described in GHSA-67h7-w3jq-vh4q.",
        "func": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (setns), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n\n    /* seccomp can't look into clone3()'s struct clone_args to check whether\n     * the flags are OK, so we have no choice but to block clone3().\n     * Return ENOSYS so user-space will fall back to clone().\n     * (GHSA-67h7-w3jq-vh4q; see also https://github.com/moby/moby/commit/9f6b562d) */\n    {SCMP_SYS (clone3), ENOSYS},\n\n    /* New mount manipulation APIs can also change our VFS. There's no\n     * legitimate reason to do these in the sandbox, so block all of them\n     * rather than thinking about which ones might be dangerous.\n     * (GHSA-67h7-w3jq-vh4q) */\n    {SCMP_SYS (open_tree), ENOSYS},\n    {SCMP_SYS (move_mount), ENOSYS},\n    {SCMP_SYS (fsopen), ENOSYS},\n    {SCMP_SYS (fsconfig), ENOSYS},\n    {SCMP_SYS (fsmount), ENOSYS},\n    {SCMP_SYS (fspick), ENOSYS},\n    {SCMP_SYS (mount_setattr), ENOSYS},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "commit_message": "run: Don't allow unmounting filesystems\n\nIf we don't allow mounting filesystems, we shouldn't allow unmounting\neither.\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "target": 1
      },
      {
        "idx": 195232,
        "reasoning": "The code is vulnerable to a path traversal due to the previous, limited behavior of `--nofilesystem=host`, which didn't fully restrict filesystem access as intended. Specifically, before this commit, `--nofilesystem=host` didn't prevent access to subdirectories within `/home`, allowing a malicious application\u2014especially when combined with `flatpak build --nofilesystem=host appstream-utils mirror-screenshots`\u2014to potentially exploit permissions and execute arbitrary code by replacing utilities like `appstream-util`.",
        "func": "flatpak_context_merge (FlatpakContext *context,\n                       FlatpakContext *other)\n{\n  GHashTableIter iter;\n  gpointer key, value;\n\n  context->shares &= ~other->shares_valid;\n  context->shares |= other->shares;\n  context->shares_valid |= other->shares_valid;\n  context->sockets &= ~other->sockets_valid;\n  context->sockets |= other->sockets;\n  context->sockets_valid |= other->sockets_valid;\n  context->devices &= ~other->devices_valid;\n  context->devices |= other->devices;\n  context->devices_valid |= other->devices_valid;\n  context->features &= ~other->features_valid;\n  context->features |= other->features;\n  context->features_valid |= other->features_valid;\n\n  g_hash_table_iter_init (&iter, other->env_vars);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->env_vars, g_strdup (key), g_strdup (value));\n\n  g_hash_table_iter_init (&iter, other->persistent);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->persistent, g_strdup (key), value);\n\n  g_hash_table_iter_init (&iter, other->filesystems);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->filesystems, g_strdup (key), value);\n\n  g_hash_table_iter_init (&iter, other->session_bus_policy);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->session_bus_policy, g_strdup (key), value);\n\n  g_hash_table_iter_init (&iter, other->system_bus_policy);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->system_bus_policy, g_strdup (key), value);\n\n  g_hash_table_iter_init (&iter, other->system_bus_policy);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    g_hash_table_insert (context->system_bus_policy, g_strdup (key), value);\n\n  g_hash_table_iter_init (&iter, other->generic_policy);\n  while (g_hash_table_iter_next (&iter, &key, &value))\n    {\n      const char **policy_values = (const char **) value;\n      int i;\n\n      for (i = 0; policy_values[i] != NULL; i++)\n        flatpak_context_apply_generic_policy (context, (char *) key, policy_values[i]);\n    }\n}",
        "commit_message": "Make --nofilesystem=host/home remove access to subdirs of those\n\nPreviously --nofilesystem=host only removed specifically access to the\n`host` permissions, and not necessarily other filesystems (like `home`\nor `/some/path`). This isn't very useful to limit access because you\ndon't know what other filesystems the app may have access too.\n\nWe change this to mean that `--nofilesystem=host` removes *all* filesystem\naccess from the parent layer, and `--nofilesystem=home` removes all\nfile access to the homedir and paths inside it.\n\nThe available layers are, in order:\n\n * app permissions\n * overrides\n * commandline args\n\nThis allows you to start from scratch with the filesystem permissions\nin the overrides or the commandline. This is a small change in\nbehaviour, but not a lot of things use --nofilesystem, and the ones\nthat do probably expects this behaviour.",
        "cve_desc": "Flatpak is a Linux application sandboxing and distribution framework. A path traversal vulnerability affects versions of Flatpak prior to 1.12.3 and 1.10.6. flatpak-builder applies `finish-args` last in the build. At this point the build directory will have the full access that is specified in the manifest, so running `flatpak build` against it will gain those permissions. Normally this will not be done, so this is not problem. However, if `--mirror-screenshots-url` is specified, then flatpak-builder will launch `flatpak build --nofilesystem=host appstream-utils mirror-screenshots` after finalization, which can lead to issues even with the `--nofilesystem=host` protection. In normal use, the only issue is that these empty directories can be created wherever the user has write permissions. However, a malicious application could replace the `appstream-util` binary and potentially do something more hostile. This has been resolved in Flatpak 1.12.3 and 1.10.6 by changing the behaviour of `--nofilesystem=home` and `--nofilesystem=host`.",
        "target": 1
      },
      {
        "idx": 195304,
        "reasoning": "The code is vulnerable because it doesn't adequately block syscalls related to mount manipulation, allowing a sandboxed Flatpak app to potentially manipulate its virtual filesystem (VFS) and forge or remove the `/.flatpak-info` file. This manipulation can trick host services into believing the Flatpak app is a trusted, non-sandboxed process, leading to privilege escalation.",
        "func": "setup_seccomp (FlatpakBwrap   *bwrap,\n               const char     *arch,\n               gulong          allowed_personality,\n               FlatpakRunFlags run_flags,\n               GError        **error)\n{\n  gboolean multiarch = (run_flags & FLATPAK_RUN_FLAG_MULTIARCH) != 0;\n  gboolean devel = (run_flags & FLATPAK_RUN_FLAG_DEVEL) != 0;\n\n  __attribute__((cleanup (cleanup_seccomp))) scmp_filter_ctx seccomp = NULL;\n\n  /**** BEGIN NOTE ON CODE SHARING\n   *\n   * There are today a number of different Linux container\n   * implementations.  That will likely continue for long into the\n   * future.  But we can still try to share code, and it's important\n   * to do so because it affects what library and application writers\n   * can do, and we should support code portability between different\n   * container tools.\n   *\n   * This syscall blocklist is copied from linux-user-chroot, which was in turn\n   * clearly influenced by the Sandstorm.io blocklist.\n   *\n   * If you make any changes here, I suggest sending the changes along\n   * to other sandbox maintainers.  Using the libseccomp list is also\n   * an appropriate venue:\n   * https://groups.google.com/forum/#!forum/libseccomp\n   *\n   * A non-exhaustive list of links to container tooling that might\n   * want to share this blocklist:\n   *\n   *  https://github.com/sandstorm-io/sandstorm\n   *    in src/sandstorm/supervisor.c++\n   *  https://github.com/flatpak/flatpak.git\n   *    in common/flatpak-run.c\n   *  https://git.gnome.org/browse/linux-user-chroot\n   *    in src/setup-seccomp.c\n   *\n   * Other useful resources:\n   * https://github.com/systemd/systemd/blob/HEAD/src/shared/seccomp-util.c\n   * https://github.com/moby/moby/blob/HEAD/profiles/seccomp/default.json\n   *\n   **** END NOTE ON CODE SHARING\n   */\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_blocklist[] = {\n    /* Block dmesg */\n    {SCMP_SYS (syslog), EPERM},\n    /* Useless old syscall */\n    {SCMP_SYS (uselib), EPERM},\n    /* Don't allow disabling accounting */\n    {SCMP_SYS (acct), EPERM},\n    /* 16-bit code is unnecessary in the sandbox, and modify_ldt is a\n       historic source of interesting information leaks. */\n    {SCMP_SYS (modify_ldt), EPERM},\n    /* Don't allow reading current quota use */\n    {SCMP_SYS (quotactl), EPERM},\n\n    /* Don't allow access to the kernel keyring */\n    {SCMP_SYS (add_key), EPERM},\n    {SCMP_SYS (keyctl), EPERM},\n    {SCMP_SYS (request_key), EPERM},\n\n    /* Scary VM/NUMA ops */\n    {SCMP_SYS (move_pages), EPERM},\n    {SCMP_SYS (mbind), EPERM},\n    {SCMP_SYS (get_mempolicy), EPERM},\n    {SCMP_SYS (set_mempolicy), EPERM},\n    {SCMP_SYS (migrate_pages), EPERM},\n\n    /* Don't allow subnamespace setups: */\n    {SCMP_SYS (unshare), EPERM},\n    {SCMP_SYS (mount), EPERM},\n    {SCMP_SYS (pivot_root), EPERM},\n#if defined(__s390__) || defined(__s390x__) || defined(__CRIS__)\n    /* Architectures with CONFIG_CLONE_BACKWARDS2: the child stack\n     * and flags arguments are reversed so the flags come second */\n    {SCMP_SYS (clone), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#else\n    /* Normally the flags come first */\n    {SCMP_SYS (clone), EPERM, &SCMP_A0 (SCMP_CMP_MASKED_EQ, CLONE_NEWUSER, CLONE_NEWUSER)},\n#endif\n\n    /* Don't allow faking input to the controlling tty (CVE-2017-5226) */\n    {SCMP_SYS (ioctl), EPERM, &SCMP_A1 (SCMP_CMP_MASKED_EQ, 0xFFFFFFFFu, (int) TIOCSTI)},\n  };\n\n  struct\n  {\n    int                  scall;\n    int                  errnum;\n    struct scmp_arg_cmp *arg;\n  } syscall_nondevel_blocklist[] = {\n    /* Profiling operations; we expect these to be done by tools from outside\n     * the sandbox.  In particular perf has been the source of many CVEs.\n     */\n    {SCMP_SYS (perf_event_open), EPERM},\n    /* Don't allow you to switch to bsd emulation or whatnot */\n    {SCMP_SYS (personality), EPERM, &SCMP_A0 (SCMP_CMP_NE, allowed_personality)},\n    {SCMP_SYS (ptrace), EPERM}\n  };\n  /* Blocklist all but unix, inet, inet6 and netlink */\n  struct\n  {\n    int             family;\n    FlatpakRunFlags flags_mask;\n  } socket_family_allowlist[] = {\n    /* NOTE: Keep in numerical order */\n    { AF_UNSPEC, 0 },\n    { AF_LOCAL, 0 },\n    { AF_INET, 0 },\n    { AF_INET6, 0 },\n    { AF_NETLINK, 0 },\n    { AF_CAN, FLATPAK_RUN_FLAG_CANBUS },\n    { AF_BLUETOOTH, FLATPAK_RUN_FLAG_BLUETOOTH },\n  };\n  int last_allowed_family;\n  int i, r;\n  g_auto(GLnxTmpfile) seccomp_tmpf  = { 0, };\n\n  seccomp = seccomp_init (SCMP_ACT_ALLOW);\n  if (!seccomp)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Initialize seccomp failed\"));\n\n  if (arch != NULL)\n    {\n      uint32_t arch_id = 0;\n      const uint32_t *extra_arches = NULL;\n\n      if (strcmp (arch, \"i386\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86;\n        }\n      else if (strcmp (arch, \"x86_64\") == 0)\n        {\n          arch_id = SCMP_ARCH_X86_64;\n          extra_arches = seccomp_x86_64_extra_arches;\n        }\n      else if (strcmp (arch, \"arm\") == 0)\n        {\n          arch_id = SCMP_ARCH_ARM;\n        }\n#ifdef SCMP_ARCH_AARCH64\n      else if (strcmp (arch, \"aarch64\") == 0)\n        {\n          arch_id = SCMP_ARCH_AARCH64;\n          extra_arches = seccomp_aarch64_extra_arches;\n        }\n#endif\n\n      /* We only really need to handle arches on multiarch systems.\n       * If only one arch is supported the default is fine */\n      if (arch_id != 0)\n        {\n          /* This *adds* the target arch, instead of replacing the\n             native one. This is not ideal, because we'd like to only\n             allow the target arch, but we can't really disallow the\n             native arch at this point, because then bubblewrap\n             couldn't continue running. */\n          r = seccomp_arch_add (seccomp, arch_id);\n          if (r < 0 && r != -EEXIST)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add architecture to seccomp filter\"));\n\n          if (multiarch && extra_arches != NULL)\n            {\n              for (i = 0; extra_arches[i] != 0; i++)\n                {\n                  r = seccomp_arch_add (seccomp, extra_arches[i]);\n                  if (r < 0 && r != -EEXIST)\n                    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to add multiarch architecture to seccomp filter\"));\n                }\n            }\n        }\n    }\n\n  /* TODO: Should we filter the kernel keyring syscalls in some way?\n   * We do want them to be used by desktop apps, but they could also perhaps\n   * leak system stuff or secrets from other apps.\n   */\n\n  for (i = 0; i < G_N_ELEMENTS (syscall_blocklist); i++)\n    {\n      int scall = syscall_blocklist[i].scall;\n      int errnum = syscall_blocklist[i].errnum;\n\n      g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n      if (syscall_blocklist[i].arg)\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_blocklist[i].arg);\n      else\n        r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n      if (r < 0 && r == -EFAULT /* unknown syscall */)\n        return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n    }\n\n  if (!devel)\n    {\n      for (i = 0; i < G_N_ELEMENTS (syscall_nondevel_blocklist); i++)\n        {\n          int scall = syscall_nondevel_blocklist[i].scall;\n          int errnum = syscall_nondevel_blocklist[i].errnum;\n\n          g_return_val_if_fail (errnum == EPERM || errnum == ENOSYS, FALSE);\n\n          if (syscall_nondevel_blocklist[i].arg)\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 1, *syscall_nondevel_blocklist[i].arg);\n          else\n            r = seccomp_rule_add (seccomp, SCMP_ACT_ERRNO (errnum), scall, 0);\n\n          if (r < 0 && r == -EFAULT /* unknown syscall */)\n            return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to block syscall %d\"), scall);\n        }\n    }\n\n  /* Socket filtering doesn't work on e.g. i386, so ignore failures here\n   * However, we need to user seccomp_rule_add_exact to avoid libseccomp doing\n   * something else: https://github.com/seccomp/libseccomp/issues/8 */\n  last_allowed_family = -1;\n  for (i = 0; i < G_N_ELEMENTS (socket_family_allowlist); i++)\n    {\n      int family = socket_family_allowlist[i].family;\n      int disallowed;\n\n      if (socket_family_allowlist[i].flags_mask != 0 &&\n          (socket_family_allowlist[i].flags_mask & run_flags) != socket_family_allowlist[i].flags_mask)\n        continue;\n\n      for (disallowed = last_allowed_family + 1; disallowed < family; disallowed++)\n        {\n          /* Blocklist the in-between valid families */\n          seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_EQ, disallowed));\n        }\n      last_allowed_family = family;\n    }\n  /* Blocklist the rest */\n  seccomp_rule_add_exact (seccomp, SCMP_ACT_ERRNO (EAFNOSUPPORT), SCMP_SYS (socket), 1, SCMP_A0 (SCMP_CMP_GE, last_allowed_family + 1));\n\n  if (!glnx_open_anonymous_tmpfile_full (O_RDWR | O_CLOEXEC, \"/tmp\", &seccomp_tmpf, error))\n    return FALSE;\n\n  if (seccomp_export_bpf (seccomp, seccomp_tmpf.fd) != 0)\n    return flatpak_fail_error (error, FLATPAK_ERROR_SETUP_FAILED, _(\"Failed to export bpf\"));\n\n  lseek (seccomp_tmpf.fd, 0, SEEK_SET);\n\n  flatpak_bwrap_add_args_data_fd (bwrap,\n                                  \"--seccomp\", glnx_steal_fd (&seccomp_tmpf.fd), NULL);\n\n  return TRUE;\n}",
        "commit_message": "run: Block clone3() in sandbox\n\nclone3() can be used to implement clone() with CLONE_NEWUSER, allowing\na sandboxed process to get CAP_SYS_ADMIN in a new namespace and\nmanipulate its root directory. We need to block this so that AF_UNIX-based\nsocket servers (X11, Wayland, etc.) can rely on\n/proc/PID/root/.flatpak-info existing for all Flatpak-sandboxed apps.\n\nPartially fixes GHSA-67h7-w3jq-vh4q.\n\nThanks: an anonymous reporter\nSigned-off-by: Simon McVittie <smcv@collabora.com>",
        "cve_desc": "Flatpak is a system for building, distributing, and running sandboxed desktop applications on Linux. In versions prior to 1.10.4 and 1.12.0, Flatpak apps with direct access to AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can trick portals and other host-OS services into treating the Flatpak app as though it was an ordinary, non-sandboxed host-OS process. They can do this by manipulating the VFS using recent mount-related syscalls that are not blocked by Flatpak's denylist seccomp filter, in order to substitute a crafted `/.flatpak-info` or make that file disappear entirely. Flatpak apps that act as clients for AF_UNIX sockets such as those used by Wayland, Pipewire or pipewire-pulse can escalate the privileges that the corresponding services will believe the Flatpak app has. Note that protocols that operate entirely over the D-Bus session bus (user bus), system bus or accessibility bus are not affected by this. This is due to the use of a proxy process `xdg-dbus-proxy`, whose VFS cannot be manipulated by the Flatpak app, when interacting with these buses. Patches exist for versions 1.10.4 and 1.12.0, and as of time of publication, a patch for version 1.8.2 is being planned. There are no workarounds aside from upgrading to a patched version.",
        "target": 1
      }
    ]
  },
  "fluent-bit": {
    "0": [],
    "1": []
  },
  "fontforge": {
    "0": [],
    "1": []
  },
  "gd-libgd": {
    "0": [],
    "1": []
  },
  "gegl": {
    "0": [
      {
        "idx": 421835,
        "reasoning": "This code addresses a potential integer overflow vulnerability by explicitly limiting the maximum allocated memory to 2GB via `MAX_PPM_SIZE`. The added check `MAX_PPM_SIZE / img->width / img->height / CHANNEL_COUNT < img->bpc` prevents allocation of excessively large buffers that could lead to a denial-of-service or potentially exploitable memory exhaustion.\n\n\n\n",
        "func": "ppm_load_read_header(FILE       *fp,\n                     pnm_struct *img)\n{\n    /* PPM Headers Variable Declaration */\n    gchar *ptr;\n    //gchar *retval;\n    gchar  header[MAX_CHARS_IN_ROW];\n    gint   maxval;\n    int    channel_count;\n\n    /* Check the PPM file Type P3 or P6 */\n    if (fgets (header, MAX_CHARS_IN_ROW, fp) == NULL ||\n        header[0] != ASCII_P ||\n        (header[1] != PIXMAP_ASCII_GRAY &&\n         header[1] != PIXMAP_ASCII &&\n         header[1] != PIXMAP_RAW_GRAY &&\n         header[1] != PIXMAP_RAW))\n      {\n        g_warning (\"Image is not a portable pixmap\");\n        return FALSE;\n      }\n\n    img->type = header[1];\n\n    if (img->type == PIXMAP_RAW_GRAY || img->type == PIXMAP_ASCII_GRAY)\n      channel_count = CHANNEL_COUNT_GRAY;\n    else\n      channel_count = CHANNEL_COUNT;\n\n    /* Check the Comments */\n    while((fgets (header, MAX_CHARS_IN_ROW, fp)) && (header[0] == '#'))\n      ;\n\n    /* Get Width and Height */\n    errno = 0;\n\n    img->width = strtol (header, &ptr, 10);\n    if (errno)\n      {\n        g_warning (\"Error reading width: %s\", strerror(errno));\n        return FALSE;\n      }\n    else if (img->width < 0)\n      {\n        g_warning (\"Error: width is negative\");\n        return FALSE;\n      }\n\n    img->height = strtol (ptr, &ptr, 10);\n    if (errno)\n      {\n        g_warning (\"Error reading height: %s\", strerror(errno));\n        return FALSE;\n      }\n    else if (img->width < 0)\n      {\n        g_warning (\"Error: height is negative\");\n        return FALSE;\n      }\n\n    if (fgets (header, MAX_CHARS_IN_ROW, fp))\n      maxval = strtol (header, &ptr, 10);\n    else\n      maxval = 0;\n\n    if ((maxval != 255) && (maxval != 65535))\n      {\n        g_warning (\"Image is not an 8-bit or 16-bit portable pixmap\");\n        return FALSE;\n      }\n\n  switch (maxval)\n    {\n    case 255:\n      img->bpc = sizeof (guchar);\n      break;\n\n    case 65535:\n      img->bpc = sizeof (gushort);\n      break;\n\n    default:\n      g_warning (\"%s: Programmer stupidity error\", G_STRLOC);\n    }\n\n    /* Later on, img->numsamples is multiplied with img->bpc to allocate\n     * memory. Ensure it doesn't overflow. G_MAXSIZE might have been\n       good enough on 32bit, for now lets just fail if the size is beyond\n       2GB\n     */\n#define MAX_PPM_SIZE (1<<31)\n\n    if (!img->width || !img->height ||\n        MAX_PPM_SIZE / img->width / img->height / CHANNEL_COUNT < img->bpc)\n      {\n        g_warning (\"Illegal width/height: %ld/%ld\", img->width, img->height);\n        return FALSE;\n      }\n\n    img->channels = channel_count;\n    img->numsamples = img->width * img->height * channel_count;\n\n    return TRUE;\n}",
        "commit_message": "ppm-load: limit max permitted buffer allocation to 2GB\n\nFixing bug #795248",
        "cve_desc": "An issue was discovered in GEGL through 0.3.32. The gegl_buffer_iterate_read_simple function in buffer/gegl-buffer-access.c allows remote attackers to cause a denial of service (write access violation) or possibly have unspecified other impact via a malformed PPM file, related to improper restrictions on memory allocation in the ppm_load_read_header function in operations/external/ppm-load.c.",
        "target": 0
      }
    ],
    "1": []
  },
  "ghostpdl": {
    "0": [
      {
        "idx": 279445,
        "reasoning": "This code snippet appears to be part of a device driver initialization and parameter handling function, specifically retrieving parameters for a printer device. The provided information states the commit fixed a buffer expansion issue in a *different* function (`lxm5700m_print_page()`) and this snippet doesn't show any obvious memory management or input validation flaws that would indicate a vulnerability.\n\n\n\n",
        "func": " * I've copied my routines from gdevcdj.c\n */\n\nstatic int\nlxm_get_params(gx_device *pdev, gs_param_list *plist)\n{\n    lxm_device* const ldev = (lxm_device*)pdev;\n    int code = gdev_prn_get_params(pdev, plist);\n\n    if ( code < 0 ) return code;\n    code = param_write_int(plist,\n                           \"HeadSeparation\",",
        "commit_message": "Bug 701827: fixed incorrect buffer expansion in lxm5700m_print_page().\n\nFixes:\n    ./sanbin/gs -dBATCH -dNOPAUSE -r425 -dFitPage -sOutputFile=tmp -sDEVICE=lxm5700m ../bug-701827.eps",
        "cve_desc": "A buffer overflow vulnerability in lxm5700m_print_page() in devices/gdevlxm.c of Artifex Software GhostScript v9.50 allows a remote attacker to cause a denial of service via a crafted eps file. This is fixed in v9.51.",
        "target": 0
      }
    ],
    "1": []
  },
  "gilcc": {
    "0": [],
    "1": []
  },
  "git": {
    "0": [],
    "1": []
  },
  "glibc": {
    "0": [],
    "1": []
  },
  "gnulib": {
    "0": [],
    "1": []
  },
  "gnumeric": {
    "0": [],
    "1": []
  },
  "gnuplot": {
    "0": [],
    "1": []
  },
  "gnutls": {
    "0": [],
    "1": [
      {
        "idx": 201856,
        "reasoning": "This code is vulnerable because it allocates memory for the certificate serial number (`cserial`) based on the size reported in the OCSP response (`rserial.size`) without validating that this size is reasonable or expected for a serial number. This can lead to a buffer being allocated that is larger than the actual serial number, potentially allowing crafted OCSP responses to bypass certificate validation due to trailing bytes left over from `gnutls_malloc` as described in the CVE.",
        "func": "gnutls_ocsp_resp_check_crt(gnutls_ocsp_resp_t resp,\n\t\t\t   unsigned int indx, gnutls_x509_crt_t crt)\n{\n\tint ret;\n\tgnutls_digest_algorithm_t digest;\n\tgnutls_datum_t rdn_hash = { NULL, 0 }, rserial = {\n\tNULL, 0};\n\tgnutls_datum_t cserial = { NULL, 0 };\n\tgnutls_datum_t dn = { NULL, 0 };\n\tuint8_t cdn_hash[MAX_HASH_SIZE];\n\tsize_t t, hash_len;\n\n\tret =\n\t    gnutls_ocsp_resp_get_single(resp, indx, &digest, &rdn_hash,\n\t\t\t\t\tNULL, &rserial, NULL, NULL, NULL,\n\t\t\t\t\tNULL, NULL);\n\tif (ret < 0)\n\t\treturn gnutls_assert_val(ret);\n\n\tif (rserial.size == 0 || digest == GNUTLS_DIG_UNKNOWN) {\n\t\tret = gnutls_assert_val(GNUTLS_E_OCSP_RESPONSE_ERROR);\n\t\tgoto cleanup;\n\t}\n\n\thash_len = _gnutls_hash_get_algo_len(hash_to_entry(digest));\n\tif (hash_len != rdn_hash.size) {\n\t\tret = gnutls_assert_val(GNUTLS_E_OCSP_RESPONSE_ERROR);\n\t\tgoto cleanup;\n\t}\n\n\tcserial.size = rserial.size;\n\tcserial.data = gnutls_malloc(cserial.size);\n\tif (cserial.data == NULL) {\n\t\tret = gnutls_assert_val(GNUTLS_E_MEMORY_ERROR);\n\t\tgoto cleanup;\n\t}\n\n\tt = cserial.size;\n\tret = gnutls_x509_crt_get_serial(crt, cserial.data, &t);\n\tif (ret < 0) {\n\t\tgnutls_assert();\n\t\tgoto cleanup;\n\t}\n\n\tif (rserial.size != cserial.size\n\t    || memcmp(cserial.data, rserial.data, rserial.size) != 0) {\n\t\tret = GNUTLS_E_OCSP_RESPONSE_ERROR;\n\t\tgnutls_assert();\n\t\tgoto cleanup;\n\t}\n\n\tret = gnutls_x509_crt_get_raw_issuer_dn(crt, &dn);\n\tif (ret < 0) {\n\t\tgnutls_assert();\n\t\tgoto cleanup;\n\t}\n\n\tret = _gnutls_hash_fast(digest, dn.data, dn.size, cdn_hash);\n\tif (ret < 0) {\n\t\tgnutls_assert();\n\t\tgoto cleanup;\n\t}\n\n\tif (memcmp(cdn_hash, rdn_hash.data, hash_len) != 0) {\n\t\tret = GNUTLS_E_OCSP_RESPONSE_ERROR;\n\t\tgnutls_assert();\n\t\tgoto cleanup;\n\t}\n\n\tret = 0;\n\n      cleanup:\n\tgnutls_free(rdn_hash.data);\n\tgnutls_free(rserial.data);\n\tgnutls_free(cserial.data);\n\tgnutls_free(dn.data);\n\n\treturn ret;\n}",
        "commit_message": "ocsp: corrected the comparison of the serial size in OCSP response\n\nPreviously the OCSP certificate check wouldn't verify the serial length\nand could succeed in cases it shouldn't.\n\nReported by Stefan Buehler.",
        "cve_desc": "The gnutls_ocsp_resp_check_crt function in lib/x509/ocsp.c in GnuTLS before 3.4.15 and 3.5.x before 3.5.4 does not verify the serial length of an OCSP response, which might allow remote attackers to bypass an intended certificate validation mechanism via vectors involving trailing bytes left by gnutls_malloc.",
        "target": 1
      },
      {
        "idx": 202128,
        "reasoning": "The vulnerability lies in how `_gnutls_mpi_print` is used with `MAX_MPI_BYTES` without proper bounds checking, potentially writing beyond the allocated `p` buffer on the stack, leading to a stack-based buffer overflow. This overflow occurs when processing RSA public keys with a specific version, as the code attempts to extract 8 bytes from the potentially larger MPI representation into the fixed-size `p` array.",
        "func": "u32 cdk_pk_get_keyid(cdk_pubkey_t pk, u32 * keyid)\n{\n\tu32 lowbits = 0;\n\tbyte buf[24];\n\n\tif (pk && (!pk->keyid[0] || !pk->keyid[1])) {\n\t\tif (pk->version < 4 && is_RSA(pk->pubkey_algo)) {\n\t\t\tbyte p[MAX_MPI_BYTES];\n\t\t\tsize_t n;\n\n\t\t\tn = MAX_MPI_BYTES;\n\t\t\t_gnutls_mpi_print(pk->mpi[0], p, &n);\n\t\t\tpk->keyid[0] =\n\t\t\t    p[n - 8] << 24 | p[n - 7] << 16 | p[n -\n\t\t\t\t\t\t\t\t6] << 8 |\n\t\t\t    p[n - 5];\n\t\t\tpk->keyid[1] =\n\t\t\t    p[n - 4] << 24 | p[n - 3] << 16 | p[n -\n\t\t\t\t\t\t\t\t2] << 8 |\n\t\t\t    p[n - 1];\n\t\t} else if (pk->version == 4) {\n\t\t\tcdk_pk_get_fingerprint(pk, buf);\n\t\t\tpk->keyid[0] = _cdk_buftou32(buf + 12);\n\t\t\tpk->keyid[1] = _cdk_buftou32(buf + 16);\n\t\t}\n\t}\n\tlowbits = pk ? pk->keyid[1] : 0;\n\tif (keyid && pk) {\n\t\tkeyid[0] = pk->keyid[0];\n\t\tkeyid[1] = pk->keyid[1];\n\t}\n\n\treturn lowbits;\n}",
        "commit_message": "opencdk: cdk_pk_get_keyid: fix stack overflow\n\nIssue found using oss-fuzz:\n  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=340\n\nSigned-off-by: Nikos Mavrogiannopoulos <nmav@redhat.com>",
        "cve_desc": "Stack-based buffer overflow in the cdk_pk_get_keyid function in lib/opencdk/pubkey.c in GnuTLS before 3.3.26 and 3.5.x before 3.5.8 allows remote attackers to have unspecified impact via a crafted OpenPGP certificate.",
        "target": 1
      },
      {
        "idx": 202606,
        "reasoning": "This code is vulnerable to a use-after-free because the `extdata` buffer, used to accumulate key share data, might be reallocated during the loop generating key shares, invalidating previously written data. Specifically, `client_gen_key_share` or `server_gen_key_share` could potentially trigger a reallocation of `extdata`, and the code later accesses the buffer based on `cur_length` which would be based on the old buffer size, leading to a use-after-free.",
        "func": "key_share_send_params(gnutls_session_t session,\n\t\t      gnutls_buffer_st * extdata)\n{\n\tunsigned i;\n\tint ret;\n\tunsigned char *lengthp;\n\tunsigned int cur_length;\n\tunsigned int generated = 0;\n\tconst gnutls_group_entry_st *group;\n\tconst version_entry_st *ver;\n\n\t/* this extension is only being sent on client side */\n\tif (session->security_parameters.entity == GNUTLS_CLIENT) {\n\t\tver = _gnutls_version_max(session);\n\t\tif (unlikely(ver == NULL || ver->key_shares == 0))\n\t\t\treturn 0;\n\n\t\tif (!have_creds_for_tls13(session))\n\t\t\treturn 0;\n\n\t\t/* write the total length later */\n\t\tlengthp = &extdata->data[extdata->length];\n\n\t\tret =\n\t\t    _gnutls_buffer_append_prefix(extdata, 16, 0);\n\t\tif (ret < 0)\n\t\t\treturn gnutls_assert_val(ret);\n\n\t\tcur_length = extdata->length;\n\n\t\tif (session->internals.hsk_flags & HSK_HRR_RECEIVED) { /* we know the group */\n\t\t\tgroup = get_group(session);\n\t\t\tif (unlikely(group == NULL))\n\t\t\t\treturn gnutls_assert_val(GNUTLS_E_RECEIVED_ILLEGAL_PARAMETER);\n\n\t\t\tret = client_gen_key_share(session, group, extdata);\n\t\t\tif (ret == GNUTLS_E_INT_RET_0)\n\t\t\t\treturn gnutls_assert_val(GNUTLS_E_NO_COMMON_KEY_SHARE);\n\t\t\tif (ret < 0)\n\t\t\t\treturn gnutls_assert_val(ret);\n\t\t} else {\n\t\t\tgnutls_pk_algorithm_t selected_groups[3];\n\t\t\tunsigned max_groups = 2; /* GNUTLS_KEY_SHARE_TOP2 */\n\n\t\t\tif (session->internals.flags & GNUTLS_KEY_SHARE_TOP)\n\t\t\t\tmax_groups = 1;\n\t\t\telse if (session->internals.flags & GNUTLS_KEY_SHARE_TOP3)\n\t\t\t\tmax_groups = 3;\n\n\t\t\tassert(max_groups <= sizeof(selected_groups)/sizeof(selected_groups[0]));\n\n\t\t\t/* generate key shares for out top-(max_groups) groups\n\t\t\t * if they are of different PK type. */\n\t\t\tfor (i = 0; i < session->internals.priorities->groups.size; i++) {\n\t\t\t\tgroup = session->internals.priorities->groups.entry[i];\n\n\t\t\t\tif (generated == 1 && group->pk == selected_groups[0])\n\t\t\t\t\tcontinue;\n\t\t\t\telse if (generated == 2 && (group->pk == selected_groups[1] || group->pk == selected_groups[0]))\n\t\t\t\t\tcontinue;\n\n\t\t\t\tselected_groups[generated] = group->pk;\n\n\t\t\t\tret = client_gen_key_share(session, group, extdata);\n\t\t\t\tif (ret == GNUTLS_E_INT_RET_0)\n\t\t\t\t\tcontinue; /* no key share for this algorithm */\n\t\t\t\tif (ret < 0)\n\t\t\t\t\treturn gnutls_assert_val(ret);\n\n\t\t\t\tgenerated++;\n\n\t\t\t\tif (generated >= max_groups)\n\t\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\t/* copy actual length */\n\t\t_gnutls_write_uint16(extdata->length - cur_length, lengthp);\n\n\t} else { /* server */\n\t\tver = get_version(session);\n\t\tif (unlikely(ver == NULL || ver->key_shares == 0))\n\t\t\treturn gnutls_assert_val(0);\n\n\t\tif (_gnutls_ext_get_msg(session) == GNUTLS_EXT_FLAG_HRR) {\n\t\t\tgroup = session->internals.cand_group;\n\n\t\t\tif (group == NULL)\n\t\t\t\treturn gnutls_assert_val(GNUTLS_E_NO_COMMON_KEY_SHARE);\n\n\t\t\t_gnutls_session_group_set(session, group);\n\n\t\t\t_gnutls_handshake_log(\"EXT[%p]: requesting retry with group %s\\n\", session, group->name);\n\t\t\tret =\n\t\t\t    _gnutls_buffer_append_prefix(extdata, 16, group->tls_id);\n\t\t\tif (ret < 0)\n\t\t\t\treturn gnutls_assert_val(ret);\n\t\t} else {\n\t\t\t/* if we are negotiating PSK without DH, do not send a key share */\n\t\t\tif ((session->internals.hsk_flags & HSK_PSK_SELECTED) &&\n\t\t\t    (session->internals.hsk_flags & HSK_PSK_KE_MODE_PSK))\n\t\t\t\treturn gnutls_assert_val(0);\n\n\t\t\tgroup = get_group(session);\n\t\t\tif (unlikely(group == NULL))\n\t\t\t\treturn gnutls_assert_val(GNUTLS_E_RECEIVED_ILLEGAL_PARAMETER);\n\n\t\t\tret = server_gen_key_share(session, group, extdata);\n\t\t\tif (ret < 0)\n\t\t\t\treturn gnutls_assert_val(ret);\n\t\t}\n\n\t\tsession->internals.hsk_flags |= HSK_KEY_SHARE_SENT;\n\t}\n\n\treturn 0;\n}",
        "commit_message": "key_share: avoid use-after-free around realloc\n\nSigned-off-by: Daiki Ueno <ueno@gnu.org>",
        "cve_desc": "A flaw was found in gnutls. A use after free issue in client sending key_share extension may lead to memory corruption and other consequences.",
        "target": 1
      },
      {
        "idx": 204813,
        "reasoning": "The code is vulnerable due to a potential uninitialized pointer access within the `hsk` variable, specifically `hsk.header` and `hsk.data.data`, before they are used in `_gnutls_buffer_append_data` calls within the `GNUTLS_HANDSHAKE_CERTIFICATE_REQUEST` case.  The commit message and CVE description indicate this can occur with certain post-handshake messages, leading to a crash or potentially exploitable behavior if these pointers haven't been properly initialized by `_gnutls_handshake_io_recv_int`.",
        "func": "_gnutls13_recv_async_handshake(gnutls_session_t session)\n{\n\tint ret;\n\thandshake_buffer_st hsk;\n\trecv_state_t next_state = RECV_STATE_0;\n\n\t/* The following messages are expected asynchronously after\n\t * the handshake process is complete */\n\tif (unlikely(session->internals.handshake_in_progress))\n\t\treturn gnutls_assert_val(GNUTLS_E_UNEXPECTED_PACKET);\n\n\tdo {\n\t\t/* the received handshake message has already been pushed into\n\t\t * handshake buffers. As we do not need to use the handshake hash\n\t\t * buffers we call the lower level receive functions */\n\t\tret = _gnutls_handshake_io_recv_int(session, GNUTLS_HANDSHAKE_ANY, &hsk, 0);\n\t\tif (ret < 0) {\n\t\t\tgnutls_assert();\n\t\t\tgoto cleanup;\n\t\t}\n\t\tsession->internals.last_handshake_in = hsk.htype;\n\n\t\tret = _gnutls_call_hook_func(session, hsk.htype, GNUTLS_HOOK_PRE, 1,\n\t\t\t\t\t     hsk.data.data, hsk.data.length);\n\t\tif (ret < 0) {\n\t\t\tgnutls_assert();\n\t\t\tgoto cleanup;\n\t\t}\n\n\t\tswitch(hsk.htype) {\n\t\t\tcase GNUTLS_HANDSHAKE_CERTIFICATE_REQUEST:\n\t\t\t\tif (!(session->security_parameters.entity == GNUTLS_CLIENT) ||\n\t\t\t\t    !(session->internals.flags & GNUTLS_POST_HANDSHAKE_AUTH)) {\n\t\t\t\t\tret = gnutls_assert_val(GNUTLS_E_UNEXPECTED_PACKET);\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\t_gnutls_buffer_reset(&session->internals.reauth_buffer);\n\n\t\t\t\t/* include the handshake headers in reauth buffer */\n\t\t\t\tret = _gnutls_buffer_append_data(&session->internals.reauth_buffer,\n\t\t\t\t\t\t\t\t hsk.header, hsk.header_size);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tgnutls_assert();\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\tret = _gnutls_buffer_append_data(&session->internals.reauth_buffer,\n\t\t\t\t\t\t\t\t hsk.data.data, hsk.data.length);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tgnutls_assert();\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\tif (session->internals.flags & GNUTLS_AUTO_REAUTH) {\n\t\t\t\t\tret = gnutls_reauth(session, 0);\n\t\t\t\t\tif (ret == GNUTLS_E_AGAIN || ret == GNUTLS_E_INTERRUPTED) {\n\t\t\t\t\t\tnext_state = RECV_STATE_REAUTH;\n\t\t\t\t\t} else if (ret < 0) {\n\t\t\t\t\t\tgnutls_assert();\n\t\t\t\t\t\tgoto cleanup;\n\t\t\t\t\t}\n\t\t\t\t} else {\n\t\t\t\t\t/* Application is expected to handle re-authentication\n\t\t\t\t\t * explicitly.  */\n\t\t\t\t\tret = GNUTLS_E_REAUTH_REQUEST;\n\t\t\t\t}\n\n\t\t\t\tgoto cleanup;\n\n\t\t\tcase GNUTLS_HANDSHAKE_KEY_UPDATE:\n\t\t\t\tret = _gnutls13_recv_key_update(session, &hsk.data);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tgnutls_assert();\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\t/* Handshake messages MUST NOT span key changes, i.e., we\n\t\t\t\t * should not have any other pending handshake messages from\n\t\t\t\t * the same record. */\n\t\t\t\tif (session->internals.handshake_recv_buffer_size != 0) {\n\t\t\t\t\tret = gnutls_assert_val(GNUTLS_E_UNEXPECTED_PACKET);\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase GNUTLS_HANDSHAKE_NEW_SESSION_TICKET:\n\t\t\t\tif (session->security_parameters.entity != GNUTLS_CLIENT) {\n\t\t\t\t\tret = gnutls_assert_val(GNUTLS_E_UNEXPECTED_PACKET);\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\tret = _gnutls13_recv_session_ticket(session, &hsk.data);\n\t\t\t\tif (ret < 0) {\n\t\t\t\t\tgnutls_assert();\n\t\t\t\t\tgoto cleanup;\n\t\t\t\t}\n\n\t\t\t\tmemcpy(session->internals.tls13_ticket.resumption_master_secret,\n\t\t\t\t       session->key.proto.tls13.ap_rms,\n\t\t\t\t       session->key.proto.tls13.temp_secret_size);\n\n\t\t\t\tsession->internals.tls13_ticket.prf = session->security_parameters.prf;\n\t\t\t\tsession->internals.hsk_flags |= HSK_TICKET_RECEIVED;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tgnutls_assert();\n\t\t\t\tret = GNUTLS_E_UNEXPECTED_PACKET;\n\t\t\t\tgoto cleanup;\n\t\t}\n\n\t\tret = _gnutls_call_hook_func(session, hsk.htype, GNUTLS_HOOK_POST, 1, hsk.data.data, hsk.data.length);\n\t\tif (ret < 0) {\n\t\t\tgnutls_assert();\n\t\t\tgoto cleanup;\n\t\t}\n\t\t_gnutls_handshake_buffer_clear(&hsk);\n\n\t} while (_gnutls_record_buffer_get_size(session) > 0);\n\n\tsession->internals.recv_state = next_state;\n\n\treturn 0;\n\n cleanup:\n\t/* if we have pending/partial handshake data in buffers, ensure that\n\t * next read will read handshake data */\n\tif (_gnutls_record_buffer_get_size(session) > 0)\n\t\tsession->internals.recv_state = RECV_STATE_ASYNC_HANDSHAKE;\n\telse\n\t\tsession->internals.recv_state = next_state;\n\n\t_gnutls_handshake_buffer_clear(&hsk);\n\treturn ret;\n}",
        "commit_message": "handshake: add missing initialization of local variable\n\nResolves: #704\n\nSigned-off-by: Daiki Ueno <dueno@redhat.com>\nSigned-off-by: Nikos Mavrogiannopoulos <nmav@redhat.com>",
        "cve_desc": "It was discovered in gnutls before version 3.6.7 upstream that there is an uninitialized pointer access in gnutls versions 3.6.3 or later which can be triggered by certain post-handshake messages.",
        "target": 1
      }
    ]
  },
  "gpac": {
    "0": [
      {
        "idx": 73686,
        "reasoning": "This code is likely safe regarding heap overflows despite the commit message mentioning potential fixes elsewhere. The snippet itself reads a fixed-size u32 and then a null-terminated string, bounded by the box's size (`s->size`), preventing unbounded memory access\u2014a key factor in heap overflows. \n\n\n\n",
        "func": "GF_Err ainf_Read(GF_Box *s,GF_BitStream *bs)\n{\n\tGF_AssetInformationBox *ptr = (GF_AssetInformationBox *) s;\n\n\tISOM_DECREASE_SIZE(s, 4)\n\tptr->profile_version = gf_bs_read_u32(bs);\n\treturn gf_isom_read_null_terminated_string(s, bs, s->size, &ptr->APID);\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 0
      },
      {
        "idx": 73687,
        "reasoning": "This code is likely **not vulnerable** to a heap overflow despite the commit message suggesting potential overflows were addressed elsewhere. The `strlen` function is used to determine the length of `ptr->APID` *before* adding it to the size, preventing a write beyond the allocated buffer\u2014assuming `s->size` is appropriately managed in other parts of the code not shown here. \n\n\n\n",
        "func": "GF_Err ainf_Size(GF_Box *s)\n{\n\tGF_AssetInformationBox *ptr = (GF_AssetInformationBox *) s;\n\ts->size += 4 +  strlen(ptr->APID) + 1;\n\treturn GF_OK;\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 0
      },
      {
        "idx": 73688,
        "reasoning": "This code is likely safe regarding heap overflows despite the commit message mentioning potential fixes elsewhere. The `gf_bs_write_data` function writes a string (`ptr->APID`) to the bitstream, but crucially includes the length of the string (`strlen(ptr->APID) + 1`) in the write operation, preventing a buffer overflow by ensuring the correct number of bytes are written. \n\n\n\n",
        "func": "GF_Err ainf_Write(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_Err e;\n\tGF_AssetInformationBox *ptr = (GF_AssetInformationBox *) s;\n\n\te = gf_isom_full_box_write(s, bs);\n\tif (e) return e;\n\tgf_bs_write_u32(bs, ptr->profile_version);\n\tgf_bs_write_data(bs, ptr->APID, (u32) strlen(ptr->APID) + 1);\n\treturn GF_OK;\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 0
      },
      {
        "idx": 73689,
        "reasoning": "This code snippet is likely safe regarding heap overflows, despite the commit message mentioning fixes for them elsewhere. The function simply frees two pointers\u2014`ptr->APID` and `s`\u2014using `gf_free`, which suggests a custom memory management scheme; without knowing the implementation of `gf_free`, we can't definitively say there *is* a vulnerability *in this specific code*. \n\n\n\n",
        "func": "void ainf_del(GF_Box *s)\n{\n\tGF_AssetInformationBox *ptr = (GF_AssetInformationBox *) s;\n\tif (ptr->APID) gf_free(ptr->APID);\n\tgf_free(s);\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 0
      },
      {
        "idx": 73690,
        "reasoning": "This code is likely safe, as the commit message explicitly states it *fixed* two potential heap overflows, implying the vulnerabilities were addressed before this commit. The code then proceeds to handle various box types with specific assignments and checks, without obvious immediate risks of buffer overflows or other memory corruption issues in its current state.\n\n\n\n",
        "func": "GF_Err audio_sample_entry_AddBox(GF_Box *s, GF_Box *a)\n{\n\tGF_MPEGAudioSampleEntryBox *ptr = (GF_MPEGAudioSampleEntryBox *)s;\n\tswitch (a->type) {\n\tcase GF_ISOM_BOX_TYPE_ESDS:\n\t\tif (ptr->esd) ERROR_ON_DUPLICATED_BOX(a, ptr)\n\t\t\tptr->esd = (GF_ESDBox *)a;\n\t\tbreak;\n\tcase GF_ISOM_BOX_TYPE_SINF:\n\t\tgf_list_add(ptr->protections, a);\n\t\tbreak;\n\tcase GF_ISOM_BOX_TYPE_DAMR:\n\tcase GF_ISOM_BOX_TYPE_DEVC:\n\tcase GF_ISOM_BOX_TYPE_DQCP:\n\tcase GF_ISOM_BOX_TYPE_DSMV:\n\t\tptr->cfg_3gpp = (GF_3GPPConfigBox *) a;\n\t\t/*for 3GP config, remember sample entry type in config*/\n\t\tptr->cfg_3gpp->cfg.type = ptr->type;\n\t\tbreak;\n\n\tcase GF_ISOM_BOX_TYPE_DAC3:\n\t\tptr->cfg_ac3 = (GF_AC3ConfigBox *) a;\n\t\tbreak;\n\tcase GF_ISOM_BOX_TYPE_DEC3:\n\t\tptr->cfg_ac3 = (GF_AC3ConfigBox *) a;\n\t\tbreak;\n\n\tcase GF_ISOM_BOX_TYPE_UNKNOWN:\n\t\tif (ptr->esd) ERROR_ON_DUPLICATED_BOX(a, ptr)\n\t\t\t/*HACK for QT files: get the esds box from the track*/\n\t\t{\n\t\t\tGF_UnknownBox *wave = (GF_UnknownBox *)a;\n \t\t\tif ((wave->original_4cc == GF_ISOM_BOX_TYPE_WAVE) && gf_list_count(wave->other_boxes)) {\n \t\t\t\tu32 i;\n                for (i =0; i<gf_list_count(wave->other_boxes); i++) {\n                    GF_Box *inner_box = (GF_Box *)gf_list_get(wave->other_boxes, i);\n                    if (inner_box->type == GF_ISOM_BOX_TYPE_ESDS) {\n                        ptr->esd = (GF_ESDBox *)inner_box;\n                    }\n                }\n                return gf_isom_box_add_default(s, a);\n            }\n            else if (wave->data != NULL) {\n                u32 offset = 0;\n                while ((wave->data[offset + 4] != 'e') && (wave->data[offset + 5] != 's')) {\n                    offset++;\n                    if (offset == wave->dataSize) break;\n                }\n                if (offset < wave->dataSize) {\n                    GF_Box *a;\n                    GF_Err e;\n                    GF_BitStream *bs = gf_bs_new(wave->data + offset, wave->dataSize - offset, GF_BITSTREAM_READ);\n                    e = gf_isom_box_parse(&a, bs);\n                    gf_bs_del(bs);\n                    if (e) return e;\n                    ptr->esd = (GF_ESDBox *)a;\n                    gf_isom_box_add_for_dump_mode((GF_Box *)ptr, a);\n\n                }\n\t\t\t\tGF_LOG(GF_LOG_WARNING, GF_LOG_CONTAINER, (\"[iso file] Cannot process box %s!\\n\", gf_4cc_to_str(wave->original_4cc)));\n\t\t\t\treturn gf_isom_box_add_default(s, a);\n\t\t\t}\n\t\t\tgf_isom_box_del(a);\n\t\t\treturn GF_ISOM_INVALID_MEDIA;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\treturn gf_isom_box_add_default(s, a);\n\t}\n\treturn GF_OK;\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3662,
        "reasoning": "The code is vulnerable to a heap-based buffer over-read because it directly uses `p->nameUTF8` and `p->nameUTF8+1` in `fprintf` without validating the size of the UTF-8 string, potentially reading beyond the allocated buffer. Specifically, the condition `(u32) p->nameUTF8[0] == strlen(p->nameUTF8+1)` attempts to check string length but is flawed and doesn't prevent accessing memory outside the bounds of `p->nameUTF8` when the UTF-8 string is malformed or unexpectedly short.",
        "func": "GF_Err hdlr_dump(GF_Box *a, FILE * trace)\n {\n \tGF_HandlerBox *p = (GF_HandlerBox *)a;\n \tgf_isom_box_dump_start(a, \"HandlerBox\", trace);\n\tif (p->nameUTF8 && (u32) p->nameUTF8[0] == strlen(p->nameUTF8+1)) {\n \t\tfprintf(trace, \"hdlrType=\\\"%s\\\" Name=\\\"%s\\\" \", gf_4cc_to_str(p->handlerType), p->nameUTF8+1);\n \t} else {\n \t\tfprintf(trace, \"hdlrType=\\\"%s\\\" Name=\\\"%s\\\" \", gf_4cc_to_str(p->handlerType), p->nameUTF8);\n\t}\n\tfprintf(trace, \"reserved1=\\\"%d\\\" reserved2=\\\"\", p->reserved1);\n\tdump_data(trace, (char *) p->reserved2, 12);\n\tfprintf(trace, \"\\\"\");\n\n\tfprintf(trace, \">\\n\");\n\tgf_isom_box_dump_done(\"HandlerBox\", a, trace);\n\treturn GF_OK;\n}\n",
        "commit_message": "fixed 2 possible heap overflows (inc. #1088)",
        "cve_desc": "An issue was discovered in MP4Box in GPAC 0.7.1. There is a heap-based buffer over-read in the isomedia/box_dump.c function hdlr_dump.",
        "target": 1
      },
      {
        "idx": 4077,
        "reasoning": "This code is vulnerable to a buffer overflow because the `sprintf` function doesn't perform bounds checking when copying characters from `string` into the `szV` buffer, potentially writing beyond its 5-byte capacity. This overflow can occur if `string[j]` and `string[j+1]` are not valid hexadecimal characters, leading to an uncontrolled format string and subsequent write, as exploited in crafted files like `drm_file.xml`.",
        "func": "GF_Err gf_bin128_parse(const char *string, bin128 value)\n{\n\tu32 len;\n\tu32\ti=0;\n\tif (!strnicmp(string, \"0x\", 2)) string += 2;\n\tlen = (u32) strlen(string);\n\tif (len >= 32) {\n\t\tu32 j;\n\t\tfor (j=0; j<len; j+=2) {\n\t\t\tu32 v;\n\t\t\tchar szV[5];\n\n\t\t\twhile (string[j] && !isalnum(string[j]))\n\t\t\t\tj++;\n\t\t\tif (!string[j])\n\t\t\t\tbreak;\n\t\t\tsprintf(szV, \"%c%c\", string[j], string[j+1]);\n \t\t\tsscanf(szV, \"%x\", &v);\n \t\t\tvalue[i] = v;\n \t\t\ti++;\n \t\t}\n \t}\n \tif (i != 16) {\n\t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CORE, (\"[CORE] 128bit blob is not 16-bytes long: %s\\n\", string));\n\t\treturn GF_BAD_PARAM;\n\t}\n\treturn GF_OK;\n}\n",
        "commit_message": "None",
        "cve_desc": "gf_bin128_parse in utils/os_divers.c in GPAC 0.7.1 has a buffer overflow issue for the crypt feature when encountering a crafted_drm_file.xml file.",
        "target": 1
      },
      {
        "idx": 4118,
        "reasoning": "This code is vulnerable to a memory leak because if `gf_isom_box_array_read` fails, the function returns early without initializing the `dref` member of the `GF_DataInformationBox`. Consequently, if a `dref` box is missing and `gf_isom_box_array_read` fails, a new `GF_DataReferenceBox` is allocated but never freed if the function is called again with similar invalid input, leading to a memory leak.",
        "func": "GF_Err dinf_Read(GF_Box *s, GF_BitStream *bs)\n{\n\tGF_Err e = gf_isom_box_array_read(s, bs, dinf_AddBox);\n\tif (e) {\n \t\treturn e;\n \t}\n \tif (!((GF_DataInformationBox *)s)->dref) {\n \t\tGF_LOG(GF_LOG_ERROR, GF_LOG_CONTAINER, (\"[iso file] Missing dref box in dinf\\n\"));\n\t\t((GF_DataInformationBox *)s)->dref = (GF_DataReferenceBox *)gf_isom_box_new(GF_ISOM_BOX_TYPE_DREF);\n \t}\n \treturn GF_OK;\n }\n",
        "commit_message": "prevent dref memleak on invalid input (#1183)",
        "cve_desc": "GPAC 0.7.1 has a memory leak in dinf_Read in isomedia/box_code_base.c.",
        "target": 1
      },
      {
        "idx": 4143,
        "reasoning": "This code is vulnerable to buffer overflows due to the repeated use of `strcpy`. `strcpy` copies data without bounds checking, meaning if `fileName` or any substring extracted from it (like in `szRad1` or `szRad2`) is larger than the allocated buffer size of `cat_enum.szPath`, `cat_enum.szRad1`, `cat_enum.szRad2` or `cat_enum.szOpt`, it will write past the end of the buffer, leading to a potential crash or arbitrary code execution \u2013 similar to the buffer overflow described in the provided CVE.",
        "func": "GF_Err cat_multiple_files(GF_ISOFile *dest, char *fileName, u32 import_flags, Double force_fps, u32 frames_per_sample, char *tmp_dir, Bool force_cat, Bool align_timelines, Bool allow_add_in_command)\n{\n\tCATEnum cat_enum;\n\tchar *sep;\n\n\tcat_enum.dest = dest;\n\tcat_enum.import_flags = import_flags;\n\tcat_enum.force_fps = force_fps;\n\tcat_enum.frames_per_sample = frames_per_sample;\n\tcat_enum.tmp_dir = tmp_dir;\n\tcat_enum.force_cat = force_cat;\n \tcat_enum.align_timelines = align_timelines;\n \tcat_enum.allow_add_in_command = allow_add_in_command;\n \n \tstrcpy(cat_enum.szPath, fileName);\n \tsep = strrchr(cat_enum.szPath, GF_PATH_SEPARATOR);\n \tif (!sep) sep = strrchr(cat_enum.szPath, '/');\n \tif (!sep) {\n \t\tstrcpy(cat_enum.szPath, \".\");\n \t\tstrcpy(cat_enum.szRad1, fileName);\n \t} else {\n \t\tstrcpy(cat_enum.szRad1, sep+1);\n \t\tsep[0] = 0;\n \t}\n \tsep = strchr(cat_enum.szRad1, '*');\n \tstrcpy(cat_enum.szRad2, sep+1);\n \tsep[0] = 0;\n \tsep = strchr(cat_enum.szRad2, '%');\n \tif (!sep) sep = strchr(cat_enum.szRad2, '#');\n \tif (!sep) sep = strchr(cat_enum.szRad2, ':');\n \tstrcpy(cat_enum.szOpt, \"\");\n \tif (sep) {\n \t\tstrcpy(cat_enum.szOpt, sep);\n \t\tsep[0] = 0;\n \t}\n\treturn gf_enum_directory(cat_enum.szPath, 0, cat_enumerate, &cat_enum, NULL);\n}\n",
        "commit_message": "fix some overflows due to strcpy\n\nfixes #1184, #1186, #1187 among other things",
        "cve_desc": "GPAC version 0.7.1 and earlier has a Buffer Overflow vulnerability in the gf_sm_load_init function in scene_manager.c in libgpac_static.a.",
        "target": 1
      }
    ]
  },
  "graphviz": {
    "0": [
      {
        "idx": 507424,
        "reasoning": "This code snippet is not directly related to the described vulnerability of an out-of-bounds write during label parsing. The provided code focuses on determining if a point is inside a polygon, and there's no apparent memory manipulation or string handling that would be susceptible to the described issue with the \"\\N\" label replacement.\n\n\n\n",
        "func": "static boolean poly_inside(inside_t * inside_context, pointf p)\n{\n    static node_t *lastn;\t/* last node argument */\n    static polygon_t *poly;\n    static int last, outp, sides;\n    static pointf O;\t\t/* point (0,0) */\n    static pointf *vertex;\n    static double xsize, ysize, scalex, scaley, box_URx, box_URy;\n\n    int i, i1, j, s;\n    pointf P, Q, R;\n    boxf *bp;\n    node_t *n;\n\n    if (!inside_context) {\n\tlastn = NULL;\n\treturn FALSE;\n    }\n\n    bp = inside_context->s.bp;\n    n = inside_context->s.n;\n    P = ccwrotatepf(p, 90 * GD_rankdir(agraphof(n)));\n\n    /* Quick test if port rectangle is target */\n    if (bp) {\n\tboxf bbox = *bp;\n\treturn INSIDE(P, bbox);\n    }\n\n    if (n != lastn) {\n\tdouble n_width, n_height;\n\tpoly = (polygon_t *) ND_shape_info(n);\n\tvertex = poly->vertices;\n\tsides = poly->sides;\n\n\tif (poly->option & FIXEDSHAPE) {\n\t   boxf bb = polyBB(poly); \n\t    n_width = bb.UR.x - bb.LL.x;\n\t    n_height = bb.UR.y - bb.LL.y;\n\t    /* get point and node size adjusted for rankdir=LR */\n\t    if (GD_flip(agraphof(n))) {\n\t\tysize = n_width;\n\t\txsize = n_height;\n\t    } else {\n\t\txsize = n_width;\n\t\tysize = n_height;\n\t    }\n\t} else {\n\t    /* get point and node size adjusted for rankdir=LR */\n\t    if (GD_flip(agraphof(n))) {\n\t\tysize = ND_lw(n) + ND_rw(n);\n\t\txsize = ND_ht(n);\n\t    } else {\n\t\txsize = ND_lw(n) + ND_rw(n);\n\t\tysize = ND_ht(n);\n\t    }\n\t    n_width = POINTS(ND_width(n));\n\t    n_height = POINTS(ND_height(n));\n\t}\n\n\t/* scale */\n\tif (xsize == 0.0)\n\t    xsize = 1.0;\n\tif (ysize == 0.0)\n\t    ysize = 1.0;\n\tscalex = n_width / xsize;\n\tscaley = n_height / ysize;\n\tbox_URx = n_width / 2.0;\n\tbox_URy = n_height / 2.0;\n\n\t/* index to outer-periphery */\n\toutp = (poly->peripheries - 1) * sides;\n\tif (outp < 0)\n\t    outp = 0;\n\tlastn = n;\n    }\n\n    /* scale */\n    P.x *= scalex;\n    P.y *= scaley;\n\n    /* inside bounding box? */\n    if ((fabs(P.x) > box_URx) || (fabs(P.y) > box_URy))\n\treturn FALSE;\n\n    /* ellipses */\n    if (sides <= 2)\n\treturn (hypot(P.x / box_URx, P.y / box_URy) < 1.);\n\n    /* use fast test in case we are converging on a segment */\n    i = last % sides;\t\t/* in case last left over from larger polygon */\n    i1 = (i + 1) % sides;\n    Q = vertex[i + outp];\n    R = vertex[i1 + outp];\n    if (!(same_side(P, O, Q, R)))   /* false if outside the segment's face */\n\treturn FALSE;\n    /* else inside the segment face... */\n    if ((s = same_side(P, Q, R, O)) && (same_side(P, R, O, Q))) /* true if between the segment's sides */\n\treturn TRUE;\n    /* else maybe in another segment */\n    for (j = 1; j < sides; j++) { /* iterate over remaining segments */\n\tif (s) { /* clockwise */\n\t    i = i1;\n\t    i1 = (i + 1) % sides;\n\t} else { /* counter clockwise */\n\t    i1 = i;\n\t    i = (i + sides - 1) % sides;\n\t}\n\tif (!(same_side(P, O, vertex[i + outp], vertex[i1 + outp]))) { /* false if outside any other segment's face */\n\t    last = i;\n\t    return FALSE;\n\t}\n    }\n    /* inside all segments' faces */\n    last = i;\t\t\t/* in case next edge is to same side */\n    return TRUE;\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 0
      },
      {
        "idx": 507425,
        "reasoning": "This code snippet is not directly related to the described vulnerability of an out-of-bounds write during label parsing and replacement with \"\\N\". The provided code focuses on recursive positioning of fields within a layout and doesn't handle label manipulation or memory allocation for string storage, therefore it doesn't introduce the reported issue.\n\n\n\n",
        "func": "static void pos_reclbl(field_t * f, pointf ul, int sides)\n{\n    int i, last, mask;\n\n    f->sides = sides;\n    f->b.LL = pointfof(ul.x, ul.y - f->size.y);\n    f->b.UR = pointfof(ul.x + f->size.x, ul.y);\n    last = f->n_flds - 1;\n    for (i = 0; i <= last; i++) {\n\tif (sides) {\n\t    if (f->LR) {\n\t\tif (i == 0) {\n\t\t    if (i == last)\n\t\t\tmask = TOP | BOTTOM | RIGHT | LEFT;\n\t\t    else\n\t\t\tmask = TOP | BOTTOM | LEFT;\n\t\t} else if (i == last)\n\t\t    mask = TOP | BOTTOM | RIGHT;\n\t\telse\n\t\t    mask = TOP | BOTTOM;\n\t    } else {\n\t\tif (i == 0) {\n\t\t    if (i == last)\n\t\t\tmask = TOP | BOTTOM | RIGHT | LEFT;\n\t\t    else\n\t\t\tmask = TOP | RIGHT | LEFT;\n\t\t} else if (i == last)\n\t\t    mask = LEFT | BOTTOM | RIGHT;\n\t\telse\n\t\t    mask = LEFT | RIGHT;\n\t    }\n\t} else\n\t    mask = 0;\n\tpos_reclbl(f->fld[i], ul, sides & mask);\n\tif (f->LR)\n\t    ul.x = ul.x + f->fld[i]->size.x;\n\telse\n\t    ul.y = ul.y - f->fld[i]->size.y;\n    }\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 0
      },
      {
        "idx": 507426,
        "reasoning": "This code snippet is **not vulnerable** because it only *prints* the label text and box information; it doesn't perform any memory allocation or modification of the label itself. The vulnerability described in the commit message relates to dynamic label alteration during parsing, which isn't present in this `dumpL` function responsible for debugging output.\n\n\n\n",
        "func": "static void dumpL(field_t * info, int level)\n{\n    int i;\n\n    indent(level);\n    if (info->n_flds == 0) {\n\tfprintf(stderr, \"Label \\\"%s\\\" \", info->lp->text);\n\tprbox(info->b);\n    } else {\n\tfprintf(stderr, \"Tbl \");\n\tprbox(info->b);\n\tfor (i = 0; i < info->n_flds; i++) {\n\t    dumpL(info->fld[i], level + 1);\n\t}\n    }\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 0
      },
      {
        "idx": 507427,
        "reasoning": "This code snippet is not vulnerable because it pertains to the geometric calculation of star vertices and bounding box adjustments\u2014it doesn't handle string manipulation or label parsing as described in the commit message concerning the out-of-bounds write. The vulnerability fix relates to dynamically altering node labels with potentially longer strings (\"\\N\") than the original label, a process absent in this `star_vertices` function.\n\n\n\n",
        "func": "static void star_vertices (pointf* vertices, pointf* bb)\n{\n    int i;\n    pointf sz = *bb;\n    double offset, a, aspect = (1 + sin(alpha3))/(2*cos(alpha));\n    double r, r0, theta = alpha;\n\n    /* Scale up width or height to required aspect ratio */\n    a = sz.y/sz.x;\n    if (a > aspect) {\n\tsz.x = sz.y/aspect;\n    }\n    else if (a < aspect) {\n\tsz.y = sz.x*aspect;\n    }\n\n    /* for given sz, get radius */\n    r = sz.x/(2*cos(alpha));\n    r0 = (r*cos(alpha)*cos(alpha4))/(sin(alpha4)*cos(alpha2));\n    \n    /* offset is the y shift of circle center from bb center */\n    offset = (r*(1 - sin(alpha3)))/2;\n\n    for (i = 0; i < 10; i += 2) {\n\tvertices[i].x = r*cos(theta);\n\tvertices[i].y = r*sin(theta) - offset;\n\ttheta += alpha2;\n\tvertices[i+1].x = r0*cos(theta);\n\tvertices[i+1].y = r0*sin(theta) - offset;\n\ttheta += alpha2;\n    }\n\n    *bb = sz;\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 0
      },
      {
        "idx": 507428,
        "reasoning": "This code snippet, dealing with recursive freeing of a field structure, is not directly related to the described vulnerability of an out-of-bounds write during label parsing and replacement with \"\\N\". The provided commit message focuses on dynamic label allocation and potential buffer overflows during label assignment, while this code solely handles memory deallocation\u2014it doesn't perform any label manipulation or string copying that could trigger the described issue.\n\n\n\n",
        "func": "static void free_field(field_t * f)\n{\n    int i;\n\n    for (i = 0; i < f->n_flds; i++) {\n\tfree_field(f->fld[i]);\n    }\n\n    free(f->id);\n    free_label(f->lp);\n    free(f->fld);\n    free(f);\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 216840,
        "reasoning": "The code is vulnerable to a buffer overflow because it allocates `textbuf` based on the *original* label length, but then potentially overwrites it with \"\\N\" which could be longer without reallocating the buffer. This occurs when `parse_reclbl` fails, leading to `reclblp` being set to \"\\N\" and subsequently passed to `parse_reclbl` again with the insufficient `textbuf` size, matching the described CVE scenario.",
        "func": "static void record_init(node_t * n)\n{\n    field_t *info;\n    pointf ul, sz;\n    int flip, len;\n    char *textbuf;\t\t/* temp buffer for storing labels */\n    int sides = BOTTOM | RIGHT | TOP | LEFT;\n\n    /* Always use rankdir to determine how records are laid out */\n    flip = NOT(GD_realflip(agraphof(n)));\n    reclblp = ND_label(n)->text;\n    len = strlen(reclblp);\n    /* For some forgotten reason, an empty label is parsed into a space, so\n     * we need at least two bytes in textbuf.\n     */\n    len = MAX(len, 1);\n    textbuf = N_NEW(len + 1, char);\n    if (!(info = parse_reclbl(n, flip, TRUE, textbuf))) {\n\tagerr(AGERR, \"bad label format %s\\n\", ND_label(n)->text);\n\treclblp = \"\\\\N\";\n\tinfo = parse_reclbl(n, flip, TRUE, textbuf);\n    }\n    free(textbuf);\n    size_reclbl(n, info);\n    sz.x = POINTS(ND_width(n));\n    sz.y = POINTS(ND_height(n));\n    if (mapbool(late_string(n, N_fixed, \"false\"))) {\n\tif ((sz.x < info->size.x) || (sz.y < info->size.y)) {\n/* should check that the record really won't fit, e.g., there may be no text.\n\t\t\tagerr(AGWARN, \"node '%s' size may be too small\\n\", agnameof(n));\n*/\n\t}\n    } else {\n\tsz.x = MAX(info->size.x, sz.x);\n\tsz.y = MAX(info->size.y, sz.y);\n    }\n    resize_reclbl(info, sz, mapbool(late_string(n, N_nojustify, \"false\")));\n    ul = pointfof(-sz.x / 2., sz.y / 2.);\t/* FIXME - is this still true:    suspected to introduce ronding error - see Kluge below */\n    pos_reclbl(info, ul, sides);\n    ND_width(n) = PS2INCH(info->size.x);\n    ND_height(n) = PS2INCH(info->size.y + 1);\t/* Kluge!!  +1 to fix rounding diff between layout and rendering \n\t\t\t\t\t\t   otherwise we can get -1 coords in output */\n    ND_shape_info(n) = (void *) info;\n}",
        "commit_message": "fix: out-of-bounds write on invalid label\n\nWhen the label for a node cannot be parsed (due to it being malformed), it falls\nback on the symbol name of the node itself. I.e. the default label the node\nwould have had if it had no label attribute at all. However, this is applied by\ndynamically altering the node's label to \"\\N\", a shortcut for the symbol name of\nthe node. All of this is fine, however if the hand written label itself is\nshorter than the literal string \"\\N\", not enough memory would have been\nallocated to write \"\\N\" into the label text.\n\nHere we account for the possibility of error during label parsing, and assume\nthat the label text may need to be overwritten with \"\\N\" after the fact. Fixes\nissue #1700.",
        "cve_desc": "Buffer Overflow in Graphviz Graph Visualization Tools from commit ID f8b9e035 and earlier allows remote attackers to execute arbitrary code or cause a denial of service (application crash) by loading a crafted file into the \"lib/common/shapes.c\" component.",
        "target": 1
      }
    ]
  },
  "grep": {
    "0": [],
    "1": []
  },
  "gssproxy": {
    "0": [],
    "1": []
  },
  "gst-plugins-good": {
    "0": [
      {
        "idx": 409261,
        "reasoning": "This code snippet is **not vulnerable** because it focuses on retrieving an existing index and correctly handles its reference counting with `gst_object_ref`. The commit message and issue describe a problem in a different part of the `matroskademux` code related to initializing an *output parameter* to NULL, which isn't present in this specific function for getting the index.\n\n\n\n",
        "func": "gst_matroska_demux_get_index (GstElement * element)\n{\n  GstIndex *result = NULL;\n  GstMatroskaDemux *demux = GST_MATROSKA_DEMUX (element);\n\n  GST_OBJECT_LOCK (demux);\n  if (demux->common.element_index)\n    result = gst_object_ref (demux->common.element_index);\n  GST_OBJECT_UNLOCK (demux);\n\n  GST_DEBUG_OBJECT (demux, \"Returning index %\" GST_PTR_FORMAT, result);\n\n  return result;\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 0
      },
      {
        "idx": 409262,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message. The commit addresses an issue in `gst_matroska_demux_add_stream_headers_to_caps` where a track context pointer wasn't initialized to NULL, leading to potential memory corruption \u2013 this snippet simply appends buffer data to caps and doesn't handle track context initialization or parsing.\n\n\n\n",
        "func": "gst_matroska_demux_add_stream_headers_to_caps (GstMatroskaDemux * demux,\n    GstBufferList * list, GstCaps * caps)\n{\n  GstStructure *s;\n  GValue arr_val = G_VALUE_INIT;\n  GValue buf_val = G_VALUE_INIT;\n  gint i, num;\n\n  g_assert (gst_caps_is_writable (caps));\n\n  g_value_init (&arr_val, GST_TYPE_ARRAY);\n  g_value_init (&buf_val, GST_TYPE_BUFFER);\n\n  num = gst_buffer_list_length (list);\n  for (i = 0; i < num; ++i) {\n    g_value_set_boxed (&buf_val, gst_buffer_list_get (list, i));\n    gst_value_array_append_value (&arr_val, &buf_val);\n  }\n\n  s = gst_caps_get_structure (caps, 0);\n  gst_structure_take_value (s, \"streamheader\", &arr_val);\n  g_value_unset (&buf_val);\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 0
      },
      {
        "idx": 409263,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message. The commit addresses an issue in `matroskademux` where a track context pointer wasn't consistently initialized to NULL, leading to potential memory corruption \u2013 this code snippet focuses on parsing EBML numbers and doesn't handle any pointers or memory allocation that would introduce similar risks.\n\n\n\n",
        "func": "gst_matroska_ebmlnum_sint (guint8 * data, guint size, gint64 * num)\n{\n  guint64 unum;\n  gint res;\n\n  /* read as unsigned number first */\n  if ((res = gst_matroska_ebmlnum_uint (data, size, &unum)) < 0)\n    return -1;\n\n  /* make signed */\n  if (unum == G_MAXUINT64)\n    *num = G_MAXINT64;\n  else\n    *num = unum - ((1 << ((7 * res) - 1)) - 1);\n\n  return res;\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 0
      },
      {
        "idx": 409264,
        "reasoning": "This code snippet is **not directly vulnerable** to the issue described in the commit message. The commit message details a problem with initializing `track context` to NULL *before* parsing, while this code snippet focuses on pushing stream headers and managing buffers *after* a track context has presumably been established \u2013 it doesn't show the initial parsing or context creation where the vulnerability resided.\n\n\n\n",
        "func": "gst_matroska_demux_push_stream_headers (GstMatroskaDemux * demux,\n    GstMatroskaTrackContext * stream)\n{\n  GstFlowReturn ret = GST_FLOW_OK;\n  gint i, num;\n\n  num = gst_buffer_list_length (stream->stream_headers);\n  for (i = 0; i < num; ++i) {\n    GstBuffer *buf;\n\n    buf = gst_buffer_list_get (stream->stream_headers, i);\n    buf = gst_buffer_copy (buf);\n\n    GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_HEADER);\n\n    if (stream->set_discont) {\n      GST_BUFFER_FLAG_SET (buf, GST_BUFFER_FLAG_DISCONT);\n      stream->set_discont = FALSE;\n    } else {\n      GST_BUFFER_FLAG_UNSET (buf, GST_BUFFER_FLAG_DISCONT);\n    }\n\n    /* push out all headers in one go and use last flow return */\n    ret = gst_pad_push (stream->pad, buf);\n  }\n\n  /* don't need these any  longer */\n  gst_buffer_list_unref (stream->stream_headers);\n  stream->stream_headers = NULL;\n\n  /* combine flows */\n  ret = gst_flow_combiner_update_flow (demux->flowcombiner, ret);\n\n  return ret;\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 0
      },
      {
        "idx": 409265,
        "reasoning": "This code snippet is not directly vulnerable because it only *uses* the `GstMatroskaTrackContext` structure, it doesn't show the initialization or parsing logic where the vulnerability existed. The commit message explicitly states the issue was in how the `track context` *out parameter* was initialized *before* parsing, and this snippet only demonstrates its usage *after* potential initialization elsewhere.\n\n\n\n",
        "func": "gst_matroska_demux_push_codec_data_all (GstMatroskaDemux * demux)\n{\n  gint stream_nr;\n\n  g_assert (demux->common.num_streams == demux->common.src->len);\n  for (stream_nr = 0; stream_nr < demux->common.src->len; stream_nr++) {\n    GstMatroskaTrackContext *stream;\n\n    stream = g_ptr_array_index (demux->common.src, stream_nr);\n\n    if (stream->send_stream_headers) {\n      if (stream->stream_headers != NULL) {\n        gst_matroska_demux_push_stream_headers (demux, stream);\n      } else {\n        /* FIXME: perhaps we can just disable and skip this stream then */\n        GST_ELEMENT_ERROR (demux, STREAM, DECODE, (NULL),\n            (\"Failed to extract stream headers from codec private data\"));\n      }\n      stream->send_stream_headers = FALSE;\n    }\n\n    if (stream->send_dvd_event) {\n      gst_matroska_demux_push_dvd_clut_change_event (demux, stream);\n      /* FIXME: should we send this event again after (flushing) seek ? */\n      stream->send_dvd_event = FALSE;\n    }\n  }\n\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 208402,
        "reasoning": "The code is vulnerable because the `context` pointer is allocated on the stack and initialized with default values, but isn't guaranteed to be set to `NULL` in all error return paths before the function exits. This can lead to the caller receiving a dangling pointer, which when dereferenced, results in memory corruption as it points to uninitialized or previously freed memory, aligning with the reported heap corruption issue.",
        "func": "gst_matroska_demux_parse_stream (GstMatroskaDemux * demux, GstEbmlRead * ebml,\n    GstMatroskaTrackContext ** dest_context)\n{\n  GstMatroskaTrackContext *context;\n  GstCaps *caps = NULL;\n  GstTagList *cached_taglist;\n  GstFlowReturn ret;\n  guint32 id, riff_fourcc = 0;\n  guint16 riff_audio_fmt = 0;\n  gchar *codec = NULL;\n\n  DEBUG_ELEMENT_START (demux, ebml, \"TrackEntry\");\n\n  /* start with the master */\n  if ((ret = gst_ebml_read_master (ebml, &id)) != GST_FLOW_OK) {\n    DEBUG_ELEMENT_STOP (demux, ebml, \"TrackEntry\", ret);\n    return ret;\n  }\n\n  /* allocate generic... if we know the type, we'll g_renew()\n   * with the precise type */\n  context = g_new0 (GstMatroskaTrackContext, 1);\n  context->index_writer_id = -1;\n  context->type = 0;            /* no type yet */\n  context->default_duration = 0;\n  context->pos = 0;\n  context->set_discont = TRUE;\n  context->timecodescale = 1.0;\n  context->flags =\n      GST_MATROSKA_TRACK_ENABLED | GST_MATROSKA_TRACK_DEFAULT |\n      GST_MATROSKA_TRACK_LACING;\n  context->from_time = GST_CLOCK_TIME_NONE;\n  context->from_offset = -1;\n  context->to_offset = G_MAXINT64;\n  context->alignment = 1;\n  context->dts_only = FALSE;\n  context->intra_only = FALSE;\n  context->tags = gst_tag_list_new_empty ();\n  g_queue_init (&context->protection_event_queue);\n  context->protection_info = NULL;\n\n  GST_DEBUG_OBJECT (demux, \"Parsing a TrackEntry (%d tracks parsed so far)\",\n      demux->common.num_streams);\n\n  /* try reading the trackentry headers */\n  while (ret == GST_FLOW_OK && gst_ebml_read_has_remaining (ebml, 1, TRUE)) {\n    if ((ret = gst_ebml_peek_id (ebml, &id)) != GST_FLOW_OK)\n      break;\n\n    switch (id) {\n        /* track number (unique stream ID) */\n      case GST_MATROSKA_ID_TRACKNUMBER:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num == 0) {\n          GST_ERROR_OBJECT (demux, \"Invalid TrackNumber 0\");\n          ret = GST_FLOW_ERROR;\n          break;\n        }\n\n        GST_DEBUG_OBJECT (demux, \"TrackNumber: %\" G_GUINT64_FORMAT, num);\n        context->num = num;\n        break;\n      }\n        /* track UID (unique identifier) */\n      case GST_MATROSKA_ID_TRACKUID:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num == 0) {\n          GST_ERROR_OBJECT (demux, \"Invalid TrackUID 0\");\n          ret = GST_FLOW_ERROR;\n          break;\n        }\n\n        GST_DEBUG_OBJECT (demux, \"TrackUID: %\" G_GUINT64_FORMAT, num);\n        context->uid = num;\n        break;\n      }\n\n        /* track type (video, audio, combined, subtitle, etc.) */\n      case GST_MATROSKA_ID_TRACKTYPE:{\n        guint64 track_type;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &track_type)) != GST_FLOW_OK) {\n          break;\n        }\n\n        if (context->type != 0 && context->type != track_type) {\n          GST_WARNING_OBJECT (demux,\n              \"More than one tracktype defined in a TrackEntry - skipping\");\n          break;\n        } else if (track_type < 1 || track_type > 254) {\n          GST_WARNING_OBJECT (demux, \"Invalid TrackType %\" G_GUINT64_FORMAT,\n              track_type);\n          break;\n        }\n\n        GST_DEBUG_OBJECT (demux, \"TrackType: %\" G_GUINT64_FORMAT, track_type);\n\n        /* ok, so we're actually going to reallocate this thing */\n        switch (track_type) {\n          case GST_MATROSKA_TRACK_TYPE_VIDEO:\n            gst_matroska_track_init_video_context (&context);\n            break;\n          case GST_MATROSKA_TRACK_TYPE_AUDIO:\n            gst_matroska_track_init_audio_context (&context);\n            break;\n          case GST_MATROSKA_TRACK_TYPE_SUBTITLE:\n            gst_matroska_track_init_subtitle_context (&context);\n            break;\n          case GST_MATROSKA_TRACK_TYPE_COMPLEX:\n          case GST_MATROSKA_TRACK_TYPE_LOGO:\n          case GST_MATROSKA_TRACK_TYPE_BUTTONS:\n          case GST_MATROSKA_TRACK_TYPE_CONTROL:\n          default:\n            GST_WARNING_OBJECT (demux,\n                \"Unknown or unsupported TrackType %\" G_GUINT64_FORMAT,\n                track_type);\n            context->type = 0;\n            break;\n        }\n        break;\n      }\n\n        /* tracktype specific stuff for video */\n      case GST_MATROSKA_ID_TRACKVIDEO:{\n        GstMatroskaTrackVideoContext *videocontext;\n\n        DEBUG_ELEMENT_START (demux, ebml, \"TrackVideo\");\n\n        if (!gst_matroska_track_init_video_context (&context)) {\n          GST_WARNING_OBJECT (demux,\n              \"TrackVideo element in non-video track - ignoring track\");\n          ret = GST_FLOW_ERROR;\n          break;\n        } else if ((ret = gst_ebml_read_master (ebml, &id)) != GST_FLOW_OK) {\n          break;\n        }\n        videocontext = (GstMatroskaTrackVideoContext *) context;\n\n        while (ret == GST_FLOW_OK &&\n            gst_ebml_read_has_remaining (ebml, 1, TRUE)) {\n          if ((ret = gst_ebml_peek_id (ebml, &id)) != GST_FLOW_OK)\n            break;\n\n          switch (id) {\n              /* Should be one level up but some broken muxers write it here. */\n            case GST_MATROSKA_ID_TRACKDEFAULTDURATION:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackDefaultDuration 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackDefaultDuration: %\" G_GUINT64_FORMAT, num);\n              context->default_duration = num;\n              break;\n            }\n\n              /* video framerate */\n              /* NOTE: This one is here only for backward compatibility.\n               * Use _TRACKDEFAULDURATION one level up. */\n            case GST_MATROSKA_ID_VIDEOFRAMERATE:{\n              gdouble num;\n\n              if ((ret = gst_ebml_read_float (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num <= 0.0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackVideoFPS %lf\", num);\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux, \"TrackVideoFrameRate: %lf\", num);\n              if (context->default_duration == 0)\n                context->default_duration =\n                    gst_gdouble_to_guint64 ((gdouble) GST_SECOND * (1.0 / num));\n              videocontext->default_fps = num;\n              break;\n            }\n\n              /* width of the size to display the video at */\n            case GST_MATROSKA_ID_VIDEODISPLAYWIDTH:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackVideoDisplayWidth 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoDisplayWidth: %\" G_GUINT64_FORMAT, num);\n              videocontext->display_width = num;\n              break;\n            }\n\n              /* height of the size to display the video at */\n            case GST_MATROSKA_ID_VIDEODISPLAYHEIGHT:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackVideoDisplayHeight 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoDisplayHeight: %\" G_GUINT64_FORMAT, num);\n              videocontext->display_height = num;\n              break;\n            }\n\n              /* width of the video in the file */\n            case GST_MATROSKA_ID_VIDEOPIXELWIDTH:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackVideoPixelWidth 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoPixelWidth: %\" G_GUINT64_FORMAT, num);\n              videocontext->pixel_width = num;\n              break;\n            }\n\n              /* height of the video in the file */\n            case GST_MATROSKA_ID_VIDEOPIXELHEIGHT:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackVideoPixelHeight 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoPixelHeight: %\" G_GUINT64_FORMAT, num);\n              videocontext->pixel_height = num;\n              break;\n            }\n\n              /* whether the video is interlaced */\n            case GST_MATROSKA_ID_VIDEOFLAGINTERLACED:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 1)\n                videocontext->interlace_mode =\n                    GST_MATROSKA_INTERLACE_MODE_INTERLACED;\n              else if (num == 2)\n                videocontext->interlace_mode =\n                    GST_MATROSKA_INTERLACE_MODE_PROGRESSIVE;\n              else\n                videocontext->interlace_mode =\n                    GST_MATROSKA_INTERLACE_MODE_UNKNOWN;\n\n              GST_DEBUG_OBJECT (demux, \"video track interlacing mode: %d\",\n                  videocontext->interlace_mode);\n              break;\n            }\n\n              /* interlaced field order */\n            case GST_MATROSKA_ID_VIDEOFIELDORDER:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (videocontext->interlace_mode !=\n                  GST_MATROSKA_INTERLACE_MODE_INTERLACED) {\n                GST_WARNING_OBJECT (demux,\n                    \"FieldOrder element when not interlaced - ignoring\");\n                break;\n              }\n\n              if (num == 0)\n                /* turns out we're actually progressive */\n                videocontext->interlace_mode =\n                    GST_MATROSKA_INTERLACE_MODE_PROGRESSIVE;\n              else if (num == 2)\n                videocontext->field_order = GST_VIDEO_FIELD_ORDER_UNKNOWN;\n              else if (num == 9)\n                videocontext->field_order =\n                    GST_VIDEO_FIELD_ORDER_TOP_FIELD_FIRST;\n              else if (num == 14)\n                videocontext->field_order =\n                    GST_VIDEO_FIELD_ORDER_BOTTOM_FIELD_FIRST;\n              else {\n                GST_FIXME_OBJECT (demux,\n                    \"Unknown or unsupported FieldOrder %\" G_GUINT64_FORMAT,\n                    num);\n                videocontext->field_order = GST_VIDEO_FIELD_ORDER_UNKNOWN;\n              }\n\n              GST_DEBUG_OBJECT (demux, \"video track field order: %d\",\n                  videocontext->field_order);\n              break;\n            }\n\n              /* aspect ratio behaviour */\n            case GST_MATROSKA_ID_VIDEOASPECTRATIOTYPE:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num != GST_MATROSKA_ASPECT_RATIO_MODE_FREE &&\n                  num != GST_MATROSKA_ASPECT_RATIO_MODE_KEEP &&\n                  num != GST_MATROSKA_ASPECT_RATIO_MODE_FIXED) {\n                GST_WARNING_OBJECT (demux,\n                    \"Unknown TrackVideoAspectRatioType 0x%x\", (guint) num);\n                break;\n              }\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoAspectRatioType: %\" G_GUINT64_FORMAT, num);\n              videocontext->asr_mode = num;\n              break;\n            }\n\n              /* colourspace (only matters for raw video) fourcc */\n            case GST_MATROSKA_ID_VIDEOCOLOURSPACE:{\n              guint8 *data;\n              guint64 datalen;\n\n              if ((ret =\n                      gst_ebml_read_binary (ebml, &id, &data,\n                          &datalen)) != GST_FLOW_OK)\n                break;\n\n              if (datalen != 4) {\n                g_free (data);\n                GST_WARNING_OBJECT (demux,\n                    \"Invalid TrackVideoColourSpace length %\" G_GUINT64_FORMAT,\n                    datalen);\n                break;\n              }\n\n              memcpy (&videocontext->fourcc, data, 4);\n              GST_DEBUG_OBJECT (demux,\n                  \"TrackVideoColourSpace: %\" GST_FOURCC_FORMAT,\n                  GST_FOURCC_ARGS (videocontext->fourcc));\n              g_free (data);\n              break;\n            }\n\n              /* color info */\n            case GST_MATROSKA_ID_VIDEOCOLOUR:{\n              ret = gst_matroska_demux_parse_colour (demux, ebml, videocontext);\n              break;\n            }\n\n            case GST_MATROSKA_ID_VIDEOSTEREOMODE:\n            {\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              GST_DEBUG_OBJECT (demux, \"StereoMode: %\" G_GUINT64_FORMAT, num);\n\n              switch (num) {\n                case GST_MATROSKA_STEREO_MODE_SBS_RL:\n                  videocontext->multiview_flags =\n                      GST_VIDEO_MULTIVIEW_FLAGS_RIGHT_VIEW_FIRST;\n                  /* fall through */\n                case GST_MATROSKA_STEREO_MODE_SBS_LR:\n                  videocontext->multiview_mode =\n                      GST_VIDEO_MULTIVIEW_MODE_SIDE_BY_SIDE;\n                  break;\n                case GST_MATROSKA_STEREO_MODE_TB_RL:\n                  videocontext->multiview_flags =\n                      GST_VIDEO_MULTIVIEW_FLAGS_RIGHT_VIEW_FIRST;\n                  /* fall through */\n                case GST_MATROSKA_STEREO_MODE_TB_LR:\n                  videocontext->multiview_mode =\n                      GST_VIDEO_MULTIVIEW_MODE_TOP_BOTTOM;\n                  break;\n                case GST_MATROSKA_STEREO_MODE_CHECKER_RL:\n                  videocontext->multiview_flags =\n                      GST_VIDEO_MULTIVIEW_FLAGS_RIGHT_VIEW_FIRST;\n                  /* fall through */\n                case GST_MATROSKA_STEREO_MODE_CHECKER_LR:\n                  videocontext->multiview_mode =\n                      GST_VIDEO_MULTIVIEW_MODE_CHECKERBOARD;\n                  break;\n                case GST_MATROSKA_STEREO_MODE_FBF_RL:\n                  videocontext->multiview_flags =\n                      GST_VIDEO_MULTIVIEW_FLAGS_RIGHT_VIEW_FIRST;\n                  /* fall through */\n                case GST_MATROSKA_STEREO_MODE_FBF_LR:\n                  videocontext->multiview_mode =\n                      GST_VIDEO_MULTIVIEW_MODE_FRAME_BY_FRAME;\n                  /* FIXME: In frame-by-frame mode, left/right frame buffers are\n                   * laced within one block, and we'll need to apply FIRST_IN_BUNDLE\n                   * accordingly. See http://www.matroska.org/technical/specs/index.html#StereoMode */\n                  GST_FIXME_OBJECT (demux,\n                      \"Frame-by-frame stereoscopic mode not fully implemented\");\n                  break;\n              }\n              break;\n            }\n\n            default:\n              GST_WARNING_OBJECT (demux,\n                  \"Unknown TrackVideo subelement 0x%x - ignoring\", id);\n              /* fall through */\n            case GST_MATROSKA_ID_VIDEODISPLAYUNIT:\n            case GST_MATROSKA_ID_VIDEOPIXELCROPBOTTOM:\n            case GST_MATROSKA_ID_VIDEOPIXELCROPTOP:\n            case GST_MATROSKA_ID_VIDEOPIXELCROPLEFT:\n            case GST_MATROSKA_ID_VIDEOPIXELCROPRIGHT:\n            case GST_MATROSKA_ID_VIDEOGAMMAVALUE:\n              ret = gst_ebml_read_skip (ebml);\n              break;\n          }\n        }\n\n        DEBUG_ELEMENT_STOP (demux, ebml, \"TrackVideo\", ret);\n        break;\n      }\n\n        /* tracktype specific stuff for audio */\n      case GST_MATROSKA_ID_TRACKAUDIO:{\n        GstMatroskaTrackAudioContext *audiocontext;\n\n        DEBUG_ELEMENT_START (demux, ebml, \"TrackAudio\");\n\n        if (!gst_matroska_track_init_audio_context (&context)) {\n          GST_WARNING_OBJECT (demux,\n              \"TrackAudio element in non-audio track - ignoring track\");\n          ret = GST_FLOW_ERROR;\n          break;\n        }\n\n        if ((ret = gst_ebml_read_master (ebml, &id)) != GST_FLOW_OK)\n          break;\n\n        audiocontext = (GstMatroskaTrackAudioContext *) context;\n\n        while (ret == GST_FLOW_OK &&\n            gst_ebml_read_has_remaining (ebml, 1, TRUE)) {\n          if ((ret = gst_ebml_peek_id (ebml, &id)) != GST_FLOW_OK)\n            break;\n\n          switch (id) {\n              /* samplerate */\n            case GST_MATROSKA_ID_AUDIOSAMPLINGFREQ:{\n              gdouble num;\n\n              if ((ret = gst_ebml_read_float (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n\n              if (num <= 0.0) {\n                GST_WARNING_OBJECT (demux,\n                    \"Invalid TrackAudioSamplingFrequency %lf\", num);\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux, \"TrackAudioSamplingFrequency: %lf\", num);\n              audiocontext->samplerate = num;\n              break;\n            }\n\n              /* bitdepth */\n            case GST_MATROSKA_ID_AUDIOBITDEPTH:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackAudioBitDepth 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux, \"TrackAudioBitDepth: %\" G_GUINT64_FORMAT,\n                  num);\n              audiocontext->bitdepth = num;\n              break;\n            }\n\n              /* channels */\n            case GST_MATROSKA_ID_AUDIOCHANNELS:{\n              guint64 num;\n\n              if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n                break;\n\n              if (num == 0) {\n                GST_WARNING_OBJECT (demux, \"Invalid TrackAudioChannels 0\");\n                break;\n              }\n\n              GST_DEBUG_OBJECT (demux, \"TrackAudioChannels: %\" G_GUINT64_FORMAT,\n                  num);\n              audiocontext->channels = num;\n              break;\n            }\n\n            default:\n              GST_WARNING_OBJECT (demux,\n                  \"Unknown TrackAudio subelement 0x%x - ignoring\", id);\n              /* fall through */\n            case GST_MATROSKA_ID_AUDIOCHANNELPOSITIONS:\n            case GST_MATROSKA_ID_AUDIOOUTPUTSAMPLINGFREQ:\n              ret = gst_ebml_read_skip (ebml);\n              break;\n          }\n        }\n\n        DEBUG_ELEMENT_STOP (demux, ebml, \"TrackAudio\", ret);\n\n        break;\n      }\n\n        /* codec identifier */\n      case GST_MATROSKA_ID_CODECID:{\n        gchar *text;\n\n        if ((ret = gst_ebml_read_ascii (ebml, &id, &text)) != GST_FLOW_OK)\n          break;\n\n        GST_DEBUG_OBJECT (demux, \"CodecID: %s\", GST_STR_NULL (text));\n        context->codec_id = text;\n        break;\n      }\n\n        /* codec private data */\n      case GST_MATROSKA_ID_CODECPRIVATE:{\n        guint8 *data;\n        guint64 size;\n\n        if ((ret =\n                gst_ebml_read_binary (ebml, &id, &data, &size)) != GST_FLOW_OK)\n          break;\n\n        context->codec_priv = data;\n        context->codec_priv_size = size;\n\n        GST_DEBUG_OBJECT (demux, \"CodecPrivate of size %\" G_GUINT64_FORMAT,\n            size);\n        break;\n      }\n\n        /* name of the codec */\n      case GST_MATROSKA_ID_CODECNAME:{\n        gchar *text;\n\n        if ((ret = gst_ebml_read_utf8 (ebml, &id, &text)) != GST_FLOW_OK)\n          break;\n\n        GST_DEBUG_OBJECT (demux, \"CodecName: %s\", GST_STR_NULL (text));\n        context->codec_name = text;\n        break;\n      }\n\n        /* codec delay */\n      case GST_MATROSKA_ID_CODECDELAY:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        context->codec_delay = num;\n\n        GST_DEBUG_OBJECT (demux, \"CodecDelay: %\" GST_TIME_FORMAT,\n            GST_TIME_ARGS (num));\n        break;\n      }\n\n        /* codec delay */\n      case GST_MATROSKA_ID_SEEKPREROLL:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        context->seek_preroll = num;\n\n        GST_DEBUG_OBJECT (demux, \"SeekPreroll: %\" GST_TIME_FORMAT,\n            GST_TIME_ARGS (num));\n        break;\n      }\n\n        /* name of this track */\n      case GST_MATROSKA_ID_TRACKNAME:{\n        gchar *text;\n\n        if ((ret = gst_ebml_read_utf8 (ebml, &id, &text)) != GST_FLOW_OK)\n          break;\n\n        context->name = text;\n        GST_DEBUG_OBJECT (demux, \"TrackName: %s\", GST_STR_NULL (text));\n        break;\n      }\n\n        /* language (matters for audio/subtitles, mostly) */\n      case GST_MATROSKA_ID_TRACKLANGUAGE:{\n        gchar *text;\n\n        if ((ret = gst_ebml_read_utf8 (ebml, &id, &text)) != GST_FLOW_OK)\n          break;\n\n\n        context->language = text;\n\n        /* fre-ca => fre */\n        if (strlen (context->language) >= 4 && context->language[3] == '-')\n          context->language[3] = '\\0';\n\n        GST_DEBUG_OBJECT (demux, \"TrackLanguage: %s\",\n            GST_STR_NULL (context->language));\n        break;\n      }\n\n        /* whether this is actually used */\n      case GST_MATROSKA_ID_TRACKFLAGENABLED:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num)\n          context->flags |= GST_MATROSKA_TRACK_ENABLED;\n        else\n          context->flags &= ~GST_MATROSKA_TRACK_ENABLED;\n\n        GST_DEBUG_OBJECT (demux, \"TrackEnabled: %d\",\n            (context->flags & GST_MATROSKA_TRACK_ENABLED) ? 1 : 0);\n        break;\n      }\n\n        /* whether it's the default for this track type */\n      case GST_MATROSKA_ID_TRACKFLAGDEFAULT:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num)\n          context->flags |= GST_MATROSKA_TRACK_DEFAULT;\n        else\n          context->flags &= ~GST_MATROSKA_TRACK_DEFAULT;\n\n        GST_DEBUG_OBJECT (demux, \"TrackDefault: %d\",\n            (context->flags & GST_MATROSKA_TRACK_DEFAULT) ? 1 : 0);\n        break;\n      }\n\n        /* whether the track must be used during playback */\n      case GST_MATROSKA_ID_TRACKFLAGFORCED:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num)\n          context->flags |= GST_MATROSKA_TRACK_FORCED;\n        else\n          context->flags &= ~GST_MATROSKA_TRACK_FORCED;\n\n        GST_DEBUG_OBJECT (demux, \"TrackForced: %d\",\n            (context->flags & GST_MATROSKA_TRACK_FORCED) ? 1 : 0);\n        break;\n      }\n\n        /* lacing (like MPEG, where blocks don't end/start on frame\n         * boundaries) */\n      case GST_MATROSKA_ID_TRACKFLAGLACING:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num)\n          context->flags |= GST_MATROSKA_TRACK_LACING;\n        else\n          context->flags &= ~GST_MATROSKA_TRACK_LACING;\n\n        GST_DEBUG_OBJECT (demux, \"TrackLacing: %d\",\n            (context->flags & GST_MATROSKA_TRACK_LACING) ? 1 : 0);\n        break;\n      }\n\n        /* default length (in time) of one data block in this track */\n      case GST_MATROSKA_ID_TRACKDEFAULTDURATION:{\n        guint64 num;\n\n        if ((ret = gst_ebml_read_uint (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n\n        if (num == 0) {\n          GST_WARNING_OBJECT (demux, \"Invalid TrackDefaultDuration 0\");\n          break;\n        }\n\n        GST_DEBUG_OBJECT (demux, \"TrackDefaultDuration: %\" G_GUINT64_FORMAT,\n            num);\n        context->default_duration = num;\n        break;\n      }\n\n      case GST_MATROSKA_ID_CONTENTENCODINGS:{\n        ret = gst_matroska_read_common_read_track_encodings (&demux->common,\n            ebml, context);\n        break;\n      }\n\n      case GST_MATROSKA_ID_TRACKTIMECODESCALE:{\n        gdouble num;\n\n        if ((ret = gst_ebml_read_float (ebml, &id, &num)) != GST_FLOW_OK)\n          break;\n\n        if (num <= 0.0) {\n          GST_WARNING_OBJECT (demux, \"Invalid TrackTimeCodeScale %lf\", num);\n          break;\n        }\n\n        GST_DEBUG_OBJECT (demux, \"TrackTimeCodeScale: %lf\", num);\n        context->timecodescale = num;\n        break;\n      }\n\n      default:\n        GST_WARNING (\"Unknown TrackEntry subelement 0x%x - ignoring\", id);\n        /* pass-through */\n\n        /* we ignore these because they're nothing useful (i.e. crap)\n         * or simply not implemented yet. */\n      case GST_MATROSKA_ID_TRACKMINCACHE:\n      case GST_MATROSKA_ID_TRACKMAXCACHE:\n      case GST_MATROSKA_ID_MAXBLOCKADDITIONID:\n      case GST_MATROSKA_ID_TRACKATTACHMENTLINK:\n      case GST_MATROSKA_ID_TRACKOVERLAY:\n      case GST_MATROSKA_ID_TRACKTRANSLATE:\n      case GST_MATROSKA_ID_TRACKOFFSET:\n      case GST_MATROSKA_ID_CODECSETTINGS:\n      case GST_MATROSKA_ID_CODECINFOURL:\n      case GST_MATROSKA_ID_CODECDOWNLOADURL:\n      case GST_MATROSKA_ID_CODECDECODEALL:\n        ret = gst_ebml_read_skip (ebml);\n        break;\n    }\n  }\n\n  DEBUG_ELEMENT_STOP (demux, ebml, \"TrackEntry\", ret);\n\n  /* Decode codec private data if necessary */\n  if (context->encodings && context->encodings->len > 0 && context->codec_priv\n      && context->codec_priv_size > 0) {\n    if (!gst_matroska_decode_data (context->encodings,\n            &context->codec_priv, &context->codec_priv_size,\n            GST_MATROSKA_TRACK_ENCODING_SCOPE_CODEC_DATA, TRUE)) {\n      GST_WARNING_OBJECT (demux, \"Decoding codec private data failed\");\n      ret = GST_FLOW_ERROR;\n    }\n  }\n\n  if (context->type == 0 || context->codec_id == NULL || (ret != GST_FLOW_OK\n          && ret != GST_FLOW_EOS)) {\n    if (ret == GST_FLOW_OK || ret == GST_FLOW_EOS)\n      GST_WARNING_OBJECT (ebml, \"Unknown stream/codec in track entry header\");\n\n    gst_matroska_track_free (context);\n    context = NULL;\n    *dest_context = NULL;\n    return ret;\n  }\n\n  /* check for a cached track taglist  */\n  cached_taglist =\n      (GstTagList *) g_hash_table_lookup (demux->common.cached_track_taglists,\n      GUINT_TO_POINTER (context->uid));\n  if (cached_taglist)\n    gst_tag_list_insert (context->tags, cached_taglist, GST_TAG_MERGE_APPEND);\n\n  /* compute caps */\n  switch (context->type) {\n    case GST_MATROSKA_TRACK_TYPE_VIDEO:{\n      GstMatroskaTrackVideoContext *videocontext =\n          (GstMatroskaTrackVideoContext *) context;\n\n      caps = gst_matroska_demux_video_caps (videocontext,\n          context->codec_id, context->codec_priv,\n          context->codec_priv_size, &codec, &riff_fourcc);\n\n      if (codec) {\n        gst_tag_list_add (context->tags, GST_TAG_MERGE_REPLACE,\n            GST_TAG_VIDEO_CODEC, codec, NULL);\n        context->tags_changed = TRUE;\n        g_free (codec);\n      }\n      break;\n    }\n\n    case GST_MATROSKA_TRACK_TYPE_AUDIO:{\n      GstClockTime lead_in_ts = 0;\n      GstMatroskaTrackAudioContext *audiocontext =\n          (GstMatroskaTrackAudioContext *) context;\n\n      caps = gst_matroska_demux_audio_caps (audiocontext,\n          context->codec_id, context->codec_priv, context->codec_priv_size,\n          &codec, &riff_audio_fmt, &lead_in_ts);\n      if (lead_in_ts > demux->audio_lead_in_ts) {\n        demux->audio_lead_in_ts = lead_in_ts;\n        GST_DEBUG_OBJECT (demux, \"Increased audio lead-in to %\" GST_TIME_FORMAT,\n            GST_TIME_ARGS (lead_in_ts));\n      }\n\n      if (codec) {\n        gst_tag_list_add (context->tags, GST_TAG_MERGE_REPLACE,\n            GST_TAG_AUDIO_CODEC, codec, NULL);\n        context->tags_changed = TRUE;\n        g_free (codec);\n      }\n      break;\n    }\n\n    case GST_MATROSKA_TRACK_TYPE_SUBTITLE:{\n      GstMatroskaTrackSubtitleContext *subtitlecontext =\n          (GstMatroskaTrackSubtitleContext *) context;\n\n      caps = gst_matroska_demux_subtitle_caps (subtitlecontext,\n          context->codec_id, context->codec_priv, context->codec_priv_size);\n      break;\n    }\n\n    case GST_MATROSKA_TRACK_TYPE_COMPLEX:\n    case GST_MATROSKA_TRACK_TYPE_LOGO:\n    case GST_MATROSKA_TRACK_TYPE_BUTTONS:\n    case GST_MATROSKA_TRACK_TYPE_CONTROL:\n    default:\n      /* we should already have quit by now */\n      g_assert_not_reached ();\n  }\n\n  if ((context->language == NULL || *context->language == '\\0') &&\n      (context->type == GST_MATROSKA_TRACK_TYPE_AUDIO ||\n          context->type == GST_MATROSKA_TRACK_TYPE_SUBTITLE)) {\n    GST_LOG (\"stream %d: language=eng (assuming default)\", context->index);\n    context->language = g_strdup (\"eng\");\n  }\n\n  if (context->language) {\n    const gchar *lang;\n\n    /* Matroska contains ISO 639-2B codes, we want ISO 639-1 */\n    lang = gst_tag_get_language_code (context->language);\n    gst_tag_list_add (context->tags, GST_TAG_MERGE_REPLACE,\n        GST_TAG_LANGUAGE_CODE, (lang) ? lang : context->language, NULL);\n\n    if (context->name) {\n      gst_tag_list_add (context->tags, GST_TAG_MERGE_REPLACE,\n          GST_TAG_TITLE, context->name, NULL);\n    }\n    context->tags_changed = TRUE;\n  }\n\n  if (caps == NULL) {\n    GST_WARNING_OBJECT (demux, \"could not determine caps for stream with \"\n        \"codec_id='%s'\", context->codec_id);\n    switch (context->type) {\n      case GST_MATROSKA_TRACK_TYPE_VIDEO:\n        caps = gst_caps_new_empty_simple (\"video/x-unknown\");\n        break;\n      case GST_MATROSKA_TRACK_TYPE_AUDIO:\n        caps = gst_caps_new_empty_simple (\"audio/x-unknown\");\n        break;\n      case GST_MATROSKA_TRACK_TYPE_SUBTITLE:\n        caps = gst_caps_new_empty_simple (\"application/x-subtitle-unknown\");\n        break;\n      case GST_MATROSKA_TRACK_TYPE_COMPLEX:\n      default:\n        caps = gst_caps_new_empty_simple (\"application/x-matroska-unknown\");\n        break;\n    }\n    gst_caps_set_simple (caps, \"codec-id\", G_TYPE_STRING, context->codec_id,\n        NULL);\n\n    /* add any unrecognised riff fourcc / audio format, but after codec-id */\n    if (context->type == GST_MATROSKA_TRACK_TYPE_AUDIO && riff_audio_fmt != 0)\n      gst_caps_set_simple (caps, \"format\", G_TYPE_INT, riff_audio_fmt, NULL);\n    else if (context->type == GST_MATROSKA_TRACK_TYPE_VIDEO && riff_fourcc != 0) {\n      gchar *fstr = g_strdup_printf (\"%\" GST_FOURCC_FORMAT,\n          GST_FOURCC_ARGS (riff_fourcc));\n      gst_caps_set_simple (caps, \"fourcc\", G_TYPE_STRING, fstr, NULL);\n      g_free (fstr);\n    }\n  } else if (context->stream_headers != NULL) {\n    gst_matroska_demux_add_stream_headers_to_caps (demux,\n        context->stream_headers, caps);\n  }\n\n  if (context->encodings) {\n    GstMatroskaTrackEncoding *enc;\n    guint i;\n\n    for (i = 0; i < context->encodings->len; i++) {\n      enc = &g_array_index (context->encodings, GstMatroskaTrackEncoding, i);\n      if (enc->type == GST_MATROSKA_ENCODING_ENCRYPTION /* encryption */ ) {\n        GstStructure *s = gst_caps_get_structure (caps, 0);\n        if (!gst_structure_has_name (s, \"application/x-webm-enc\")) {\n          gst_structure_set (s, \"original-media-type\", G_TYPE_STRING,\n              gst_structure_get_name (s), NULL);\n          gst_structure_set (s, \"encryption-algorithm\", G_TYPE_STRING,\n              gst_matroska_track_encryption_algorithm_name (enc->enc_algo),\n              NULL);\n          gst_structure_set (s, \"encoding-scope\", G_TYPE_STRING,\n              gst_matroska_track_encoding_scope_name (enc->scope), NULL);\n          gst_structure_set (s, \"cipher-mode\", G_TYPE_STRING,\n              gst_matroska_track_encryption_cipher_mode_name\n              (enc->enc_cipher_mode), NULL);\n          gst_structure_set_name (s, \"application/x-webm-enc\");\n        }\n      }\n    }\n  }\n\n  context->caps = caps;\n\n  /* tadaah! */\n  *dest_context = context;\n  return ret;\n}",
        "commit_message": "matroskademux: Initialize track context out parameter to NULL before parsing\n\nVarious error return paths don't set it to NULL and callers are only\nchecking if the pointer is NULL. As it's allocated on the stack this\nusually contains random stack memory, and more often than not the memory\nof a previously parsed track.\n\nThis then causes all kinds of memory corruptions further down the line.\n\nThanks to Natalie Silvanovich for reporting.\n\nFixes https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/issues/858\n\nPart-of: <https://gitlab.freedesktop.org/gstreamer/gst-plugins-good/-/merge_requests/903>",
        "cve_desc": "GStreamer before 1.18.4 might cause heap corruption when parsing certain malformed Matroska files.",
        "target": 1
      },
      {
        "idx": 212025,
        "reasoning": "This code is vulnerable because it directly accesses `map.data` without checking if `gst_buffer_map` successfully mapped the buffer, potentially leading to a read from unmapped memory. The CVE confirms this vulnerability results in an invalid memory read and crash when processing a crafted audio file that causes the buffer mapping to fail.",
        "func": "gst_aac_parse_sink_setcaps (GstBaseParse * parse, GstCaps * caps)\n{\n  GstAacParse *aacparse;\n  GstStructure *structure;\n  gchar *caps_str;\n  const GValue *value;\n\n  aacparse = GST_AAC_PARSE (parse);\n  structure = gst_caps_get_structure (caps, 0);\n  caps_str = gst_caps_to_string (caps);\n\n  GST_DEBUG_OBJECT (aacparse, \"setcaps: %s\", caps_str);\n  g_free (caps_str);\n\n  /* This is needed at least in case of RTP\n   * Parses the codec_data information to get ObjectType,\n   * number of channels and samplerate */\n  value = gst_structure_get_value (structure, \"codec_data\");\n  if (value) {\n    GstBuffer *buf = gst_value_get_buffer (value);\n\n    if (buf) {\n      GstMapInfo map;\n      guint sr_idx;\n\n      gst_buffer_map (buf, &map, GST_MAP_READ);\n\n      sr_idx = ((map.data[0] & 0x07) << 1) | ((map.data[1] & 0x80) >> 7);\n      aacparse->object_type = (map.data[0] & 0xf8) >> 3;\n      aacparse->sample_rate =\n          gst_codec_utils_aac_get_sample_rate_from_index (sr_idx);\n      aacparse->channels = (map.data[1] & 0x78) >> 3;\n      if (aacparse->channels == 7)\n        aacparse->channels = 8;\n      else if (aacparse->channels == 11)\n        aacparse->channels = 7;\n      else if (aacparse->channels == 12 || aacparse->channels == 14)\n        aacparse->channels = 8;\n      aacparse->header_type = DSPAAC_HEADER_NONE;\n      aacparse->mpegversion = 4;\n      aacparse->frame_samples = (map.data[1] & 4) ? 960 : 1024;\n      gst_buffer_unmap (buf, &map);\n\n      GST_DEBUG (\"codec_data: object_type=%d, sample_rate=%d, channels=%d, \"\n          \"samples=%d\", aacparse->object_type, aacparse->sample_rate,\n          aacparse->channels, aacparse->frame_samples);\n\n      /* arrange for metadata and get out of the way */\n      gst_aac_parse_set_src_caps (aacparse, caps);\n      if (aacparse->header_type == aacparse->output_header_type)\n        gst_base_parse_set_passthrough (parse, TRUE);\n    } else {\n      return FALSE;\n    }\n\n    /* caps info overrides */\n    gst_structure_get_int (structure, \"rate\", &aacparse->sample_rate);\n    gst_structure_get_int (structure, \"channels\", &aacparse->channels);\n  } else {\n    const gchar *stream_format =\n        gst_structure_get_string (structure, \"stream-format\");\n\n    if (g_strcmp0 (stream_format, \"raw\") == 0) {\n      GST_ERROR_OBJECT (parse, \"Need codec_data for raw AAC\");\n      return FALSE;\n    } else {\n      aacparse->sample_rate = 0;\n      aacparse->channels = 0;\n      aacparse->header_type = DSPAAC_HEADER_NOT_PARSED;\n      gst_base_parse_set_passthrough (parse, FALSE);\n    }\n  }\n  return TRUE;\n}",
        "commit_message": "aacparse: Make sure we have enough data in the codec_data to be able to parse it\n\nAlso error out cleanly if mapping the buffer failed.\n\nhttps://bugzilla.gnome.org/show_bug.cgi?id=775450",
        "cve_desc": "The gst_aac_parse_sink_setcaps function in gst/audioparsers/gstaacparse.c in gst-plugins-good in GStreamer before 1.10.3 allows remote attackers to cause a denial of service (invalid memory read and crash) via a crafted audio file.",
        "target": 1
      }
    ]
  },
  "haproxy": {
    "0": [
      {
        "idx": 11334,
        "reasoning": "This code snippet focuses on *building* a DNS query, not *parsing* it\u2014the vulnerability described in the commit message relates to a recursion loop during DNS name *reading* (specifically in `dns_read_name()`). Therefore, this code is not directly vulnerable to the stack-exhaustion issue addressed by the patch, as it doesn't handle compressed DNS name pointers or recursive calls to read names.\n\n\n\n",
        "func": "static int dns_build_query(int query_id, int query_type, unsigned int accepted_payload_size,\n\t\t\t   char *hostname_dn, int hostname_dn_len, char *buf, int bufsize)\n{\n\tstruct dns_header            dns_hdr;\n\tstruct dns_question          qinfo;\n\tstruct dns_additional_record edns;\n\tchar *p = buf;\n\n\tif (sizeof(dns_hdr) + sizeof(qinfo) +  sizeof(edns) + hostname_dn_len >= bufsize)\n\t\treturn -1;\n\n\tmemset(buf, 0, bufsize);\n\n\t/* Set dns query headers */\n\tdns_hdr.id      = (unsigned short) htons(query_id);\n\tdns_hdr.flags   = htons(0x0100); /* qr=0, opcode=0, aa=0, tc=0, rd=1, ra=0, z=0, rcode=0 */\n\tdns_hdr.qdcount = htons(1);      /* 1 question */\n\tdns_hdr.ancount = 0;\n\tdns_hdr.nscount = 0;\n\tdns_hdr.arcount = htons(1);\n\tmemcpy(p, &dns_hdr, sizeof(dns_hdr));\n\tp += sizeof(dns_hdr);\n\n\t/* Set up query hostname */\n\tmemcpy(p, hostname_dn, hostname_dn_len);\n\tp += hostname_dn_len;\n\t*p++ = 0;\n\n\t/* Set up query info (type and class) */\n\tqinfo.qtype  = htons(query_type);\n\tqinfo.qclass = htons(DNS_RCLASS_IN);\n\tmemcpy(p, &qinfo, sizeof(qinfo));\n\tp += sizeof(qinfo);\n\n\t/* Set the DNS extension */\n\tedns.name             = 0;\n\tedns.type             = htons(DNS_RTYPE_OPT);\n\tedns.udp_payload_size = htons(accepted_payload_size);\n\tedns.extension        = 0;\n\tedns.data_length      = 0;\n\tmemcpy(p, &edns, sizeof(edns));\n\tp += sizeof(edns);\n\n\treturn (p - buf);\n}\n",
        "commit_message": "BUG: dns: Prevent stack-exhaustion via recursion loop in dns_read_name\n\nWhen a compressed pointer is encountered, dns_read_name() will call\nitself with the pointed-to offset in the packet.\nWith a specially crafted packet, it was possible to trigger an\ninfinite-loop recursion by making the pointer points to itself.\nWhile it would be possible to handle that particular case differently\nby making sure that the target is different from the current offset,\nit would still be possible to craft a packet with a very long chain\nof valid pointers, always pointing backwards. To prevent a stack\nexhaustion in that case, this patch restricts the number of recursive\ncalls to 100, which should be more than enough.\n\nTo be backported to 1.8, probably also 1.7.",
        "cve_desc": "An issue was discovered in dns.c in HAProxy through 1.8.14. In the case of a compressed pointer, a crafted packet can trigger infinite recursion by making the pointer point to itself, or create a long chain of valid pointers resulting in stack exhaustion.",
        "target": 0
      }
    ],
    "1": []
  },
  "hermes": {
    "0": [],
    "1": []
  },
  "hhvm": {
    "0": [],
    "1": []
  },
  "hivex": {
    "0": [
      {
        "idx": 356433,
        "reasoning": "This code is likely safe because the commit message explicitly addresses a boundary check issue (\"Check that pages do not extend beyond the end of the file\"), suggesting previous vulnerabilities related to out-of-bounds reads were mitigated. The `header_checksum` function iterates a fixed number of times (0x1fc / 4) and directly accesses memory within the provided `hive_h` structure's address, without any user-controlled offsets that could lead to an overflow\u2014assuming `h->addr` itself is valid and points to allocated memory.\n\n\n\n",
        "func": "header_checksum (const hive_h *h)\n{\n  uint32_t *daddr = (uint32_t *) h->addr;\n  size_t i;\n  uint32_t sum = 0;\n\n  for (i = 0; i < 0x1fc / 4; ++i) {\n    sum ^= le32toh (*daddr);\n    daddr++;\n  }\n\n  return sum;\n}",
        "commit_message": "handle: Check that pages do not extend beyond the end of the file.\n\nThanks: Mahmoud Al-Qudsi",
        "cve_desc": "lib/handle.c in Hivex before 1.3.11 allows local users to execute arbitrary code and gain privileges via a small hive files, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 356434,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The `hivex_close` function properly frees allocated memory (bitmap, address space, filename, and the hive handle itself) and unmaps or closes the file descriptor, demonstrating good resource management and lacking obvious exploitable flaws like buffer overflows or use-after-free conditions. \n\n\n\n",
        "func": "hivex_close (hive_h *h)\n{\n  int r;\n\n  DEBUG (1, \"hivex_close\");\n\n  free (h->bitmap);\n  if (!h->writable)\n    munmap (h->addr, h->size);\n  else\n    free (h->addr);\n  if (h->fd >= 0)\n    r = close (h->fd);\n  else\n    r = 0;\n  free (h->filename);\n  free (h);\n\n  return r;\n}",
        "commit_message": "handle: Check that pages do not extend beyond the end of the file.\n\nThanks: Mahmoud Al-Qudsi",
        "cve_desc": "lib/handle.c in Hivex before 1.3.11 allows local users to execute arbitrary code and gain privileges via a small hive files, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 356435,
        "reasoning": "This code is safe and addresses a potential vulnerability. The commit message explicitly states the change is to \"Check that pages do not extend beyond the end of the file,\" and the code snippet demonstrates this check within the loop that reads pages, preventing potential out-of-bounds reads and associated security risks.",
        "func": "hivex_open (const char *filename, int flags)\n{\n  hive_h *h = NULL;\n\n  assert (sizeof (struct ntreg_header) == 0x1000);\n  assert (offsetof (struct ntreg_header, csum) == 0x1fc);\n\n  h = calloc (1, sizeof *h);\n  if (h == NULL)\n    goto error;\n\n  h->msglvl = flags & HIVEX_OPEN_MSGLVL_MASK;\n\n  const char *debug = getenv (\"HIVEX_DEBUG\");\n  if (debug && STREQ (debug, \"1\"))\n    h->msglvl = 2;\n\n  DEBUG (2, \"created handle %p\", h);\n\n  h->writable = !!(flags & HIVEX_OPEN_WRITE);\n  h->filename = strdup (filename);\n  if (h->filename == NULL)\n    goto error;\n\n#ifdef O_CLOEXEC\n  h->fd = open (filename, O_RDONLY | O_CLOEXEC | O_BINARY);\n#else\n  h->fd = open (filename, O_RDONLY | O_BINARY);\n#endif\n  if (h->fd == -1)\n    goto error;\n#ifndef O_CLOEXEC\n  fcntl (h->fd, F_SETFD, FD_CLOEXEC);\n#endif\n\n  struct stat statbuf;\n  if (fstat (h->fd, &statbuf) == -1)\n    goto error;\n\n  h->size = statbuf.st_size;\n\n  if (h->size < 0x2000) {\n    SET_ERRNO (EINVAL,\n               \"%s: file is too small to be a Windows NT Registry hive file\",\n               filename);\n    goto error;\n  }\n\n  if (!h->writable) {\n    h->addr = mmap (NULL, h->size, PROT_READ, MAP_SHARED, h->fd, 0);\n    if (h->addr == MAP_FAILED)\n      goto error;\n\n    DEBUG (2, \"mapped file at %p\", h->addr);\n  } else {\n    h->addr = malloc (h->size);\n    if (h->addr == NULL)\n      goto error;\n\n    if (full_read (h->fd, h->addr, h->size) < h->size)\n      goto error;\n\n    /* We don't need the file descriptor along this path, since we\n     * have read all the data.\n     */\n    if (close (h->fd) == -1)\n      goto error;\n    h->fd = -1;\n  }\n\n  /* Check header. */\n  if (h->hdr->magic[0] != 'r' ||\n      h->hdr->magic[1] != 'e' ||\n      h->hdr->magic[2] != 'g' ||\n      h->hdr->magic[3] != 'f') {\n    SET_ERRNO (ENOTSUP,\n               \"%s: not a Windows NT Registry hive file\", filename);\n    goto error;\n  }\n\n  /* Check major version. */\n  uint32_t major_ver = le32toh (h->hdr->major_ver);\n  if (major_ver != 1) {\n    SET_ERRNO (ENOTSUP,\n               \"%s: hive file major version %\" PRIu32 \" (expected 1)\",\n               filename, major_ver);\n    goto error;\n  }\n\n  h->bitmap = calloc (1 + h->size / 32, 1);\n  if (h->bitmap == NULL)\n    goto error;\n\n  /* Header checksum. */\n  uint32_t sum = header_checksum (h);\n  if (sum != le32toh (h->hdr->csum)) {\n    SET_ERRNO (EINVAL, \"%s: bad checksum in hive header\", filename);\n    goto error;\n  }\n\n  /* Last modified time. */\n  h->last_modified = le64toh ((int64_t) h->hdr->last_modified);\n\n  if (h->msglvl >= 2) {\n    char *name = _hivex_windows_utf16_to_utf8 (h->hdr->name, 64);\n\n    fprintf (stderr,\n             \"hivex_open: header fields:\\n\"\n             \"  file version             %\" PRIu32 \".%\" PRIu32 \"\\n\"\n             \"  sequence nos             %\" PRIu32 \" %\" PRIu32 \"\\n\"\n             \"    (sequences nos should match if hive was synched at shutdown)\\n\"\n             \"  last modified            %\" PRIu64 \"\\n\"\n             \"    (Windows filetime, x 100 ns since 1601-01-01)\\n\"\n             \"  original file name       %s\\n\"\n             \"    (only 32 chars are stored, name is probably truncated)\\n\"\n             \"  root offset              0x%x + 0x1000\\n\"\n             \"  end of last page         0x%x + 0x1000 (total file size 0x%zx)\\n\"\n             \"  checksum                 0x%x (calculated 0x%x)\\n\",\n             major_ver, le32toh (h->hdr->minor_ver),\n             le32toh (h->hdr->sequence1), le32toh (h->hdr->sequence2),\n             h->last_modified,\n             name ? name : \"(conversion failed)\",\n             le32toh (h->hdr->offset),\n             le32toh (h->hdr->blocks), h->size,\n             le32toh (h->hdr->csum), sum);\n    free (name);\n  }\n\n  h->rootoffs = le32toh (h->hdr->offset) + 0x1000;\n  h->endpages = le32toh (h->hdr->blocks) + 0x1000;\n\n  DEBUG (2, \"root offset = 0x%zx\", h->rootoffs);\n\n  /* We'll set this flag when we see a block with the root offset (ie.\n   * the root block).\n   */\n  int seen_root_block = 0, bad_root_block = 0;\n\n  /* Collect some stats. */\n  size_t pages = 0;           /* Number of hbin pages read. */\n  size_t smallest_page = SIZE_MAX, largest_page = 0;\n  size_t blocks = 0;          /* Total number of blocks found. */\n  size_t smallest_block = SIZE_MAX, largest_block = 0, blocks_bytes = 0;\n  size_t used_blocks = 0;     /* Total number of used blocks found. */\n  size_t used_size = 0;       /* Total size (bytes) of used blocks. */\n\n  /* Read the pages and blocks.  The aim here is to be robust against\n   * corrupt or malicious registries.  So we make sure the loops\n   * always make forward progress.  We add the address of each block\n   * we read to a hash table so pointers will only reference the start\n   * of valid blocks.\n   */\n  size_t off;\n  struct ntreg_hbin_page *page;\n  for (off = 0x1000; off < h->size; off += le32toh (page->page_size)) {\n    if (off >= h->endpages)\n      break;\n\n    page = (struct ntreg_hbin_page *) ((char *) h->addr + off);\n    if (page->magic[0] != 'h' ||\n        page->magic[1] != 'b' ||\n        page->magic[2] != 'i' ||\n        page->magic[3] != 'n') {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: trailing garbage at end of file \"\n                 \"(at 0x%zx, after %zu pages)\",\n                 filename, off, pages);\n      goto error;\n    }\n\n    size_t page_size = le32toh (page->page_size);\n    DEBUG (2, \"page at 0x%zx, size %zu\", off, page_size);\n    pages++;\n    if (page_size < smallest_page) smallest_page = page_size;\n    if (page_size > largest_page) largest_page = page_size;\n\n    if (page_size <= sizeof (struct ntreg_hbin_page) ||\n        (page_size & 0x0fff) != 0) {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: page size %zu at 0x%zx, bad registry\",\n                 filename, page_size, off);\n      goto error;\n    }\n\n    if (off + page_size > h->size) {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: page size %zu at 0x%zx extends beyond end of file, bad registry\",\n                 filename, page_size, off);\n      goto error;\n    }\n\n    /* Read the blocks in this page. */\n    size_t blkoff;\n    struct ntreg_hbin_block *block;\n    size_t seg_len;\n    for (blkoff = off + 0x20;\n         blkoff < off + page_size;\n         blkoff += seg_len) {\n      blocks++;\n\n      int is_root = blkoff == h->rootoffs;\n      if (is_root)\n        seen_root_block = 1;\n\n      block = (struct ntreg_hbin_block *) ((char *) h->addr + blkoff);\n      int used;\n      seg_len = block_len (h, blkoff, &used);\n      if (seg_len <= 4 || (seg_len & 3) != 0) {\n        SET_ERRNO (ENOTSUP,\n                   \"%s: block size %\" PRIu32 \" at 0x%zx, bad registry\",\n                   filename, le32toh (block->seg_len), blkoff);\n        goto error;\n      }\n\n      if (h->msglvl >= 2) {\n        unsigned char *id = (unsigned char *) block->id;\n        int id0 = id[0], id1 = id[1];\n\n        fprintf (stderr, \"%s: %s: \"\n                 \"%s block id %d,%d (%c%c) at 0x%zx size %zu%s\\n\",\n                 \"hivex\", __func__,\n                 used ? \"used\" : \"free\",\n                 id0, id1,\n                 c_isprint (id0) ? id0 : '.',\n                 c_isprint (id1) ? id1 : '.',\n                 blkoff,\n                 seg_len, is_root ? \" (root)\" : \"\");\n      }\n\n      blocks_bytes += seg_len;\n      if (seg_len < smallest_block) smallest_block = seg_len;\n      if (seg_len > largest_block) largest_block = seg_len;\n\n      if (is_root && !used)\n        bad_root_block = 1;\n\n      if (used) {\n        used_blocks++;\n        used_size += seg_len;\n\n        /* Root block must be an nk-block. */\n        if (is_root && (block->id[0] != 'n' || block->id[1] != 'k'))\n          bad_root_block = 1;\n\n        /* Note this blkoff is a valid address. */\n        BITMAP_SET (h->bitmap, blkoff);\n      }\n    }\n  }\n\n  if (!seen_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: no root block found\", filename);\n    goto error;\n  }\n\n  if (bad_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: bad root block (free or not nk)\", filename);\n    goto error;\n  }\n\n  DEBUG (1, \"successfully read Windows Registry hive file:\\n\"\n         \"  pages:          %zu [sml: %zu, lge: %zu]\\n\"\n         \"  blocks:         %zu [sml: %zu, avg: %zu, lge: %zu]\\n\"\n         \"  blocks used:    %zu\\n\"\n         \"  bytes used:     %zu\",\n         pages, smallest_page, largest_page,\n         blocks, smallest_block, blocks_bytes / blocks, largest_block,\n         used_blocks, used_size);\n\n  return h;\n\n error:;\n  int err = errno;\n  if (h) {\n    free (h->bitmap);\n    if (h->addr && h->size && h->addr != MAP_FAILED) {\n      if (!h->writable)\n        munmap (h->addr, h->size);\n      else\n        free (h->addr);\n    }\n    if (h->fd >= 0)\n      close (h->fd);\n    free (h->filename);\n    free (h);\n  }\n  errno = err;\n  return NULL;\n}",
        "commit_message": "handle: Check that pages do not extend beyond the end of the file.\n\nThanks: Mahmoud Al-Qudsi",
        "cve_desc": "lib/handle.c in Hivex before 1.3.11 allows local users to execute arbitrary code and gain privileges via a small hive files, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 448456,
        "reasoning": "This code *is* safe, as the commit message explicitly states it fixes a vulnerability (CVE-2021-3622) by limiting the recursion depth within `ri`-records to a maximum of 32. The added `if (depth >= 32)` check prevents the stack overflow that could occur with arbitrarily nested `ri`-records, effectively mitigating the original vulnerability.\n\n\n\n",
        "func": "_get_children (hive_h *h, hive_node_h blkoff,\n               offset_list *children, offset_list *blocks,\n               int flags, unsigned depth)\n{\n  /* Add this intermediate block. */\n  if (_hivex_add_to_offset_list (blocks, blkoff) == -1)\n    return -1;\n\n  struct ntreg_hbin_block *block =\n    (struct ntreg_hbin_block *) ((char *) h->addr + blkoff);\n\n  size_t len = block_len (h, blkoff, NULL);\n\n  /* Points to lf-record?  (Note, also \"lh\" but that is basically the\n   * same as \"lf\" as far as we are concerned here).\n   */\n  if (block->id[0] == 'l' && (block->id[1] == 'f' || block->id[1] == 'h')) {\n    struct ntreg_lf_record *lf = (struct ntreg_lf_record *) block;\n\n    /* Check number of subkeys in the nk-record matches number of subkeys\n     * in the lf-record.\n     */\n    size_t nr_subkeys_in_lf = le16toh (lf->nr_keys);\n\n    if (8 + nr_subkeys_in_lf * 8 > len) {\n      SET_ERRNO (EFAULT, \"too many subkeys (%zu, %zu)\", nr_subkeys_in_lf, len);\n      return -1;\n    }\n\n    size_t i;\n    for (i = 0; i < nr_subkeys_in_lf; ++i) {\n      hive_node_h subkey = le32toh (lf->keys[i].offset);\n      subkey += 0x1000;\n      if (check_child_is_nk_block (h, subkey, flags) == -1) {\n        if (h->unsafe) {\n          DEBUG (2, \"subkey at 0x%zx is not an NK block, skipping\", subkey);\n          continue;\n        } else {\n          return -1;\n        }\n      }\n      if (_hivex_add_to_offset_list (children, subkey) == -1)\n        return -1;\n    }\n  }\n  /* Points to li-record? */\n  else if (block->id[0] == 'l' && block->id[1] == 'i') {\n    /* li-records are formatted the same as ri-records, but they\n     * contain direct links to child records (same as lf/lh), so\n     * we treat them the same way as lf/lh.\n     */\n    struct ntreg_ri_record *ri = (struct ntreg_ri_record *) block;\n\n    /* Check number of subkeys in the nk-record matches number of subkeys\n     * in the li-record.\n     */\n    size_t nr_offsets = le16toh (ri->nr_offsets);\n\n    if (8 + nr_offsets * 4 > len) {\n      SET_ERRNO (EFAULT, \"too many offsets (%zu, %zu)\", nr_offsets, len);\n      return -1;\n    }\n\n    size_t i;\n    for (i = 0; i < nr_offsets; ++i) {\n      hive_node_h subkey = le32toh (ri->offset[i]);\n      subkey += 0x1000;\n      if (check_child_is_nk_block (h, subkey, flags) == -1) {\n        if (h->unsafe) {\n          DEBUG (2, \"subkey at 0x%zx is not an NK block, skipping\", subkey);\n          continue;\n        } else {\n          return -1;\n        }\n      }\n      if (_hivex_add_to_offset_list (children, subkey) == -1)\n        return -1;\n    }\n  }\n  /* Points to ri-record? */\n  else if (block->id[0] == 'r' && block->id[1] == 'i') {\n    struct ntreg_ri_record *ri = (struct ntreg_ri_record *) block;\n\n    size_t nr_offsets = le16toh (ri->nr_offsets);\n\n    if (8 + nr_offsets * 4 > len) {\n      SET_ERRNO (EFAULT, \"too many offsets (%zu, %zu)\", nr_offsets, len);\n      return -1;\n    }\n\n    /* Copy list of children. */\n    size_t i;\n    for (i = 0; i < nr_offsets; ++i) {\n      hive_node_h offset = le32toh (ri->offset[i]);\n      offset += 0x1000;\n      if (!IS_VALID_BLOCK (h, offset)) {\n        if (h->unsafe) {\n          DEBUG (2, \"ri-offset is not a valid block (0x%zx), skipping\", offset);\n          continue;\n        } else {\n          SET_ERRNO (EFAULT, \"ri-offset is not a valid block (0x%zx)\", offset);\n          return -1;\n        }\n      }\n\n      /* Although in theory hive ri records might be nested to any\n       * depth, in practice this is unlikely.  Recursing here caused\n       * CVE-2021-3622.  Thus limit the depth we will recurse to\n       * something small.\n       */\n      if (depth >= 32) {\n        SET_ERRNO (EINVAL, \"ri-record nested to depth >= %u\", depth);\n        return -1;\n      }\n\n      if (_get_children (h, offset, children, blocks, flags, depth+1) == -1)\n        return -1;\n    }\n  }\n  else {\n    SET_ERRNO (ENOTSUP,\n               \"subkey block is not lf/lh/li/ri (0x%zx, %d, %d)\",\n               blkoff, block->id[0], block->id[1]);\n    return -1;\n  }\n\n  return 0;\n}",
        "commit_message": "lib/node.c: Limit recursion in ri-records (CVE-2021-3622)\n\nWindows Registry hive \"ri\"-records are arbitrarily nested B-tree-like\nstructures:\n\n  +-------------+\n  | ri          |\n  |-------------|\n  | nr_offsets  |\n  |   offset[0] ------>  points to another lf/lh/li/ri block\n  |   offset[1] ------>\n  |   offset[2] ------>\n  +-------------+\n\nIt is possible to construct a hive with a very deeply nested tree of\nri-records, causing the internal _get_children function to recurse to\nany depth which can cause programs linked to hivex to crash with a\nstack overflow.\n\nSince it is not thought that deeply nested ri-records occur in real\nhives, limit recursion depth.  If you hit this limit you will see the\nfollowing error and the operation will return an error instead of\ncrashing:\n\n  \\> ls\n  hivex: _get_children: returning EINVAL because: ri-record nested to depth >= 32\n  ls: Invalid argument\n\nThanks to Jeremy Galindo for finding and reporting this bug.\n\nReported-by: Jeremy Galindo, Sr Security Engineer, Datto.com\nSigned-off-by: Richard W.M. Jones <rjones@redhat.com>\nFixes: CVE-2021-3622\nFixes: https://bugzilla.redhat.com/show_bug.cgi?id=1975489\n(cherry picked from commit 781a12c4a49dd81365c9c567c5aa5e19e894ba0e)",
        "cve_desc": "A flaw was found in the hivex library. This flaw allows an attacker to input a specially crafted Windows Registry (hive) file, which would cause hivex to recursively call the _get_children() function, leading to a stack overflow. The highest threat from this vulnerability is to system availability.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 204290,
        "reasoning": "The code is vulnerable to out-of-bounds reads due to insufficient validation of the `page_size` and block lengths within the hive file, potentially allowing access beyond the allocated memory region. Specifically, the loop `for (off = 0x1000; off < h->size; off += le32toh (page->page_size))` and nested block processing loop can read past the end of the allocated `h->addr` buffer if `page_size` or calculated block offsets are maliciously crafted, as highlighted by the CVE description.",
        "func": "hivex_open (const char *filename, int flags)\n{\n  hive_h *h = NULL;\n\n  assert (sizeof (struct ntreg_header) == 0x1000);\n  assert (offsetof (struct ntreg_header, csum) == 0x1fc);\n\n  h = calloc (1, sizeof *h);\n  if (h == NULL)\n    goto error;\n\n  h->msglvl = flags & HIVEX_OPEN_MSGLVL_MASK;\n\n  const char *debug = getenv (\"HIVEX_DEBUG\");\n  if (debug && STREQ (debug, \"1\"))\n    h->msglvl = 2;\n\n  DEBUG (2, \"created handle %p\", h);\n\n  h->writable = !!(flags & HIVEX_OPEN_WRITE);\n  h->filename = strdup (filename);\n  if (h->filename == NULL)\n    goto error;\n\n#ifdef O_CLOEXEC\n  h->fd = open (filename, O_RDONLY | O_CLOEXEC | O_BINARY);\n#else\n  h->fd = open (filename, O_RDONLY | O_BINARY);\n#endif\n  if (h->fd == -1)\n    goto error;\n#ifndef O_CLOEXEC\n  fcntl (h->fd, F_SETFD, FD_CLOEXEC);\n#endif\n\n  struct stat statbuf;\n  if (fstat (h->fd, &statbuf) == -1)\n    goto error;\n\n  h->size = statbuf.st_size;\n\n  if (h->size < 0x2000) {\n    SET_ERRNO (EINVAL,\n               \"%s: file is too small to be a Windows NT Registry hive file\",\n               filename);\n    goto error;\n  }\n\n  if (!h->writable) {\n    h->addr = mmap (NULL, h->size, PROT_READ, MAP_SHARED, h->fd, 0);\n    if (h->addr == MAP_FAILED)\n      goto error;\n\n    DEBUG (2, \"mapped file at %p\", h->addr);\n  } else {\n    h->addr = malloc (h->size);\n    if (h->addr == NULL)\n      goto error;\n\n    if (full_read (h->fd, h->addr, h->size) < h->size)\n      goto error;\n\n    /* We don't need the file descriptor along this path, since we\n     * have read all the data.\n     */\n    if (close (h->fd) == -1)\n      goto error;\n    h->fd = -1;\n  }\n\n  /* Check header. */\n  if (h->hdr->magic[0] != 'r' ||\n      h->hdr->magic[1] != 'e' ||\n      h->hdr->magic[2] != 'g' ||\n      h->hdr->magic[3] != 'f') {\n    SET_ERRNO (ENOTSUP,\n               \"%s: not a Windows NT Registry hive file\", filename);\n    goto error;\n  }\n\n  /* Check major version. */\n  uint32_t major_ver = le32toh (h->hdr->major_ver);\n  if (major_ver != 1) {\n    SET_ERRNO (ENOTSUP,\n               \"%s: hive file major version %\" PRIu32 \" (expected 1)\",\n               filename, major_ver);\n    goto error;\n  }\n\n  h->bitmap = calloc (1 + h->size / 32, 1);\n  if (h->bitmap == NULL)\n    goto error;\n\n  /* Header checksum. */\n  uint32_t sum = header_checksum (h);\n  if (sum != le32toh (h->hdr->csum)) {\n    SET_ERRNO (EINVAL, \"%s: bad checksum in hive header\", filename);\n    goto error;\n  }\n\n  /* Last modified time. */\n  h->last_modified = le64toh ((int64_t) h->hdr->last_modified);\n\n  if (h->msglvl >= 2) {\n    char *name = _hivex_windows_utf16_to_utf8 (h->hdr->name, 64);\n\n    fprintf (stderr,\n             \"hivex_open: header fields:\\n\"\n             \"  file version             %\" PRIu32 \".%\" PRIu32 \"\\n\"\n             \"  sequence nos             %\" PRIu32 \" %\" PRIu32 \"\\n\"\n             \"    (sequences nos should match if hive was synched at shutdown)\\n\"\n             \"  last modified            %\" PRIu64 \"\\n\"\n             \"    (Windows filetime, x 100 ns since 1601-01-01)\\n\"\n             \"  original file name       %s\\n\"\n             \"    (only 32 chars are stored, name is probably truncated)\\n\"\n             \"  root offset              0x%x + 0x1000\\n\"\n             \"  end of last page         0x%x + 0x1000 (total file size 0x%zx)\\n\"\n             \"  checksum                 0x%x (calculated 0x%x)\\n\",\n             major_ver, le32toh (h->hdr->minor_ver),\n             le32toh (h->hdr->sequence1), le32toh (h->hdr->sequence2),\n             h->last_modified,\n             name ? name : \"(conversion failed)\",\n             le32toh (h->hdr->offset),\n             le32toh (h->hdr->blocks), h->size,\n             le32toh (h->hdr->csum), sum);\n    free (name);\n  }\n\n  h->rootoffs = le32toh (h->hdr->offset) + 0x1000;\n  h->endpages = le32toh (h->hdr->blocks) + 0x1000;\n\n  DEBUG (2, \"root offset = 0x%zx\", h->rootoffs);\n\n  /* We'll set this flag when we see a block with the root offset (ie.\n   * the root block).\n   */\n  int seen_root_block = 0, bad_root_block = 0;\n\n  /* Collect some stats. */\n  size_t pages = 0;           /* Number of hbin pages read. */\n  size_t smallest_page = SIZE_MAX, largest_page = 0;\n  size_t blocks = 0;          /* Total number of blocks found. */\n  size_t smallest_block = SIZE_MAX, largest_block = 0, blocks_bytes = 0;\n  size_t used_blocks = 0;     /* Total number of used blocks found. */\n  size_t used_size = 0;       /* Total size (bytes) of used blocks. */\n\n  /* Read the pages and blocks.  The aim here is to be robust against\n   * corrupt or malicious registries.  So we make sure the loops\n   * always make forward progress.  We add the address of each block\n   * we read to a hash table so pointers will only reference the start\n   * of valid blocks.\n   */\n  size_t off;\n  struct ntreg_hbin_page *page;\n  for (off = 0x1000; off < h->size; off += le32toh (page->page_size)) {\n    if (off >= h->endpages)\n      break;\n\n    page = (struct ntreg_hbin_page *) ((char *) h->addr + off);\n    if (page->magic[0] != 'h' ||\n        page->magic[1] != 'b' ||\n        page->magic[2] != 'i' ||\n        page->magic[3] != 'n') {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: trailing garbage at end of file \"\n                 \"(at 0x%zx, after %zu pages)\",\n                 filename, off, pages);\n      goto error;\n    }\n\n    size_t page_size = le32toh (page->page_size);\n    DEBUG (2, \"page at 0x%zx, size %zu\", off, page_size);\n    pages++;\n    if (page_size < smallest_page) smallest_page = page_size;\n    if (page_size > largest_page) largest_page = page_size;\n\n    if (page_size <= sizeof (struct ntreg_hbin_page) ||\n        (page_size & 0x0fff) != 0) {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: page size %zu at 0x%zx, bad registry\",\n                 filename, page_size, off);\n      goto error;\n    }\n\n    /* Read the blocks in this page. */\n    size_t blkoff;\n    struct ntreg_hbin_block *block;\n    size_t seg_len;\n    for (blkoff = off + 0x20;\n         blkoff < off + page_size;\n         blkoff += seg_len) {\n      blocks++;\n\n      int is_root = blkoff == h->rootoffs;\n      if (is_root)\n        seen_root_block = 1;\n\n      block = (struct ntreg_hbin_block *) ((char *) h->addr + blkoff);\n      int used;\n      seg_len = block_len (h, blkoff, &used);\n      if (seg_len <= 4 || (seg_len & 3) != 0) {\n        SET_ERRNO (ENOTSUP,\n                   \"%s: block size %\" PRIu32 \" at 0x%zx, bad registry\",\n                   filename, le32toh (block->seg_len), blkoff);\n        goto error;\n      }\n\n      if (h->msglvl >= 2) {\n        unsigned char *id = (unsigned char *) block->id;\n        int id0 = id[0], id1 = id[1];\n\n        fprintf (stderr, \"%s: %s: \"\n                 \"%s block id %d,%d (%c%c) at 0x%zx size %zu%s\\n\",\n                 \"hivex\", __func__,\n                 used ? \"used\" : \"free\",\n                 id0, id1,\n                 c_isprint (id0) ? id0 : '.',\n                 c_isprint (id1) ? id1 : '.',\n                 blkoff,\n                 seg_len, is_root ? \" (root)\" : \"\");\n      }\n\n      blocks_bytes += seg_len;\n      if (seg_len < smallest_block) smallest_block = seg_len;\n      if (seg_len > largest_block) largest_block = seg_len;\n\n      if (is_root && !used)\n        bad_root_block = 1;\n\n      if (used) {\n        used_blocks++;\n        used_size += seg_len;\n\n        /* Root block must be an nk-block. */\n        if (is_root && (block->id[0] != 'n' || block->id[1] != 'k'))\n          bad_root_block = 1;\n\n        /* Note this blkoff is a valid address. */\n        BITMAP_SET (h->bitmap, blkoff);\n      }\n    }\n  }\n\n  if (!seen_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: no root block found\", filename);\n    goto error;\n  }\n\n  if (bad_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: bad root block (free or not nk)\", filename);\n    goto error;\n  }\n\n  DEBUG (1, \"successfully read Windows Registry hive file:\\n\"\n         \"  pages:          %zu [sml: %zu, lge: %zu]\\n\"\n         \"  blocks:         %zu [sml: %zu, avg: %zu, lge: %zu]\\n\"\n         \"  blocks used:    %zu\\n\"\n         \"  bytes used:     %zu\",\n         pages, smallest_page, largest_page,\n         blocks, smallest_block, blocks_bytes / blocks, largest_block,\n         used_blocks, used_size);\n\n  return h;\n\n error:;\n  int err = errno;\n  if (h) {\n    free (h->bitmap);\n    if (h->addr && h->size && h->addr != MAP_FAILED) {\n      if (!h->writable)\n        munmap (h->addr, h->size);\n      else\n        free (h->addr);\n    }\n    if (h->fd >= 0)\n      close (h->fd);\n    free (h->filename);\n    free (h);\n  }\n  errno = err;\n  return NULL;\n}",
        "commit_message": "handle: Check that pages do not extend beyond the end of the file.\n\nThanks: Mahmoud Al-Qudsi",
        "cve_desc": "lib/handle.c in Hivex before 1.3.11 allows local users to execute arbitrary code and gain privileges via a small hive files, which triggers an out-of-bounds read or write.",
        "target": 1
      },
      {
        "idx": 211453,
        "reasoning": "The code is vulnerable to a stack overflow because the `_get_children` function recursively calls itself when encountering `ri`-records without a depth limit. An attacker can craft a malicious hive file with deeply nested `ri`-records, triggering excessive recursion and ultimately crashing the program.",
        "func": "_get_children (hive_h *h, hive_node_h blkoff,\n               offset_list *children, offset_list *blocks,\n               int flags)\n{\n  /* Add this intermediate block. */\n  if (_hivex_add_to_offset_list (blocks, blkoff) == -1)\n    return -1;\n\n  struct ntreg_hbin_block *block =\n    (struct ntreg_hbin_block *) ((char *) h->addr + blkoff);\n\n  size_t len = block_len (h, blkoff, NULL);\n\n  /* Points to lf-record?  (Note, also \"lh\" but that is basically the\n   * same as \"lf\" as far as we are concerned here).\n   */\n  if (block->id[0] == 'l' && (block->id[1] == 'f' || block->id[1] == 'h')) {\n    struct ntreg_lf_record *lf = (struct ntreg_lf_record *) block;\n\n    /* Check number of subkeys in the nk-record matches number of subkeys\n     * in the lf-record.\n     */\n    size_t nr_subkeys_in_lf = le16toh (lf->nr_keys);\n\n    if (8 + nr_subkeys_in_lf * 8 > len) {\n      SET_ERRNO (EFAULT, \"too many subkeys (%zu, %zu)\", nr_subkeys_in_lf, len);\n      return -1;\n    }\n\n    size_t i;\n    for (i = 0; i < nr_subkeys_in_lf; ++i) {\n      hive_node_h subkey = le32toh (lf->keys[i].offset);\n      subkey += 0x1000;\n      if (check_child_is_nk_block (h, subkey, flags) == -1) {\n        if (h->unsafe) {\n          DEBUG (2, \"subkey at 0x%zx is not an NK block, skipping\", subkey);\n          continue;\n        } else {\n          return -1;\n        }\n      }\n      if (_hivex_add_to_offset_list (children, subkey) == -1)\n        return -1;\n    }\n  }\n  /* Points to li-record? */\n  else if (block->id[0] == 'l' && block->id[1] == 'i') {\n    /* li-records are formatted the same as ri-records, but they\n     * contain direct links to child records (same as lf/lh), so\n     * we treat them the same way as lf/lh.\n     */\n    struct ntreg_ri_record *ri = (struct ntreg_ri_record *) block;\n\n    /* Check number of subkeys in the nk-record matches number of subkeys\n     * in the li-record.\n     */\n    size_t nr_offsets = le16toh (ri->nr_offsets);\n\n    if (8 + nr_offsets * 4 > len) {\n      SET_ERRNO (EFAULT, \"too many offsets (%zu, %zu)\", nr_offsets, len);\n      return -1;\n    }\n\n    size_t i;\n    for (i = 0; i < nr_offsets; ++i) {\n      hive_node_h subkey = le32toh (ri->offset[i]);\n      subkey += 0x1000;\n      if (check_child_is_nk_block (h, subkey, flags) == -1) {\n        if (h->unsafe) {\n          DEBUG (2, \"subkey at 0x%zx is not an NK block, skipping\", subkey);\n          continue;\n        } else {\n          return -1;\n        }\n      }\n      if (_hivex_add_to_offset_list (children, subkey) == -1)\n        return -1;\n    }\n  }\n  /* Points to ri-record? */\n  else if (block->id[0] == 'r' && block->id[1] == 'i') {\n    struct ntreg_ri_record *ri = (struct ntreg_ri_record *) block;\n\n    size_t nr_offsets = le16toh (ri->nr_offsets);\n\n    if (8 + nr_offsets * 4 > len) {\n      SET_ERRNO (EFAULT, \"too many offsets (%zu, %zu)\", nr_offsets, len);\n      return -1;\n    }\n\n    /* Copy list of children. */\n    size_t i;\n    for (i = 0; i < nr_offsets; ++i) {\n      hive_node_h offset = le32toh (ri->offset[i]);\n      offset += 0x1000;\n      if (!IS_VALID_BLOCK (h, offset)) {\n        if (h->unsafe) {\n          DEBUG (2, \"ri-offset is not a valid block (0x%zx), skipping\", offset);\n          continue;\n        } else {\n          SET_ERRNO (EFAULT, \"ri-offset is not a valid block (0x%zx)\", offset);\n          return -1;\n        }\n      }\n\n      if (_get_children (h, offset, children, blocks, flags) == -1)\n        return -1;\n    }\n  }\n  else {\n    SET_ERRNO (ENOTSUP,\n               \"subkey block is not lf/lh/li/ri (0x%zx, %d, %d)\",\n               blkoff, block->id[0], block->id[1]);\n    return -1;\n  }\n\n  return 0;\n}",
        "commit_message": "lib/node.c: Limit recursion in ri-records (CVE-2021-3622)\n\nWindows Registry hive \"ri\"-records are arbitrarily nested B-tree-like\nstructures:\n\n  +-------------+\n  | ri          |\n  |-------------|\n  | nr_offsets  |\n  |   offset[0] ------>  points to another lf/lh/li/ri block\n  |   offset[1] ------>\n  |   offset[2] ------>\n  +-------------+\n\nIt is possible to construct a hive with a very deeply nested tree of\nri-records, causing the internal _get_children function to recurse to\nany depth which can cause programs linked to hivex to crash with a\nstack overflow.\n\nSince it is not thought that deeply nested ri-records occur in real\nhives, limit recursion depth.  If you hit this limit you will see the\nfollowing error and the operation will return an error instead of\ncrashing:\n\n  \\> ls\n  hivex: _get_children: returning EINVAL because: ri-record nested to depth >= 32\n  ls: Invalid argument\n\nThanks to Jeremy Galindo for finding and reporting this bug.\n\nReported-by: Jeremy Galindo, Sr Security Engineer, Datto.com\nSigned-off-by: Richard W.M. Jones <rjones@redhat.com>\nFixes: CVE-2021-3622\nFixes: https://bugzilla.redhat.com/show_bug.cgi?id=1975489\n(cherry picked from commit 781a12c4a49dd81365c9c567c5aa5e19e894ba0e)",
        "cve_desc": "A flaw was found in the hivex library. This flaw allows an attacker to input a specially crafted Windows Registry (hive) file, which would cause hivex to recursively call the _get_children() function, leading to a stack overflow. The highest threat from this vulnerability is to system availability.",
        "target": 1
      },
      {
        "idx": 211492,
        "reasoning": "The code is vulnerable because it doesn't adequately validate the file size before attempting to map or read the hive file into memory, potentially leading to out-of-bounds reads or writes when processing small, crafted hive files. Specifically, the initial check `if (h->size < 8192)` prevents opening files *smaller* than 8192 bytes, but doesn't prevent processing files that are just large enough to pass this check but still contain malicious data that can cause out-of-bounds access during subsequent operations like page and block parsing.",
        "func": "hivex_open (const char *filename, int flags)\n{\n  hive_h *h = NULL;\n\n  assert (sizeof (struct ntreg_header) == 0x1000);\n  assert (offsetof (struct ntreg_header, csum) == 0x1fc);\n\n  h = calloc (1, sizeof *h);\n  if (h == NULL)\n    goto error;\n\n  h->msglvl = flags & HIVEX_OPEN_MSGLVL_MASK;\n\n  const char *debug = getenv (\"HIVEX_DEBUG\");\n  if (debug && STREQ (debug, \"1\"))\n    h->msglvl = 2;\n\n  DEBUG (2, \"created handle %p\", h);\n\n  h->writable = !!(flags & HIVEX_OPEN_WRITE);\n  h->filename = strdup (filename);\n  if (h->filename == NULL)\n    goto error;\n\n#ifdef O_CLOEXEC\n  h->fd = open (filename, O_RDONLY | O_CLOEXEC | O_BINARY);\n#else\n  h->fd = open (filename, O_RDONLY | O_BINARY);\n#endif\n  if (h->fd == -1)\n    goto error;\n#ifndef O_CLOEXEC\n  fcntl (h->fd, F_SETFD, FD_CLOEXEC);\n#endif\n\n  struct stat statbuf;\n  if (fstat (h->fd, &statbuf) == -1)\n    goto error;\n\n  h->size = statbuf.st_size;\n\n  if (!h->writable) {\n    h->addr = mmap (NULL, h->size, PROT_READ, MAP_SHARED, h->fd, 0);\n    if (h->addr == MAP_FAILED)\n      goto error;\n\n    DEBUG (2, \"mapped file at %p\", h->addr);\n  } else {\n    h->addr = malloc (h->size);\n    if (h->addr == NULL)\n      goto error;\n\n    if (full_read (h->fd, h->addr, h->size) < h->size)\n      goto error;\n\n    /* We don't need the file descriptor along this path, since we\n     * have read all the data.\n     */\n    if (close (h->fd) == -1)\n      goto error;\n    h->fd = -1;\n  }\n\n  /* Check header. */\n  if (h->hdr->magic[0] != 'r' ||\n      h->hdr->magic[1] != 'e' ||\n      h->hdr->magic[2] != 'g' ||\n      h->hdr->magic[3] != 'f') {\n    SET_ERRNO (ENOTSUP,\n               \"%s: not a Windows NT Registry hive file\", filename);\n    goto error;\n  }\n\n  /* Check major version. */\n  uint32_t major_ver = le32toh (h->hdr->major_ver);\n  if (major_ver != 1) {\n    SET_ERRNO (ENOTSUP,\n               \"%s: hive file major version %\" PRIu32 \" (expected 1)\",\n               filename, major_ver);\n    goto error;\n  }\n\n  h->bitmap = calloc (1 + h->size / 32, 1);\n  if (h->bitmap == NULL)\n    goto error;\n\n  /* Header checksum. */\n  uint32_t sum = header_checksum (h);\n  if (sum != le32toh (h->hdr->csum)) {\n    SET_ERRNO (EINVAL, \"%s: bad checksum in hive header\", filename);\n    goto error;\n  }\n\n  /* Last modified time. */\n  h->last_modified = le64toh ((int64_t) h->hdr->last_modified);\n\n  if (h->msglvl >= 2) {\n    char *name = _hivex_windows_utf16_to_utf8 (h->hdr->name, 64);\n\n    fprintf (stderr,\n             \"hivex_open: header fields:\\n\"\n             \"  file version             %\" PRIu32 \".%\" PRIu32 \"\\n\"\n             \"  sequence nos             %\" PRIu32 \" %\" PRIu32 \"\\n\"\n             \"    (sequences nos should match if hive was synched at shutdown)\\n\"\n             \"  last modified            %\" PRIu64 \"\\n\"\n             \"    (Windows filetime, x 100 ns since 1601-01-01)\\n\"\n             \"  original file name       %s\\n\"\n             \"    (only 32 chars are stored, name is probably truncated)\\n\"\n             \"  root offset              0x%x + 0x1000\\n\"\n             \"  end of last page         0x%x + 0x1000 (total file size 0x%zx)\\n\"\n             \"  checksum                 0x%x (calculated 0x%x)\\n\",\n             major_ver, le32toh (h->hdr->minor_ver),\n             le32toh (h->hdr->sequence1), le32toh (h->hdr->sequence2),\n             h->last_modified,\n             name ? name : \"(conversion failed)\",\n             le32toh (h->hdr->offset),\n             le32toh (h->hdr->blocks), h->size,\n             le32toh (h->hdr->csum), sum);\n    free (name);\n  }\n\n  h->rootoffs = le32toh (h->hdr->offset) + 0x1000;\n  h->endpages = le32toh (h->hdr->blocks) + 0x1000;\n\n  DEBUG (2, \"root offset = 0x%zx\", h->rootoffs);\n\n  /* We'll set this flag when we see a block with the root offset (ie.\n   * the root block).\n   */\n  int seen_root_block = 0, bad_root_block = 0;\n\n  /* Collect some stats. */\n  size_t pages = 0;           /* Number of hbin pages read. */\n  size_t smallest_page = SIZE_MAX, largest_page = 0;\n  size_t blocks = 0;          /* Total number of blocks found. */\n  size_t smallest_block = SIZE_MAX, largest_block = 0, blocks_bytes = 0;\n  size_t used_blocks = 0;     /* Total number of used blocks found. */\n  size_t used_size = 0;       /* Total size (bytes) of used blocks. */\n\n  /* Read the pages and blocks.  The aim here is to be robust against\n   * corrupt or malicious registries.  So we make sure the loops\n   * always make forward progress.  We add the address of each block\n   * we read to a hash table so pointers will only reference the start\n   * of valid blocks.\n   */\n  size_t off;\n  struct ntreg_hbin_page *page;\n  for (off = 0x1000; off < h->size; off += le32toh (page->page_size)) {\n    if (off >= h->endpages)\n      break;\n\n    page = (struct ntreg_hbin_page *) ((char *) h->addr + off);\n    if (page->magic[0] != 'h' ||\n        page->magic[1] != 'b' ||\n        page->magic[2] != 'i' ||\n        page->magic[3] != 'n') {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: trailing garbage at end of file \"\n                 \"(at 0x%zx, after %zu pages)\",\n                 filename, off, pages);\n      goto error;\n    }\n\n    size_t page_size = le32toh (page->page_size);\n    DEBUG (2, \"page at 0x%zx, size %zu\", off, page_size);\n    pages++;\n    if (page_size < smallest_page) smallest_page = page_size;\n    if (page_size > largest_page) largest_page = page_size;\n\n    if (page_size <= sizeof (struct ntreg_hbin_page) ||\n        (page_size & 0x0fff) != 0) {\n      SET_ERRNO (ENOTSUP,\n                 \"%s: page size %zu at 0x%zx, bad registry\",\n                 filename, page_size, off);\n      goto error;\n    }\n\n    /* Read the blocks in this page. */\n    size_t blkoff;\n    struct ntreg_hbin_block *block;\n    size_t seg_len;\n    for (blkoff = off + 0x20;\n         blkoff < off + page_size;\n         blkoff += seg_len) {\n      blocks++;\n\n      int is_root = blkoff == h->rootoffs;\n      if (is_root)\n        seen_root_block = 1;\n\n      block = (struct ntreg_hbin_block *) ((char *) h->addr + blkoff);\n      int used;\n      seg_len = block_len (h, blkoff, &used);\n      if (seg_len <= 4 || (seg_len & 3) != 0) {\n        SET_ERRNO (ENOTSUP,\n                   \"%s: block size %\" PRIu32 \" at 0x%zx, bad registry\",\n                   filename, le32toh (block->seg_len), blkoff);\n        goto error;\n      }\n\n      if (h->msglvl >= 2) {\n        unsigned char *id = (unsigned char *) block->id;\n        int id0 = id[0], id1 = id[1];\n\n        fprintf (stderr, \"%s: %s: \"\n                 \"%s block id %d,%d (%c%c) at 0x%zx size %zu%s\\n\",\n                 \"hivex\", __func__,\n                 used ? \"used\" : \"free\",\n                 id0, id1,\n                 c_isprint (id0) ? id0 : '.',\n                 c_isprint (id1) ? id1 : '.',\n                 blkoff,\n                 seg_len, is_root ? \" (root)\" : \"\");\n      }\n\n      blocks_bytes += seg_len;\n      if (seg_len < smallest_block) smallest_block = seg_len;\n      if (seg_len > largest_block) largest_block = seg_len;\n\n      if (is_root && !used)\n        bad_root_block = 1;\n\n      if (used) {\n        used_blocks++;\n        used_size += seg_len;\n\n        /* Root block must be an nk-block. */\n        if (is_root && (block->id[0] != 'n' || block->id[1] != 'k'))\n          bad_root_block = 1;\n\n        /* Note this blkoff is a valid address. */\n        BITMAP_SET (h->bitmap, blkoff);\n      }\n    }\n  }\n\n  if (!seen_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: no root block found\", filename);\n    goto error;\n  }\n\n  if (bad_root_block) {\n    SET_ERRNO (ENOTSUP, \"%s: bad root block (free or not nk)\", filename);\n    goto error;\n  }\n\n  DEBUG (1, \"successfully read Windows Registry hive file:\\n\"\n         \"  pages:          %zu [sml: %zu, lge: %zu]\\n\"\n         \"  blocks:         %zu [sml: %zu, avg: %zu, lge: %zu]\\n\"\n         \"  blocks used:    %zu\\n\"\n         \"  bytes used:     %zu\",\n         pages, smallest_page, largest_page,\n         blocks, smallest_block, blocks_bytes / blocks, largest_block,\n         used_blocks, used_size);\n\n  return h;\n\n error:;\n  int err = errno;\n  if (h) {\n    free (h->bitmap);\n    if (h->addr && h->size && h->addr != MAP_FAILED) {\n      if (!h->writable)\n        munmap (h->addr, h->size);\n      else\n        free (h->addr);\n    }\n    if (h->fd >= 0)\n      close (h->fd);\n    free (h->filename);\n    free (h);\n  }\n  errno = err;\n  return NULL;\n}",
        "commit_message": "handle: Refuse to open files < 8192 bytes in size.\n\nThese cannot be valid hives, since they don't contain a full header\npage and at least a single page of data (in other words they couldn't\ncontain a root node).\n\nThanks: Mahmoud Al-Qudsi",
        "cve_desc": "lib/handle.c in Hivex before 1.3.11 allows local users to execute arbitrary code and gain privileges via a small hive files, which triggers an out-of-bounds read or write.",
        "target": 1
      }
    ]
  },
  "htmldoc": {
    "0": [],
    "1": []
  },
  "htslib": {
    "0": [],
    "1": []
  },
  "httpd": {
    "0": [
      {
        "idx": 246509,
        "reasoning": "This code snippet focuses on registering authentication providers and doesn't directly handle user input or sensitive operations that would introduce vulnerabilities. The commit message explicitly addresses the *replacement* of an unusable function related to authentication hooks, indicating a security fix rather than the introduction of a new flaw; therefore, the provided code itself isn't flagged as vulnerable.\n\n\n\n",
        "func": "AP_DECLARE(apr_status_t) ap_register_auth_provider(apr_pool_t *pool,\n                                                   const char *provider_group,\n                                                   const char *provider_name,\n                                                   const char *provider_version,\n                                                   const void *provider,\n                                                   int type)\n{\n    if ((type & AP_AUTH_INTERNAL_MASK) == AP_AUTH_INTERNAL_PER_CONF) {\n        ++auth_internal_per_conf_providers;\n    }\n\n    return ap_register_provider(pool, provider_group, provider_name,\n                                provider_version, provider);\n}",
        "commit_message": "SECURITY: CVE-2015-3185 (cve.mitre.org)\n\nReplacement of ap_some_auth_required (unusable in Apache httpd 2.4)\nwith new ap_some_authn_required and ap_force_authn hook.\n\nSubmitted by: breser\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1684524 13f79535-47bb-0310-9956-ffa450edef68",
        "cve_desc": "The ap_some_auth_required function in server/request.c in the Apache HTTP Server 2.4.x before 2.4.14 does not consider that a Require directive may be associated with an authorization setting rather than an authentication setting, which allows remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging the presence of a module that relies on the 2.2 API behavior.",
        "target": 0
      },
      {
        "idx": 246510,
        "reasoning": "This code snippet introduces new hooks for authentication checks (`ap_hook_check_access`, `ap_some_authn_required`, `ap_force_authn`) and doesn't directly introduce any vulnerabilities; rather, it *addresses* a known issue (CVE-2015-3185) by replacing an unusable function. The commit message explicitly states it's a security fix, and the code itself appears to be focused on properly registering and managing authentication hooks, not introducing flaws.\n\n\n\n",
        "func": "AP_DECLARE(void) ap_hook_check_access(ap_HOOK_access_checker_t *pf,\n                                      const char * const *aszPre,\n                                      const char * const *aszSucc,\n                                      int nOrder, int type)\n{\n    if ((type & AP_AUTH_INTERNAL_MASK) == AP_AUTH_INTERNAL_PER_CONF) {\n        ++auth_internal_per_conf_hooks;\n    }\n\n    ap_hook_access_checker(pf, aszPre, aszSucc, nOrder);\n}",
        "commit_message": "SECURITY: CVE-2015-3185 (cve.mitre.org)\n\nReplacement of ap_some_auth_required (unusable in Apache httpd 2.4)\nwith new ap_some_authn_required and ap_force_authn hook.\n\nSubmitted by: breser\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1684524 13f79535-47bb-0310-9956-ffa450edef68",
        "cve_desc": "The ap_some_auth_required function in server/request.c in the Apache HTTP Server 2.4.x before 2.4.14 does not consider that a Require directive may be associated with an authorization setting rather than an authentication setting, which allows remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging the presence of a module that relies on the 2.2 API behavior.",
        "target": 0
      },
      {
        "idx": 246511,
        "reasoning": "This code snippet defines a utility function `ap_is_initial_req` to determine if a request is the initial request in a connection, and it doesn't directly handle authentication or request processing in a way that introduces vulnerabilities. The commit message focuses on replacing authentication hooks, but this specific code isn't related to those changes and doesn't appear to introduce any security flaws itself.\n\n\n\n",
        "func": "AP_DECLARE(int) ap_is_initial_req(request_rec *r)\n{\n    return (r->main == NULL)       /* otherwise, this is a sub-request */\n           && (r->prev == NULL);   /* otherwise, this is an internal redirect */\n}",
        "commit_message": "SECURITY: CVE-2015-3185 (cve.mitre.org)\n\nReplacement of ap_some_auth_required (unusable in Apache httpd 2.4)\nwith new ap_some_authn_required and ap_force_authn hook.\n\nSubmitted by: breser\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1684524 13f79535-47bb-0310-9956-ffa450edef68",
        "cve_desc": "The ap_some_auth_required function in server/request.c in the Apache HTTP Server 2.4.x before 2.4.14 does not consider that a Require directive may be associated with an authorization setting rather than an authentication setting, which allows remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging the presence of a module that relies on the 2.2 API behavior.",
        "target": 0
      },
      {
        "idx": 246512,
        "reasoning": "This code snippet is not directly related to the CVE-2015-3185 fix described in the commit message, which concerns authentication hooks (`ap_some_auth_required`, `ap_some_authn_required`, and `ap_force_authn`). The provided code focuses on handling bucket brigades within sub-requests and output filters, and doesn't appear to introduce or exacerbate any authentication-related vulnerabilities.\n\n\n\n",
        "func": "AP_CORE_DECLARE_NONSTD(apr_status_t) ap_sub_req_output_filter(ap_filter_t *f,\n                                                              apr_bucket_brigade *bb)\n{\n    apr_bucket *e = APR_BRIGADE_LAST(bb);\n\n    if (APR_BUCKET_IS_EOS(e)) {\n        apr_bucket_delete(e);\n    }\n\n    if (!APR_BRIGADE_EMPTY(bb)) {\n        return ap_pass_brigade(f->next, bb);\n    }\n\n    return APR_SUCCESS;\n}",
        "commit_message": "SECURITY: CVE-2015-3185 (cve.mitre.org)\n\nReplacement of ap_some_auth_required (unusable in Apache httpd 2.4)\nwith new ap_some_authn_required and ap_force_authn hook.\n\nSubmitted by: breser\n\n\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1684524 13f79535-47bb-0310-9956-ffa450edef68",
        "cve_desc": "The ap_some_auth_required function in server/request.c in the Apache HTTP Server 2.4.x before 2.4.14 does not consider that a Require directive may be associated with an authorization setting rather than an authentication setting, which allows remote attackers to bypass intended access restrictions in opportunistic circumstances by leveraging the presence of a module that relies on the 2.2 API behavior.",
        "target": 0
      }
    ],
    "1": []
  },
  "icu": {
    "0": [
      {
        "idx": 474617,
        "reasoning": "This code snippet is not directly vulnerable to the integer overflow issue described in the commit message \"ICU-20246 Fixing another integer overflow in number parsing.\" The code simply assigns a `double` value to a `double` member, and integer overflows relate to integer data types, not floating-point types; therefore, no overflow can occur here.\n\n\n\n",
        "func": "Formattable::Formattable(double value)\n{\n    init();\n    fType = kDouble;\n    fValue.fDouble = value;\n}",
        "commit_message": "ICU-20246 Fixing another integer overflow in number parsing.",
        "cve_desc": "International Components for Unicode (ICU) for C/C++ 63.1 has an integer overflow in number::impl::DecimalQuantity::toScientificString() in i18n/number_decimalquantity.cpp.",
        "target": 0
      }
    ],
    "1": []
  },
  "inspircd": {
    "0": [],
    "1": []
  },
  "ipmitool": {
    "0": [
      {
        "idx": 301823,
        "reasoning": "This code appears to be safe from the buffer overflow vulnerability described in the commit message and CVE-2020-5208. The code includes checks to ensure that `len` (the amount of data to copy) does not exceed the remaining buffer space (`fru.size - offset`) or the received data length (`rsp->data_len - 1`), preventing out-of-bounds writes to `spd_data`.",
        "func": "ipmi_spd_print_fru(struct ipmi_intf * intf, uint8_t id)\n{\n\tstruct ipmi_rs * rsp;\n\tstruct ipmi_rq req;\n\tstruct fru_info fru;\n\tuint8_t *spd_data, msg_data[4];\n\tuint32_t len, offset;\n\n\tmsg_data[0] = id;\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_STORAGE;\n\treq.msg.cmd = GET_FRU_INFO;\n\treq.msg.data = msg_data;\n\treq.msg.data_len = 1;\n\n\trsp = intf->sendrecv(intf, &req);\n\tif (!rsp) {\n\t\tprintf(\" Device not present (No Response)\\n\");\n\t\treturn -1;\n\t}\n\tif (rsp->ccode) {\n\t\tprintf(\" Device not present (%s)\\n\",\n\t\t       val2str(rsp->ccode, completion_code_vals));\n\t\treturn -1;\n\t}\n\n\tfru.size = (rsp->data[1] << 8) | rsp->data[0];\n\tfru.access = rsp->data[2] & 0x1;\n\n\tlprintf(LOG_DEBUG, \"fru.size = %d bytes (accessed by %s)\",\n\t\tfru.size, fru.access ? \"words\" : \"bytes\");\n\n\n\tif (fru.size < 1) {\n\t\tlprintf(LOG_ERR, \" Invalid FRU size %d\", fru.size);\n\t\treturn -1;\n\t}\n\n        spd_data = malloc(fru.size);\n\n        if (!spd_data) {\n\t\tprintf(\" Unable to malloc memory for spd array of size=%d\\n\",\n\t\t       fru.size);\n\t\treturn -1;\n        }\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_STORAGE;\n\treq.msg.cmd = GET_FRU_DATA;\n\treq.msg.data = msg_data;\n\treq.msg.data_len = 4;\n\n\toffset = 0;\n\tmemset(spd_data, 0, fru.size);\n\tdo {\n\t\tmsg_data[0] = id;\n\t\tmsg_data[1] = offset & 0xFF;\n\t\tmsg_data[2] = offset >> 8;\n\t\tmsg_data[3] = FRU_DATA_RQST_SIZE;\n\n\t\trsp = intf->sendrecv(intf, &req);\n\t\tif (!rsp) {\n\t\t\tprintf(\" Device not present (No Response)\\n\");\n                        free(spd_data);\n                        spd_data = NULL;\n\t\t\treturn -1;\n\t\t}\n\t\tif (rsp->ccode) {\n\t\t\tprintf(\" Device not present (%s)\\n\",\n\t\t\t       val2str(rsp->ccode, completion_code_vals));\n\n                        free(spd_data);\n                        spd_data = NULL;\n\t\t\t/* Timeouts are acceptable. No DIMM in the socket */\n\t\t\tif (rsp->ccode == 0xc3)\n\t\t\t\treturn 1;\n\n\t\t\treturn -1;\n\t\t}\n\n\t\tlen = rsp->data[0];\n\t\tif(rsp->data_len < 1\n\t\t   || len > rsp->data_len - 1\n\t\t   || len > fru.size - offset)\n\t\t{\n\t\t\tprintf(\" Not enough buffer size\");\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(&spd_data[offset], rsp->data + 1, len);\n\t\toffset += len;\n\t} while (offset < fru.size);\n\n\t/* now print spd info */\n\tipmi_spd_print(spd_data, offset);\n        free(spd_data);\n        spd_data = NULL;\n\n\treturn 0;\n}",
        "commit_message": "fru: Fix buffer overflow in ipmi_spd_print_fru\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_spd_print_fru` function has a similar issue as the one fixed\nby the previous commit in `read_fru_area_section`. An initial request is\nmade to get the `fru.size`, which is used as the size for the allocation\nof `spd_data`. Inside a loop, further requests are performed to get the\ncopy sizes which are not checked before being used as the size for a\ncopy into the buffer.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 0
      },
      {
        "idx": 301824,
        "reasoning": "This code is likely safe with respect to the vulnerability described in the commit message. While the function handles potentially variable-length data (`spd_data`) and performs multiple checks for minimum lengths (`len < 92`, `len < 148`, `len < 348`, `len < 100`), it doesn't appear to directly use unchecked values from the data as sizes for memory copy operations like `memcpy` or similar functions, which was the root cause of the previously identified buffer overflows. \n\n\n\n",
        "func": "ipmi_spd_print(uint8_t *spd_data, int len)\n{\n\tint k = 0;\n\tint ii = 0;\n\n\tif (len < 92)\n\t\treturn -1; /* we need first 91 bytes to do our thing */\n\n\tprintf(\" Memory Type           : %s\\n\",\n\t       val2str(spd_data[2], spd_memtype_vals));\n\n\tif (spd_data[2] == 0x0B)\t/* DDR3 SDRAM */\n\t{\n\t\tint iPN;\n\t\tint sdram_cap = 0;\n\t\tint pri_bus_width = 0;\n\t\tint sdram_width = 0;\n\t\tint ranks = 0;\n\t\tint mem_size = 0;\n\n\t\tif (len < 148)\n\t\t\treturn -1; /* we need first 91 bytes to do our thing */\n\n\n\t\tsdram_cap = ldexp(256,(spd_data[4]&15));\n\t\tpri_bus_width = ldexp(8,(spd_data[8]&7));\n\t\tsdram_width = ldexp(4,(spd_data[7]&7));\n\t\tranks = ldexp(1,((spd_data[7]&0x3F)>>3));\n\t\tmem_size = (sdram_cap/8) * (pri_bus_width/sdram_width) * ranks;\n\t\tprintf(\" SDRAM Capacity        : %d MB\\n\", sdram_cap );\n\t\tprintf(\" Memory Banks          : %s\\n\", val2str(spd_data[4]>>4, ddr3_banks_vals));\n\t\tprintf(\" Primary Bus Width     : %d bits\\n\", pri_bus_width );\n\t\tprintf(\" SDRAM Device Width    : %d bits\\n\", sdram_width );\n\t\tprintf(\" Number of Ranks       : %d\\n\", ranks );\n\t\tprintf(\" Memory size           : %d MB\\n\", mem_size );\n\n\t\t/* printf(\" Memory Density        : %s\\n\", val2str(spd_data[4]&15, ddr3_density_vals)); */\n\t\tprintf(\" 1.5 V Nominal Op      : %s\\n\", (((spd_data[6]&1) != 0) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" 1.35 V Nominal Op     : %s\\n\", (((spd_data[6]&2) != 0) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" 1.2X V Nominal Op     : %s\\n\", (((spd_data[6]&4) != 0) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" Error Detect/Cor      : %s\\n\", val2str(spd_data[8]>>3, ddr3_ecc_vals));\n\n\t\tprintf(\" Manufacturer          : \");\n\t\tswitch (spd_data[117]&127)\n\t\t{\n\t\tcase\t0:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id1_vals));\n\t\t\tbreak;\n\n\t\tcase\t1:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id2_vals));\n\t\t\tbreak;\n\n\t\tcase\t2:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id3_vals));\n\t\t\tbreak;\n\n\t\tcase\t3:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id4_vals));\n\t\t\tbreak;\n\n\t\tcase\t4:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id5_vals));\n\t\t\tbreak;\n\n\t\tcase\t5:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id6_vals));\n\t\t\tbreak;\n\n\t\tcase\t6:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id7_vals));\n\t\t\tbreak;\n\n\t\tcase\t7:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id8_vals));\n\t\t\tbreak;\n\n\t\tcase\t8:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[118], jedec_id9_vals));\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tprintf(\"%s\\n\", \"JEDEC JEP106 update required\" );\n\n\t\t}\n\n\t\tprintf(\" Manufacture Date      : year %c%c week %c%c\\n\",\n\t\t'0'+(spd_data[120]>>4), '0'+(spd_data[120]&15), '0'+(spd_data[121]>>4), '0'+(spd_data[121]&15) );\n\n\t\tprintf(\" Serial Number         : %02x%02x%02x%02x\\n\",\n\t\tspd_data[122], spd_data[123], spd_data[124], spd_data[125]);\n\n\t\tprintf(\" Part Number           : \");\n\t\tfor (iPN = 128; iPN < 146; iPN++) {\n\t\t\tprintf(\"%c\", spd_data[iPN]);\n\t\t}\n\t\tprintf(\"\\n\");\n\t} else if (spd_data[2] == 0x0C)\t/* DDR4 SDRAM */\n\t{\n\t\tint i;\n\t\tint sdram_cap = 0;\n\t\tint pri_bus_width = 0;\n\t\tint sdram_width = 0;\n\t\tint mem_size = 0;\n\t\tint lrank_dimm;\n\t\tuint32_t year;\n\t\tuint32_t week;\n\n\t\tif (len < 348)\n\t\t\treturn -1;\n\n\t\t/* \"Logical rank\" referes to the individually addressable die\n\t\t * in a 3DS stack and has no meaning for monolithic or\n\t\t * multi-load stacked SDRAMs; however, for the purposes of\n\t\t * calculating the capacity of the module, one should treat\n\t\t * monolithic and multi-load stack SDRAMs as having one logical\n\t\t * rank per package rank.\n\t\t */\n\t\tlrank_dimm = (spd_data[12]>>3&0x3) + 1; /* Number of Package Ranks per DIMM */\n\t\tif ((spd_data[6] & 0x3) == 0x2) { /* 3DS package Type */\n\t\t\tlrank_dimm *= ((spd_data[6]>>4)&0x3) + 1; /* Die Count */\n\t\t}\n\t\tsdram_cap = ldexp(256,(spd_data[4]&15));\n\t\tpri_bus_width = ldexp(8,(spd_data[13]&7));\n\t\tsdram_width = ldexp(4,(spd_data[12]&7));\n\t\tmem_size = (sdram_cap/8) * (pri_bus_width/sdram_width) * lrank_dimm;\n\t\tprintf(\" SDRAM Package Type    : %s\\n\", val2str((spd_data[6]>>7), ddr4_package_type));\n\t\tprintf(\" Technology            : %s\\n\", val2str((spd_data[3]&15), ddr4_technology_type));\n\t\tprintf(\" SDRAM Die Count       : %d\\n\", ((spd_data[6]>>4) & 3)+1);\n\t\tprintf(\" SDRAM Capacity        : %d Mb\\n\", sdram_cap );\n\t\tprintf(\" Memory Bank Group     : %s\\n\", val2str((spd_data[4]>>6 & 0x3), ddr4_bank_groups));\n\t\tprintf(\" Memory Banks          : %s\\n\", val2str((spd_data[4]>>4 & 0x3), ddr4_banks_vals));\n\t\tprintf(\" Primary Bus Width     : %d bits\\n\", pri_bus_width );\n\t\tprintf(\" SDRAM Device Width    : %d bits\\n\", sdram_width );\n\t\tprintf(\" Logical Rank per DIMM : %d\\n\", lrank_dimm );\n\t\tprintf(\" Memory size           : %d MB\\n\", mem_size );\n\n\t\tprintf(\" Memory Density        : %s\\n\", val2str(spd_data[4]&15, ddr4_density_vals));\n\t\tprintf(\" 1.2 V Nominal Op      : %s\\n\", (((spd_data[11]&3) != 3) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" TBD1 V Nominal Op     : %s\\n\", (((spd_data[11]>>2&3) != 3) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" TBD2 V Nominal Op     : %s\\n\", (((spd_data[11]>>4&3) != 3) ? \"No\":\"Yes\" ) );\n\t\tprintf(\" Error Detect/Cor      : %s\\n\", val2str(spd_data[13]>>3, ddr4_ecc_vals));\n\n\t\tprintf(\" Manufacturer          : \");\n\t\tswitch (spd_data[320]&127)\n\t\t{\n\t\tcase\t0:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id1_vals));\n\t\t\tbreak;\n\n\t\tcase\t1:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id2_vals));\n\t\t\tbreak;\n\n\t\tcase\t2:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id3_vals));\n\t\t\tbreak;\n\n\t\tcase\t3:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id4_vals));\n\t\t\tbreak;\n\n\t\tcase\t4:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id5_vals));\n\t\t\tbreak;\n\n\t\tcase\t5:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id6_vals));\n\t\t\tbreak;\n\n\t\tcase\t6:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id7_vals));\n\t\t\tbreak;\n\n\t\tcase\t7:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id8_vals));\n\t\t\tbreak;\n\n\t\tcase\t8:\n\t\t\tprintf(\"%s\\n\", val2str(spd_data[321], jedec_id9_vals));\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tprintf(\"%s\\n\", \"JEDEC JEP106 update required\");\n\n\t\t}\n\n\t\tyear = ((spd_data[323] >> 4) * 10) + (spd_data[323] & 15);\n\t\tweek = ((spd_data[324]>>4) * 10) + (spd_data[324] & 15);\n\t\tprintf(\" Manufacture Date      : year %4d week %2d\\n\",\n\t\t       2000 + year, week);\n\n\t\tprintf(\" Serial Number         : %02x%02x%02x%02x\\n\",\n\t\tspd_data[325], spd_data[326], spd_data[327], spd_data[328]);\n\n\t\tprintf(\" Part Number           : \");\n\t\tfor (i=329; i <= 348; i++)\n\t\t{\n\t\t\tprintf( \"%c\", spd_data[i]);\n\t\t}\n\t\tprintf(\"\\n\");\n\t}\n\telse\n\t{\n\t\tif (len < 100) {\n\t\t\treturn (-1);\n\t\t}\n\t\tii = (spd_data[3] & 0x0f) + (spd_data[4] & 0x0f) - 17;\n\t\tk = ((spd_data[5] & 0x7) + 1) * spd_data[17];\n\n\t\tif(ii > 0 && ii <= 12 && k > 0) {\n\t\t\tprintf(\" Memory Size           : %d MB\\n\", ((1 << ii) * k));\n\t\t} else {\n\t\t\tprintf(\" Memory Size    INVALID: %d, %d, %d, %d\\n\", spd_data[3],\n\t\t\t\t\tspd_data[4], spd_data[5], spd_data[17]);\n\t\t}\n\t\tprintf(\" Voltage Intf          : %s\\n\",\n\t\tval2str(spd_data[8], spd_voltage_vals));\n\t\tprintf(\" Error Detect/Cor      : %s\\n\",\n\t\tval2str(spd_data[11], spd_config_vals));\n\n\t\t/* handle jedec table bank continuation values */\n\t\tprintf(\" Manufacturer          : \");\n\t\tif (spd_data[64] != 0x7f)\n\t\t\tprintf(\"%s\\n\",\n\t\t\tval2str(spd_data[64], jedec_id1_vals));\n\t\telse {\n\t\t\tif (spd_data[65] != 0x7f)\n\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\tval2str(spd_data[65], jedec_id2_vals));\n\t\t\telse {\n\t\t\t\tif (spd_data[66] != 0x7f)\n\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\tval2str(spd_data[66], jedec_id3_vals));\n\t\t\t\telse {\n\t\t\t\t\tif (spd_data[67] != 0x7f)\n\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\tval2str(spd_data[67], jedec_id4_vals));\n\t\t\t\t\telse {\n\t\t\t\t\t\tif (spd_data[68] != 0x7f)\n\t\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\t\tval2str(spd_data[68], jedec_id5_vals));\n\t\t\t\t\t\telse {\n\t\t\t\t\t\t\tif (spd_data[69] != 0x7f)\n\t\t\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\t\t\tval2str(spd_data[69], jedec_id6_vals));\n\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\tif (spd_data[70] != 0x7f)\n\t\t\t\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\t\t\t\tval2str(spd_data[70], jedec_id7_vals));\n\t\t\t\t\t\t\t\telse {\n\t\t\t\t\t\t\t\t\tif (spd_data[71] != 0x7f)\n\t\t\t\t\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\t\t\t\t\tval2str(spd_data[71], jedec_id8_vals));\n\t\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\t\tprintf(\"%s\\n\",\n\t\t\t\t\t\t\t\t\t\tval2str(spd_data[72], jedec_id9_vals));\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tif (spd_data[73]) {\n\t\t\tchar part[19];\n\t\t\tmemcpy(part, spd_data+73, 18);\n\t\t\tpart[18] = 0;\n\t\t\tprintf(\" Part Number           : %s\\n\", part);\n\t\t}\n\n\t\tprintf(\" Serial Number         : %02x%02x%02x%02x\\n\",\n\t\tspd_data[95], spd_data[96], spd_data[97], spd_data[98]);\n\t}\n\n\tif (verbose) {\n\t\tprintf(\"\\n\");\n\t\tprintbuf(spd_data, len, \"SPD DATA\");\n\t}\n\n\treturn 0;\n}",
        "commit_message": "fru: Fix buffer overflow in ipmi_spd_print_fru\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_spd_print_fru` function has a similar issue as the one fixed\nby the previous commit in `read_fru_area_section`. An initial request is\nmade to get the `fru.size`, which is used as the size for the allocation\nof `spd_data`. Inside a loop, further requests are performed to get the\ncopy sizes which are not checked before being used as the size for a\ncopy into the buffer.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 0
      },
      {
        "idx": 368724,
        "reasoning": "This code is **not vulnerable** to the described buffer overflow (CVE-2020-5208) because it specifically handles the `rsp->data_len` check, ensuring it's equal to 9 before proceeding with data copying. The vulnerability existed in a different function (`ipmi_get_channel_cipher_suites`) not shown here, and this snippet correctly bounds the `memcpy` operations to the expected data lengths within the response.\n\n\n\n",
        "func": "_ipmi_get_channel_info(struct ipmi_intf *intf,\n\t\tstruct channel_info_t *channel_info)\n{\n\tstruct ipmi_rs *rsp;\n\tstruct ipmi_rq req = {0};\n\tuint8_t data[1];\n\n\tif (!channel_info) {\n\t\treturn (-3);\n\t}\n\tdata[0] = channel_info->channel & 0x0F;\n\treq.msg.netfn = IPMI_NETFN_APP;\n\treq.msg.cmd = IPMI_GET_CHANNEL_INFO;\n\treq.msg.data = data;\n\treq.msg.data_len = 1;\n\n\trsp = intf->sendrecv(intf, &req);\n\tif (!rsp) {\n\t\treturn (-1);\n\t} else if (rsp->ccode) {\n\t\treturn rsp->ccode;\n\t} else if (rsp->data_len != 9) {\n\t\treturn (-2);\n\t}\n\tchannel_info->channel = rsp->data[0] & 0x0F;\n\tchannel_info->medium = rsp->data[1] & 0x7F;\n\tchannel_info->protocol = rsp->data[2] & 0x1F;\n\tchannel_info->session_support = rsp->data[3] & 0xC0;\n\tchannel_info->active_sessions = rsp->data[3] & 0x3F;\n\tmemcpy(channel_info->vendor_id, &rsp->data[4],\n\t\t\tsizeof(channel_info->vendor_id));\n\tmemcpy(channel_info->aux_info, &rsp->data[7],\n\t\t\tsizeof(channel_info->aux_info));\n\treturn 0;\n}",
        "commit_message": "channel: Fix buffer overflow\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_get_channel_cipher_suites` function does not properly check\nthe final response\u2019s `data_len`, which can lead to stack buffer overflow\non the final copy.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 0
      },
      {
        "idx": 368725,
        "reasoning": "This code is not directly related to the identified vulnerability in `ipmi_get_channel_cipher_suites` concerning a buffer overflow during response handling. The provided snippet focuses on *sending* a request (`_ipmi_set_channel_access`) with a fixed-size data buffer of 3 bytes, and doesn't include any code that processes potentially unbounded response data that could lead to a buffer overflow.\n\n\n\n",
        "func": "_ipmi_set_channel_access(struct ipmi_intf *intf,\n\t\tstruct channel_access_t channel_access,\n\t\tuint8_t access_option,\n\t\tuint8_t privilege_option)\n{\n\tstruct ipmi_rs *rsp;\n\tstruct ipmi_rq req;\n\tuint8_t data[3];\n\t/* Only values from <0..2> are accepted as valid. */\n\tif (access_option > 2 || privilege_option > 2) {\n\t\treturn (-3);\n\t}\n\n\tmemset(&data, 0, sizeof(data));\n\tdata[0] = channel_access.channel & 0x0F;\n\tdata[1] = (access_option << 6);\n\tif (channel_access.alerting) {\n\t\tdata[1] |= 0x20;\n\t}\n\tif (channel_access.per_message_auth) {\n\t\tdata[1] |= 0x10;\n\t}\n\tif (channel_access.user_level_auth) {\n\t\tdata[1] |= 0x08;\n\t}\n\tdata[1] |= (channel_access.access_mode & 0x07);\n\tdata[2] = (privilege_option << 6);\n\tdata[2] |= (channel_access.privilege_limit & 0x0F);\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_APP;\n\treq.msg.cmd = IPMI_SET_CHANNEL_ACCESS;\n\treq.msg.data = data;\n\treq.msg.data_len = 3;\n\t\n\trsp = intf->sendrecv(intf, &req);\n\tif (!rsp) {\n\t\treturn (-1);\n\t}\n\treturn rsp->ccode;\n}",
        "commit_message": "channel: Fix buffer overflow\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_get_channel_cipher_suites` function does not properly check\nthe final response\u2019s `data_len`, which can lead to stack buffer overflow\non the final copy.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 0
      },
      {
        "idx": 368726,
        "reasoning": "This code snippet is **not directly related to the identified vulnerability** in `ipmi_get_channel_cipher_suites`. The commit message and advisory specifically mention a buffer overflow in a different function concerning cipher suite handling, while this code focuses on retrieving and displaying user access information \u2013 there's no apparent data copying or length checking that would lead to a stack buffer overflow here.\n\n\n\n",
        "func": "ipmi_get_user_access(struct ipmi_intf *intf, uint8_t channel, uint8_t user_id)\n{\n\tstruct user_access_t user_access;\n\tstruct user_name_t user_name;\n\tint ccode = 0;\n\tint curr_uid;\n\tint init = 1;\n\tint max_uid = 0;\n\n\tcurr_uid = user_id ? user_id : 1;\n\tdo {\n\t\tmemset(&user_access, 0, sizeof(user_access));\n\t\tuser_access.channel = channel;\n\t\tuser_access.user_id = curr_uid;\n\t\tccode = _ipmi_get_user_access(intf, &user_access);\n\t\tif (eval_ccode(ccode) != 0) {\n\t\t\tlprintf(LOG_ERR,\n\t\t\t\t\t\"Unable to Get User Access (channel %d id %d)\",\n\t\t\t\t\tchannel, curr_uid);\n\t\t\treturn (-1);\n\t\t}\n\n\t\tmemset(&user_name, 0, sizeof(user_name));\n\t\tuser_name.user_id = curr_uid;\n\t\tccode = _ipmi_get_user_name(intf, &user_name);\n\t\tif (ccode == 0xCC) {\n\t\t\tuser_name.user_id = curr_uid;\n\t\t\tmemset(&user_name.user_name, '\\0', 17);\n\t\t} else if (eval_ccode(ccode) != 0) {\n\t\t\tlprintf(LOG_ERR, \"Unable to Get User Name (id %d)\", curr_uid);\n\t\t\treturn (-1);\n\t\t}\n\t\tif (init) {\n\t\t\tprintf(\"Maximum User IDs     : %d\\n\", user_access.max_user_ids);\n\t\t\tprintf(\"Enabled User IDs     : %d\\n\", user_access.enabled_user_ids);\n\t\t\tmax_uid = user_access.max_user_ids;\n\t\t\tinit = 0;\n\t\t}\n\n\t\tprintf(\"\\n\");\n\t\tprintf(\"User ID              : %d\\n\", curr_uid);\n\t\tprintf(\"User Name            : %s\\n\", user_name.user_name);\n\t\tprintf(\"Fixed Name           : %s\\n\",\n\t\t       (curr_uid <= user_access.fixed_user_ids) ? \"Yes\" : \"No\");\n\t\tprintf(\"Access Available     : %s\\n\",\n\t\t       (user_access.callin_callback) ? \"callback\" : \"call-in / callback\");\n\t\tprintf(\"Link Authentication  : %sabled\\n\",\n\t\t       (user_access.link_auth) ? \"en\" : \"dis\");\n\t\tprintf(\"IPMI Messaging       : %sabled\\n\",\n\t\t       (user_access.ipmi_messaging) ? \"en\" : \"dis\");\n\t\tprintf(\"Privilege Level      : %s\\n\",\n\t\t       val2str(user_access.privilege_limit, ipmi_privlvl_vals));\n\t\tprintf(\"Enable Status        : %s\\n\",\n\t\t\tval2str(user_access.enable_status, ipmi_user_enable_status_vals));\n\t\tcurr_uid ++;\n\t} while (!user_id && curr_uid <= max_uid);\n\n\treturn 0;\n}",
        "commit_message": "channel: Fix buffer overflow\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_get_channel_cipher_suites` function does not properly check\nthe final response\u2019s `data_len`, which can lead to stack buffer overflow\non the final copy.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200371,
        "reasoning": "This code is vulnerable to a buffer overflow because the `len` value received in the response (`rsp->data[0]`) is used directly as the size for `memcpy` without validation, potentially exceeding the allocated `spd_data` buffer size.  Specifically, a malicious or buggy BMC could report a `len` value larger than the remaining space in `spd_data` leading to a write beyond the buffer's boundaries, as highlighted by the CVE description regarding unchecked data from remote sources.",
        "func": "ipmi_spd_print_fru(struct ipmi_intf * intf, uint8_t id)\n{\n\tstruct ipmi_rs * rsp;\n\tstruct ipmi_rq req;\n\tstruct fru_info fru;\n\tuint8_t *spd_data, msg_data[4];\n\tint len, offset;\n\n\tmsg_data[0] = id;\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_STORAGE;\n\treq.msg.cmd = GET_FRU_INFO;\n\treq.msg.data = msg_data;\n\treq.msg.data_len = 1;\n\n\trsp = intf->sendrecv(intf, &req);\n\tif (!rsp) {\n\t\tprintf(\" Device not present (No Response)\\n\");\n\t\treturn -1;\n\t}\n\tif (rsp->ccode) {\n\t\tprintf(\" Device not present (%s)\\n\",\n\t\t       val2str(rsp->ccode, completion_code_vals));\n\t\treturn -1;\n\t}\n\n\tfru.size = (rsp->data[1] << 8) | rsp->data[0];\n\tfru.access = rsp->data[2] & 0x1;\n\n\tlprintf(LOG_DEBUG, \"fru.size = %d bytes (accessed by %s)\",\n\t\tfru.size, fru.access ? \"words\" : \"bytes\");\n\n\n\tif (fru.size < 1) {\n\t\tlprintf(LOG_ERR, \" Invalid FRU size %d\", fru.size);\n\t\treturn -1;\n\t}\n\n        spd_data = malloc(fru.size);\n\n        if (!spd_data) {\n\t\tprintf(\" Unable to malloc memory for spd array of size=%d\\n\",\n\t\t       fru.size);\n\t\treturn -1;\n        }\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_STORAGE;\n\treq.msg.cmd = GET_FRU_DATA;\n\treq.msg.data = msg_data;\n\treq.msg.data_len = 4;\n\n\toffset = 0;\n\tmemset(spd_data, 0, fru.size);\n\tdo {\n\t\tmsg_data[0] = id;\n\t\tmsg_data[1] = offset & 0xFF;\n\t\tmsg_data[2] = offset >> 8;\n\t\tmsg_data[3] = FRU_DATA_RQST_SIZE;\n\n\t\trsp = intf->sendrecv(intf, &req);\n\t\tif (!rsp) {\n\t\t\tprintf(\" Device not present (No Response)\\n\");\n                        free(spd_data);\n                        spd_data = NULL;\n\t\t\treturn -1;\n\t\t}\n\t\tif (rsp->ccode) {\n\t\t\tprintf(\" Device not present (%s)\\n\",\n\t\t\t       val2str(rsp->ccode, completion_code_vals));\n\n                        free(spd_data);\n                        spd_data = NULL;\n\t\t\t/* Timeouts are acceptable. No DIMM in the socket */\n\t\t\tif (rsp->ccode == 0xc3)\n\t\t\t\treturn 1;\n\n\t\t\treturn -1;\n\t\t}\n\n\t\tlen = rsp->data[0];\n\t\tmemcpy(&spd_data[offset], rsp->data + 1, len);\n\t\toffset += len;\n\t} while (offset < fru.size);\n\n\t/* now print spd info */\n\tipmi_spd_print(spd_data, offset);\n        free(spd_data);\n        spd_data = NULL;\n\n\treturn 0;\n}",
        "commit_message": "fru: Fix buffer overflow in ipmi_spd_print_fru\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_spd_print_fru` function has a similar issue as the one fixed\nby the previous commit in `read_fru_area_section`. An initial request is\nmade to get the `fru.size`, which is used as the size for the allocation\nof `spd_data`. Inside a loop, further requests are performed to get the\ncopy sizes which are not checked before being used as the size for a\ncopy into the buffer.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 1
      },
      {
        "idx": 205605,
        "reasoning": "The code is vulnerable to a stack buffer overflow because it copies data from the IPMI response (`rsp->data + 1`) into `cipher_suite_data` without verifying that `offset + rsp->data_len - 1` does not exceed the bounds of `cipher_suite_data`. This lack of bounds checking, as highlighted in the CVE description, allows a malicious IPMI server to send a response with a `data_len` large enough to overwrite the stack, potentially leading to remote code execution.",
        "func": "ipmi_get_channel_cipher_suites(struct ipmi_intf *intf,\n                               const char *payload_type,\n                               uint8_t channel,\n                               struct cipher_suite_info *suites,\n                               size_t *count)\n{\n\tstruct ipmi_rs *rsp;\n\tstruct ipmi_rq req;\n\n\tuint8_t rqdata[3];\n\tuint8_t list_index = 0;\n\t/* 0x40 sets * 16 bytes per set */\n\tuint8_t cipher_suite_data[MAX_CIPHER_SUITE_RECORD_OFFSET *\n\t                          MAX_CIPHER_SUITE_DATA_LEN];\n\tsize_t offset = 0;\n\tsize_t nr_suites = 0;\n\n\tif (!suites || !count || !*count)\n\t\treturn -1;\n\n\tnr_suites = *count;\n\t*count = 0;\n\tmemset(cipher_suite_data, 0, sizeof(cipher_suite_data));\n\n\tmemset(&req, 0, sizeof(req));\n\treq.msg.netfn = IPMI_NETFN_APP;\n\treq.msg.cmd = IPMI_GET_CHANNEL_CIPHER_SUITES;\n\treq.msg.data = rqdata;\n\treq.msg.data_len = sizeof(rqdata);\n\n\trqdata[0] = channel;\n\trqdata[1] = ((strncmp(payload_type, \"ipmi\", 4) == 0)? 0: 1);\n\n\tdo {\n\t\t/* Always ask for cipher suite format */\n\t\trqdata[2] = LIST_ALGORITHMS_BY_CIPHER_SUITE | list_index;\n\t\trsp = intf->sendrecv(intf, &req);\n\t\tif (!rsp) {\n\t\t\tlprintf(LOG_ERR, \"Unable to Get Channel Cipher Suites\");\n\t\t\treturn -1;\n\t\t}\n\t\tif (rsp->ccode || rsp->data_len < 1) {\n\t\t\tlprintf(LOG_ERR, \"Get Channel Cipher Suites failed: %s\",\n\t\t\t\t\tval2str(rsp->ccode, completion_code_vals));\n\t\t\treturn -1;\n\t\t}\n\t\t/*\n\t\t * We got back cipher suite data -- store it.\n\t\t * printf(\"copying data to offset %d\\n\", offset);\n\t\t * printbuf(rsp->data + 1, rsp->data_len - 1, \"this is the data\");\n\t\t */\n\t\tmemcpy(cipher_suite_data + offset, rsp->data + 1, rsp->data_len - 1);\n\t\toffset += rsp->data_len - 1;\n\n\t\t/*\n\t\t * Increment our list for the next call\n\t\t */\n\t\t++list_index;\n\t} while ((rsp->data_len == (sizeof(uint8_t) + MAX_CIPHER_SUITE_DATA_LEN))\n\t         && (list_index < MAX_CIPHER_SUITE_RECORD_OFFSET));\n\n\t*count = parse_channel_cipher_suite_data(cipher_suite_data, offset, suites,\n\t                                         nr_suites);\n\treturn 0;\n}",
        "commit_message": "channel: Fix buffer overflow\n\nPartial fix for CVE-2020-5208, see\nhttps://github.com/ipmitool/ipmitool/security/advisories/GHSA-g659-9qxw-p7cp\n\nThe `ipmi_get_channel_cipher_suites` function does not properly check\nthe final response\u2019s `data_len`, which can lead to stack buffer overflow\non the final copy.",
        "cve_desc": "It's been found that multiple functions in ipmitool before 1.8.19 neglect proper checking of the data received from a remote LAN party, which may lead to buffer overflows and potentially to remote code execution on the ipmitool side. This is especially dangerous if ipmitool is run as a privileged user. This problem is fixed in version 1.8.19.",
        "target": 1
      }
    ]
  },
  "iproute2": {
    "0": [
      {
        "idx": 299987,
        "reasoning": "This code snippet is **not vulnerable** because it only performs string validation on a network namespace name and doesn't involve any memory allocation or manipulation related to the reported use-after-free issue in `get_netnsid_from_name`. The vulnerability lies within the `get_netnsid_from_name` function itself, not in the name validation logic presented here.\n\n\n\n",
        "func": "static int invalid_name(const char *name)\n{\n\treturn !*name || strlen(name) > NAME_MAX ||\n\t\tstrchr(name, '/') || !strcmp(name, \".\") || !strcmp(name, \"..\");\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 0
      },
      {
        "idx": 299988,
        "reasoning": "This code snippet, `netns_get_name`, is **not directly vulnerable** to the described use-after-free issue. The vulnerability exists within the `get_netnsid_from_name` function itself, which this code *calls*, but the provided snippet doesn't exhibit the problematic memory access pattern; it simply iterates through netns directories and calls the vulnerable function to compare IDs.\n\n\n\n",
        "func": "static int netns_get_name(int nsid, char *name)\n{\n\tstruct dirent *entry;\n\tDIR *dir;\n\tint id;\n\n\tdir = opendir(NETNS_RUN_DIR);\n\tif (!dir)\n\t\treturn -ENOENT;\n\n\twhile ((entry = readdir(dir)) != NULL) {\n\t\tif (strcmp(entry->d_name, \".\") == 0)\n\t\t\tcontinue;\n\t\tif (strcmp(entry->d_name, \"..\") == 0)\n\t\t\tcontinue;\n\t\tid = get_netnsid_from_name(entry->d_name);\n\n\t\tif (nsid == id) {\n\t\t\tstrcpy(name, entry->d_name);\n\t\t\tclosedir(dir);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tclosedir(dir);\n\treturn -ENOENT;\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 0
      },
      {
        "idx": 299989,
        "reasoning": "This code snippet simply defines the usage instructions for the `ip netns` command and doesn't contain any logic related to network namespace management or memory handling. The vulnerability described in the commit message exists within the `get_netnsid_from_name` function, which is *not* present in this provided code, therefore this snippet is safe.\n\n\n\n",
        "func": "static int usage(void)\n{\n\tfprintf(stderr, \"Usage: ip netns list\\n\");\n\tfprintf(stderr, \"       ip netns add NAME\\n\");\n\tfprintf(stderr, \"       ip netns attach NAME PID\\n\");\n\tfprintf(stderr, \"       ip netns set NAME NETNSID\\n\");\n\tfprintf(stderr, \"       ip [-all] netns delete [NAME]\\n\");\n\tfprintf(stderr, \"       ip netns identify [PID]\\n\");\n\tfprintf(stderr, \"       ip netns pids NAME\\n\");\n\tfprintf(stderr, \"       ip [-all] netns exec [NAME] cmd ...\\n\");\n\tfprintf(stderr, \"       ip netns monitor\\n\");\n\tfprintf(stderr, \"       ip netns list-id\\n\");\n\tfprintf(stderr, \"NETNSID := auto | POSITIVE-INT\\n\");\n\texit(-1);\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 0
      },
      {
        "idx": 299990,
        "reasoning": "This code snippet, `on_netns_del`, is not directly related to the reported use-after-free vulnerability in `get_netnsid_from_name`. The vulnerability exists within the netlink attribute parsing logic, specifically how memory allocated for `answer` is handled *before* being freed, while this function only deals with removing namespace files and directories.\n\n\n\n",
        "func": "static int on_netns_del(char *nsname, void *arg)\n{\n\tchar netns_path[PATH_MAX];\n\n\tsnprintf(netns_path, sizeof(netns_path), \"%s/%s\", NETNS_RUN_DIR, nsname);\n\tumount2(netns_path, MNT_DETACH);\n\tif (unlink(netns_path) < 0) {\n\t\tfprintf(stderr, \"Cannot remove namespace file \\\"%s\\\": %s\\n\",\n\t\t\tnetns_path, strerror(errno));\n\t\treturn -1;\n\t}\n\treturn 0;\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 0
      },
      {
        "idx": 299991,
        "reasoning": "This code snippet from `on_netns_exec` is not directly related to the reported vulnerability in `get_netnsid_from_name`. The vulnerability lies within the `get_netnsid_from_name` function itself, concerning memory management with `rtnl_talk` and how `mmap` interacts with freeing memory, while this snippet simply executes commands and doesn't handle network namespace IDs or memory allocation in a way that would trigger the use-after-free.\n\n\n\n",
        "func": "static int on_netns_exec(char *nsname, void *arg)\n{\n\tchar **argv = arg;\n\n\tcmd_exec(argv[1], argv + 1, true);\n\treturn 0;\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200164,
        "reasoning": "The code is vulnerable to a use-after-free because it frees the `answer` buffer before potentially accessing its content via `tb[NETNSA_NSID]` within `rta_getattr_u32`. Specifically, when `MALLOC_MMAP_THRESHOLD_` is set to 0, the `free(answer)` call immediately releases the memory, leading to a read of freed memory if `tb[NETNSA_NSID]` is non-null.",
        "func": "int get_netnsid_from_name(const char *name)\n{\n\tstruct {\n\t\tstruct nlmsghdr n;\n\t\tstruct rtgenmsg g;\n\t\tchar            buf[1024];\n\t} req = {\n\t\t.n.nlmsg_len = NLMSG_LENGTH(sizeof(struct rtgenmsg)),\n\t\t.n.nlmsg_flags = NLM_F_REQUEST,\n\t\t.n.nlmsg_type = RTM_GETNSID,\n\t\t.g.rtgen_family = AF_UNSPEC,\n\t};\n\tstruct nlmsghdr *answer;\n\tstruct rtattr *tb[NETNSA_MAX + 1];\n\tstruct rtgenmsg *rthdr;\n\tint len, fd;\n\n\tnetns_nsid_socket_init();\n\n\tfd = netns_get_fd(name);\n\tif (fd < 0)\n\t\treturn fd;\n\n\taddattr32(&req.n, 1024, NETNSA_FD, fd);\n\tif (rtnl_talk(&rtnsh, &req.n, &answer) < 0) {\n\t\tclose(fd);\n\t\treturn -2;\n\t}\n\tclose(fd);\n\n\t/* Validate message and parse attributes */\n\tif (answer->nlmsg_type == NLMSG_ERROR)\n\t\tgoto err_out;\n\n\trthdr = NLMSG_DATA(answer);\n\tlen = answer->nlmsg_len - NLMSG_SPACE(sizeof(*rthdr));\n\tif (len < 0)\n\t\tgoto err_out;\n\n\tparse_rtattr(tb, NETNSA_MAX, NETNS_RTA(rthdr), len);\n\n\tif (tb[NETNSA_NSID]) {\n\t\tfree(answer);\n\t\treturn rta_getattr_u32(tb[NETNSA_NSID]);\n\t}\n\nerr_out:\n\tfree(answer);\n\treturn -1;\n}",
        "commit_message": "ipnetns: use-after-free problem in get_netnsid_from_name func\n\nFollow the following steps:\n # ip netns add net1\n # export MALLOC_MMAP_THRESHOLD_=0\n # ip netns list\nthen Segmentation fault (core dumped) will occur.\n\nIn get_netnsid_from_name func, answer is freed before\nrta_getattr_u32(tb[NETNSA_NSID]), where tb[] refers to answer`s\ncontent. If we set MALLOC_MMAP_THRESHOLD_=0, mmap will be adoped to\nmalloc memory, which will be freed immediately after calling free\nfunc.  So reading tb[NETNSA_NSID] will access the released memory\nafter free(answer).\n\nHere, we will call get_netnsid_from_name(tb[NETNSA_NSID]) before free(answer).\n\nFixes: 86bf43c7c2f (\"lib/libnetlink: update rtnl_talk to support malloc buff at run time\")\nReported-by: Huiying Kou <kouhuiying@huawei.com>\nSigned-off-by: Zhiqiang Liu <liuzhiqiang26@huawei.com>\nAcked-by: Phil Sutter <phil@nwl.cc>\nSigned-off-by: Stephen Hemminger <stephen@networkplumber.org>",
        "cve_desc": "iproute2 before 5.1.0 has a use-after-free in get_netnsid_from_name in ip/ipnetns.c. NOTE: security relevance may be limited to certain uses of setuid that, although not a default, are sometimes a configuration option offered to end users. Even when setuid is used, other factors (such as C library configuration) may block exploitability.",
        "target": 1
      }
    ]
  },
  "isolated-vm": {
    "0": [],
    "1": []
  },
  "jasper": {
    "0": [
      {
        "idx": 65559,
        "reasoning": "This code is not directly vulnerable to the integer overflow issue described in the commit message. The commit message states the overflow was in the *JPC codec* itself, and this function `jpc_pchg_copy` simply copies data\u2014it doesn't perform any calculations that could be susceptible to an integer overflow leading to uninitialized data use. \n\n\n\n",
        "func": "jpc_pchg_t *jpc_pchg_copy(jpc_pchg_t *pchg)\n{\n\tjpc_pchg_t *newpchg;\n\tif (!(newpchg = jas_malloc(sizeof(jpc_pchg_t)))) {\n\t\treturn 0;\n\t}\n\t*newpchg = *pchg;\n\treturn newpchg;\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 0
      },
      {
        "idx": 65560,
        "reasoning": "This code snippet is not vulnerable because it simply frees memory associated with a data structure (`jpc_pchg_t *pchg`) using `jas_free`. The commit message describes a fix in the *JPC codec* itself, but this `jpc_pchg_destroy` function only handles deallocation and doesn't contain any logic related to the integer overflow or uninitialized data issues mentioned in the commit\u2014it safely releases the allocated memory.\n\n\n\n",
        "func": "void jpc_pchg_destroy(jpc_pchg_t *pchg)\n{\n\tjas_free(pchg);\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 0
      },
      {
        "idx": 65561,
        "reasoning": "This code is not directly vulnerable to the integer overflow issue described in the commit message. The commit message states the overflow *resulted* in uninitialized data use, implying the overflow happened elsewhere\u2014likely during the calculation of `pchglist->numpchgs`\u2014and this function simply iterates based on that potentially flawed value, but doesn't introduce a new overflow itself. \n\n\n\n",
        "func": "jpc_pchglist_t *jpc_pchglist_copy(jpc_pchglist_t *pchglist)\n{\n\tjpc_pchglist_t *newpchglist;\n\tjpc_pchg_t *newpchg;\n\tint pchgno;\n\tif (!(newpchglist = jpc_pchglist_create())) {\n\t\treturn 0;\n\t}\n\tfor (pchgno = 0; pchgno < pchglist->numpchgs; ++pchgno) {\n\t\tif (!(newpchg = jpc_pchg_copy(pchglist->pchgs[pchgno])) ||\n\t\t  jpc_pchglist_insert(newpchglist, -1, newpchg)) {\n\t\t\tjpc_pchglist_destroy(newpchglist);\n\t\t\treturn 0;\n\t\t}\n\t}\n\treturn newpchglist;\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 0
      },
      {
        "idx": 65562,
        "reasoning": "This code snippet is not directly vulnerable to the integer overflow issue described in the commit message. The commit message states the overflow *resulted* in uninitialized data use, implying the vulnerability was elsewhere in the JPC codec\u2014this `jpc_pchglist_destroy` function simply cleans up allocated memory and doesn't appear to perform calculations susceptible to overflow.",
        "func": "void jpc_pchglist_destroy(jpc_pchglist_t *pchglist)\n{\n\tint pchgno;\n\tif (pchglist->pchgs) {\n\t\tfor (pchgno = 0; pchgno < pchglist->numpchgs; ++pchgno) {\n\t\t\tjpc_pchg_destroy(pchglist->pchgs[pchgno]);\n\t\t}\n\t\tjas_free(pchglist->pchgs);\n\t}\n\tjas_free(pchglist);\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 0
      },
      {
        "idx": 65563,
        "reasoning": "This code snippet is likely safe because it simply retrieves a pointer from an array using an index. The commit message refers to a fix in the *JPC codec* generally, but doesn't indicate this specific `jpc_pchglist_get` function was the source of the overflow or uninitialized data issue\u2014it likely accesses data *affected* by the earlier fix, but doesn't introduce new vulnerabilities itself.\n\n\n\n",
        "func": "jpc_pchg_t *jpc_pchglist_get(jpc_pchglist_t *pchglist, int pchgno)\n{\n\treturn pchglist->pchgs[pchgno];\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3070,
        "reasoning": "This code is vulnerable to an integer overflow due to the calculations involving left bit shifts (`<<`) on `pi->picomp->hsamp` and `pi->picomp->vsamp` within the nested loops, specifically when calculating `pi->xstep` and `pi->ystep`. This overflow can lead to unexpectedly small values for `pi->xstep` and `pi->ystep`, ultimately causing the code to access and use uninitialized data when indexing into arrays like `pi->pirlvl->prclyrnos`.",
        "func": "static int jpc_pi_nextcprl(register jpc_pi_t *pi)\n{\n\tint rlvlno;\n\tjpc_pirlvl_t *pirlvl;\n\tjpc_pchg_t *pchg;\n\tint prchind;\n\tint prcvind;\n\tint *prclyrno;\n\tuint_fast32_t trx0;\n\tuint_fast32_t try0;\n\tuint_fast32_t r;\n\tuint_fast32_t rpx;\n\tuint_fast32_t rpy;\n\n\tpchg = pi->pchg;\n\tif (!pi->prgvolfirst) {\n\t\tgoto skip;\n\t} else {\n\t\tpi->prgvolfirst = 0;\n\t}\n\n\tfor (pi->compno = pchg->compnostart, pi->picomp =\n \t  &pi->picomps[pi->compno]; pi->compno < JAS_CAST(int, pchg->compnoend) && pi->compno < pi->numcomps; ++pi->compno,\n \t  ++pi->picomp) {\n \t\tpirlvl = pi->picomp->pirlvls;\n\t\tpi->xstep = pi->picomp->hsamp * (1 << (pirlvl->prcwidthexpn +\n\t\t  pi->picomp->numrlvls - 1));\n\t\tpi->ystep = pi->picomp->vsamp * (1 << (pirlvl->prcheightexpn +\n\t\t  pi->picomp->numrlvls - 1));\n \t\tfor (rlvlno = 1, pirlvl = &pi->picomp->pirlvls[1];\n \t\t  rlvlno < pi->picomp->numrlvls; ++rlvlno, ++pirlvl) {\n\t\t\tpi->xstep = JAS_MIN(pi->xstep, pi->picomp->hsamp * (1 <<\n\t\t\t  (pirlvl->prcwidthexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n\t\t\tpi->ystep = JAS_MIN(pi->ystep, pi->picomp->vsamp * (1 <<\n\t\t\t  (pirlvl->prcheightexpn + pi->picomp->numrlvls -\n\t\t\t  rlvlno - 1)));\n \t\t}\n \t\tfor (pi->y = pi->ystart; pi->y < pi->yend;\n \t\t  pi->y += pi->ystep - (pi->y % pi->ystep)) {\n\t\t\tfor (pi->x = pi->xstart; pi->x < pi->xend;\n\t\t\t  pi->x += pi->xstep - (pi->x % pi->xstep)) {\n\t\t\t\tfor (pi->rlvlno = pchg->rlvlnostart,\n\t\t\t\t  pi->pirlvl = &pi->picomp->pirlvls[pi->rlvlno];\n\t\t\t\t  pi->rlvlno < pi->picomp->numrlvls && pi->rlvlno <\n\t\t\t\t  pchg->rlvlnoend; ++pi->rlvlno, ++pi->pirlvl) {\n\t\t\t\t\tif (pi->pirlvl->numprcs == 0) {\n\t\t\t\t\t\tcontinue;\n\t\t\t\t\t}\n\t\t\t\t\tr = pi->picomp->numrlvls - 1 - pi->rlvlno;\n\t\t\t\t\ttrx0 = JPC_CEILDIV(pi->xstart, pi->picomp->hsamp << r);\n\t\t\t\t\ttry0 = JPC_CEILDIV(pi->ystart, pi->picomp->vsamp << r);\n\t\t\t\t\trpx = r + pi->pirlvl->prcwidthexpn;\n\t\t\t\t\trpy = r + pi->pirlvl->prcheightexpn;\n\t\t\t\t\tif (((pi->x == pi->xstart && ((trx0 << r) % (1 << rpx))) ||\n\t\t\t\t\t  !(pi->x % (pi->picomp->hsamp << rpx))) &&\n\t\t\t\t\t  ((pi->y == pi->ystart && ((try0 << r) % (1 << rpy))) ||\n\t\t\t\t\t  !(pi->y % (pi->picomp->vsamp << rpy)))) {\n\t\t\t\t\t\tprchind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->x, pi->picomp->hsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcwidthexpn) - JPC_FLOORDIVPOW2(trx0,\n\t\t\t\t\t\t  pi->pirlvl->prcwidthexpn);\n\t\t\t\t\t\tprcvind = JPC_FLOORDIVPOW2(JPC_CEILDIV(pi->y, pi->picomp->vsamp\n\t\t\t\t\t\t  << r), pi->pirlvl->prcheightexpn) - JPC_FLOORDIVPOW2(try0,\n\t\t\t\t\t\t  pi->pirlvl->prcheightexpn);\n\t\t\t\t\t\tpi->prcno = prcvind *\n\t\t\t\t\t\t  pi->pirlvl->numhprcs +\n\t\t\t\t\t\t  prchind;\n\t\t\t\t\t\tassert(pi->prcno <\n\t\t\t\t\t\t  pi->pirlvl->numprcs);\n\t\t\t\t\t\tfor (pi->lyrno = 0; pi->lyrno <\n\t\t\t\t\t\t  pi->numlyrs && pi->lyrno < JAS_CAST(int, pchg->lyrnoend); ++pi->lyrno) {\n\t\t\t\t\t\t\tprclyrno = &pi->pirlvl->prclyrnos[pi->prcno];\n\t\t\t\t\t\t\tif (pi->lyrno >= *prclyrno) {\n\t\t\t\t\t\t\t\t++(*prclyrno);\n\t\t\t\t\t\t\t\treturn 0;\n\t\t\t\t\t\t\t}\nskip:\n\t\t\t\t\t\t\t;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn 1;\n}\n",
        "commit_message": "Fixed an integer overflow problem in the JPC codec that later resulted\nin the use of uninitialized data.",
        "cve_desc": "Integer overflow in the jpc_pi_nextcprl function in jpc_t2cod.c in JasPer before 1.900.20 allows remote attackers to have unspecified impact via a crafted file, which triggers use of an uninitialized value.",
        "target": 1
      },
      {
        "idx": 3072,
        "reasoning": "This code is vulnerable to a NULL pointer dereference because the `box->ops` pointer can be reset to `&jp2_boxinfo_unk.ops` within the error handling block *after* potentially being used to call a `getdata` function. If `(*box->ops->getdata)(box, tmpstream)` fails, the code jumps to `error`, resetting `box->ops` before `tmpstream` is closed, potentially leading to a crash if `jp2_box_destroy` attempts to use the now-invalid `box->ops` pointer during cleanup.",
        "func": "jp2_box_t *jp2_box_get(jas_stream_t *in)\n{\n\tjp2_box_t *box;\n\tjp2_boxinfo_t *boxinfo;\n\tjas_stream_t *tmpstream;\n\tuint_fast32_t len;\n\tuint_fast64_t extlen;\n\tbool dataflag;\n\n\tbox = 0;\n\ttmpstream = 0;\n\n \tif (!(box = jas_malloc(sizeof(jp2_box_t)))) {\n \t\tgoto error;\n \t}\n \tbox->ops = &jp2_boxinfo_unk.ops;\n \tif (jp2_getuint32(in, &len) || jp2_getuint32(in, &box->type)) {\n \t\tgoto error;\n \t}\n \tboxinfo = jp2_boxinfolookup(box->type);\n \tbox->info = boxinfo;\n\tbox->ops = &boxinfo->ops;\n \tbox->len = len;\n \tJAS_DBGLOG(10, (\n \t  \"preliminary processing of JP2 box: type=%c%s%c (0x%08x); length=%d\\n\",\n\t  '\"', boxinfo->name, '\"', box->type, box->len\n\t  ));\n\tif (box->len == 1) {\n\t\tif (jp2_getuint64(in, &extlen)) {\n\t\t\tgoto error;\n\t\t}\n\t\tif (extlen > 0xffffffffUL) {\n\t\t\tjas_eprintf(\"warning: cannot handle large 64-bit box length\\n\");\n\t\t\textlen = 0xffffffffUL;\n\t\t}\n\t\tbox->len = extlen;\n\t\tbox->datalen = extlen - JP2_BOX_HDRLEN(true);\n\t} else {\n\t\tbox->datalen = box->len - JP2_BOX_HDRLEN(false);\n\t}\n\tif (box->len != 0 && box->len < 8) {\n\t\tgoto error;\n\t}\n\n\tdataflag = !(box->info->flags & (JP2_BOX_SUPER | JP2_BOX_NODATA));\n\n\tif (dataflag) {\n\t\tif (!(tmpstream = jas_stream_memopen(0, 0))) {\n \t\t\tgoto error;\n \t\t}\n \t\tif (jas_stream_copy(tmpstream, in, box->datalen)) {\n\t\t\tbox->ops = &jp2_boxinfo_unk.ops;\n \t\t\tjas_eprintf(\"cannot copy box data\\n\");\n \t\t\tgoto error;\n \t\t}\n \t\tjas_stream_rewind(tmpstream);\n \n \t\tif (box->ops->getdata) {\n \t\t\tif ((*box->ops->getdata)(box, tmpstream)) {\n \t\t\t\tjas_eprintf(\"cannot parse box data\\n\");\n\t\t\t\tgoto error;\n\t\t\t}\n\t\t}\n\t\tjas_stream_close(tmpstream);\n\t}\n\n\tif (jas_getdbglevel() >= 1) {\n\t\tjp2_box_dump(box, stderr);\n\t}\n\n\treturn box;\n\nerror:\n\tif (box) {\n\t\tjp2_box_destroy(box);\n\t}\n\tif (tmpstream) {\n\t\tjas_stream_close(tmpstream);\n\t}\n\treturn 0;\n}\n",
        "commit_message": "Fixed another problem with incorrect cleanup of JP2 box data upon error.",
        "cve_desc": "The jp2_colr_destroy function in jp2_cod.c in JasPer before 1.900.13 allows remote attackers to cause a denial of service (NULL pointer dereference) by leveraging incorrect cleanup of JP2 box data on error. NOTE: this vulnerability exists because of an incomplete fix for CVE-2016-8887.",
        "target": 1
      },
      {
        "idx": 3076,
        "reasoning": "This code is vulnerable to a NULL pointer dereference because, despite the attempt to avoid it, `jas_seq2d_getref(a, jas_seq2d_xstart(a), jas_seq2d_ystart(a))` can still return a null pointer if `a` is an empty sequence. The conditional `(tsfb->numlvls > 0)` only prevents calling `jpc_tsfb_synthesize2` with invalid level counts, but doesn't validate the result of `jas_seq2d_getref` before passing it as an argument, leading to a crash when dereferenced.",
        "func": " int jpc_tsfb_synthesize(jpc_tsfb_t *tsfb, jas_seq2d_t *a)\n {\n\treturn (tsfb->numlvls > 0) ? jpc_tsfb_synthesize2(tsfb,\n \t  jas_seq2d_getref(a, jas_seq2d_xstart(a), jas_seq2d_ystart(a)),\n \t  jas_seq2d_xstart(a), jas_seq2d_ystart(a), jas_seq2d_width(a),\n \t  jas_seq2d_height(a), jas_seq2d_rowstep(a), tsfb->numlvls - 1) : 0;\n}\n",
        "commit_message": "Fixed an integral type promotion problem by adding a JAS_CAST.\nModified the jpc_tsfb_synthesize function so that it will be a noop for\nan empty sequence (in order to avoid dereferencing a null pointer).",
        "cve_desc": "The jpc_tsfb_synthesize function in jpc_tsfb.c in JasPer before 1.900.9 allows remote attackers to cause a denial of service (NULL pointer dereference) via vectors involving an empty sequence.",
        "target": 1
      },
      {
        "idx": 3274,
        "reasoning": "The commit message mentions re-enabling a regression test `jasper-doublefree-mem_close.jpg`, which previously exposed a double-free vulnerability. Given the CVE description specifically details a double-free in `jasper_image_stop_load` triggered by crafted images, and this commit aims to make that test \"work more predictably,\" the code likely still contains the underlying vulnerability or a similar one related to memory management during image loading/unloading.\n\n\n\n",
        "func": "jas_matrix_t *jas_seq2d_create(int xstart, int ystart, int xend, int yend)\n {\n \tjas_matrix_t *matrix;\n \tassert(xstart <= xend && ystart <= yend);\n\tif (!(matrix = jas_matrix_create(yend - ystart, xend - xstart))) {\n\t\treturn 0;\n\t}\n\tmatrix->xstart_ = xstart;\n\tmatrix->ystart_ = ystart;\n\tmatrix->xend_ = xend;\n\tmatrix->yend_ = yend;\n \treturn matrix;\n }\n",
        "commit_message": "The generation of the configuration file jas_config.h has been completely\nreworked in order to avoid pollution of the global namespace.\n\nSome problematic types like uchar, ulong, and friends have been replaced\nwith names with a jas_ prefix.\n\nAn option max_samples has been added to the BMP and JPEG decoders to\nrestrict the maximum size of image that they can decode.  This change\nwas made as a (possibly temporary) fix to address security concerns.\nA max_samples command-line option has also been added to imginfo.\n\nWhether an image component (for jas_image_t) is stored in memory or on\ndisk is now based on the component size (rather than the image size).\n\nSome debug log message were added.\n\nSome new integer overflow checks were added.\n\nSome new safe integer add/multiply functions were added.\n\nMore pre-C99 cruft was removed.  JasPer has numerous \"hacks\" to\nhandle pre-C99 compilers.  JasPer now assumes C99 support.  So, this\npre-C99 cruft is unnecessary and can be removed.\n\nThe regression jasper-doublefree-mem_close.jpg has been re-enabled.\nTheoretically, it should work more predictably now.",
        "cve_desc": "Double free vulnerability in the jasper_image_stop_load function in JasPer 1.900.17 allows remote attackers to cause a denial of service (crash) via a crafted JPEG 2000 image file.",
        "target": 1
      },
      {
        "idx": 3295,
        "reasoning": "This code is vulnerable to an integer overflow due to the multiplication implied when allocating memory for `siz->comps` using `siz->numcomps`. A malicious actor could provide a large value for `siz->numcomps` (up to the maximum value of a uint_16, 65535) leading to a very large allocation size, potentially exhausting memory resources and causing a denial of service, similar to the issue described in the CVE.",
        "func": "static int jpc_siz_getparms(jpc_ms_t *ms, jpc_cstate_t *cstate,\n  jas_stream_t *in)\n{\n\tjpc_siz_t *siz = &ms->parms.siz;\n \tunsigned int i;\n \tuint_fast8_t tmp;\n \n \t/* Eliminate compiler warning about unused variables. */\n \tcstate = 0;\n \n\tif (jpc_getuint16(in, &siz->caps) ||\n\t  jpc_getuint32(in, &siz->width) ||\n\t  jpc_getuint32(in, &siz->height) ||\n\t  jpc_getuint32(in, &siz->xoff) ||\n\t  jpc_getuint32(in, &siz->yoff) ||\n\t  jpc_getuint32(in, &siz->tilewidth) ||\n\t  jpc_getuint32(in, &siz->tileheight) ||\n \t  jpc_getuint32(in, &siz->tilexoff) ||\n \t  jpc_getuint32(in, &siz->tileyoff) ||\n \t  jpc_getuint16(in, &siz->numcomps)) {\n\t\treturn -1;\n \t}\n\tif (!siz->width || !siz->height || !siz->tilewidth ||\n\t  !siz->tileheight || !siz->numcomps || siz->numcomps > 16384) {\n\t\treturn -1;\n \t}\n\tif (siz->tilexoff >= siz->width || siz->tileyoff >= siz->height) {\n\t\tjas_eprintf(\"all tiles are outside the image area\\n\");\n\t\treturn -1;\n \t}\n \tif (!(siz->comps = jas_alloc2(siz->numcomps, sizeof(jpc_sizcomp_t)))) {\n\t\treturn -1;\n \t}\n \tfor (i = 0; i < siz->numcomps; ++i) {\n \t\tif (jpc_getuint8(in, &tmp) ||\n \t\t  jpc_getuint8(in, &siz->comps[i].hsamp) ||\n \t\t  jpc_getuint8(in, &siz->comps[i].vsamp)) {\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n \t\t}\n \t\tif (siz->comps[i].hsamp == 0 || siz->comps[i].hsamp > 255) {\n \t\t\tjas_eprintf(\"invalid XRsiz value %d\\n\", siz->comps[i].hsamp);\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n \t\t}\n \t\tif (siz->comps[i].vsamp == 0 || siz->comps[i].vsamp > 255) {\n \t\t\tjas_eprintf(\"invalid YRsiz value %d\\n\", siz->comps[i].vsamp);\n\t\t\tjas_free(siz->comps);\n\t\t\treturn -1;\n \t\t}\n \t\tsiz->comps[i].sgnd = (tmp >> 7) & 1;\n \t\tsiz->comps[i].prec = (tmp & 0x7f) + 1;\n \t}\n \tif (jas_stream_eof(in)) {\n\t\tjas_free(siz->comps);\n\t\treturn -1;\n \t}\n \treturn 0;\n }\n",
        "commit_message": "Added some missing sanity checks on the data in a SIZ marker segment.",
        "cve_desc": "The jas_seq2d_create function in jas_seq.c in JasPer before 1.900.17 allows remote attackers to cause a denial of service (assertion failure) via a crafted file.",
        "target": 1
      }
    ]
  },
  "jerryscript": {
    "0": [
      {
        "idx": 269926,
        "reasoning": "This code is safe and doesn't introduce a vulnerability. The commit message explicitly states it *prevents* memory allocation for zero-length strings, addressing a previously reported issue (#1821), and the code itself focuses on parsing hexadecimal escape sequences without any apparent memory management flaws that could lead to exploitation.",
        "func": "lexer_hex_to_character (parser_context_t *context_p, /**< context */\n                        const uint8_t *source_p, /**< current source position */\n                        int length) /**< source length */\n{\n  uint32_t result = 0;\n\n  do\n  {\n    uint32_t byte = *source_p++;\n\n    result <<= 4;\n\n    if (byte >= LIT_CHAR_0 && byte <= LIT_CHAR_9)\n    {\n      result += byte - LIT_CHAR_0;\n    }\n    else\n    {\n      byte = LEXER_TO_ASCII_LOWERCASE (byte);\n      if (byte >= LIT_CHAR_LOWERCASE_A && byte <= LIT_CHAR_LOWERCASE_F)\n      {\n        result += byte - (LIT_CHAR_LOWERCASE_A - 10);\n      }\n      else\n      {\n        parser_raise_error (context_p, PARSER_ERR_INVALID_ESCAPE_SEQUENCE);\n      }\n    }\n  }\n  while (--length > 0);\n\n  return (ecma_char_t) result;\n} /* lexer_hex_to_character */",
        "commit_message": "Do not allocate memory for zero length strings. (#1844)\n\nFixes #1821.\n\nJerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 0
      },
      {
        "idx": 269927,
        "reasoning": "This code is safe and addresses a potential vulnerability. The commit message explicitly states the fix prevents memory allocation for zero-length strings, resolving issue #1821, which likely involved a potential buffer overflow or denial-of-service scenario when handling empty regular expressions.",
        "func": "lexer_construct_regexp_object (parser_context_t *context_p, /**< context */\n                               bool parse_only) /**< parse only */\n{\n#ifndef CONFIG_DISABLE_REGEXP_BUILTIN\n  const uint8_t *source_p = context_p->source_p;\n  const uint8_t *regex_start_p = context_p->source_p;\n  const uint8_t *regex_end_p = regex_start_p;\n  const uint8_t *source_end_p = context_p->source_end_p;\n  parser_line_counter_t column = context_p->column;\n  lexer_literal_t *literal_p;\n  bool in_class = false;\n  uint16_t current_flags;\n  lit_utf8_size_t length;\n\n  JERRY_ASSERT (context_p->token.type == LEXER_DIVIDE\n                || context_p->token.type == LEXER_ASSIGN_DIVIDE);\n\n  if (context_p->token.type == LEXER_ASSIGN_DIVIDE)\n  {\n    regex_start_p--;\n  }\n\n  while (true)\n  {\n    if (source_p >= source_end_p)\n    {\n      parser_raise_error (context_p, PARSER_ERR_UNTERMINATED_REGEXP);\n    }\n\n    if (!in_class && source_p[0] == LIT_CHAR_SLASH)\n    {\n      regex_end_p = source_p;\n      source_p++;\n      column++;\n      break;\n    }\n\n    switch (source_p[0])\n    {\n      case LIT_CHAR_CR:\n      case LIT_CHAR_LF:\n      case LEXER_NEWLINE_LS_PS_BYTE_1:\n      {\n        if (source_p[0] != LEXER_NEWLINE_LS_PS_BYTE_1\n            || LEXER_NEWLINE_LS_PS_BYTE_23 (source_p))\n        {\n          parser_raise_error (context_p, PARSER_ERR_NEWLINE_NOT_ALLOWED);\n        }\n        break;\n      }\n      case LIT_CHAR_TAB:\n      {\n        column = align_column_to_tab (column);\n         /* Subtract -1 because column is increased below. */\n        column--;\n        break;\n      }\n      case LIT_CHAR_LEFT_SQUARE:\n      {\n        in_class = true;\n        break;\n      }\n      case LIT_CHAR_RIGHT_SQUARE:\n      {\n        in_class = false;\n        break;\n      }\n      case LIT_CHAR_BACKSLASH:\n      {\n        if (source_p + 1 >= source_end_p)\n        {\n          parser_raise_error (context_p, PARSER_ERR_UNTERMINATED_REGEXP);\n        }\n\n        if (source_p[1] >= 0x20 && source_p[1] <= LIT_UTF8_1_BYTE_CODE_POINT_MAX)\n        {\n          source_p++;\n          column++;\n        }\n      }\n    }\n\n    source_p++;\n    column++;\n\n    while (source_p < source_end_p\n           && IS_UTF8_INTERMEDIATE_OCTET (source_p[0]))\n    {\n      source_p++;\n    }\n  }\n\n  current_flags = 0;\n  while (source_p < source_end_p)\n  {\n    uint32_t flag = 0;\n\n    if (source_p[0] == LIT_CHAR_LOWERCASE_G)\n    {\n      flag = RE_FLAG_GLOBAL;\n    }\n    else if (source_p[0] == LIT_CHAR_LOWERCASE_I)\n    {\n      flag = RE_FLAG_IGNORE_CASE;\n    }\n    else if (source_p[0] == LIT_CHAR_LOWERCASE_M)\n    {\n      flag = RE_FLAG_MULTILINE;\n    }\n\n    if (flag == 0)\n    {\n      break;\n    }\n\n    if (current_flags & flag)\n    {\n      parser_raise_error (context_p, PARSER_ERR_DUPLICATED_REGEXP_FLAG);\n    }\n\n    current_flags = (uint16_t) (current_flags | flag);\n    source_p++;\n    column++;\n  }\n\n  if (source_p < source_end_p\n      && lit_char_is_identifier_part (source_p))\n  {\n    parser_raise_error (context_p, PARSER_ERR_UNKNOWN_REGEXP_FLAG);\n  }\n\n  context_p->source_p = source_p;\n  context_p->column = column;\n\n  length = (lit_utf8_size_t) (regex_end_p - regex_start_p);\n  if (length > PARSER_MAXIMUM_STRING_LENGTH)\n  {\n    parser_raise_error (context_p, PARSER_ERR_REGEXP_TOO_LONG);\n  }\n\n  context_p->column = column;\n  context_p->source_p = source_p;\n\n  if (parse_only)\n  {\n    return;\n  }\n\n  if (context_p->literal_count >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = LEXER_UNUSED_LITERAL;\n  literal_p->status_flags = 0;\n\n  context_p->literal_count++;\n\n  /* Compile the RegExp literal and store the RegExp bytecode pointer */\n  const re_compiled_code_t *re_bytecode_p = NULL;\n  ecma_value_t completion_value;\n\n  ecma_string_t *pattern_str_p = ecma_new_ecma_string_from_utf8 (regex_start_p, length);\n  completion_value = re_compile_bytecode (&re_bytecode_p,\n                                          pattern_str_p,\n                                          current_flags);\n  ecma_deref_ecma_string (pattern_str_p);\n\n  bool is_throw = ECMA_IS_VALUE_ERROR (completion_value);\n\n  ecma_free_value (completion_value);\n\n  if (is_throw)\n  {\n    parser_raise_error (context_p, PARSER_ERR_INVALID_REGEXP);\n  }\n\n  literal_p->type = LEXER_REGEXP_LITERAL;\n  literal_p->u.bytecode_p = (ecma_compiled_code_t *) re_bytecode_p;\n\n  context_p->token.type = LEXER_LITERAL;\n  context_p->token.literal_is_reserved = false;\n  context_p->token.lit_location.type = LEXER_REGEXP_LITERAL;\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) (context_p->literal_count - 1);\n  context_p->lit_object.type = LEXER_LITERAL_OBJECT_ANY;\n#else /* CONFIG_DISABLE_REGEXP_BUILTIN */\n  JERRY_UNUSED (parse_only);\n  parser_raise_error (context_p, PARSER_ERR_UNSUPPORTED_REGEXP);\n#endif /* !CONFIG_DISABLE_REGEXP_BUILTIN */\n} /* lexer_construct_regexp_object */",
        "commit_message": "Do not allocate memory for zero length strings. (#1844)\n\nFixes #1821.\n\nJerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 0
      },
      {
        "idx": 269928,
        "reasoning": "This code is safe and addresses a potential issue rather than introducing a vulnerability. The commit message explicitly states it prevents memory allocation for zero-length strings (Fixes #1821), which likely resolves a potential resource exhaustion or error condition, not a security flaw.",
        "func": "lexer_construct_number_object (parser_context_t *context_p, /**< context */\n                               bool push_number_allowed, /**< push number support is allowed */\n                               bool is_negative_number) /**< sign is negative */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  ecma_number_t num;\n  uint32_t literal_index = 0;\n  uint16_t length = context_p->token.lit_location.length;\n\n  if (context_p->token.extra_value != LEXER_NUMBER_OCTAL)\n  {\n    num = ecma_utf8_string_to_number (context_p->token.lit_location.char_p,\n                                      length);\n  }\n  else\n  {\n    const uint8_t *src_p = context_p->token.lit_location.char_p;\n    const uint8_t *src_end_p = src_p + length - 1;\n\n    num = 0;\n    do\n    {\n      src_p++;\n      num = num * 8 + (ecma_number_t) (*src_p - LIT_CHAR_0);\n    }\n    while (src_p < src_end_p);\n  }\n\n  if (push_number_allowed)\n  {\n    int32_t int_num = (int32_t) num;\n\n    if (int_num == num)\n    {\n      if (int_num <= CBC_PUSH_NUMBER_BYTE_RANGE_END\n          && (int_num != 0 || !is_negative_number))\n      {\n        context_p->lit_object.index = (uint16_t) int_num;\n        return true;\n      }\n    }\n  }\n\n  if (is_negative_number)\n  {\n    num = -num;\n  }\n\n  jmem_cpointer_t lit_cp = ecma_find_or_create_literal_number (num);\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == LEXER_NUMBER_LITERAL\n        && literal_p->u.value == lit_cp)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      context_p->lit_object.type = LEXER_LITERAL_OBJECT_ANY;\n      return false;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = context_p->token.lit_location.length;\n  literal_p->type = LEXER_UNUSED_LITERAL;\n  literal_p->status_flags = 0;\n\n  context_p->literal_count++;\n\n  literal_p->u.value = lit_cp;\n  literal_p->type = LEXER_NUMBER_LITERAL;\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->lit_object.type = LEXER_LITERAL_OBJECT_ANY;\n\n  return false;\n} /* lexer_construct_number_object */",
        "commit_message": "Do not allocate memory for zero length strings. (#1844)\n\nFixes #1821.\n\nJerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 0
      },
      {
        "idx": 269929,
        "reasoning": "This code is safe and does not introduce any new vulnerabilities. The commit message explicitly states it fixes an issue related to memory allocation for zero-length strings, and the provided code snippet focuses on skipping whitespace and handling various newline/comment characters \u2013 it doesn't involve any string allocation or manipulation that could lead to vulnerabilities like buffer overflows or memory leaks.",
        "func": "skip_spaces (parser_context_t *context_p) /**< context */\n{\n  skip_mode_t mode = LEXER_SKIP_SPACES;\n  const uint8_t *source_end_p = context_p->source_end_p;\n\n  context_p->token.was_newline = 0;\n\n  while (true)\n  {\n    if (context_p->source_p >= source_end_p)\n    {\n      if (mode == LEXER_SKIP_MULTI_LINE_COMMENT)\n      {\n        parser_raise_error (context_p, PARSER_ERR_UNTERMINATED_MULTILINE_COMMENT);\n      }\n      return;\n    }\n\n    switch (context_p->source_p[0])\n    {\n      case LIT_CHAR_CR:\n      {\n        if (context_p->source_p + 1 < source_end_p\n            && context_p->source_p[1] == LIT_CHAR_LF)\n        {\n          context_p->source_p++;\n        }\n        /* FALLTHRU */\n      }\n\n      case LIT_CHAR_LF:\n      {\n        context_p->line++;\n        context_p->column = 0;\n        context_p->token.was_newline = 1;\n\n        if (mode == LEXER_SKIP_SINGLE_LINE_COMMENT)\n        {\n          mode = LEXER_SKIP_SPACES;\n        }\n        /* FALLTHRU */\n      }\n\n      case LIT_CHAR_VTAB:\n      case LIT_CHAR_FF:\n      case LIT_CHAR_SP:\n      {\n        context_p->source_p++;\n        context_p->column++;\n        continue;\n      }\n\n      case LIT_CHAR_TAB:\n      {\n        context_p->column = align_column_to_tab (context_p->column);\n        context_p->source_p++;\n        continue;\n      }\n\n      case LIT_CHAR_SLASH:\n      {\n        if (mode == LEXER_SKIP_SPACES\n            && context_p->source_p + 1 < source_end_p)\n        {\n          if (context_p->source_p[1] == LIT_CHAR_SLASH)\n          {\n            mode = LEXER_SKIP_SINGLE_LINE_COMMENT;\n          }\n          else if (context_p->source_p[1] == LIT_CHAR_ASTERISK)\n          {\n            mode = LEXER_SKIP_MULTI_LINE_COMMENT;\n            context_p->token.line = context_p->line;\n            context_p->token.column = context_p->column;\n          }\n\n          if (mode != LEXER_SKIP_SPACES)\n          {\n            context_p->source_p += 2;\n            PARSER_PLUS_EQUAL_LC (context_p->column, 2);\n            continue;\n          }\n        }\n        break;\n      }\n\n      case LIT_CHAR_ASTERISK:\n      {\n        if (mode == LEXER_SKIP_MULTI_LINE_COMMENT\n            && context_p->source_p + 1 < source_end_p\n            && context_p->source_p[1] == LIT_CHAR_SLASH)\n        {\n          mode = LEXER_SKIP_SPACES;\n          context_p->source_p += 2;\n          PARSER_PLUS_EQUAL_LC (context_p->column, 2);\n          continue;\n        }\n        break;\n      }\n\n      case 0xc2:\n      {\n        if (context_p->source_p + 1 < source_end_p\n            && context_p->source_p[1] == 0xa0)\n        {\n          /* Codepoint \\u00A0 */\n          context_p->source_p += 2;\n          context_p->column++;\n          continue;\n        }\n        break;\n      }\n\n      case LEXER_NEWLINE_LS_PS_BYTE_1:\n      {\n        JERRY_ASSERT (context_p->source_p + 2 < source_end_p);\n        if (LEXER_NEWLINE_LS_PS_BYTE_23 (context_p->source_p))\n        {\n          /* Codepoint \\u2028 and \\u2029 */\n          context_p->source_p += 3;\n          context_p->line++;\n          context_p->column = 1;\n          context_p->token.was_newline = 1;\n\n          if (mode == LEXER_SKIP_SINGLE_LINE_COMMENT)\n          {\n            mode = LEXER_SKIP_SPACES;\n          }\n          continue;\n        }\n        break;\n      }\n\n      case 0xef:\n      {\n        if (context_p->source_p + 2 < source_end_p\n            && context_p->source_p[1] == 0xbb\n            && context_p->source_p[2] == 0xbf)\n        {\n          /* Codepoint \\uFEFF */\n          context_p->source_p += 3;\n          context_p->column++;\n          continue;\n        }\n        break;\n      }\n\n      default:\n      {\n        break;\n      }\n    }\n\n    if (mode == LEXER_SKIP_SPACES)\n    {\n      return;\n    }\n\n    context_p->source_p++;\n\n    if (context_p->source_p < source_end_p\n        && IS_UTF8_INTERMEDIATE_OCTET (context_p->source_p[0]))\n    {\n      context_p->column++;\n    }\n  }\n} /* skip_spaces */",
        "commit_message": "Do not allocate memory for zero length strings. (#1844)\n\nFixes #1821.\n\nJerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 0
      },
      {
        "idx": 269930,
        "reasoning": "This code addresses a potential vulnerability by preventing memory allocation for zero-length strings, as highlighted by the commit message fixing issue #1821. By avoiding allocation in this case and directly using the input pointer, it eliminates a potential memory exhaustion or allocation failure scenario, making the code safe with respect to the addressed issue.\n\n\n\n",
        "func": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n    parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n  }\n\n  if (length == 0)\n  {\n    has_escape = false;\n  }\n\n  literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n  literal_p->prop.length = (uint16_t) length;\n  literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */",
        "commit_message": "Do not allocate memory for zero length strings. (#1844)\n\nFixes #1821.\n\nJerryScript-DCO-1.0-Signed-off-by: Zoltan Herczeg zherczeg.u-szeged@partner.samsung.com",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 2765,
        "reasoning": "The code is vulnerable because it allocates memory using `jmem_heap_alloc_block` even when `has_escape` is true and `length` is 0, leading to a potential NULL pointer dereference when this allocated memory is later accessed. This occurs because the code doesn't check for zero length before allocating, as highlighted in the CVE, ultimately causing a denial of service via application crash.",
        "func": "lexer_process_char_literal (parser_context_t *context_p, /**< context */\n                            const uint8_t *char_p, /**< characters */\n                            size_t length, /**< length of string */\n                            uint8_t literal_type, /**< final literal type */\n                            bool has_escape) /**< has escape sequences */\n{\n  parser_list_iterator_t literal_iterator;\n  lexer_literal_t *literal_p;\n  uint32_t literal_index = 0;\n\n  JERRY_ASSERT (literal_type == LEXER_IDENT_LITERAL\n                || literal_type == LEXER_STRING_LITERAL);\n\n  JERRY_ASSERT (literal_type != LEXER_IDENT_LITERAL || length <= PARSER_MAXIMUM_IDENT_LENGTH);\n  JERRY_ASSERT (literal_type != LEXER_STRING_LITERAL || length <= PARSER_MAXIMUM_STRING_LENGTH);\n\n  parser_list_iterator_init (&context_p->literal_pool, &literal_iterator);\n\n  while ((literal_p = (lexer_literal_t *) parser_list_iterator_next (&literal_iterator)) != NULL)\n  {\n    if (literal_p->type == literal_type\n        && literal_p->prop.length == length\n        && memcmp (literal_p->u.char_p, char_p, length) == 0)\n    {\n      context_p->lit_object.literal_p = literal_p;\n      context_p->lit_object.index = (uint16_t) literal_index;\n      literal_p->status_flags = (uint8_t) (literal_p->status_flags & ~LEXER_FLAG_UNUSED_IDENT);\n      return;\n    }\n\n    literal_index++;\n  }\n\n  JERRY_ASSERT (literal_index == context_p->literal_count);\n\n  if (literal_index >= PARSER_MAXIMUM_NUMBER_OF_LITERALS)\n  {\n     parser_raise_error (context_p, PARSER_ERR_LITERAL_LIMIT_REACHED);\n   }\n \n   literal_p = (lexer_literal_t *) parser_list_append (context_p, &context_p->literal_pool);\n   literal_p->prop.length = (uint16_t) length;\n   literal_p->type = literal_type;\n  literal_p->status_flags = has_escape ? 0 : LEXER_FLAG_SOURCE_PTR;\n\n  if (has_escape)\n  {\n    literal_p->u.char_p = (uint8_t *) jmem_heap_alloc_block (length);\n    memcpy ((uint8_t *) literal_p->u.char_p, char_p, length);\n  }\n  else\n  {\n    literal_p->u.char_p = char_p;\n  }\n\n  context_p->lit_object.literal_p = literal_p;\n  context_p->lit_object.index = (uint16_t) literal_index;\n  context_p->literal_count++;\n} /* lexer_process_char_literal */\n",
        "commit_message": "None",
        "cve_desc": "The lexer_process_char_literal function in jerry-core/parser/js/js-lexer.c in JerryScript 1.0 does not skip memory allocation for empty strings, which allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via malformed JavaScript source code, related to the jmem_heap_free_block function.",
        "target": 1
      }
    ]
  },
  "jhead": {
    "0": [],
    "1": []
  },
  "jsish": {
    "0": [
      {
        "idx": 519856,
        "reasoning": "This code is not flagged as vulnerable because it appears to be a debugging function (`jsiFlagDebugValues`) focused on marking objects and values within a JavaScript interpreter's internal data structures. The function recursively traverses objects and arrays, setting flags to track visited status and object inclusion, but doesn't perform any operations that directly expose security risks like memory corruption or arbitrary code execution\u2014it's primarily concerned with internal state management for debugging purposes.",
        "func": "void jsiFlagDebugValues(Jsi_Interp *interp, Jsi_Obj *obj)\n{\n    Jsi_Value *v;\n    int oflags;\n    if (obj->ot != JSI_OT_OBJECT && obj->ot != JSI_OT_ARRAY)\n        return;\n    if (obj->tree) {\n        Jsi_TreeEntry *hPtr;\n        Jsi_TreeSearch srch;\n        for (hPtr=Jsi_TreeSearchFirst(obj->tree, &srch,  JSI_TREE_ORDER_IN, NULL); hPtr;\n            hPtr=Jsi_TreeSearchNext(&srch)) {\n            v = (Jsi_Value*)Jsi_TreeValueGet(hPtr);\n            if (v == NULL || v->sig != JSI_SIG_VALUE) continue;\n            oflags = v->VD.flags;\n            v->VD.flags |= (MDB_VISITED|MDB_INOBJ);\n            if (oflags&MDB_VISITED || v->vt != JSI_VT_OBJECT)\n                continue;\n            jsiFlagDebugValues(interp, v->d.obj);\n        }\n    }\n    if (obj->arr) {\n        uint i;\n        for (i=0; i<obj->arrCnt; i++) {\n            v = obj->arr[i];\n            if (v == NULL || v->sig != JSI_SIG_VALUE) continue;\n            oflags = v->VD.flags;\n            v->VD.flags |= (MDB_VISITED|MDB_INOBJ);\n            if (oflags&MDB_VISITED || v->vt != JSI_VT_OBJECT)\n                continue;\n            jsiFlagDebugValues(interp, v->d.obj);\n        }\n    }\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 0
      },
      {
        "idx": 519857,
        "reasoning": "This code is not flagged as vulnerable because the commit message addresses a bug in `toPrecision` within a different part of the `jsish` project, and the provided snippet focuses on SQLite transaction handling. There are no immediately obvious vulnerabilities like SQL injection or improper input validation present in this specific function's logic.\n\n\n\n",
        "func": "static Jsi_RC SqliteTransactionCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Value *_this,\n                                Jsi_Value **ret, Jsi_Func *funcPtr)\n{\n    int rc;\n    Jsi_Db *jdb;\n\n    int argc = Jsi_ValueGetLength(interp, args);\n    if (!(jdb = dbGetDbHandle(interp, _this, funcPtr))) return JSI_ERROR;\n\n    Jsi_Value *pScript;\n    const char *zBegin = \"SAVEPOINT _jsi_transaction\";\n\n    if( jdb->nTransaction==0 && argc==2 ) {\n        Jsi_Value *arg = Jsi_ValueArrayIndex(interp, args, 0);\n        static const char *TTYPE_strs[] = {\n            \"deferred\",   \"exclusive\",  \"immediate\", 0\n        };\n        enum TTYPE_enum {\n            TTYPE_DEFERRED, TTYPE_EXCLUSIVE, TTYPE_IMMEDIATE\n        };\n        int ttype;\n        if( Jsi_ValueGetIndex(interp, arg, TTYPE_strs, \"transaction type\",\n                              0, &ttype) ) {\n            return JSI_ERROR;\n        }\n        switch( (enum TTYPE_enum)ttype ) {\n        case TTYPE_DEFERRED:    /* no-op */\n            ;\n            break;\n        case TTYPE_EXCLUSIVE:\n            zBegin = \"BEGIN EXCLUSIVE\";\n            break;\n        case TTYPE_IMMEDIATE:\n            zBegin = \"BEGIN IMMEDIATE\";\n            break;\n        }\n    }\n    pScript = Jsi_ValueArrayIndex(interp, args, argc-1);\n    if(!Jsi_ValueIsFunction(interp, pScript)) \n        return Jsi_LogError(\"expected function\");\n\n    /* Run the SQLite BEGIN command to open a transaction or savepoint. */\n    jdb->disableAuth++;\n    rc = sqlite3_exec(jdb->db, zBegin, 0, 0 ,0);\n    jdb->disableAuth--;\n    if( rc!=SQLITE_OK ) \n        return Jsi_LogError(\"%s\", sqlite3_errmsg(jdb->db));\n    jdb->nTransaction++;\n\n    /* Evaluate the function , then\n    ** call function dbTransPostCmd() to commit (or rollback) the transaction\n    ** or savepoint.  */\n    Jsi_RC rv = Jsi_FunctionInvoke(interp, pScript, NULL, NULL, NULL);\n    rv = dbTransPostCmd(jdb, interp, rv);\n    return rv;\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 0
      },
      {
        "idx": 519858,
        "reasoning": "This code snippet appears safe as it focuses on validating string balance\u2014specifically checking for matching quotes and brackets\u2014and doesn't directly handle user input in a way that could lead to injection or memory corruption vulnerabilities. The fix mentioned in the commit message addresses a bug in `toPrecision`, a separate function, and doesn't indicate any issues with this string balancing function itself.\n\n\n\n",
        "func": "bool jsi_StrIsBalanced(char *str) {\n    int cnt = 0, quote = 0;\n    char *cp = str;\n    while (*cp) {\n        switch (*cp) {\n        case '\\\\':\n            cp++;\n            break;\n        case '{': case '(': case '[':\n            cnt++;\n            break;\n        case '\\'': case '\\\"':\n            quote++;\n            break;\n        case '}': case ')': case ']':\n            cnt--;\n            break;\n        }\n        if (*cp == 0)\n            break;\n        cp++;\n    }\n    return ((quote%2) == 0 && cnt <= 0);\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 0
      },
      {
        "idx": 519859,
        "reasoning": "This code snippet is not directly related to the \"toPrecision bug\" mentioned in the commit message, which likely resides in the JavaScript engine's number handling. The `Jsi_Flush` function simply calls a flush procedure associated with a file system pointer, and doesn't appear to introduce any vulnerabilities itself\u2014it safely handles potential null pointers or missing flush procedures by returning an error code.\n\n\n\n",
        "func": "int Jsi_Flush(Jsi_Interp *interp, Jsi_Channel chan) {\n    if (chan->fsPtr==0 || !chan->fsPtr->flushProc) return -1;\n    return chan->fsPtr->flushProc(chan);\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 0
      },
      {
        "idx": 519860,
        "reasoning": "This code snippet appears safe as it simply delegates the `stat` operation to a filesystem-specific procedure (`fsPtr->statProc`) after validating its existence. The commit message references a bug fix in `toPrecision`, which is unrelated to file system statistics and doesn't introduce vulnerabilities in this particular function dealing with file system interactions.\n\n\n\n",
        "func": "int Jsi_Stat(Jsi_Interp *interp, Jsi_Value* path, Jsi_StatBuf *buf) {\n    void *data;\n    Jsi_Filesystem *fsPtr = Jsi_FilesystemForPath(interp, path, &data);\n    if (fsPtr == NULL || !fsPtr->statProc) return -1;\n    return fsPtr->statProc(interp, path, buf);\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 217285,
        "reasoning": "This code is vulnerable to a buffer overflow because `snprintf` is used with a fixed-size buffer (`buf[100]`) to format a string based on user-controlled precision (`prec`). If `prec` is sufficiently large, the formatted string can exceed the buffer's capacity, leading to a write beyond the allocated memory and potentially allowing for arbitrary code execution as described in the CVE.",
        "func": "static Jsi_RC NumberToPrecisionCmd(Jsi_Interp *interp, Jsi_Value *args, Jsi_Value *_this,\n    Jsi_Value **ret, Jsi_Func *funcPtr)\n{\n    char buf[100];\n    int prec = 0, skip = 0;\n    Jsi_Number num;\n    Jsi_Value *v;\n    ChkStringN(_this, funcPtr, v);\n    if (Jsi_GetIntFromValue(interp, Jsi_ValueArrayIndex(interp, args, skip), &prec) != JSI_OK)\n        return JSI_ERROR;\n    if (prec<=0) return JSI_ERROR;\n    Jsi_GetDoubleFromValue(interp, v, &num);\n    snprintf(buf, sizeof(buf),\"%.*\" JSI_NUMFFMT, prec, num);\n    if (num<0)\n        prec++;\n    buf[prec+1] = 0;\n    if (buf[prec] == '.')\n        buf[prec] = 0;\n    Jsi_ValueMakeStringDup(interp, ret, buf);\n    return JSI_OK;\n}",
        "commit_message": "Release \"3.0.7\": Fix toPrecision bug \"stack overflow #4\".\n\nFossilOrigin-Name: 6c7f0c37027d7f890b57cb38f776af39b8f81f03e60ceeb0a231a1d21e24b5de",
        "cve_desc": "Buffer overflow vulnerability in function NumberToPrecisionCmd in jsish before 3.0.7, allows remote attackers to execute arbitrary code.",
        "target": 1
      }
    ]
  },
  "kdeconnect-kde": {
    "0": [
      {
        "idx": 228574,
        "reasoning": "This code is safe and addresses a potential vulnerability. The commit message and code snippet demonstrate a mitigation by limiting the TCP ports KDE Connect attempts to connect to within a defined range (MIN_TCP_PORT to MAX_TCP_PORT), preventing connections to arbitrary services and thus reducing the attack surface. \n\n\n\n",
        "func": "void LanLinkProvider::udpBroadcastReceived()\n{\n    while (m_udpSocket.hasPendingDatagrams()) {\n\n        QByteArray datagram;\n        datagram.resize(m_udpSocket.pendingDatagramSize());\n        QHostAddress sender;\n\n        m_udpSocket.readDatagram(datagram.data(), datagram.size(), &sender);\n\n        if (sender.isLoopback() && !m_testMode)\n            continue;\n\n        NetworkPacket* receivedPacket = new NetworkPacket(QLatin1String(\"\"));\n        bool success = NetworkPacket::unserialize(datagram, receivedPacket);\n\n        //qCDebug(KDECONNECT_CORE) << \"udp connection from \" << receivedPacket->;\n\n        //qCDebug(KDECONNECT_CORE) << \"Datagram \" << datagram.data() ;\n\n        if (!success) {\n            qCDebug(KDECONNECT_CORE) << \"Could not unserialize UDP packet\";\n            delete receivedPacket;\n            continue;\n        }\n\n        if (receivedPacket->type() != PACKET_TYPE_IDENTITY) {\n            qCDebug(KDECONNECT_CORE) << \"Received a UDP packet of wrong type\" << receivedPacket->type();\n            delete receivedPacket;\n            continue;\n        }\n\n        if (receivedPacket->get<QString>(QStringLiteral(\"deviceId\")) == KdeConnectConfig::instance().deviceId()) {\n            //qCDebug(KDECONNECT_CORE) << \"Ignoring my own broadcast\";\n            delete receivedPacket;\n            continue;\n        }\n\n        int tcpPort = receivedPacket->get<int>(QStringLiteral(\"tcpPort\"));\n        if (tcpPort < MIN_TCP_PORT || tcpPort > MAX_TCP_PORT) {\n            qCDebug(KDECONNECT_CORE) << \"TCP port outside of kdeconnect's range\";\n            delete receivedPacket;\n            continue;\n        }\n\n        //qCDebug(KDECONNECT_CORE) << \"Received Udp identity packet from\" << sender << \" asking for a tcp connection on port \" << tcpPort;\n\n        if (m_receivedIdentityPackets.size() > MAX_REMEMBERED_IDENTITY_PACKETS) {\n            qCWarning(KDECONNECT_CORE) << \"Too many remembered identities, ignoring\" << receivedPacket->get<QString>(QStringLiteral(\"deviceId\")) << \"received via UDP\";\n            delete receivedPacket;\n            continue;\n        }\n\n        QSslSocket* socket = new QSslSocket(this);\n        socket->setProxy(QNetworkProxy::NoProxy);\n        m_receivedIdentityPackets[socket].np = receivedPacket;\n        m_receivedIdentityPackets[socket].sender = sender;\n        connect(socket, &QAbstractSocket::connected, this, &LanLinkProvider::tcpSocketConnected);\n#if QT_VERSION < QT_VERSION_CHECK(5,15,0)\n        connect(socket, QOverload<QAbstractSocket::SocketError>::of(&QAbstractSocket::error), this, &LanLinkProvider::connectError);\n#else\n        connect(socket, &QAbstractSocket::errorOccurred, this, &LanLinkProvider::connectError);\n#endif\n        socket->connectToHost(sender, tcpPort);\n    }\n}",
        "commit_message": "Limit the ports we try to connect to to the port range of KDE Connect\n\nSo we can't trigger connections to other services.\n\nThanks Matthias Gerstner <mgerstner@suse.de> for reporting this.",
        "cve_desc": "In kdeconnect-kde (aka KDE Connect) before 20.08.2, an attacker on the local network could send crafted packets that trigger use of large amounts of CPU, memory, or network connection slots, aka a Denial of Service attack.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195647,
        "reasoning": "This code is vulnerable to a Denial of Service (DoS) attack because it accepts and configures SSL sockets without immediate authentication, as indicated by the commit message addressing long-lived, unauthenticated connections. An attacker could repeatedly open connections, exhausting server resources (CPU, memory, network slots) by sending minimal or crafted data, relying on the `while` loop to accept them before the socket times out or is explicitly rejected \u2013 aligning with the CVE description of resource exhaustion via crafted packets.",
        "func": "void LanLinkProvider::newConnection()\n{\n    qCDebug(KDECONNECT_CORE) << \"LanLinkProvider newConnection\";\n\n    while (m_server->hasPendingConnections()) {\n        QSslSocket* socket = m_server->nextPendingConnection();\n        configureSocket(socket);\n        //This socket is still managed by us (and child of the QTcpServer), if\n        //it disconnects before we manage to pass it to a LanDeviceLink, it's\n        //our responsibility to delete it. We do so with this connection.\n        connect(socket, &QAbstractSocket::disconnected,\n                socket, &QObject::deleteLater);\n        connect(socket, &QIODevice::readyRead,\n                this, &LanLinkProvider::dataReceived);\n\n    }\n}",
        "commit_message": "Do not let lanlink connections stay open for long without authenticating\n\nIf there's no information received, close the socket to try again.\n\nThanks Matthias Gerstner <mgerstner@suse.de> for reporting this.",
        "cve_desc": "In kdeconnect-kde (aka KDE Connect) before 20.08.2, an attacker on the local network could send crafted packets that trigger use of large amounts of CPU, memory, or network connection slots, aka a Denial of Service attack.",
        "target": 1
      }
    ]
  },
  "keepkey-firmware": {
    "0": [],
    "1": []
  },
  "kitty": {
    "0": [],
    "1": []
  },
  "kopano-core": {
    "0": [],
    "1": []
  },
  "krb5": {
    "0": [
      {
        "idx": 24187,
        "reasoning": "This code is not directly vulnerable to the described CVE-2012-1013. The commit message states the bug occurs in `kadmind` when a create-principal request lacks a password *and* includes `KRB5_KDB_DISALLOW_ALL_TIX`, but this code snippet focuses on managing password history *after* a principal is created, and doesn't handle the initial principal creation logic where the null password dereference occurs.",
        "func": "static kadm5_ret_t add_to_history(krb5_context context,\n                                  krb5_kvno hist_kvno,\n                                  osa_princ_ent_t adb,\n                                  kadm5_policy_ent_t pol,\n                                  osa_pw_hist_ent *pw)\n{\n    osa_pw_hist_ent *histp;\n    uint32_t nhist;\n    unsigned int i, knext, nkeys;\n\n    nhist = pol->pw_history_num;\n    /* A history of 1 means just check the current password */\n    if (nhist <= 1)\n        return 0;\n\n    if (adb->admin_history_kvno != hist_kvno) {\n        /* The history key has changed since the last password change, so we\n         * have to reset the password history. */\n        free(adb->old_keys);\n        adb->old_keys = NULL;\n        adb->old_key_len = 0;\n        adb->old_key_next = 0;\n        adb->admin_history_kvno = hist_kvno;\n    }\n\n    nkeys = adb->old_key_len;\n    knext = adb->old_key_next;\n    /* resize the adb->old_keys array if necessary */\n    if (nkeys + 1 < nhist) {\n        if (adb->old_keys == NULL) {\n            adb->old_keys = (osa_pw_hist_ent *)\n                malloc((nkeys + 1) * sizeof (osa_pw_hist_ent));\n        } else {\n            adb->old_keys = (osa_pw_hist_ent *)\n                realloc(adb->old_keys,\n                        (nkeys + 1) * sizeof (osa_pw_hist_ent));\n        }\n        if (adb->old_keys == NULL)\n            return(ENOMEM);\n\n        memset(&adb->old_keys[nkeys], 0, sizeof(osa_pw_hist_ent));\n        nkeys = ++adb->old_key_len;\n        /*\n         * To avoid losing old keys, shift forward each entry after\n         * knext.\n         */\n        for (i = nkeys - 1; i > knext; i--) {\n            adb->old_keys[i] = adb->old_keys[i - 1];\n        }\n        memset(&adb->old_keys[knext], 0, sizeof(osa_pw_hist_ent));\n    } else if (nkeys + 1 > nhist) {\n        /*\n         * The policy must have changed!  Shrink the array.\n         * Can't simply realloc() down, since it might be wrapped.\n         * To understand the arithmetic below, note that we are\n         * copying into new positions 0 .. N-1 from old positions\n         * old_key_next-N .. old_key_next-1, modulo old_key_len,\n         * where N = pw_history_num - 1 is the length of the\n         * shortened list.        Matt Crawford, FNAL\n         */\n        /*\n         * M = adb->old_key_len, N = pol->pw_history_num - 1\n         *\n         * tmp[0] .. tmp[N-1] = old[(knext-N)%M] .. old[(knext-1)%M]\n         */\n        int j;\n        osa_pw_hist_t tmp;\n\n        tmp = (osa_pw_hist_ent *)\n            malloc((nhist - 1) * sizeof (osa_pw_hist_ent));\n        if (tmp == NULL)\n            return ENOMEM;\n        for (i = 0; i < nhist - 1; i++) {\n            /*\n             * Add nkeys once before taking remainder to avoid\n             * negative values.\n             */\n            j = (i + nkeys + knext - (nhist - 1)) % nkeys;\n            tmp[i] = adb->old_keys[j];\n        }\n        /* Now free the ones we don't keep (the oldest ones) */\n        for (i = 0; i < nkeys - (nhist - 1); i++) {\n            j = (i + nkeys + knext) % nkeys;\n            histp = &adb->old_keys[j];\n            for (j = 0; j < histp->n_key_data; j++) {\n                krb5_free_key_data_contents(context, &histp->key_data[j]);\n            }\n            free(histp->key_data);\n        }\n        free(adb->old_keys);\n        adb->old_keys = tmp;\n        nkeys = adb->old_key_len = nhist - 1;\n        knext = adb->old_key_next = 0;\n    }\n\n    /*\n     * If nhist decreased since the last password change, and nkeys+1\n     * is less than the previous nhist, it is possible for knext to\n     * index into unallocated space.  This condition would not be\n     * caught by the resizing code above.\n     */\n    if (knext + 1 > nkeys)\n        knext = adb->old_key_next = 0;\n    /* free the old pw history entry if it contains data */\n    histp = &adb->old_keys[knext];\n    for (i = 0; i < (unsigned int) histp->n_key_data; i++)\n        krb5_free_key_data_contents(context, &histp->key_data[i]);\n    free(histp->key_data);\n\n    /* store the new entry */\n    adb->old_keys[knext] = *pw;\n\n    /* update the next pointer */\n    if (++adb->old_key_next == nhist - 1)\n        adb->old_key_next = 0;\n\n    return(0);\n}\n",
        "commit_message": "Null pointer deref in kadmind [CVE-2012-1013]\n\nThe fix for #6626 could cause kadmind to dereference a null pointer if\na create-principal request contains no password but does contain the\nKRB5_KDB_DISALLOW_ALL_TIX flag (e.g. \"addprinc -randkey -allow_tix\nname\").  Only clients authorized to create principals can trigger the\nbug.  Fix the bug by testing for a null password in check_1_6_dummy.\n\nCVSSv2 vector: AV:N/AC:M/Au:S/C:N/I:N/A:P/E:H/RL:O/RC:C\n\n[ghudson@mit.edu: Minor style change and commit message]\n\nticket: 7152\ntarget_version: 1.10.2\ntags: pullup",
        "cve_desc": "The check_1_6_dummy function in lib/kadm5/srv/svr_principal.c in kadmind in MIT Kerberos 5 (aka krb5) 1.8.x, 1.9.x, and 1.10.x before 1.10.2 allows remote authenticated administrators to cause a denial of service (NULL pointer dereference and daemon crash) via a KRB5_KDB_DISALLOW_ALL_TIX create request that lacks a password.",
        "target": 0
      },
      {
        "idx": 24188,
        "reasoning": "This code snippet is not directly related to the described vulnerability (CVE-2012-1013) which occurs in `kadmind` during principal creation when a null password and the `KRB5_KDB_DISALLOW_ALL_TIX` flag are used. The provided code focuses on password reuse checking and doesn't handle the principal creation logic where the null pointer dereference happens, therefore it isn't flagged as vulnerable.",
        "func": "check_pw_reuse(krb5_context context,\n               krb5_keyblock *hist_keyblocks,\n               int n_new_key_data, krb5_key_data *new_key_data,\n               unsigned int n_pw_hist_data, osa_pw_hist_ent *pw_hist_data)\n{\n    unsigned int x, y, z;\n    krb5_keyblock newkey, histkey, *kb;\n    krb5_key_data *key_data;\n    krb5_error_code ret;\n\n    assert (n_new_key_data >= 0);\n    for (x = 0; x < (unsigned) n_new_key_data; x++) {\n        /* Check only entries with the most recent kvno. */\n        if (new_key_data[x].key_data_kvno != new_key_data[0].key_data_kvno)\n            break;\n        ret = krb5_dbe_decrypt_key_data(context, NULL, &(new_key_data[x]),\n                                        &newkey, NULL);\n        if (ret)\n            return(ret);\n        for (y = 0; y < n_pw_hist_data; y++) {\n            for (z = 0; z < (unsigned int) pw_hist_data[y].n_key_data; z++) {\n                for (kb = hist_keyblocks; kb->enctype != 0; kb++) {\n                    key_data = &pw_hist_data[y].key_data[z];\n                    ret = krb5_dbe_decrypt_key_data(context, kb, key_data,\n                                                    &histkey, NULL);\n                    if (ret)\n                        continue;\n                    if (newkey.length == histkey.length &&\n                        newkey.enctype == histkey.enctype &&\n                        memcmp(newkey.contents, histkey.contents,\n                               histkey.length) == 0) {\n                        krb5_free_keyblock_contents(context, &histkey);\n                        krb5_free_keyblock_contents(context, &newkey);\n                        return KADM5_PASS_REUSE;\n                    }\n                    krb5_free_keyblock_contents(context, &histkey);\n                }\n            }\n        }\n        krb5_free_keyblock_contents(context, &newkey);\n    }\n\n    return(0);\n}\n",
        "commit_message": "Null pointer deref in kadmind [CVE-2012-1013]\n\nThe fix for #6626 could cause kadmind to dereference a null pointer if\na create-principal request contains no password but does contain the\nKRB5_KDB_DISALLOW_ALL_TIX flag (e.g. \"addprinc -randkey -allow_tix\nname\").  Only clients authorized to create principals can trigger the\nbug.  Fix the bug by testing for a null password in check_1_6_dummy.\n\nCVSSv2 vector: AV:N/AC:M/Au:S/C:N/I:N/A:P/E:H/RL:O/RC:C\n\n[ghudson@mit.edu: Minor style change and commit message]\n\nticket: 7152\ntarget_version: 1.10.2\ntags: pullup",
        "cve_desc": "The check_1_6_dummy function in lib/kadm5/srv/svr_principal.c in kadmind in MIT Kerberos 5 (aka krb5) 1.8.x, 1.9.x, and 1.10.x before 1.10.2 allows remote authenticated administrators to cause a denial of service (NULL pointer dereference and daemon crash) via a KRB5_KDB_DISALLOW_ALL_TIX create request that lacks a password.",
        "target": 0
      },
      {
        "idx": 24189,
        "reasoning": "This code snippet, `cleanup_key_data`, is not directly related to the CVE-2012-1013 null pointer dereference in `kadmind`. The commit message specifically mentions a fix within `check_1_6_dummy` to handle null passwords during principal creation, while this code focuses on freeing key data \u2013 a separate function with no apparent connection to the vulnerability's trigger.\n\n\n\n",
        "func": "static void cleanup_key_data(context, count, data)\n    krb5_context   context;\n    int                    count;\n    krb5_key_data        * data;\n{\n    int i, j;\n\n    for (i = 0; i < count; i++)\n        for (j = 0; j < data[i].key_data_ver; j++)\n            if (data[i].key_data_length[j])\n                krb5_db_free(context, data[i].key_data_contents[j]);\n    krb5_db_free(context, data);\n}\n",
        "commit_message": "Null pointer deref in kadmind [CVE-2012-1013]\n\nThe fix for #6626 could cause kadmind to dereference a null pointer if\na create-principal request contains no password but does contain the\nKRB5_KDB_DISALLOW_ALL_TIX flag (e.g. \"addprinc -randkey -allow_tix\nname\").  Only clients authorized to create principals can trigger the\nbug.  Fix the bug by testing for a null password in check_1_6_dummy.\n\nCVSSv2 vector: AV:N/AC:M/Au:S/C:N/I:N/A:P/E:H/RL:O/RC:C\n\n[ghudson@mit.edu: Minor style change and commit message]\n\nticket: 7152\ntarget_version: 1.10.2\ntags: pullup",
        "cve_desc": "The check_1_6_dummy function in lib/kadm5/srv/svr_principal.c in kadmind in MIT Kerberos 5 (aka krb5) 1.8.x, 1.9.x, and 1.10.x before 1.10.2 allows remote authenticated administrators to cause a denial of service (NULL pointer dereference and daemon crash) via a KRB5_KDB_DISALLOW_ALL_TIX create request that lacks a password.",
        "target": 0
      },
      {
        "idx": 24190,
        "reasoning": "This code snippet is not directly related to the described vulnerability of a null pointer dereference in `kadmind` when handling principal creation with no password and the `KRB5_KDB_DISALLOW_ALL_TIX` flag. The commit message specifically mentions a fix within `check_1_6_dummy` to address the null password scenario, and this provided code focuses on key data encryption/decryption within history entry creation \u2013 a separate function.\n\n\n\n",
        "func": "int create_history_entry(krb5_context context,\n                         krb5_keyblock *hist_key, int n_key_data,\n                         krb5_key_data *key_data, osa_pw_hist_ent *hist)\n{\n    int i, ret;\n    krb5_keyblock key;\n    krb5_keysalt salt;\n\n    hist->key_data = (krb5_key_data*)malloc(n_key_data*sizeof(krb5_key_data));\n    if (hist->key_data == NULL)\n        return ENOMEM;\n    memset(hist->key_data, 0, n_key_data*sizeof(krb5_key_data));\n\n    for (i = 0; i < n_key_data; i++) {\n        ret = krb5_dbe_decrypt_key_data(context, NULL, &key_data[i], &key,\n                                        &salt);\n        if (ret)\n            return ret;\n\n        ret = krb5_dbe_encrypt_key_data(context, hist_key, &key, &salt,\n                                        key_data[i].key_data_kvno,\n                                        &hist->key_data[i]);\n        if (ret)\n            return ret;\n\n        krb5_free_keyblock_contents(context, &key);\n        /* krb5_free_keysalt(context, &salt); */\n    }\n\n    hist->n_key_data = n_key_data;\n    return 0;\n}\n",
        "commit_message": "Null pointer deref in kadmind [CVE-2012-1013]\n\nThe fix for #6626 could cause kadmind to dereference a null pointer if\na create-principal request contains no password but does contain the\nKRB5_KDB_DISALLOW_ALL_TIX flag (e.g. \"addprinc -randkey -allow_tix\nname\").  Only clients authorized to create principals can trigger the\nbug.  Fix the bug by testing for a null password in check_1_6_dummy.\n\nCVSSv2 vector: AV:N/AC:M/Au:S/C:N/I:N/A:P/E:H/RL:O/RC:C\n\n[ghudson@mit.edu: Minor style change and commit message]\n\nticket: 7152\ntarget_version: 1.10.2\ntags: pullup",
        "cve_desc": "The check_1_6_dummy function in lib/kadm5/srv/svr_principal.c in kadmind in MIT Kerberos 5 (aka krb5) 1.8.x, 1.9.x, and 1.10.x before 1.10.2 allows remote authenticated administrators to cause a denial of service (NULL pointer dereference and daemon crash) via a KRB5_KDB_DISALLOW_ALL_TIX create request that lacks a password.",
        "target": 0
      },
      {
        "idx": 24191,
        "reasoning": "This code snippet is not directly related to the described vulnerability of a null pointer dereference in `kadmind` when handling principal creation requests with no password and the `KRB5_KDB_DISALLOW_ALL_TIX` flag. The commit message specifically mentions a fix within `check_1_6_dummy`, while this code focuses on key decryption and doesn't appear to be involved in the principal creation process where the bug occurs.\n\n\n\n",
        "func": "static int decrypt_key_data(krb5_context context,\n                            int n_key_data, krb5_key_data *key_data,\n                            krb5_keyblock **keyblocks, int *n_keys)\n{\n    krb5_keyblock *keys;\n    int ret, i;\n\n    keys = (krb5_keyblock *) malloc(n_key_data*sizeof(krb5_keyblock));\n    if (keys == NULL)\n        return ENOMEM;\n    memset(keys, 0, n_key_data*sizeof(krb5_keyblock));\n\n    for (i = 0; i < n_key_data; i++) {\n        ret = krb5_dbe_decrypt_key_data(context, NULL, &key_data[i], &keys[i],\n                                        NULL);\n        if (ret) {\n            for (; i >= 0; i--) {\n                if (keys[i].contents) {\n                    memset (keys[i].contents, 0, keys[i].length);\n                    free( keys[i].contents );\n                }\n            }\n\n            memset(keys, 0, n_key_data*sizeof(krb5_keyblock));\n            free(keys);\n            return ret;\n        }\n    }\n\n    *keyblocks = keys;\n    if (n_keys)\n        *n_keys = n_key_data;\n\n    return 0;\n}\n",
        "commit_message": "Null pointer deref in kadmind [CVE-2012-1013]\n\nThe fix for #6626 could cause kadmind to dereference a null pointer if\na create-principal request contains no password but does contain the\nKRB5_KDB_DISALLOW_ALL_TIX flag (e.g. \"addprinc -randkey -allow_tix\nname\").  Only clients authorized to create principals can trigger the\nbug.  Fix the bug by testing for a null password in check_1_6_dummy.\n\nCVSSv2 vector: AV:N/AC:M/Au:S/C:N/I:N/A:P/E:H/RL:O/RC:C\n\n[ghudson@mit.edu: Minor style change and commit message]\n\nticket: 7152\ntarget_version: 1.10.2\ntags: pullup",
        "cve_desc": "The check_1_6_dummy function in lib/kadm5/srv/svr_principal.c in kadmind in MIT Kerberos 5 (aka krb5) 1.8.x, 1.9.x, and 1.10.x before 1.10.2 allows remote authenticated administrators to cause a denial of service (NULL pointer dereference and daemon crash) via a KRB5_KDB_DISALLOW_ALL_TIX create request that lacks a password.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 910,
        "reasoning": "This code is vulnerable to a null pointer dereference because the `find_realm_data` function can return NULL when a realm isn't found, and the code immediately dereferences this potentially null `newrealm` pointer by assigning it to `kdc_active_realm` without a check. This occurs when the KDC serves multiple realms and a crafted request specifies a realm that doesn't exist, leading to a KDC crash and denial of service.",
        "func": "setup_server_realm(krb5_principal sprinc)\n{\n    krb5_error_code     kret;\n     kdc_realm_t         *newrealm;\n \n     kret = 0;\n     if (kdc_numrealms > 1) {\n         if (!(newrealm = find_realm_data(sprinc->realm.data,\n                                          (krb5_ui_4) sprinc->realm.length)))\n            kret = ENOENT;\n        else\n            kdc_active_realm = newrealm;\n    }\n    else\n        kdc_active_realm = kdc_realmlist[0];\n    return(kret);\n}\n",
        "commit_message": "Multi-realm KDC null deref [CVE-2013-1418]\n\nIf a KDC serves multiple realms, certain requests can cause\nsetup_server_realm() to dereference a null pointer, crashing the KDC.\n\nCVSSv2: AV:N/AC:M/Au:N/C:N/I:N/A:P/E:POC/RL:OF/RC:C\n\nA related but more minor vulnerability requires authentication to\nexploit, and is only present if a third-party KDC database module can\ndereference a null pointer under certain conditions.\n\n(back ported from commit 5d2d9a1abe46a2c1a8614d4672d08d9d30a5f8bf)\n\nticket: 7757 (new)\nversion_fixed: 1.10.7\nstatus: resolved",
        "cve_desc": "The setup_server_realm function in main.c in the Key Distribution Center (KDC) in MIT Kerberos 5 (aka krb5) before 1.10.7, when multiple realms are configured, allows remote attackers to cause a denial of service (NULL pointer dereference and daemon crash) via a crafted request.",
        "target": 1
      },
      {
        "idx": 1083,
        "reasoning": "This code is vulnerable to a null pointer dereference because the `strlcpy` function is called with `comp1->data` when `comp1` could be NULL, specifically if memory allocation for `comp1_str` fails. The vulnerability is triggered by a specially crafted TGS-REQ request that leads to this condition, causing the KDC process to crash.",
        "func": "prep_reprocess_req(krb5_kdc_req *request, krb5_principal *krbtgt_princ)\n{\n    krb5_error_code retval = KRB5KRB_AP_ERR_BADMATCH;\n    char **realms, **cpp, *temp_buf=NULL;\n    krb5_data *comp1 = NULL, *comp2 = NULL;\n    char *comp1_str = NULL;\n\n    /* By now we know that server principal name is unknown.\n     * If CANONICALIZE flag is set in the request\n     * If req is not U2U authn. req\n     * the requested server princ. has exactly two components\n     * either\n     *      the name type is NT-SRV-HST\n     *      or name type is NT-UNKNOWN and\n     *         the 1st component is listed in conf file under host_based_services\n     * the 1st component is not in a list in conf under \"no_host_referral\"\n     * the 2d component looks like fully-qualified domain name (FQDN)\n     * If all of these conditions are satisfied - try mapping the FQDN and\n     * re-process the request as if client had asked for cross-realm TGT.\n     */\n    if (isflagset(request->kdc_options, KDC_OPT_CANONICALIZE) &&\n        !isflagset(request->kdc_options, KDC_OPT_ENC_TKT_IN_SKEY) &&\n        krb5_princ_size(kdc_context, request->server) == 2) {\n\n        comp1 = krb5_princ_component(kdc_context, request->server, 0);\n        comp2 = krb5_princ_component(kdc_context, request->server, 1);\n\n        comp1_str = calloc(1,comp1->length+1);\n        if (!comp1_str) {\n             retval = ENOMEM;\n             goto cleanup;\n         }\n        strlcpy(comp1_str,comp1->data,comp1->length+1);\n \n         if ((krb5_princ_type(kdc_context, request->server) == KRB5_NT_SRV_HST ||\n              krb5_princ_type(kdc_context, request->server) == KRB5_NT_SRV_INST ||\n             (krb5_princ_type(kdc_context, request->server) == KRB5_NT_UNKNOWN &&\n              kdc_active_realm->realm_host_based_services != NULL &&\n              (krb5_match_config_pattern(kdc_active_realm->realm_host_based_services,\n                                         comp1_str) == TRUE ||\n               krb5_match_config_pattern(kdc_active_realm->realm_host_based_services,\n                                         KRB5_CONF_ASTERISK) == TRUE))) &&\n            (kdc_active_realm->realm_no_host_referral == NULL ||\n             (krb5_match_config_pattern(kdc_active_realm->realm_no_host_referral,\n                                        KRB5_CONF_ASTERISK) == FALSE &&\n              krb5_match_config_pattern(kdc_active_realm->realm_no_host_referral,\n                                        comp1_str) == FALSE))) {\n\n            if (memchr(comp2->data, '.', comp2->length) == NULL)\n                goto cleanup;\n            temp_buf = calloc(1, comp2->length+1);\n            if (!temp_buf) {\n                 retval = ENOMEM;\n                 goto cleanup;\n             }\n            strlcpy(temp_buf, comp2->data,comp2->length+1);\n             retval = krb5int_get_domain_realm_mapping(kdc_context, temp_buf, &realms);\n             free(temp_buf);\n             if (retval) {\n                /* no match found */\n                kdc_err(kdc_context, retval, \"unable to find realm of host\");\n                goto cleanup;\n            }\n            if (realms == 0) {\n                retval = KRB5KRB_AP_ERR_BADMATCH;\n                goto cleanup;\n            }\n            /* Don't return a referral to the null realm or the service\n             * realm. */\n            if (realms[0] == 0 ||\n                data_eq_string(request->server->realm, realms[0])) {\n                free(realms[0]);\n                free(realms);\n                retval = KRB5KRB_AP_ERR_BADMATCH;\n                goto cleanup;\n            }\n            /* Modify request.\n             * Construct cross-realm tgt :  krbtgt/REMOTE_REALM@LOCAL_REALM\n             * and use it as a principal in this req.\n             */\n            retval = krb5_build_principal(kdc_context, krbtgt_princ,\n                                          (*request->server).realm.length,\n                                          (*request->server).realm.data,\n                                          \"krbtgt\", realms[0], (char *)0);\n            for (cpp = realms; *cpp; cpp++)\n                free(*cpp);\n        }\n    }\ncleanup:\n    free(comp1_str);\n\n    return retval;\n}\n",
        "commit_message": "KDC TGS-REQ null deref [CVE-2013-1416]\n\nBy sending an unusual but valid TGS-REQ, an authenticated remote\nattacker can cause the KDC process to crash by dereferencing a null\npointer.\n\nprep_reprocess_req() can cause a null pointer dereference when\nprocessing a service principal name.  Code in this function can\ninappropriately pass a null pointer to strlcpy().  Unmodified client\nsoftware can trivially trigger this vulnerability, but the attacker\nmust have already authenticated and received a valid Kerberos ticket.\n\nThe vulnerable code was introduced by the implementation of new\nservice principal realm referral functionality in krb5-1.7, but was\ncorrected as a side effect of the KDC refactoring in krb5-1.11.\n\nCVSSv2 vector: AV:N/AC:L/Au:S/C:N/I:N/A:C/E:H/RL:O/RC:C\n\nticket: 7600 (new)\nversion_fixed: 1.10.5\nstatus: resolved",
        "cve_desc": "The prep_reprocess_req function in do_tgs_req.c in the Key Distribution Center (KDC) in MIT Kerberos 5 (aka krb5) before 1.10.5 does not properly perform service-principal realm referral, which allows remote authenticated users to cause a denial of service (NULL pointer dereference and daemon crash) via a crafted TGS-REQ request.",
        "target": 1
      },
      {
        "idx": 1084,
        "reasoning": "The code is vulnerable because the `d2i_PKCS7_ISSUER_AND_SERIAL` function can return a NULL pointer if the input `pdid_buf` is malformed, and this NULL pointer is then dereferenced in the `cleanup` section when attempting to free `is->issuer` and `is->serial`. This results in a null pointer dereference and a crash of the KDC process, leading to a denial of service.",
        "func": "pkinit_check_kdc_pkid(krb5_context context,\n                      pkinit_plg_crypto_context plg_cryptoctx,\n                      pkinit_req_crypto_context req_cryptoctx,\n                      pkinit_identity_crypto_context id_cryptoctx,\n                      unsigned char *pdid_buf,\n                      unsigned int pkid_len,\n                      int *valid_kdcPkId)\n{\n    krb5_error_code retval = KRB5KDC_ERR_PREAUTH_FAILED;\n    PKCS7_ISSUER_AND_SERIAL *is = NULL;\n    const unsigned char *p = pdid_buf;\n    int status = 1;\n    X509 *kdc_cert = sk_X509_value(id_cryptoctx->my_certs, id_cryptoctx->cert_index);\n\n    *valid_kdcPkId = 0;\n     pkiDebug(\"found kdcPkId in AS REQ\\n\");\n     is = d2i_PKCS7_ISSUER_AND_SERIAL(NULL, &p, (int)pkid_len);\n     if (is == NULL)\n        goto cleanup;\n \n     status = X509_NAME_cmp(X509_get_issuer_name(kdc_cert), is->issuer);\n     if (!status) {\n        status = ASN1_INTEGER_cmp(X509_get_serialNumber(kdc_cert), is->serial);\n        if (!status)\n            *valid_kdcPkId = 1;\n     }\n \n     retval = 0;\ncleanup:\n     X509_NAME_free(is->issuer);\n     ASN1_INTEGER_free(is->serial);\n     free(is);\n\n    return retval;\n}\n",
        "commit_message": "PKINIT null pointer deref [CVE-2013-1415]\n\nDon't dereference a null pointer when cleaning up.\n\nThe KDC plugin for PKINIT can dereference a null pointer when a\nmalformed packet causes processing to terminate early, leading to\na crash of the KDC process.  An attacker would need to have a valid\nPKINIT certificate or have observed a successful PKINIT authentication,\nor an unauthenticated attacker could execute the attack if anonymous\nPKINIT is enabled.\n\nCVSSv2 vector: AV:N/AC:M/Au:N/C:N/I:N/A:C/E:P/RL:O/RC:C\n\nThis is a minimal commit for pullup; style fixes in a followup.\n[kaduk@mit.edu: reformat and edit commit message]\n\n(cherry picked from commit c773d3c775e9b2d88bcdff5f8a8ba88d7ec4e8ed)\n\nticket: 7570\nversion_fixed: 1.11.1\nstatus: resolved",
        "cve_desc": "The pkinit_check_kdc_pkid function in plugins/preauth/pkinit/pkinit_crypto_openssl.c in the PKINIT implementation in the Key Distribution Center (KDC) in MIT Kerberos 5 (aka krb5) before 1.10.4 and 1.11.x before 1.11.1 does not properly handle errors during extraction of fields from an X.509 certificate, which allows remote attackers to cause a denial of service (NULL pointer dereference and daemon crash) via a malformed KRB5_PADATA_PK_AS_REQ AS-REQ request.",
        "target": 1
      },
      {
        "idx": 1150,
        "reasoning": "The code is vulnerable to a NULL pointer dereference because it attempts to access `rep->u.dh_Info.kdfID` without checking if `rep` is NULL, specifically when handling draft9 requests. This occurs when processing DH key exchange, leading to a crash if a KDF identifier is sought in a non-existent structure, as described in CVE-2012-1016.",
        "func": "pkinit_server_return_padata(krb5_context context,\n                            krb5_pa_data * padata,\n                            krb5_data *req_pkt,\n                            krb5_kdc_req * request,\n                            krb5_kdc_rep * reply,\n                            krb5_keyblock * encrypting_key,\n                            krb5_pa_data ** send_pa,\n                            krb5_kdcpreauth_callbacks cb,\n                            krb5_kdcpreauth_rock rock,\n                            krb5_kdcpreauth_moddata moddata,\n                            krb5_kdcpreauth_modreq modreq)\n{\n    krb5_error_code retval = 0;\n    krb5_data scratch = {0, 0, NULL};\n    krb5_pa_pk_as_req *reqp = NULL;\n    krb5_pa_pk_as_req_draft9 *reqp9 = NULL;\n    int i = 0;\n\n    unsigned char *subjectPublicKey = NULL;\n    unsigned char *dh_pubkey = NULL, *server_key = NULL;\n    unsigned int subjectPublicKey_len = 0;\n    unsigned int server_key_len = 0, dh_pubkey_len = 0;\n\n    krb5_kdc_dh_key_info dhkey_info;\n    krb5_data *encoded_dhkey_info = NULL;\n    krb5_pa_pk_as_rep *rep = NULL;\n    krb5_pa_pk_as_rep_draft9 *rep9 = NULL;\n    krb5_data *out_data = NULL;\n    krb5_octet_data secret;\n\n    krb5_enctype enctype = -1;\n\n    krb5_reply_key_pack *key_pack = NULL;\n    krb5_reply_key_pack_draft9 *key_pack9 = NULL;\n    krb5_data *encoded_key_pack = NULL;\n\n    pkinit_kdc_context plgctx;\n    pkinit_kdc_req_context reqctx;\n\n    int fixed_keypack = 0;\n\n    *send_pa = NULL;\n    if (padata->pa_type == KRB5_PADATA_PKINIT_KX) {\n        return return_pkinit_kx(context, request, reply,\n                                encrypting_key, send_pa);\n    }\n    if (padata->length <= 0 || padata->contents == NULL)\n        return 0;\n\n    if (modreq == NULL) {\n        pkiDebug(\"missing request context \\n\");\n        return EINVAL;\n    }\n\n    plgctx = pkinit_find_realm_context(context, moddata, request->server);\n    if (plgctx == NULL) {\n        pkiDebug(\"Unable to locate correct realm context\\n\");\n        return ENOENT;\n    }\n\n    pkiDebug(\"pkinit_return_padata: entered!\\n\");\n    reqctx = (pkinit_kdc_req_context)modreq;\n\n    if (encrypting_key->contents) {\n        free(encrypting_key->contents);\n        encrypting_key->length = 0;\n        encrypting_key->contents = NULL;\n    }\n\n    for(i = 0; i < request->nktypes; i++) {\n        enctype = request->ktype[i];\n        if (!krb5_c_valid_enctype(enctype))\n            continue;\n        else {\n            pkiDebug(\"KDC picked etype = %d\\n\", enctype);\n            break;\n        }\n    }\n\n    if (i == request->nktypes) {\n        retval = KRB5KDC_ERR_ETYPE_NOSUPP;\n        goto cleanup;\n    }\n\n    switch((int)reqctx->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        init_krb5_pa_pk_as_rep(&rep);\n        if (rep == NULL) {\n            retval = ENOMEM;\n            goto cleanup;\n        }\n        /* let's assume it's RSA. we'll reset it to DH if needed */\n        rep->choice = choice_pa_pk_as_rep_encKeyPack;\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        init_krb5_pa_pk_as_rep_draft9(&rep9);\n        if (rep9 == NULL) {\n            retval = ENOMEM;\n            goto cleanup;\n        }\n        rep9->choice = choice_pa_pk_as_rep_draft9_encKeyPack;\n        break;\n    default:\n        retval = KRB5KDC_ERR_PREAUTH_FAILED;\n        goto cleanup;\n    }\n\n    if (reqctx->rcv_auth_pack != NULL &&\n        reqctx->rcv_auth_pack->clientPublicValue != NULL) {\n        subjectPublicKey =\n            reqctx->rcv_auth_pack->clientPublicValue->subjectPublicKey.data;\n        subjectPublicKey_len =\n            reqctx->rcv_auth_pack->clientPublicValue->subjectPublicKey.length;\n        rep->choice = choice_pa_pk_as_rep_dhInfo;\n    } else if (reqctx->rcv_auth_pack9 != NULL &&\n               reqctx->rcv_auth_pack9->clientPublicValue != NULL) {\n        subjectPublicKey =\n            reqctx->rcv_auth_pack9->clientPublicValue->subjectPublicKey.data;\n        subjectPublicKey_len =\n            reqctx->rcv_auth_pack9->clientPublicValue->subjectPublicKey.length;\n        rep9->choice = choice_pa_pk_as_rep_draft9_dhSignedData;\n    }\n\n    /* if this DH, then process finish computing DH key */\n    if (rep != NULL && (rep->choice == choice_pa_pk_as_rep_dhInfo ||\n                        rep->choice == choice_pa_pk_as_rep_draft9_dhSignedData)) {\n        pkiDebug(\"received DH key delivery AS REQ\\n\");\n        retval = server_process_dh(context, plgctx->cryptoctx,\n                                   reqctx->cryptoctx, plgctx->idctx, subjectPublicKey,\n                                   subjectPublicKey_len, &dh_pubkey, &dh_pubkey_len,\n                                   &server_key, &server_key_len);\n        if (retval) {\n            pkiDebug(\"failed to process/create dh paramters\\n\");\n            goto cleanup;\n        }\n    }\n    if ((rep9 != NULL &&\n         rep9->choice == choice_pa_pk_as_rep_draft9_dhSignedData) ||\n        (rep != NULL && rep->choice == choice_pa_pk_as_rep_dhInfo)) {\n\n        /*\n         * This is DH, so don't generate the key until after we\n         * encode the reply, because the encoded reply is needed\n         * to generate the key in some cases.\n         */\n\n        dhkey_info.subjectPublicKey.length = dh_pubkey_len;\n        dhkey_info.subjectPublicKey.data = dh_pubkey;\n        dhkey_info.nonce = request->nonce;\n        dhkey_info.dhKeyExpiration = 0;\n\n        retval = k5int_encode_krb5_kdc_dh_key_info(&dhkey_info,\n                                                   &encoded_dhkey_info);\n        if (retval) {\n            pkiDebug(\"encode_krb5_kdc_dh_key_info failed\\n\");\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin((unsigned char *)encoded_dhkey_info->data,\n                         encoded_dhkey_info->length,\n                         \"/tmp/kdc_dh_key_info\");\n#endif\n\n        switch ((int)padata->pa_type) {\n        case KRB5_PADATA_PK_AS_REQ:\n            retval = cms_signeddata_create(context, plgctx->cryptoctx,\n                                           reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_SERVER, 1,\n                                           (unsigned char *)encoded_dhkey_info->data,\n                                           encoded_dhkey_info->length,\n                                           &rep->u.dh_Info.dhSignedData.data,\n                                           &rep->u.dh_Info.dhSignedData.length);\n            if (retval) {\n                pkiDebug(\"failed to create pkcs7 signed data\\n\");\n                goto cleanup;\n            }\n            break;\n        case KRB5_PADATA_PK_AS_REP_OLD:\n        case KRB5_PADATA_PK_AS_REQ_OLD:\n            retval = cms_signeddata_create(context, plgctx->cryptoctx,\n                                           reqctx->cryptoctx, plgctx->idctx, CMS_SIGN_DRAFT9, 1,\n                                           (unsigned char *)encoded_dhkey_info->data,\n                                           encoded_dhkey_info->length,\n                                           &rep9->u.dhSignedData.data,\n                                           &rep9->u.dhSignedData.length);\n            if (retval) {\n                pkiDebug(\"failed to create pkcs7 signed data\\n\");\n                goto cleanup;\n            }\n            break;\n        }\n\n    } else {\n        pkiDebug(\"received RSA key delivery AS REQ\\n\");\n\n        retval = krb5_c_make_random_key(context, enctype, encrypting_key);\n        if (retval) {\n            pkiDebug(\"unable to make a session key\\n\");\n            goto cleanup;\n        }\n\n        /* check if PA_TYPE of 132 is present which means the client is\n         * requesting that a checksum is send back instead of the nonce\n         */\n        for (i = 0; request->padata[i] != NULL; i++) {\n            pkiDebug(\"%s: Checking pa_type 0x%08x\\n\",\n                     __FUNCTION__, request->padata[i]->pa_type);\n            if (request->padata[i]->pa_type == 132)\n                fixed_keypack = 1;\n        }\n        pkiDebug(\"%s: return checksum instead of nonce = %d\\n\",\n                 __FUNCTION__, fixed_keypack);\n\n        /* if this is an RFC reply or draft9 client requested a checksum\n         * in the reply instead of the nonce, create an RFC-style keypack\n         */\n        if ((int)padata->pa_type == KRB5_PADATA_PK_AS_REQ || fixed_keypack) {\n            init_krb5_reply_key_pack(&key_pack);\n            if (key_pack == NULL) {\n                retval = ENOMEM;\n                goto cleanup;\n            }\n\n            retval = krb5_c_make_checksum(context, 0,\n                                          encrypting_key, KRB5_KEYUSAGE_TGS_REQ_AUTH_CKSUM,\n                                          req_pkt, &key_pack->asChecksum);\n            if (retval) {\n                pkiDebug(\"unable to calculate AS REQ checksum\\n\");\n                goto cleanup;\n            }\n#ifdef DEBUG_CKSUM\n            pkiDebug(\"calculating checksum on buf size = %d\\n\", req_pkt->length);\n            print_buffer(req_pkt->data, req_pkt->length);\n            pkiDebug(\"checksum size = %d\\n\", key_pack->asChecksum.length);\n            print_buffer(key_pack->asChecksum.contents,\n                         key_pack->asChecksum.length);\n            pkiDebug(\"encrypting key (%d)\\n\", encrypting_key->length);\n            print_buffer(encrypting_key->contents, encrypting_key->length);\n#endif\n\n            krb5_copy_keyblock_contents(context, encrypting_key,\n                                        &key_pack->replyKey);\n\n            retval = k5int_encode_krb5_reply_key_pack(key_pack,\n                                                      &encoded_key_pack);\n            if (retval) {\n                pkiDebug(\"failed to encode reply_key_pack\\n\");\n                goto cleanup;\n            }\n        }\n\n        switch ((int)padata->pa_type) {\n        case KRB5_PADATA_PK_AS_REQ:\n            rep->choice = choice_pa_pk_as_rep_encKeyPack;\n            retval = cms_envelopeddata_create(context, plgctx->cryptoctx,\n                                              reqctx->cryptoctx, plgctx->idctx, padata->pa_type, 1,\n                                              (unsigned char *)encoded_key_pack->data,\n                                              encoded_key_pack->length,\n                                              &rep->u.encKeyPack.data, &rep->u.encKeyPack.length);\n            break;\n        case KRB5_PADATA_PK_AS_REP_OLD:\n        case KRB5_PADATA_PK_AS_REQ_OLD:\n            /* if the request is from the broken draft9 client that\n             * expects back a nonce, create it now\n             */\n            if (!fixed_keypack) {\n                init_krb5_reply_key_pack_draft9(&key_pack9);\n                if (key_pack9 == NULL) {\n                    retval = ENOMEM;\n                    goto cleanup;\n                }\n                key_pack9->nonce = reqctx->rcv_auth_pack9->pkAuthenticator.nonce;\n                krb5_copy_keyblock_contents(context, encrypting_key,\n                                            &key_pack9->replyKey);\n\n                retval = k5int_encode_krb5_reply_key_pack_draft9(key_pack9,\n                                                                 &encoded_key_pack);\n                if (retval) {\n                    pkiDebug(\"failed to encode reply_key_pack\\n\");\n                    goto cleanup;\n                }\n            }\n\n            rep9->choice = choice_pa_pk_as_rep_draft9_encKeyPack;\n            retval = cms_envelopeddata_create(context, plgctx->cryptoctx,\n                                              reqctx->cryptoctx, plgctx->idctx, padata->pa_type, 1,\n                                              (unsigned char *)encoded_key_pack->data,\n                                              encoded_key_pack->length,\n                                              &rep9->u.encKeyPack.data, &rep9->u.encKeyPack.length);\n            break;\n        }\n        if (retval) {\n            pkiDebug(\"failed to create pkcs7 enveloped data: %s\\n\",\n                     error_message(retval));\n            goto cleanup;\n        }\n#ifdef DEBUG_ASN1\n        print_buffer_bin((unsigned char *)encoded_key_pack->data,\n                         encoded_key_pack->length,\n                         \"/tmp/kdc_key_pack\");\n        switch ((int)padata->pa_type) {\n        case KRB5_PADATA_PK_AS_REQ:\n            print_buffer_bin(rep->u.encKeyPack.data,\n                             rep->u.encKeyPack.length,\n                             \"/tmp/kdc_enc_key_pack\");\n            break;\n        case KRB5_PADATA_PK_AS_REP_OLD:\n        case KRB5_PADATA_PK_AS_REQ_OLD:\n            print_buffer_bin(rep9->u.encKeyPack.data,\n                             rep9->u.encKeyPack.length,\n                             \"/tmp/kdc_enc_key_pack\");\n            break;\n        }\n#endif\n    }\n\n    if ((rep != NULL && rep->choice == choice_pa_pk_as_rep_dhInfo) &&\n        ((reqctx->rcv_auth_pack != NULL &&\n          reqctx->rcv_auth_pack->supportedKDFs != NULL))) {\n\n        /* If using the alg-agility KDF, put the algorithm in the reply\n         * before encoding it.\n         */\n        if (reqctx->rcv_auth_pack != NULL &&\n            reqctx->rcv_auth_pack->supportedKDFs != NULL) {\n            retval = pkinit_pick_kdf_alg(context, reqctx->rcv_auth_pack->supportedKDFs,\n                                         &(rep->u.dh_Info.kdfID));\n            if (retval) {\n                pkiDebug(\"pkinit_pick_kdf_alg failed: %s\\n\",\n                         error_message(retval));\n                goto cleanup;\n            }\n        }\n    }\n\n    switch ((int)padata->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        retval = k5int_encode_krb5_pa_pk_as_rep(rep, &out_data);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        retval = k5int_encode_krb5_pa_pk_as_rep_draft9(rep9, &out_data);\n        break;\n    }\n    if (retval) {\n        pkiDebug(\"failed to encode AS_REP\\n\");\n        goto cleanup;\n    }\n#ifdef DEBUG_ASN1\n    if (out_data != NULL)\n        print_buffer_bin((unsigned char *)out_data->data, out_data->length,\n                         \"/tmp/kdc_as_rep\");\n#endif\n\n    /* If this is DH, we haven't computed the key yet, so do it now. */\n    if ((rep9 != NULL &&\n          rep9->choice == choice_pa_pk_as_rep_draft9_dhSignedData) ||\n         (rep != NULL && rep->choice == choice_pa_pk_as_rep_dhInfo)) {\n \n        /* If mutually supported KDFs were found, use the alg agility KDF */\n        if (rep->u.dh_Info.kdfID) {\n            secret.data = server_key;\n             secret.length = server_key_len;\n \n             retval = pkinit_alg_agility_kdf(context, &secret,\n                                            rep->u.dh_Info.kdfID,\n                                            request->client, request->server,\n                                            enctype,\n                                            (krb5_octet_data *)req_pkt,\n                                            (krb5_octet_data *)out_data,\n                                            encrypting_key);\n            if (retval) {\n                pkiDebug(\"pkinit_alg_agility_kdf failed: %s\\n\",\n                         error_message(retval));\n                goto cleanup;\n            }\n\n            /* Otherwise, use the older octetstring2key() function */\n        } else {\n            retval = pkinit_octetstring2key(context, enctype, server_key,\n                                            server_key_len, encrypting_key);\n            if (retval) {\n                pkiDebug(\"pkinit_octetstring2key failed: %s\\n\",\n                         error_message(retval));\n                goto cleanup;\n            }\n        }\n    }\n\n    *send_pa = malloc(sizeof(krb5_pa_data));\n    if (*send_pa == NULL) {\n        retval = ENOMEM;\n        free(out_data->data);\n        free(out_data);\n        out_data = NULL;\n        goto cleanup;\n    }\n    (*send_pa)->magic = KV5M_PA_DATA;\n    switch ((int)padata->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        (*send_pa)->pa_type = KRB5_PADATA_PK_AS_REP;\n        break;\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n    case KRB5_PADATA_PK_AS_REP_OLD:\n        (*send_pa)->pa_type = KRB5_PADATA_PK_AS_REP_OLD;\n        break;\n    }\n    (*send_pa)->length = out_data->length;\n    (*send_pa)->contents = (krb5_octet *) out_data->data;\n\ncleanup:\n    pkinit_fini_kdc_req_context(context, reqctx);\n    free(scratch.data);\n    free(out_data);\n    if (encoded_dhkey_info != NULL)\n        krb5_free_data(context, encoded_dhkey_info);\n    if (encoded_key_pack != NULL)\n        krb5_free_data(context, encoded_key_pack);\n    free(dh_pubkey);\n    free(server_key);\n\n    switch ((int)padata->pa_type) {\n    case KRB5_PADATA_PK_AS_REQ:\n        free_krb5_pa_pk_as_req(&reqp);\n        free_krb5_pa_pk_as_rep(&rep);\n        free_krb5_reply_key_pack(&key_pack);\n        break;\n    case KRB5_PADATA_PK_AS_REP_OLD:\n    case KRB5_PADATA_PK_AS_REQ_OLD:\n        free_krb5_pa_pk_as_req_draft9(&reqp9);\n        free_krb5_pa_pk_as_rep_draft9(&rep9);\n        if (!fixed_keypack)\n            free_krb5_reply_key_pack_draft9(&key_pack9);\n        else\n            free_krb5_reply_key_pack(&key_pack);\n        break;\n    }\n\n    if (retval)\n        pkiDebug(\"pkinit_verify_padata failure\");\n\n    return retval;\n}\n",
        "commit_message": "PKINIT (draft9) null ptr deref [CVE-2012-1016]\n\nDon't check for an agility KDF identifier in the non-draft9 reply\nstructure when we're building a draft9 reply, because it'll be NULL.\n\nThe KDC plugin for PKINIT can dereference a null pointer when handling\na draft9 request, leading to a crash of the KDC process.  An attacker\nwould need to have a valid PKINIT certificate, or an unauthenticated\nattacker could execute the attack if anonymous PKINIT is enabled.\n\nCVSSv2 vector: AV:N/AC:M/Au:N/C:N/I:N/A:P/E:P/RL:O/RC:C\n\n[tlyu@mit.edu: reformat comment and edit log message]\n\n(back ported from commit cd5ff932c9d1439c961b0cf9ccff979356686aff)\n\nticket: 7527 (new)\nversion_fixed: 1.10.4\nstatus: resolved",
        "cve_desc": "The pkinit_server_return_padata function in plugins/preauth/pkinit/pkinit_srv.c in the PKINIT implementation in the Key Distribution Center (KDC) in MIT Kerberos 5 (aka krb5) before 1.10.4 attempts to find an agility KDF identifier in inappropriate circumstances, which allows remote attackers to cause a denial of service (NULL pointer dereference and daemon crash) via a crafted Draft 9 request.",
        "target": 1
      }
    ]
  },
  "kvm": {
    "0": [
      {
        "idx": 305171,
        "reasoning": "This code snippet, `kvm_iommu_unmap_guest`, is **not directly vulnerable** to the described issue (CVE-2014-3601). The vulnerability lies within the `kvm_iommu_put_pages` function, specifically regarding an incorrect parameter calculation leading to potential DMA issues, but this function is not present in the provided code.\n\n\n\n",
        "func": "int kvm_iommu_unmap_guest(struct kvm *kvm)\n{\n\tstruct iommu_domain *domain = kvm->arch.iommu_domain;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn 0;\n\n\tmutex_lock(&kvm->slots_lock);\n\tkvm_iommu_unmap_memslots(kvm);\n\tkvm->arch.iommu_domain = NULL;\n\tkvm->arch.iommu_noncoherent = false;\n\tmutex_unlock(&kvm->slots_lock);\n\n\tiommu_domain_free(domain);\n\treturn 0;\n}",
        "commit_message": "kvm: iommu: fix the third parameter of kvm_iommu_put_pages (CVE-2014-3601)\n\nThe third parameter of kvm_iommu_put_pages is wrong,\nIt should be 'gfn - slot->base_gfn'.\n\nBy making gfn very large, malicious guest or userspace can cause kvm to\ngo to this error path, and subsequently to pass a huge value as size.\nAlternatively if gfn is small, then pages would be pinned but never\nunpinned, causing host memory leak and local DOS.\n\nPassing a reasonable but large value could be the most dangerous case,\nbecause it would unpin a page that should have stayed pinned, and thus\nallow the device to DMA into arbitrary memory.  However, this cannot\nhappen because of the condition that can trigger the error:\n\n- out of memory (where you can't allocate even a single page)\n  should not be possible for the attacker to trigger\n\n- when exceeding the iommu's address space, guest pages after gfn\n  will also exceed the iommu's address space, and inside\n  kvm_iommu_put_pages() the iommu_iova_to_phys() will fail.  The\n  page thus would not be unpinned at all.\n\nReported-by: Jack Morgenstein <jackm@mellanox.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "cve_desc": "The kvm_iommu_map_pages function in virt/kvm/iommu.c in the Linux kernel through 3.16.1 miscalculates the number of pages during the handling of a mapping failure, which allows guest OS users to (1) cause a denial of service (host OS memory corruption) or possibly have unspecified other impact by triggering a large gfn value or (2) cause a denial of service (host OS memory consumption) by triggering a small gfn value that leads to permanently pinned pages.",
        "target": 0
      },
      {
        "idx": 305172,
        "reasoning": "This code is not vulnerable because the commit message explicitly states that the conditions required to exploit the incorrect parameter calculation\u2014out of memory or exceeding the iommu's address space\u2014are not reliably triggerable by an attacker. Even if the incorrect size calculation *could* be reached, the code includes checks (`iommu_iova_to_phys`) that prevent the dangerous unpinning of pages that should remain pinned.\n\n\n\n",
        "func": "static void kvm_iommu_put_pages(struct kvm *kvm,\n\t\t\t\tgfn_t base_gfn, unsigned long npages)\n{\n\tstruct iommu_domain *domain;\n\tgfn_t end_gfn, gfn;\n\tpfn_t pfn;\n\tu64 phys;\n\n\tdomain  = kvm->arch.iommu_domain;\n\tend_gfn = base_gfn + npages;\n\tgfn     = base_gfn;\n\n\t/* check if iommu exists and in use */\n\tif (!domain)\n\t\treturn;\n\n\twhile (gfn < end_gfn) {\n\t\tunsigned long unmap_pages;\n\t\tsize_t size;\n\n\t\t/* Get physical address */\n\t\tphys = iommu_iova_to_phys(domain, gfn_to_gpa(gfn));\n\n\t\tif (!phys) {\n\t\t\tgfn++;\n\t\t\tcontinue;\n\t\t}\n\n\t\tpfn  = phys >> PAGE_SHIFT;\n\n\t\t/* Unmap address from IO address space */\n\t\tsize       = iommu_unmap(domain, gfn_to_gpa(gfn), PAGE_SIZE);\n\t\tunmap_pages = 1ULL << get_order(size);\n\n\t\t/* Unpin all pages we just unmapped to not leak any memory */\n\t\tkvm_unpin_pages(kvm, pfn, unmap_pages);\n\n\t\tgfn += unmap_pages;\n\t}\n}",
        "commit_message": "kvm: iommu: fix the third parameter of kvm_iommu_put_pages (CVE-2014-3601)\n\nThe third parameter of kvm_iommu_put_pages is wrong,\nIt should be 'gfn - slot->base_gfn'.\n\nBy making gfn very large, malicious guest or userspace can cause kvm to\ngo to this error path, and subsequently to pass a huge value as size.\nAlternatively if gfn is small, then pages would be pinned but never\nunpinned, causing host memory leak and local DOS.\n\nPassing a reasonable but large value could be the most dangerous case,\nbecause it would unpin a page that should have stayed pinned, and thus\nallow the device to DMA into arbitrary memory.  However, this cannot\nhappen because of the condition that can trigger the error:\n\n- out of memory (where you can't allocate even a single page)\n  should not be possible for the attacker to trigger\n\n- when exceeding the iommu's address space, guest pages after gfn\n  will also exceed the iommu's address space, and inside\n  kvm_iommu_put_pages() the iommu_iova_to_phys() will fail.  The\n  page thus would not be unpinned at all.\n\nReported-by: Jack Morgenstein <jackm@mellanox.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "cve_desc": "The kvm_iommu_map_pages function in virt/kvm/iommu.c in the Linux kernel through 3.16.1 miscalculates the number of pages during the handling of a mapping failure, which allows guest OS users to (1) cause a denial of service (host OS memory corruption) or possibly have unspecified other impact by triggering a large gfn value or (2) cause a denial of service (host OS memory consumption) by triggering a small gfn value that leads to permanently pinned pages.",
        "target": 0
      },
      {
        "idx": 305173,
        "reasoning": "This code snippet is not directly vulnerable because the vulnerability lies within the `kvm_iommu_put_pages` function, and this code only calls `kvm_iommu_map_pages` which then likely calls `kvm_iommu_put_pages`. The commit message explicitly states that while a vulnerability *exists* in `kvm_iommu_put_pages`, conditions preventing exploitation (out of memory being difficult to trigger, and iommu address space limits) mitigate the risk, and this snippet doesn't introduce any new exploitable pathways.\n\n\n\n",
        "func": "static int kvm_iommu_map_memslots(struct kvm *kvm)\n{\n\tint idx, r = 0;\n\tstruct kvm_memslots *slots;\n\tstruct kvm_memory_slot *memslot;\n\n\tif (kvm->arch.iommu_noncoherent)\n\t\tkvm_arch_register_noncoherent_dma(kvm);\n\n\tidx = srcu_read_lock(&kvm->srcu);\n\tslots = kvm_memslots(kvm);\n\n\tkvm_for_each_memslot(memslot, slots) {\n\t\tr = kvm_iommu_map_pages(kvm, memslot);\n\t\tif (r)\n\t\t\tbreak;\n\t}\n\tsrcu_read_unlock(&kvm->srcu, idx);\n\n\treturn r;\n}",
        "commit_message": "kvm: iommu: fix the third parameter of kvm_iommu_put_pages (CVE-2014-3601)\n\nThe third parameter of kvm_iommu_put_pages is wrong,\nIt should be 'gfn - slot->base_gfn'.\n\nBy making gfn very large, malicious guest or userspace can cause kvm to\ngo to this error path, and subsequently to pass a huge value as size.\nAlternatively if gfn is small, then pages would be pinned but never\nunpinned, causing host memory leak and local DOS.\n\nPassing a reasonable but large value could be the most dangerous case,\nbecause it would unpin a page that should have stayed pinned, and thus\nallow the device to DMA into arbitrary memory.  However, this cannot\nhappen because of the condition that can trigger the error:\n\n- out of memory (where you can't allocate even a single page)\n  should not be possible for the attacker to trigger\n\n- when exceeding the iommu's address space, guest pages after gfn\n  will also exceed the iommu's address space, and inside\n  kvm_iommu_put_pages() the iommu_iova_to_phys() will fail.  The\n  page thus would not be unpinned at all.\n\nReported-by: Jack Morgenstein <jackm@mellanox.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Michael S. Tsirkin <mst@redhat.com>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "cve_desc": "The kvm_iommu_map_pages function in virt/kvm/iommu.c in the Linux kernel through 3.16.1 miscalculates the number of pages during the handling of a mapping failure, which allows guest OS users to (1) cause a denial of service (host OS memory corruption) or possibly have unspecified other impact by triggering a large gfn value or (2) cause a denial of service (host OS memory consumption) by triggering a small gfn value that leads to permanently pinned pages.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 210445,
        "reasoning": "This code is vulnerable because it doesn't validate the size of instructions being fetched, potentially attempting to decode instructions larger than the expected 15 bytes. This can lead to significant latency on non-preemptive hosts as the emulator struggles with invalid instruction lengths, ultimately causing a denial of service.",
        "func": "static int do_insn_fetch(struct x86_emulate_ctxt *ctxt,\n\t\t\t struct x86_emulate_ops *ops,\n\t\t\t unsigned long eip, void *dest, unsigned size)\n{\n\tint rc = 0;\n\n\teip += ctxt->cs_base;\n\twhile (size--) {\n\t\trc = do_fetch_insn_byte(ctxt, ops, eip++, dest++);\n\t\tif (rc)\n\t\t\treturn rc;\n\t}\n\treturn 0;\n}",
        "commit_message": "KVM: x86 emulator: limit instructions to 15 bytes\n\nWhile we are never normally passed an instruction that exceeds 15 bytes,\nsmp games can cause us to attempt to interpret one, which will cause\nlarge latencies in non-preempt hosts.\n\nCc: stable@kernel.org\nSigned-off-by: Avi Kivity <avi@redhat.com>",
        "cve_desc": "The do_insn_fetch function in arch/x86/kvm/emulate.c in the x86 emulator in the KVM subsystem in the Linux kernel before 2.6.32-rc8-next-20091125 tries to interpret instructions that contain too many bytes to be valid, which allows guest OS users to cause a denial of service (increased scheduling latency) on the host OS via unspecified manipulations related to SMP support.",
        "target": 1
      }
    ]
  },
  "ldns": {
    "0": [],
    "1": []
  },
  "leptonica": {
    "0": [
      {
        "idx": 77155,
        "reasoning": "This code is **not vulnerable** to the reported `sscanf()` and `fscanf()` buffer overflow issues because it uses `fwrite` and `strlen` to write data to a file, rather than the problematic format string functions. The commit message specifically addresses vulnerabilities in `fscanf()` and `sscanf()`, which are not present in this `gplotGenDataFiles` function.\n\n\n\n",
        "func": "gplotGenDataFiles(GPLOT  *gplot)\n{\nchar    *plotdata, *dataname;\nl_int32  i, nplots;\nFILE    *fp;\n\n    PROCNAME(\"gplotGenDataFiles\");\n\n    if (!gplot)\n        return ERROR_INT(\"gplot not defined\", procName, 1);\n\n    nplots = sarrayGetCount(gplot->datanames);\n    for (i = 0; i < nplots; i++) {\n        plotdata = sarrayGetString(gplot->plotdata, i, L_NOCOPY);\n        dataname = sarrayGetString(gplot->datanames, i, L_NOCOPY);\n        if ((fp = fopen(dataname, \"w\")) == NULL)\n            return ERROR_INT(\"datafile stream not opened\", procName, 1);\n        fwrite(plotdata, 1, strlen(plotdata), fp);\n        fclose(fp);\n    }\n\n    return 0;\n}\n",
        "commit_message": "Security fixes: expect final changes for release 1.75.3.\n* Fixed a debian security issue with fscanf() reading a string with\n  possible buffer overflow.\n* There were also a few similar situations with sscanf().",
        "cve_desc": "Leptonica before 1.75.3 does not limit the number of characters in a %s format argument to fscanf or sscanf, which allows remote attackers to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a long string, as demonstrated by the gplotRead and ptaReadStream functions.",
        "target": 0
      },
      {
        "idx": 77156,
        "reasoning": "This code snippet is not vulnerable to the reported `fscanf()` and `sscanf()` buffer overflow issues. The commit message specifically addresses vulnerabilities in functions using those input methods, while this code only performs direct assignment to a defined variable (`gplot->scaling`) after validating the input against a set of allowed values, eliminating any risk of uncontrolled string input.\n\n\n\n",
        "func": "gplotSetScaling(GPLOT   *gplot,\n                l_int32  scaling)\n{\n    PROCNAME(\"gplotSetScaling\");\n\n    if (!gplot)\n        return ERROR_INT(\"gplot not defined\", procName, 1);\n    if (scaling != GPLOT_LINEAR_SCALE &&\n        scaling != GPLOT_LOG_SCALE_X &&\n        scaling != GPLOT_LOG_SCALE_Y &&\n        scaling != GPLOT_LOG_SCALE_X_Y)\n        return ERROR_INT(\"invalid gplot scaling\", procName, 1);\n    gplot->scaling = scaling;\n    return 0;\n}\n",
        "commit_message": "Security fixes: expect final changes for release 1.75.3.\n* Fixed a debian security issue with fscanf() reading a string with\n  possible buffer overflow.\n* There were also a few similar situations with sscanf().",
        "cve_desc": "Leptonica before 1.75.3 does not limit the number of characters in a %s format argument to fscanf or sscanf, which allows remote attackers to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a long string, as demonstrated by the gplotRead and ptaReadStream functions.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3774,
        "reasoning": "The `pixHtmlViewer` function is vulnerable because the `rootname` parameter, which determines the base filename for generated HTML and image files, is directly used in `sprintf` calls without length validation. This allows a sufficiently long `rootname` to cause a buffer overflow in `charbuf`, potentially leading to arbitrary code execution as described in the CVE.",
        "func": "pixHtmlViewer(const char  *dirin,\n              const char  *dirout,\n              const char  *rootname,\n              l_int32      thumbwidth,\n              l_int32      viewwidth)\n{\nchar      *fname, *fullname, *outname;\nchar      *mainname, *linkname, *linknameshort;\nchar      *viewfile, *thumbfile;\nchar      *shtml, *slink;\nchar       charbuf[512];\nchar       htmlstring[] = \"<html>\";\nchar       framestring[] = \"</frameset></html>\";\nl_int32    i, nfiles, index, w, d, nimages, ret;\nl_float32  factor;\nPIX       *pix, *pixthumb, *pixview;\nSARRAY    *safiles, *sathumbs, *saviews, *sahtml, *salink;\n\n    PROCNAME(\"pixHtmlViewer\");\n\n    if (!dirin)\n        return ERROR_INT(\"dirin not defined\", procName, 1);\n    if (!dirout)\n        return ERROR_INT(\"dirout not defined\", procName, 1);\n    if (!rootname)\n        return ERROR_INT(\"rootname not defined\", procName, 1);\n\n    if (thumbwidth == 0)\n        thumbwidth = DEFAULT_THUMB_WIDTH;\n    if (thumbwidth < MIN_THUMB_WIDTH) {\n        L_WARNING(\"thumbwidth too small; using min value\\n\", procName);\n        thumbwidth = MIN_THUMB_WIDTH;\n    }\n    if (viewwidth == 0)\n        viewwidth = DEFAULT_VIEW_WIDTH;\n    if (viewwidth < MIN_VIEW_WIDTH) {\n        L_WARNING(\"viewwidth too small; using min value\\n\", procName);\n        viewwidth = MIN_VIEW_WIDTH;\n    }\n\n        /* Make the output directory if it doesn't already exist */\n#ifndef _WIN32\n    snprintf(charbuf, sizeof(charbuf), \"mkdir -p %s\", dirout);\n    ret = system(charbuf);\n#else\n    ret = CreateDirectory(dirout, NULL) ? 0 : 1;\n#endif  /* !_WIN32 */\n    if (ret) {\n        L_ERROR(\"output directory %s not made\\n\", procName, dirout);\n        return 1;\n    }\n\n        /* Capture the filenames in the input directory */\n    if ((safiles = getFilenamesInDirectory(dirin)) == NULL)\n         return ERROR_INT(\"safiles not made\", procName, 1);\n \n         /* Generate output text file names */\n    sprintf(charbuf, \"%s/%s.html\", dirout, rootname);\n     mainname = stringNew(charbuf);\n    sprintf(charbuf, \"%s/%s-links.html\", dirout, rootname);\n     linkname = stringNew(charbuf);\n     linknameshort = stringJoin(rootname, \"-links.html\");\n \n        /* Generate the thumbs and views */\n    sathumbs = sarrayCreate(0);\n    saviews = sarrayCreate(0);\n    nfiles = sarrayGetCount(safiles);\n    index = 0;\n    for (i = 0; i < nfiles; i++) {\n        fname = sarrayGetString(safiles, i, L_NOCOPY);\n        fullname = genPathname(dirin, fname);\n        fprintf(stderr, \"name: %s\\n\", fullname);\n        if ((pix = pixRead(fullname)) == NULL) {\n            fprintf(stderr, \"file %s not a readable image\\n\", fullname);\n            lept_free(fullname);\n            continue;\n        }\n        lept_free(fullname);\n\n            /* Make and store the thumbnail images */\n         pixGetDimensions(pix, &w, NULL, &d);\n         factor = (l_float32)thumbwidth / (l_float32)w;\n         pixthumb = pixScale(pix, factor, factor);\n        sprintf(charbuf, \"%s_thumb_%03d\", rootname, index);\n         sarrayAddString(sathumbs, charbuf, L_COPY);\n         outname = genPathname(dirout, charbuf);\n         WriteFormattedPix(outname, pixthumb);\n        lept_free(outname);\n        pixDestroy(&pixthumb);\n\n            /* Make and store the view images */\n        factor = (l_float32)viewwidth / (l_float32)w;\n        if (factor >= 1.0)\n            pixview = pixClone(pix);   /* no upscaling */\n        else\n            pixview = pixScale(pix, factor, factor);\n        snprintf(charbuf, sizeof(charbuf), \"%s_view_%03d\", rootname, index);\n        sarrayAddString(saviews, charbuf, L_COPY);\n        outname = genPathname(dirout, charbuf);\n        WriteFormattedPix(outname, pixview);\n        lept_free(outname);\n        pixDestroy(&pixview);\n        pixDestroy(&pix);\n        index++;\n    }\n\n        /* Generate the main html file */\n    sahtml = sarrayCreate(0);\n    sarrayAddString(sahtml, htmlstring, L_COPY);\n    sprintf(charbuf, \"<frameset cols=\\\"%d, *\\\">\", thumbwidth + 30);\n    sarrayAddString(sahtml, charbuf, L_COPY);\n    sprintf(charbuf, \"<frame name=\\\"thumbs\\\" src=\\\"%s\\\">\", linknameshort);\n    sarrayAddString(sahtml, charbuf, L_COPY);\n    sprintf(charbuf, \"<frame name=\\\"views\\\" src=\\\"%s\\\">\",\n            sarrayGetString(saviews, 0, L_NOCOPY));\n    sarrayAddString(sahtml, charbuf, L_COPY);\n    sarrayAddString(sahtml, framestring, L_COPY);\n    shtml = sarrayToString(sahtml, 1);\n    l_binaryWrite(mainname, \"w\", shtml, strlen(shtml));\n    fprintf(stderr, \"******************************************\\n\"\n                    \"Writing html file: %s\\n\"\n                    \"******************************************\\n\", mainname);\n    lept_free(shtml);\n    lept_free(mainname);\n\n        /* Generate the link html file */\n    nimages = sarrayGetCount(saviews);\n    fprintf(stderr, \"num. images = %d\\n\", nimages);\n    salink = sarrayCreate(0);\n    for (i = 0; i < nimages; i++) {\n        viewfile = sarrayGetString(saviews, i, L_NOCOPY);\n        thumbfile = sarrayGetString(sathumbs, i, L_NOCOPY);\n        sprintf(charbuf, \"<a href=\\\"%s\\\" TARGET=views><img src=\\\"%s\\\"></a>\",\n            viewfile, thumbfile);\n        sarrayAddString(salink, charbuf, L_COPY);\n    }\n    slink = sarrayToString(salink, 1);\n    l_binaryWrite(linkname, \"w\", slink, strlen(slink));\n    lept_free(slink);\n    lept_free(linkname);\n    lept_free(linknameshort);\n    sarrayDestroy(&safiles);\n    sarrayDestroy(&sathumbs);\n    sarrayDestroy(&saviews);\n    sarrayDestroy(&sahtml);\n    sarrayDestroy(&salink);\n    return 0;\n}\n",
        "commit_message": "prog/htmlviewer: Catch unbound memory access (CID 1386222)\n\nrootname can have any size, so limit the amount of copied bytes.\n\nSigned-off-by: Stefan Weil <sw@weilnetz.de>",
        "cve_desc": "An issue was discovered in pixHtmlViewer in prog/htmlviewer.c in Leptonica before 1.75.3. Unsanitized input (rootname) can overflow a buffer, leading potentially to arbitrary code execution or possibly unspecified other impact.",
        "target": 1
      },
      {
        "idx": 3779,
        "reasoning": "The code is vulnerable to a stack-based buffer overflow because `fscanf` and `sscanf` are used with the `%s` format specifier without a length limit, allowing an attacker to provide a string longer than the `buf` buffer size (`L_BUF_SIZE`). This overflow can overwrite adjacent memory on the stack, potentially leading to a denial of service or even arbitrary code execution.",
        "func": " gplotRead(const char  *filename)\n {\nchar     buf[L_BUF_SIZE];\n char    *rootname, *title, *xlabel, *ylabel, *ignores;\n l_int32  outformat, ret, version, ignore;\n FILE    *fp;\nGPLOT   *gplot;\n\n    PROCNAME(\"gplotRead\");\n\n    if (!filename)\n        return (GPLOT *)ERROR_PTR(\"filename not defined\", procName, NULL);\n\n    if ((fp = fopenReadStream(filename)) == NULL)\n        return (GPLOT *)ERROR_PTR(\"stream not opened\", procName, NULL);\n\n    ret = fscanf(fp, \"Gplot Version %d\\n\", &version);\n    if (ret != 1) {\n        fclose(fp);\n        return (GPLOT *)ERROR_PTR(\"not a gplot file\", procName, NULL);\n    }\n    if (version != GPLOT_VERSION_NUMBER) {\n        fclose(fp);\n         return (GPLOT *)ERROR_PTR(\"invalid gplot version\", procName, NULL);\n     }\n \n    ignore = fscanf(fp, \"Rootname: %s\\n\", buf);\n     rootname = stringNew(buf);\n     ignore = fscanf(fp, \"Output format: %d\\n\", &outformat);\n    ignores = fgets(buf, L_BUF_SIZE, fp);   /* Title: ... */\n     title = stringNew(buf + 7);\n     title[strlen(title) - 1] = '\\0';\n    ignores = fgets(buf, L_BUF_SIZE, fp);   /* X axis label: ... */\n     xlabel = stringNew(buf + 14);\n     xlabel[strlen(xlabel) - 1] = '\\0';\n    ignores = fgets(buf, L_BUF_SIZE, fp);   /* Y axis label: ... */\n     ylabel = stringNew(buf + 14);\n     ylabel[strlen(ylabel) - 1] = '\\0';\n \n    gplot = gplotCreate(rootname, outformat, title, xlabel, ylabel);\n    LEPT_FREE(rootname);\n    LEPT_FREE(title);\n    LEPT_FREE(xlabel);\n    LEPT_FREE(ylabel);\n    if (!gplot) {\n        fclose(fp);\n        return (GPLOT *)ERROR_PTR(\"gplot not made\", procName, NULL);\n    }\n    sarrayDestroy(&gplot->cmddata);\n    sarrayDestroy(&gplot->datanames);\n    sarrayDestroy(&gplot->plotdata);\n     sarrayDestroy(&gplot->plottitles);\n     numaDestroy(&gplot->plotstyles);\n \n    ignore = fscanf(fp, \"Commandfile name: %s\\n\", buf);\n     stringReplace(&gplot->cmdname, buf);\n     ignore = fscanf(fp, \"\\nCommandfile data:\");\n     gplot->cmddata = sarrayReadStream(fp);\n    ignore = fscanf(fp, \"\\nDatafile names:\");\n    gplot->datanames = sarrayReadStream(fp);\n    ignore = fscanf(fp, \"\\nPlot data:\");\n    gplot->plotdata = sarrayReadStream(fp);\n    ignore = fscanf(fp, \"\\nPlot titles:\");\n    gplot->plottitles = sarrayReadStream(fp);\n    ignore = fscanf(fp, \"\\nPlot styles:\");\n     gplot->plotstyles = numaReadStream(fp);\n \n     ignore = fscanf(fp, \"Number of plots: %d\\n\", &gplot->nplots);\n    ignore = fscanf(fp, \"Output file name: %s\\n\", buf);\n     stringReplace(&gplot->outname, buf);\n     ignore = fscanf(fp, \"Axis scaling: %d\\n\", &gplot->scaling);\n \n    fclose(fp);\n    return gplot;\n}\n",
        "commit_message": "Security fixes: expect final changes for release 1.75.3.\n* Fixed a debian security issue with fscanf() reading a string with\n  possible buffer overflow.\n* There were also a few similar situations with sscanf().",
        "cve_desc": "Leptonica before 1.75.3 does not limit the number of characters in a %s format argument to fscanf or sscanf, which allows remote attackers to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a long string, as demonstrated by the gplotRead and ptaReadStream functions.",
        "target": 1
      },
      {
        "idx": 3780,
        "reasoning": "This code is vulnerable to a stack-based buffer overflow because the `fscanf` function uses the `%s` format specifier to read the `typestr` variable without limiting the input string length, potentially exceeding the 128-byte buffer size. As described in the CVE, a maliciously crafted PTA file containing a long string for the format can overwrite adjacent memory on the stack, leading to a denial of service or potentially arbitrary code execution.",
        "func": " ptaReadStream(FILE  *fp)\n {\nchar       typestr[128];\n l_int32    i, n, ix, iy, type, version;\n l_float32  x, y;\n PTA       *pta;\n\n    PROCNAME(\"ptaReadStream\");\n\n    if (!fp)\n        return (PTA *)ERROR_PTR(\"stream not defined\", procName, NULL);\n\n    if (fscanf(fp, \"\\n Pta Version %d\\n\", &version) != 1)\n         return (PTA *)ERROR_PTR(\"not a pta file\", procName, NULL);\n     if (version != PTA_VERSION_NUMBER)\n         return (PTA *)ERROR_PTR(\"invalid pta version\", procName, NULL);\n    if (fscanf(fp, \" Number of pts = %d; format = %s\\n\", &n, typestr) != 2)\n         return (PTA *)ERROR_PTR(\"not a pta file\", procName, NULL);\n     if (!strcmp(typestr, \"float\"))\n         type = 0;\n    else  /* typestr is \"integer\" */\n        type = 1;\n\n    if ((pta = ptaCreate(n)) == NULL)\n        return (PTA *)ERROR_PTR(\"pta not made\", procName, NULL);\n    for (i = 0; i < n; i++) {\n        if (type == 0) {  /* data is float */\n            if (fscanf(fp, \"   (%f, %f)\\n\", &x, &y) != 2) {\n                ptaDestroy(&pta);\n                return (PTA *)ERROR_PTR(\"error reading floats\", procName, NULL);\n            }\n            ptaAddPt(pta, x, y);\n        } else {   /* data is integer */\n            if (fscanf(fp, \"   (%d, %d)\\n\", &ix, &iy) != 2) {\n                ptaDestroy(&pta);\n                return (PTA *)ERROR_PTR(\"error reading ints\", procName, NULL);\n            }\n            ptaAddPt(pta, ix, iy);\n        }\n    }\n\n    return pta;\n}\n",
        "commit_message": "Security fixes: expect final changes for release 1.75.3.\n* Fixed a debian security issue with fscanf() reading a string with\n  possible buffer overflow.\n* There were also a few similar situations with sscanf().",
        "cve_desc": "Leptonica before 1.75.3 does not limit the number of characters in a %s format argument to fscanf or sscanf, which allows remote attackers to cause a denial of service (stack-based buffer overflow) or possibly have unspecified other impact via a long string, as demonstrated by the gplotRead and ptaReadStream functions.",
        "target": 1
      },
      {
        "idx": 201334,
        "reasoning": "This code is vulnerable to a heap-buffer-overflow because the `pixRasterop` function, used for replicating columns, doesn't properly validate the source and destination regions, potentially leading to reads or writes outside the allocated buffer in `pixt`. The vulnerability is related to how columns are copied, specifically when replicating missing columns or the last column, as indicated by the CVE description referencing `rasteropGeneralLow` and adaptmap files which are closely related to pixel manipulation.",
        "func": "pixFillMapHoles(PIX     *pix,\n                l_int32  nx,\n                l_int32  ny,\n                l_int32  filltype)\n{\nl_int32   w, h, y, nmiss, goodcol, i, j, found, ival, valtest;\nl_uint32  val, lastval;\nNUMA     *na;  /* indicates if there is any data in the column */\nPIX      *pixt;\n\n    PROCNAME(\"pixFillMapHoles\");\n\n    if (!pix || pixGetDepth(pix) != 8)\n        return ERROR_INT(\"pix not defined or not 8 bpp\", procName, 1);\n    if (pixGetColormap(pix))\n        return ERROR_INT(\"pix is colormapped\", procName, 1);\n\n    /* ------------- Fill holes in the mapping image columns ----------- */\n    pixGetDimensions(pix, &w, &h, NULL);\n    na = numaCreate(0);  /* holds flag for which columns have data */\n    nmiss = 0;\n    valtest = (filltype == L_FILL_WHITE) ? 255 : 0;\n    for (j = 0; j < nx; j++) {  /* do it by columns */\n        found = FALSE;\n        for (i = 0; i < ny; i++) {\n            pixGetPixel(pix, j, i, &val);\n            if (val != valtest) {\n                y = i;\n                found = TRUE;\n                break;\n            }\n        }\n        if (found == FALSE) {\n            numaAddNumber(na, 0);  /* no data in the column */\n            nmiss++;\n        }\n        else {\n            numaAddNumber(na, 1);  /* data in the column */\n            for (i = y - 1; i >= 0; i--)  /* replicate upwards to top */\n                pixSetPixel(pix, j, i, val);\n            pixGetPixel(pix, j, 0, &lastval);\n            for (i = 1; i < h; i++) {  /* set going down to bottom */\n                pixGetPixel(pix, j, i, &val);\n                if (val == valtest)\n                    pixSetPixel(pix, j, i, lastval);\n                else\n                    lastval = val;\n            }\n        }\n    }\n    numaAddNumber(na, 0);  /* last column */\n\n    if (nmiss == nx) {  /* no data in any column! */\n        numaDestroy(&na);\n        L_WARNING(\"no bg found; no data in any column\\n\", procName);\n        return 1;\n    }\n\n    /* ---------- Fill in missing columns by replication ----------- */\n    if (nmiss > 0) {  /* replicate columns */\n        pixt = pixCopy(NULL, pix);\n            /* Find the first good column */\n        goodcol = 0;\n        for (j = 0; j < w; j++) {\n            numaGetIValue(na, j, &ival);\n            if (ival == 1) {\n                goodcol = j;\n                break;\n            }\n        }\n        if (goodcol > 0) {  /* copy cols backward */\n            for (j = goodcol - 1; j >= 0; j--) {\n                pixRasterop(pix, j, 0, 1, h, PIX_SRC, pixt, j + 1, 0);\n                pixRasterop(pixt, j, 0, 1, h, PIX_SRC, pix, j, 0);\n            }\n        }\n        for (j = goodcol + 1; j < w; j++) {   /* copy cols forward */\n            numaGetIValue(na, j, &ival);\n            if (ival == 0) {\n                    /* Copy the column to the left of j */\n                pixRasterop(pix, j, 0, 1, h, PIX_SRC, pixt, j - 1, 0);\n                pixRasterop(pixt, j, 0, 1, h, PIX_SRC, pix, j, 0);\n            }\n        }\n        pixDestroy(&pixt);\n    }\n    if (w > nx) {  /* replicate the last column */\n        for (i = 0; i < h; i++) {\n            pixGetPixel(pix, w - 2, i, &val);\n            pixSetPixel(pix, w - 1, i, val);\n        }\n    }\n\n    numaDestroy(&na);\n    return 0;\n}",
        "commit_message": "Fixing oss-fuzz issue 22512: Heap-buffer-overflow in rasteropGeneralLow()\n* Simplified the hole-filling function\n`",
        "cve_desc": "Leptonica before 1.80.0 allows a heap-based buffer over-read in rasteropGeneralLow, related to adaptmap_reg.c and adaptmap.c.",
        "target": 1
      },
      {
        "idx": 201335,
        "reasoning": "This code is vulnerable to a heap-based buffer over-read due to a flaw in `rasteropGeneralLow` as indicated by the CVE description, likely triggered during the `pixRasterop` calls within both the grayscale and color processing sections. The vulnerability stems from how the code handles memory access when creating and manipulating pixel maps, potentially reading beyond allocated boundaries during raster operations.",
        "func": "int main(int    argc,\n         char **argv)\n{\nl_int32       w, h;\nPIX          *pixs, *pixg, *pixim, *pixgm, *pixmi, *pix1, *pix2;\nPIX          *pixmr, *pixmg, *pixmb, *pixmri, *pixmgi, *pixmbi;\nPIXA         *pixa;\nL_REGPARAMS  *rp;\n\n    if (regTestSetup(argc, argv, &rp))\n        return 1;\n\n    lept_mkdir(\"lept/adapt\");  // REMOVE?\n\n    pixs = pixRead(\"wet-day.jpg\");\n    pixa = pixaCreate(0);\n    pixg = pixConvertRGBToGray(pixs, 0.33, 0.34, 0.33);\n    pixaAddPix(pixa, pixs, L_INSERT);\n    pixaAddPix(pixa, pixg, L_INSERT);\n    pixGetDimensions(pixs, &w, &h, NULL);\n\n        /* Process in grayscale */\n    startTimer();\n    pixim = pixCreate(w, h, 1);\n    pixRasterop(pixim, XS, YS, WS, HS, PIX_SET, NULL, 0, 0);\n    pixGetBackgroundGrayMap(pixg, pixim, SIZE_X, SIZE_Y,\n                            BINTHRESH, MINCOUNT, &pixgm);\n    fprintf(stderr, \"Time for gray adaptmap gen: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pixgm, IFF_PNG);  /* 0 */\n    pixaAddPix(pixa, pixgm, L_INSERT);\n\n    startTimer();\n    pixmi = pixGetInvBackgroundMap(pixgm, BGVAL, SMOOTH_X, SMOOTH_Y);\n    fprintf(stderr, \"Time for gray inv map generation: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pixmi, IFF_PNG);  /* 1 */\n    pixaAddPix(pixa, pixmi, L_INSERT);\n\n    startTimer();\n    pix1 = pixApplyInvBackgroundGrayMap(pixg, pixmi, SIZE_X, SIZE_Y);\n    fprintf(stderr, \"Time to apply gray inv map: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pix1, IFF_JFIF_JPEG);  /* 2 */\n    pixaAddPix(pixa, pix1, L_INSERT);\n\n    pix2 = pixGammaTRCMasked(NULL, pix1, pixim, 1.0, 0, 190);\n    pixInvert(pixim, pixim);\n    pixGammaTRCMasked(pix2, pix2, pixim, 1.0, 60, 190);\n    regTestWritePixAndCheck(rp, pix2, IFF_JFIF_JPEG);  /* 3 */\n    pixaAddPix(pixa, pix2, L_INSERT);\n    pixDestroy(&pixim);\n\n        /* Process in color */\n    startTimer();\n    pixim = pixCreate(w, h, 1);\n    pixRasterop(pixim, XS, YS, WS, HS, PIX_SET, NULL, 0, 0);\n    pixGetBackgroundRGBMap(pixs, pixim, NULL, SIZE_X, SIZE_Y,\n                           BINTHRESH, MINCOUNT,\n                           &pixmr, &pixmg, &pixmb);\n    fprintf(stderr, \"Time for color adaptmap gen: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pixmr, IFF_PNG);  /* 4 */\n    regTestWritePixAndCheck(rp, pixmg, IFF_PNG);  /* 5 */\n    regTestWritePixAndCheck(rp, pixmb, IFF_PNG);  /* 6 */\n    pixaAddPix(pixa, pixmr, L_INSERT);\n    pixaAddPix(pixa, pixmg, L_INSERT);\n    pixaAddPix(pixa, pixmb, L_INSERT);\n\n    startTimer();\n    pixmri = pixGetInvBackgroundMap(pixmr, BGVAL, SMOOTH_X, SMOOTH_Y);\n    pixmgi = pixGetInvBackgroundMap(pixmg, BGVAL, SMOOTH_X, SMOOTH_Y);\n    pixmbi = pixGetInvBackgroundMap(pixmb, BGVAL, SMOOTH_X, SMOOTH_Y);\n    fprintf(stderr, \"Time for color inv map generation: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pixmri, IFF_PNG);  /* 7 */\n    regTestWritePixAndCheck(rp, pixmgi, IFF_PNG);  /* 8 */\n    regTestWritePixAndCheck(rp, pixmbi, IFF_PNG);  /* 9 */\n    pixaAddPix(pixa, pixmri, L_INSERT);\n    pixaAddPix(pixa, pixmgi, L_INSERT);\n    pixaAddPix(pixa, pixmbi, L_INSERT);\n\n    startTimer();\n    pix1 = pixApplyInvBackgroundRGBMap(pixs, pixmri, pixmgi, pixmbi,\n                                       SIZE_X, SIZE_Y);\n    fprintf(stderr, \"Time to apply color inv maps: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pix1, IFF_JFIF_JPEG);  /* 10 */\n    pixaAddPix(pixa, pix1, L_INSERT);\n\n    pix2 = pixGammaTRCMasked(NULL, pix1, pixim, 1.0, 0, 190);\n    pixInvert(pixim, pixim);\n    pixGammaTRCMasked(pix2, pix2, pixim, 1.0, 60, 190);\n    regTestWritePixAndCheck(rp, pix2, IFF_JFIF_JPEG);  /* 11 */\n    pixaAddPix(pixa, pix2, L_INSERT);\n    pixDestroy(&pixim);\n\n        /* Process at higher level in color */\n    startTimer();\n    pixim = pixCreate(w, h, 1);\n    pixRasterop(pixim, XS, YS, WS, HS, PIX_SET, NULL, 0, 0);\n    pix1 = pixBackgroundNorm(pixs, pixim, NULL, 5, 10, BINTHRESH, 20,\n                             BGVAL, SMOOTH_X, SMOOTH_Y);\n    fprintf(stderr, \"Time for bg normalization: %7.3f\\n\", stopTimer());\n    regTestWritePixAndCheck(rp, pix1, IFF_JFIF_JPEG);  /* 12 */\n    pixaAddPix(pixa, pix1, L_INSERT);\n\n    pix2 = pixGammaTRCMasked(NULL, pix1, pixim, 1.0, 0, 190);\n    pixInvert(pixim, pixim);\n    pixGammaTRCMasked(pix2, pix2, pixim, 1.0, 60, 190);\n    regTestWritePixAndCheck(rp, pix2, IFF_JFIF_JPEG);  /* 13 */\n    pixaAddPix(pixa, pix2, L_INSERT);\n    pixDestroy(&pixim);\n\n        /* Display results */\n    pix1 = pixaDisplayTiledAndScaled(pixa, 32, 400, 4, 0, 20, 2);\n    pixWrite(\"/tmp/lept/adapt/results.jpg\", pix1, IFF_JFIF_JPEG);\n    pixDisplayWithTitle(pix1, 100, 0, NULL, rp->display);\n    pixDestroy(&pix1);\n    pixaDestroy(&pixa);\n\n    return regTestCleanup(rp);\n}",
        "commit_message": "Fixing oss-fuzz issue 22512: Heap-buffer-overflow in rasteropGeneralLow()\n* Simplified the hole-filling function\n`",
        "cve_desc": "Leptonica before 1.80.0 allows a heap-based buffer over-read in rasteropGeneralLow, related to adaptmap_reg.c and adaptmap.c.",
        "target": 1
      }
    ]
  },
  "libarchive": {
    "0": [
      {
        "idx": 35166,
        "reasoning": "This code snippet is not directly vulnerable because it focuses on allocating memory for write filters and doesn't handle any external input or sensitive operations that could be exploited. The commit message addresses a potential integer overflow issue in a *different* part of the library related to `write()` calls, and this specific function isn't involved in that potential overflow scenario.\n\n\n\n",
        "func": "__archive_write_allocate_filter(struct archive *_a)\n{\n\tstruct archive_write *a = (struct archive_write *)_a;\n\tstruct archive_write_filter *f;\n\n\tf = calloc(1, sizeof(*f));\n\tf->archive = _a;\n\tif (a->filter_first == NULL)\n\t\ta->filter_first = f;\n\telse\n\t\ta->filter_last->next_filter = f;\n\ta->filter_last = f;\n\treturn f;\n}\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 0
      },
      {
        "idx": 35167,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message describes a fix related to write request limits elsewhere in the library, but this specific function `__archive_write_close_filter` only handles filter closing and recursion\u2014it doesn't directly process write requests or handle potentially problematic integer values like -1.\n\n\n\n",
        "func": "__archive_write_close_filter(struct archive_write_filter *f)\n{\n\tif (f->close != NULL)\n\t\treturn (f->close)(f);\n\tif (f->next_filter != NULL)\n\t\treturn (__archive_write_close_filter(f->next_filter));\n\treturn (ARCHIVE_OK);\n}\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 0
      },
      {
        "idx": 35168,
        "reasoning": "This code is not vulnerable because the commit message explicitly addresses a potential programming error\u2014passing -1 to a write function\u2014and limits the write request size to `INT_MAX` to prevent it. The code itself simply calls a provided write function and increments a counter, without introducing any new vulnerabilities; it's a defensive measure against issues *outside* of this specific function.\n\n\n\n",
        "func": "__archive_write_filter(struct archive_write_filter *f,\n    const void *buff, size_t length)\n{\n\tint r;\n\tif (length == 0)\n\t\treturn(ARCHIVE_OK);\n\tif (f->write == NULL)\n\t\t/* If unset, a fatal error has already ocuured, so this filter\n\t\t * didn't open. We cannot write anything. */\n\t\treturn(ARCHIVE_FATAL);\n\tr = (f->write)(f, buff, length);\n\tf->bytes_written += length;\n\treturn (r);\n}\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 0
      },
      {
        "idx": 35169,
        "reasoning": "This code is not vulnerable because the commit message addresses a potential issue in *other* parts of the library by limiting write request sizes, not within this specific function itself. The `__archive_write_filters_free` function simply frees filter structures and handles potential errors from their `free` methods, posing no direct security risk related to integer overflows or invalid write sizes.\n\n\n\n",
        "func": "__archive_write_filters_free(struct archive *_a)\n{\n\tstruct archive_write *a = (struct archive_write *)_a;\n\tint r = ARCHIVE_OK, r1;\n\n\twhile (a->filter_first != NULL) {\n\t\tstruct archive_write_filter *next\n\t\t    = a->filter_first->next_filter;\n\t\tif (a->filter_first->free != NULL) {\n\t\t\tr1 = (*a->filter_first->free)(a->filter_first);\n\t\t\tif (r > r1)\n\t\t\t\tr = r1;\n\t\t}\n\t\tfree(a->filter_first);\n\t\ta->filter_first = next;\n\t}\n\ta->filter_last = NULL;\n}\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 0
      },
      {
        "idx": 35170,
        "reasoning": "This code snippet is not vulnerable because it simply calls a function pointer `f->open` if it exists. The commit message addresses a potential integer overflow issue in write requests *elsewhere* in the library, and this function doesn't directly handle any write operations itself\u2014it just delegates to another function. \n\n\n\n",
        "func": "__archive_write_open_filter(struct archive_write_filter *f)\n{\n\tif (f->open == NULL)\n\t\treturn (ARCHIVE_OK);\n\treturn (f->open)(f);\n}\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1123,
        "reasoning": "This code is vulnerable because while the commit message attempts to mitigate issues from passing -1 to write functions, it doesn't address the underlying signedness error present in functions like `archive_write_zip_data` as described in the CVE. Specifically, a large unsigned size value can be improperly converted to a signed integer, leading to a buffer overflow when used in write operations\u2014a problem this code doesn't prevent.",
        "func": " _archive_write_data(struct archive *_a, const void *buff, size_t s)\n {\n \tstruct archive_write *a = (struct archive_write *)_a;\n \tarchive_check_magic(&a->archive, ARCHIVE_WRITE_MAGIC,\n \t    ARCHIVE_STATE_DATA, \"archive_write_data\");\n \tarchive_clear_error(&a->archive);\n \treturn ((a->format_write_data)(a, buff, s));\n }\n",
        "commit_message": "Limit write requests to at most INT_MAX.\nThis prevents a certain common programming error (passing -1 to write)\nfrom leading to other problems deeper in the library.",
        "cve_desc": "Integer signedness error in the archive_write_zip_data function in archive_write_set_format_zip.c in libarchive 3.1.2 and earlier, when running on 64-bit machines, allows context-dependent attackers to cause a denial of service (crash) via unspecified vectors, which triggers an improper conversion between unsigned and signed types, leading to a buffer overflow.",
        "target": 1
      },
      {
        "idx": 1744,
        "reasoning": "This code is vulnerable because the `choose_filters` function recursively calls filter bidders without a limit, allowing a malicious archive (like the `selfgz.gz` example) to repeatedly add decompression filters. This unbounded recursion can lead to excessive memory allocation, ultimately causing a denial of service through application crash as demonstrated by the `bsdtar` example and described in the CVE.",
        "func": " choose_filters(struct archive_read *a)\n {\n\tint number_bidders, i, bid, best_bid;\n \tstruct archive_read_filter_bidder *bidder, *best_bidder;\n \tstruct archive_read_filter *filter;\n \tssize_t avail;\n \tint r;\n \n\tfor (;;) {\n \t\tnumber_bidders = sizeof(a->bidders) / sizeof(a->bidders[0]);\n \n \t\tbest_bid = 0;\n\t\tbest_bidder = NULL;\n\n\t\tbidder = a->bidders;\n\t\tfor (i = 0; i < number_bidders; i++, bidder++) {\n\t\t\tif (bidder->bid != NULL) {\n\t\t\t\tbid = (bidder->bid)(bidder, a->filter);\n\t\t\t\tif (bid > best_bid) {\n\t\t\t\t\tbest_bid = bid;\n\t\t\t\t\tbest_bidder = bidder;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t/* If no bidder, we're done. */\n\t\tif (best_bidder == NULL) {\n\t\t\t/* Verify the filter by asking it for some data. */\n\t\t\t__archive_read_filter_ahead(a->filter, 1, &avail);\n\t\t\tif (avail < 0) {\n\t\t\t\t__archive_read_close_filters(a);\n\t\t\t\t__archive_read_free_filters(a);\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\ta->archive.compression_name = a->filter->name;\n\t\t\ta->archive.compression_code = a->filter->code;\n\t\t\treturn (ARCHIVE_OK);\n\t\t}\n\n\t\tfilter\n\t\t    = (struct archive_read_filter *)calloc(1, sizeof(*filter));\n\t\tif (filter == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tfilter->bidder = best_bidder;\n\t\tfilter->archive = a;\n\t\tfilter->upstream = a->filter;\n\t\ta->filter = filter;\n\t\tr = (best_bidder->init)(a->filter);\n\t\tif (r != ARCHIVE_OK) {\n\t\t\t__archive_read_close_filters(a);\n\t\t\t__archive_read_free_filters(a);\n \t\t\treturn (ARCHIVE_FATAL);\n \t\t}\n \t}\n }\n",
        "commit_message": "Fix a potential crash issue discovered by Alexander Cherepanov:\n\nIt seems bsdtar automatically handles stacked compression. This is a\nnice feature but it could be problematic when it's completely\nunlimited.  Most clearly it's illustrated with quines:\n\n$ curl -sRO http://www.maximumcompression.com/selfgz.gz\n$ (ulimit -v 10000000 && bsdtar -tvf selfgz.gz)\nbsdtar: Error opening archive: Can't allocate data for gzip decompression\n\nWithout ulimit, bsdtar will eat all available memory. This could also\nbe a problem for other applications using libarchive.",
        "cve_desc": "libarchive before 3.2.0 does not limit the number of recursive decompressions, which allows remote attackers to cause a denial of service (memory consumption and application crash) via a crafted gzip file.",
        "target": 1
      },
      {
        "idx": 1796,
        "reasoning": "The code is vulnerable due to multiple casts of `size_t` to `int` when checking filename lengths, which can lead to integer overflows if `size_t` is larger than `int`. This overflow can result in a buffer being allocated that is smaller than the actual filename length, leading to a buffer overflow when copying the filename data, as described in the CVE.",
        "func": "isoent_gen_joliet_identifier(struct archive_write *a, struct isoent *isoent,\n    struct idr *idr)\n{\n\tstruct iso9660 *iso9660;\n\tstruct isoent *np;\n \tunsigned char *p;\n \tsize_t l;\n \tint r;\n\tint ffmax, parent_len;\n \tstatic const struct archive_rb_tree_ops rb_ops = {\n \t\tisoent_cmp_node_joliet, isoent_cmp_key_joliet\n \t};\n\n\tif (isoent->children.cnt == 0)\n\t\treturn (0);\n\n\tiso9660 = a->format_data;\n\tif (iso9660->opt.joliet == OPT_JOLIET_LONGNAME)\n\t\tffmax = 206;\n \telse\n \t\tffmax = 128;\n \n\tr = idr_start(a, idr, isoent->children.cnt, ffmax, 6, 2, &rb_ops);\n \tif (r < 0)\n \t\treturn (r);\n \n\tparent_len = 1;\n\tfor (np = isoent; np->parent != np; np = np->parent)\n\t\tparent_len += np->mb_len + 1;\n\n\tfor (np = isoent->children.first; np != NULL; np = np->chnext) {\n\t\tunsigned char *dot;\n \t\tint ext_off, noff, weight;\n \t\tsize_t lt;\n \n\t\tif ((int)(l = np->file->basename_utf16.length) > ffmax)\n \t\t\tl = ffmax;\n \n \t\tp = malloc((l+1)*2);\n\t\tif (p == NULL) {\n\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t    \"Can't allocate memory\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tmemcpy(p, np->file->basename_utf16.s, l);\n\t\tp[l] = 0;\n\t\tp[l+1] = 0;\n\n\t\tnp->identifier = (char *)p;\n\t\tlt = l;\n\t\tdot = p + l;\n\t\tweight = 0;\n\t\twhile (lt > 0) {\n\t\t\tif (!joliet_allowed_char(p[0], p[1]))\n\t\t\t\tarchive_be16enc(p, 0x005F); /* '_' */\n\t\t\telse if (p[0] == 0 && p[1] == 0x2E) /* '.' */\n\t\t\t\tdot = p;\n\t\t\tp += 2;\n\t\t\tlt -= 2;\n\t\t}\n\t\text_off = (int)(dot - (unsigned char *)np->identifier);\n\t\tnp->ext_off = ext_off;\n\t\tnp->ext_len = (int)l - ext_off;\n\t\tnp->id_len = (int)l;\n\n \t\t/*\n \t\t * Get a length of MBS of a full-pathname.\n \t\t */\n\t\tif ((int)np->file->basename_utf16.length > ffmax) {\n \t\t\tif (archive_strncpy_l(&iso9660->mbs,\n \t\t\t    (const char *)np->identifier, l,\n \t\t\t\tiso9660->sconv_from_utf16be) != 0 &&\n\t\t\t    errno == ENOMEM) {\n\t\t\t\tarchive_set_error(&a->archive, errno,\n\t\t\t\t    \"No memory\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\tnp->mb_len = (int)iso9660->mbs.length;\n\t\t\tif (np->mb_len != (int)np->file->basename.length)\n\t\t\t\tweight = np->mb_len;\n\t\t} else\n\t\t\tnp->mb_len = (int)np->file->basename.length;\n \n \t\t/* If a length of full-pathname is longer than 240 bytes,\n \t\t * it violates Joliet extensions regulation. */\n\t\tif (parent_len + np->mb_len > 240) {\n \t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n \t\t\t    \"The regulation of Joliet extensions;\"\n \t\t\t    \" A length of a full-pathname of `%s' is \"\n\t\t\t    \"longer than 240 bytes, (p=%d, b=%d)\",\n\t\t\t    archive_entry_pathname(np->file->entry),\n\t\t\t    (int)parent_len, (int)np->mb_len);\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n \n \t\t/* Make an offset of the number which is used to be set\n \t\t * hexadecimal number to avoid duplicate identifier. */\n\t\tif ((int)l == ffmax)\n \t\t\tnoff = ext_off - 6;\n\t\telse if ((int)l == ffmax-2)\n \t\t\tnoff = ext_off - 4;\n\t\telse if ((int)l == ffmax-4)\n \t\t\tnoff = ext_off - 2;\n \t\telse\n \t\t\tnoff = ext_off;\n\t\t/* Register entry to the identifier resolver. */\n\t\tidr_register(idr, np, weight, noff);\n\t}\n\n\t/* Resolve duplicate identifier with Joliet Volume. */\n\tidr_resolve(idr, idr_set_num_beutf16);\n\n\treturn (ARCHIVE_OK);\n}\n",
        "commit_message": "Issue 711:  Be more careful about verifying filename lengths when writing ISO9660 archives\n\n* Don't cast size_t to int, since this can lead to overflow\n  on machines where sizeof(int) < sizeof(size_t)\n* Check a + b > limit by writing it as\n    a > limit || b > limit || a + b > limit\n  to avoid problems when a + b wraps around.",
        "cve_desc": "Integer overflow in the ISO9660 writer in libarchive before 3.2.1 allows remote attackers to cause a denial of service (application crash) or execute arbitrary code via vectors related to verifying filename lengths when writing an ISO9660 archive, which trigger a buffer overflow.",
        "target": 1
      },
      {
        "idx": 1811,
        "reasoning": "The code is vulnerable to an integer overflow because `vd->location` is multiplied by `LOGICAL_BLOCK_SIZE` without sufficient size consideration *before* the commit, potentially exceeding the maximum value of a 32-bit integer. Although the commit message states the result won't overflow a 64-bit integer, the initial calculation still occurs using a default `int` type, leading to an incorrect `skipsize` value if the multiplication overflows *before* the cast to `int64_t` happens, causing out-of-bounds reads or other memory corruption issues.",
        "func": "choose_volume(struct archive_read *a, struct iso9660 *iso9660)\n{\n\tstruct file_info *file;\n\tint64_t skipsize;\n\tstruct vd *vd;\n\tconst void *block;\n\tchar seenJoliet;\n\n\tvd = &(iso9660->primary);\n\tif (!iso9660->opt_support_joliet)\n\t\tiso9660->seenJoliet = 0;\n\tif (iso9660->seenJoliet &&\n\t\tvd->location > iso9660->joliet.location)\n \t\t/* This condition is unlikely; by way of caution. */\n \t\tvd = &(iso9660->joliet);\n \n\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n \tskipsize = __archive_read_consume(a, skipsize);\n \tif (skipsize < 0)\n \t\treturn ((int)skipsize);\n\tiso9660->current_position = skipsize;\n\n\tblock = __archive_read_ahead(a, vd->size, NULL);\n\tif (block == NULL) {\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t    \"Failed to read full block when scanning \"\n\t\t    \"ISO9660 directory list\");\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\t/*\n\t * While reading Root Directory, flag seenJoliet must be zero to\n\t * avoid converting special name 0x00(Current Directory) and\n\t * next byte to UCS2.\n\t */\n\tseenJoliet = iso9660->seenJoliet;/* Save flag. */\n\tiso9660->seenJoliet = 0;\n\tfile = parse_file_info(a, NULL, block);\n\tif (file == NULL)\n\t\treturn (ARCHIVE_FATAL);\n\tiso9660->seenJoliet = seenJoliet;\n\n\t/*\n\t * If the iso image has both RockRidge and Joliet, we preferentially\n\t * use RockRidge Extensions rather than Joliet ones.\n\t */\n\tif (vd == &(iso9660->primary) && iso9660->seenRockridge\n\t    && iso9660->seenJoliet)\n\t\tiso9660->seenJoliet = 0;\n\n\tif (vd == &(iso9660->primary) && !iso9660->seenRockridge\n \t    && iso9660->seenJoliet) {\n \t\t/* Switch reading data from primary to joliet. */\n \t\tvd = &(iso9660->joliet);\n\t\tskipsize = LOGICAL_BLOCK_SIZE * vd->location;\n \t\tskipsize -= iso9660->current_position;\n \t\tskipsize = __archive_read_consume(a, skipsize);\n \t\tif (skipsize < 0)\n\t\t\treturn ((int)skipsize);\n\t\tiso9660->current_position += skipsize;\n\n\t\tblock = __archive_read_ahead(a, vd->size, NULL);\n\t\tif (block == NULL) {\n\t\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_MISC,\n\t\t\t    \"Failed to read full block when scanning \"\n\t\t\t    \"ISO9660 directory list\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tiso9660->seenJoliet = 0;\n\t\tfile = parse_file_info(a, NULL, block);\n\t\tif (file == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tiso9660->seenJoliet = seenJoliet;\n\t}\n\n\t/* Store the root directory in the pending list. */\n\tif (add_entry(a, iso9660, file) != ARCHIVE_OK)\n\t\treturn (ARCHIVE_FATAL);\n\tif (iso9660->seenRockridge) {\n\t\ta->archive.archive_format = ARCHIVE_FORMAT_ISO9660_ROCKRIDGE;\n\t\ta->archive.archive_format_name =\n\t\t    \"ISO9660 with Rockridge extensions\";\n\t}\n\n\treturn (ARCHIVE_OK);\n}\n",
        "commit_message": "Issue 717:  Fix integer overflow when computing location of volume descriptor\n\nThe multiplication here defaulted to 'int' but calculations\nof file positions should always use int64_t.  A simple cast\nsuffices to fix this since the base location is always 32 bits\nfor ISO, so multiplying by the sector size will never overflow\na 64-bit integer.",
        "cve_desc": "Integer overflow in the ISO parser in libarchive before 3.2.1 allows remote attackers to cause a denial of service (application crash) via a crafted ISO file.",
        "target": 1
      },
      {
        "idx": 1995,
        "reasoning": "This code is vulnerable to a denial of service because it doesn't adequately limit the size of symlink targets read from the CPIO archive; a maliciously crafted archive can include a symlink exceeding 1MB, leading to excessive memory allocation during `archive_entry_copy_symlink_l`. This large allocation can exhaust available memory, causing the application to crash as described in the CVE.",
        "func": "archive_read_format_cpio_read_header(struct archive_read *a,\n    struct archive_entry *entry)\n{\n\tstruct cpio *cpio;\n\tconst void *h;\n\tstruct archive_string_conv *sconv;\n\tsize_t namelength;\n\tsize_t name_pad;\n\tint r;\n\n\tcpio = (struct cpio *)(a->format->data);\n\tsconv = cpio->opt_sconv;\n\tif (sconv == NULL) {\n\t\tif (!cpio->init_default_conversion) {\n\t\t\tcpio->sconv_default =\n\t\t\t    archive_string_default_conversion_for_read(\n\t\t\t      &(a->archive));\n\t\t\tcpio->init_default_conversion = 1;\n\t\t}\n\t\tsconv = cpio->sconv_default;\n\t}\n\t\n\tr = (cpio->read_header(a, cpio, entry, &namelength, &name_pad));\n\n\tif (r < ARCHIVE_WARN)\n\t\treturn (r);\n\n\t/* Read name from buffer. */\n\th = __archive_read_ahead(a, namelength + name_pad, NULL);\n\tif (h == NULL)\n\t    return (ARCHIVE_FATAL);\n\tif (archive_entry_copy_pathname_l(entry,\n\t    (const char *)h, namelength, sconv) != 0) {\n\t\tif (errno == ENOMEM) {\n\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t    \"Can't allocate memory for Pathname\");\n\t\t\treturn (ARCHIVE_FATAL);\n\t\t}\n\t\tarchive_set_error(&a->archive, ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t    \"Pathname can't be converted from %s to current locale.\",\n\t\t    archive_string_conversion_charset_name(sconv));\n\t\tr = ARCHIVE_WARN;\n\t}\n\tcpio->entry_offset = 0;\n\n\t__archive_read_consume(a, namelength + name_pad);\n \n \t/* If this is a symlink, read the link contents. */\n \tif (archive_entry_filetype(entry) == AE_IFLNK) {\n \t\th = __archive_read_ahead(a,\n \t\t\t(size_t)cpio->entry_bytes_remaining, NULL);\n \t\tif (h == NULL)\n\t\t\treturn (ARCHIVE_FATAL);\n\t\tif (archive_entry_copy_symlink_l(entry, (const char *)h,\n\t\t    (size_t)cpio->entry_bytes_remaining, sconv) != 0) {\n\t\t\tif (errno == ENOMEM) {\n\t\t\t\tarchive_set_error(&a->archive, ENOMEM,\n\t\t\t\t    \"Can't allocate memory for Linkname\");\n\t\t\t\treturn (ARCHIVE_FATAL);\n\t\t\t}\n\t\t\tarchive_set_error(&a->archive,\n\t\t\t    ARCHIVE_ERRNO_FILE_FORMAT,\n\t\t\t    \"Linkname can't be converted from %s to \"\n\t\t\t    \"current locale.\",\n\t\t\t    archive_string_conversion_charset_name(sconv));\n\t\t\tr = ARCHIVE_WARN;\n\t\t}\n\t\t__archive_read_consume(a, cpio->entry_bytes_remaining);\n\t\tcpio->entry_bytes_remaining = 0;\n\t}\n\n\t/* XXX TODO: If the full mode is 0160200, then this is a Solaris\n\t * ACL description for the following entry.  Read this body\n\t * and parse it as a Solaris-style ACL, then read the next\n\t * header.  XXX */\n\n\t/* Compare name to \"TRAILER!!!\" to test for end-of-archive. */\n\tif (namelength == 11 && strcmp((const char *)h, \"TRAILER!!!\") == 0) {\n\t\t/* TODO: Store file location of start of block. */\n\t\tarchive_clear_error(&a->archive);\n\t\treturn (ARCHIVE_EOF);\n\t}\n\n\t/* Detect and record hardlinks to previously-extracted entries. */\n\tif (record_hardlink(a, cpio, entry) != ARCHIVE_OK) {\n\t\treturn (ARCHIVE_FATAL);\n\t}\n\n\treturn (r);\n}\n",
        "commit_message": "Reject cpio symlinks that exceed 1MB",
        "cve_desc": "The archive_read_format_cpio_read_header function in archive_read_support_format_cpio.c in libarchive before 3.2.1 allows remote attackers to cause a denial of service (application crash) via a CPIO archive with a large symlink.",
        "target": 1
      }
    ]
  },
  "libavif": {
    "0": [],
    "1": []
  },
  "libdwarf-code": {
    "0": [
      {
        "idx": 236240,
        "reasoning": "This code snippet addresses a potential crash by replacing it with an error report when encountering a corrupted `.debug_pubnames` or `.debug_pubtypes` section\u2014specifically, an invalid offset. The fix doesn't *introduce* a vulnerability; rather, it *mitigates* one by preventing a crash and providing diagnostic information, making it a safe change.\n\n\n\n",
        "func": "build_off_end_msg(Dwarf_Unsigned offval,\n    Dwarf_Unsigned withincr,\n    Dwarf_Unsigned secsize,\n    dwarfstring *m)\n{\n    const char *msg = \"past\";\n    if (offval < secsize){\n        msg = \"too near\";\n    }\n    dwarfstring_append_printf_u(m,\"DW_DLE_OFFSET_BAD: \"\n        \"The CU header offset of %u in a pubnames-like entry \",\n        withincr);\n    dwarfstring_append_printf_s(m,\n        \"would put us %s the end of .debug_info. \"\n        \"No room for a DIE there... \"\n        \"Corrupt Dwarf.\",(char *)msg);\n    return;\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 0
      },
      {
        "idx": 236241,
        "reasoning": "This code snippet is not directly vulnerable to DW202205-001, as it simply calculates and returns an offset based on existing global context data. The fix likely resides in how this offset is *used* elsewhere in the code, preventing a crash when encountering corrupted `.debug_pubnames` or `.debug_pubtypes` sections, rather than within this offset calculation itself.\n\n\n\n",
        "func": "dwarf_global_die_offset(Dwarf_Global global,\n    Dwarf_Off * ret_off, Dwarf_Error * error)\n{\n    if (global == NULL) {\n        _dwarf_error(NULL, error, DW_DLE_GLOBAL_NULL);\n        return DW_DLV_ERROR;\n    }\n\n    if (global->gl_context == NULL) {\n        _dwarf_error(NULL, error, DW_DLE_GLOBAL_CONTEXT_NULL);\n        return DW_DLV_ERROR;\n    }\n\n    *ret_off = (global->gl_named_die_offset_within_cu +\n        global->gl_context->pu_offset_of_cu_header);\n    return DW_DLV_OK;\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 0
      },
      {
        "idx": 236242,
        "reasoning": "This code snippet addresses a potential vulnerability by *preventing* a crash when encountering corrupted `.debug_pubnames` or `.debug_pubtypes` sections. Instead of crashing, it now reports an error, indicating a fix for the previously identified issue DW202205-001 and thus isn't introducing new vulnerabilities.\n\n\n\n",
        "func": "pubnames_error_length(Dwarf_Debug dbg,\n    Dwarf_Error *error,\n    Dwarf_Unsigned spaceneeded,\n    const char *secname,\n    const char *specificloc)\n{\n    dwarfstring m;\n\n    dwarfstring_constructor(&m);\n    dwarfstring_append(&m,\"DW_DLE_PUBNAMES_LENGTH_BAD: \"\n        \" In section \");\n    dwarfstring_append(&m,(char *)secname);\n    dwarfstring_append_printf_u(&m,\n        \" %u bytes of space needed \"\n        \"but the section is out of space \",\n        spaceneeded);\n    dwarfstring_append(&m, \"reading \");\n    dwarfstring_append(&m, (char *)specificloc);\n    dwarfstring_append(&m, \".\");\n    _dwarf_error_string(dbg,error,DW_DLE_PUBNAMES_LENGTH_BAD,\n        dwarfstring_string(&m));\n    dwarfstring_destructor(&m);\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 0
      },
      {
        "idx": 236243,
        "reasoning": "This code snippet itself isn't directly vulnerable; it simply *reads* data from context structures (`con`) that were presumably populated elsewhere. The commit message indicates the vulnerability was in how the library *handled* corrupted data within the `.debug_pubnames` or `.debug_pubtypes` sections when *reading* that data into these context structures, and this commit fixes the crash by reporting an error instead of dereferencing potentially invalid data.\n\n\n\n",
        "func": "dwarf_get_globals_header(Dwarf_Global global,\n    Dwarf_Off      *pub_section_hdr_offset,\n    Dwarf_Unsigned *pub_offset_size,\n    Dwarf_Unsigned *pub_cu_length,\n    Dwarf_Unsigned *version,\n    Dwarf_Off      *info_header_offset,\n    Dwarf_Unsigned *info_length,\n    Dwarf_Error*   error)\n{\n    Dwarf_Global_Context con = 0;\n    Dwarf_Debug dbg = 0;\n\n    if (global == NULL) {\n        _dwarf_error(NULL, error, DW_DLE_GLOBAL_NULL);\n        return DW_DLV_ERROR;\n    }\n    con = global->gl_context;\n    if (con == NULL) {\n        _dwarf_error(NULL, error, DW_DLE_GLOBAL_CONTEXT_NULL);\n        return DW_DLV_ERROR;\n    }\n    dbg = con->pu_dbg;\n    if (!dbg || dbg->de_magic != DBG_IS_VALID) {\n        _dwarf_error_string(NULL, error, DW_DLE_DBG_NULL,\n            \"DW_DLE_DBG_NULL: \"\n            \"calling dwarf_get_globals_header() \"\n            \"either null or it contains\"\n            \"a stale Dwarf_Debug pointer\");\n        return DW_DLV_ERROR;\n    }\n    if (pub_section_hdr_offset) {\n        *pub_section_hdr_offset = con->pu_pub_offset;\n    }\n    if (pub_offset_size) {\n        *pub_offset_size = con->pu_length_size;\n    }\n    if (pub_cu_length) {\n        *pub_cu_length = con->pu_length;\n    }\n    if (version) {\n        *version = con->pu_version;\n    }\n    if (info_header_offset) {\n        *info_header_offset = con->pu_offset_of_cu_header;\n    }\n    if (info_length) {\n        *info_length = con->pu_info_length;\n    }\n    return DW_DLV_OK;\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 0
      },
      {
        "idx": 236244,
        "reasoning": "This code snippet is not directly vulnerable to the reported issue (DW202205-001) because it simply returns the global name pointer. The fix, as described in the commit message, addresses crashes when *reading* the `.debug_pubnames` or `.debug_pubtypes` sections \u2013 functionality not present in this specific `dwarf_globname` function, suggesting the vulnerability lies elsewhere in the codebase where these sections are processed.\n\n\n\n",
        "func": "dwarf_globname(Dwarf_Global glob,\n    char **ret_name,\n    Dwarf_Error * error)\n{\n    if (glob == NULL) {\n        _dwarf_error(NULL, error, DW_DLE_GLOBAL_NULL);\n        return DW_DLV_ERROR;\n    }\n\n    *ret_name = (char *) (glob->gl_name);\n    return DW_DLV_OK;\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195987,
        "reasoning": "The code is vulnerable to a heap-based buffer over-read because the `_dwarf_check_string_valid` function doesn't properly validate the length of the string pointed to by `pubnames_like_ptr` against the remaining size of the section, potentially reading beyond the allocated buffer. This allows a specially crafted `.debug_pubnames` section with an oversized string length to trigger a read past the end of the section data, leading to a crash or information disclosure as described in CVE-2022-05-001.",
        "func": "_dwarf_internal_get_pubnames_like_data(Dwarf_Debug dbg,\n    const char *secname,\n    Dwarf_Small * section_data_ptr,\n    Dwarf_Unsigned section_length,\n    Dwarf_Global ** globals,\n    Dwarf_Signed * return_count,\n    Dwarf_Error * error,\n    int context_DLA_code,\n    int global_DLA_code,\n    int length_err_num,\n    int version_err_num)\n{\n    Dwarf_Small *pubnames_like_ptr = 0;\n    Dwarf_Off pubnames_section_offset = 0;\n    Dwarf_Small *section_end_ptr = section_data_ptr +section_length;\n\n    /*  Points to the context for the current set of global names, and\n        contains information to identify the compilation-unit that the\n        set refers to. */\n    Dwarf_Global_Context pubnames_context = 0;\n    Dwarf_Bool           pubnames_context_on_list = FALSE;\n\n    Dwarf_Unsigned version = 0;\n\n    /*  Offset from the start of compilation-unit for the current\n        global. */\n    Dwarf_Off die_offset_in_cu = 0;\n\n    Dwarf_Unsigned global_count = 0;\n\n    /*  Used to chain the Dwarf_Global_s structs for\n        creating contiguous list of pointers to the structs. */\n    Dwarf_Chain head_chain = 0;\n    Dwarf_Chain *plast_chain = &head_chain;\n\n    /* Points to contiguous block of Dwarf_Global to be returned. */\n    Dwarf_Global *ret_globals = 0;\n    int mres = 0;\n\n    /* Temporary counter. */\n    Dwarf_Unsigned i = 0;\n\n    if (!dbg || dbg->de_magic != DBG_IS_VALID) {\n        _dwarf_error_string(NULL, error, DW_DLE_DBG_NULL,\n            \"DW_DLE_DBG_NULL: \"\n            \"calling for pubnames-like data Dwarf_Debug \"\n            \"either null or it contains\"\n            \"a stale Dwarf_Debug pointer\");\n        return DW_DLV_ERROR;\n    }\n    /* We will eventually need the .debug_info data. Load it now. */\n    if (!dbg->de_debug_info.dss_data) {\n        int res = _dwarf_load_debug_info(dbg, error);\n\n        if (res != DW_DLV_OK) {\n            return res;\n        }\n    }\n    if (section_data_ptr == NULL) {\n        return DW_DLV_NO_ENTRY;\n    }\n    pubnames_like_ptr = section_data_ptr;\n    do {\n        Dwarf_Unsigned length = 0;\n        int local_extension_size = 0;\n        int local_length_size = 0;\n\n        /*  Some compilers emit padding at the end of each cu's area.\n            pubnames_ptr_past_end_cu records the true area end for the\n            pubnames(like) content of a cu.\n            Essentially the length in the header and the 0\n            terminator of the data are redundant information. The\n            dwarf2/3 spec does not mention what to do if the length is\n            past the 0 terminator. So we take any bytes left\n            after the 0 as padding and ignore them. */\n        Dwarf_Small *pubnames_ptr_past_end_cu = 0;\n\n        pubnames_context_on_list = FALSE;\n        pubnames_context = (Dwarf_Global_Context)\n            _dwarf_get_alloc(dbg, context_DLA_code, 1);\n        if (pubnames_context == NULL) {\n            dealloc_globals_chain(dbg,head_chain);\n            _dwarf_error(dbg, error, DW_DLE_ALLOC_FAIL);\n            return DW_DLV_ERROR;\n        }\n        /*  ========pubnames_context not recorded anywhere yet. */\n        /*  READ_AREA_LENGTH updates pubnames_like_ptr for consumed\n            bytes. */\n        if ((pubnames_like_ptr + DWARF_32BIT_SIZE +\n            DWARF_HALF_SIZE + DWARF_32BIT_SIZE) >\n            /* A minimum size needed */\n            section_end_ptr) {\n            pubnames_error_length(dbg,error,\n                DWARF_32BIT_SIZE + DWARF_HALF_SIZE + DWARF_32BIT_SIZE,\n                secname,\n                \"header-record\");\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return DW_DLV_ERROR;\n        }\n        mres = _dwarf_read_area_length_ck_wrapper(dbg,\n            &length,&pubnames_like_ptr,&local_length_size,\n            &local_extension_size,section_length,section_end_ptr,\n            error);\n        if (mres != DW_DLV_OK) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return mres;\n        }\n        pubnames_context->pu_alloc_type = context_DLA_code;\n        pubnames_context->pu_length_size = local_length_size;\n        pubnames_context->pu_length = length;\n        pubnames_context->pu_extension_size = local_extension_size;\n        pubnames_context->pu_dbg = dbg;\n        pubnames_context->pu_pub_offset = pubnames_section_offset;\n        pubnames_ptr_past_end_cu = pubnames_like_ptr + length;\n        pubnames_context->pu_pub_entries_end_ptr =\n            pubnames_ptr_past_end_cu;\n\n        if ((pubnames_like_ptr + (DWARF_HALF_SIZE) ) >\n            /* A minimum size needed */\n            section_end_ptr) {\n            pubnames_error_length(dbg,error,\n                DWARF_HALF_SIZE,\n                secname,\"version-number\");\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return DW_DLV_ERROR;\n        }\n        mres = _dwarf_read_unaligned_ck_wrapper(dbg,\n            &version,pubnames_like_ptr,DWARF_HALF_SIZE,\n            section_end_ptr,error);\n        if (mres != DW_DLV_OK) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return mres;\n        }\n        pubnames_context->pu_version = version;\n        pubnames_like_ptr += DWARF_HALF_SIZE;\n        /* ASSERT: DW_PUBNAMES_VERSION2 == DW_PUBTYPES_VERSION2 */\n        if (version != DW_PUBNAMES_VERSION2) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            _dwarf_error(dbg, error, version_err_num);\n            return DW_DLV_ERROR;\n        }\n\n        /* Offset of CU header in debug section. */\n        if ((pubnames_like_ptr + 3*pubnames_context->pu_length_size)>\n            section_end_ptr) {\n            pubnames_error_length(dbg,error,\n                3*pubnames_context->pu_length_size,\n                secname,\n                \"header/DIE offsets\");\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return DW_DLV_ERROR;\n        }\n        mres = _dwarf_read_unaligned_ck_wrapper(dbg,\n            &pubnames_context->pu_offset_of_cu_header,\n            pubnames_like_ptr,\n            pubnames_context->pu_length_size,\n            section_end_ptr,error);\n        if (mres != DW_DLV_OK) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return mres;\n        }\n\n        pubnames_like_ptr += pubnames_context->pu_length_size;\n\n        FIX_UP_OFFSET_IRIX_BUG(dbg,\n            pubnames_context->pu_offset_of_cu_header,\n            \"pubnames cu header offset\");\n        mres = _dwarf_read_unaligned_ck_wrapper(dbg,\n            &pubnames_context->pu_info_length,\n            pubnames_like_ptr,\n            pubnames_context->pu_length_size,\n            section_end_ptr,error);\n        if (mres != DW_DLV_OK) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return mres;\n        }\n        pubnames_like_ptr += pubnames_context->pu_length_size;\n\n        if (pubnames_like_ptr > (section_data_ptr + section_length)) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            _dwarf_error(dbg, error, length_err_num);\n            return DW_DLV_ERROR;\n        }\n\n        /* ====begin pubname  */\n        /*  Read initial offset (of DIE within CU) of a pubname, final\n            entry is not a pair, just a zero offset. */\n        mres = _dwarf_read_unaligned_ck_wrapper(dbg,\n            &die_offset_in_cu,\n            pubnames_like_ptr,\n            pubnames_context->pu_length_size,\n            pubnames_context->pu_pub_entries_end_ptr,error);\n        if (mres != DW_DLV_OK) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            return mres;\n        }\n        pubnames_like_ptr += pubnames_context->pu_length_size;\n        FIX_UP_OFFSET_IRIX_BUG(dbg,\n            die_offset_in_cu, \"offset of die in cu\");\n        if (pubnames_like_ptr > (section_data_ptr + section_length)) {\n            dealloc_globals_chain(dbg,head_chain);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            _dwarf_error(dbg, error, length_err_num);\n            return DW_DLV_ERROR;\n        }\n\n        /* Loop thru pairs. DIE off with CU followed by string. */\n        if (!die_offset_in_cu) {\n            if (dbg->de_return_empty_pubnames) {\n                int res = 0;\n\n                /*  Here we have a pubnames CU with no actual\n                    entries so we fake up an entry to hold the\n                    header data.  There are no 'pairs' here,\n                    just the end of list zero value.  We do this\n                    only if de_return_empty_pubnames is set\n                    so that we by default return exactly the same\n                    data this always returned, yet dwarfdump can\n                    request the empty-cu records get created\n                    to test that feature.\n                    see dwarf_get_globals_header()  */\n                res = _dwarf_make_global_add_to_chain(dbg,\n                    global_DLA_code,\n                    pubnames_context,\n                    die_offset_in_cu,\n                    /*  It is a fake global, so empty name */\n                    (unsigned char *)\"\",\n                    &global_count,\n                    &pubnames_context_on_list,\n                    &plast_chain,\n                    error);\n                if (res != DW_DLV_OK) {\n                    dealloc_globals_chain(dbg,head_chain);\n                    if (!pubnames_context_on_list) {\n                        dwarf_dealloc(dbg,pubnames_context,\n                            context_DLA_code);\n                    }\n                    return res;\n                }\n                /*  ========pubnames_context recorded in chain. */\n            } else {\n                /*  The section is empty.\n                    Nowhere to record pubnames_context); */\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n                pubnames_context = 0;\n                continue;\n            }\n        }\n        while (die_offset_in_cu) {\n            int res = 0;\n            unsigned char *glname = 0;\n\n            /*  non-zero die_offset_in_cu already read, so\n                pubnames_like_ptr points to a string.  */\n            res = _dwarf_check_string_valid(dbg,section_data_ptr,\n                pubnames_like_ptr,\n                pubnames_context->pu_pub_entries_end_ptr,\n                DW_DLE_STRING_OFF_END_PUBNAMES_LIKE,error);\n            if (res != DW_DLV_OK) {\n                dealloc_globals_chain(dbg,head_chain);\n                if (!pubnames_context_on_list) {\n                    dwarf_dealloc(dbg,pubnames_context,\n                        context_DLA_code);\n                }\n                return res;\n            }\n            glname = (unsigned char *)pubnames_like_ptr;\n            pubnames_like_ptr = pubnames_like_ptr +\n                strlen((char *) pubnames_like_ptr) + 1;\n            /*  Already read offset and verified string, glname\n                now points to the string. */\n            res = _dwarf_make_global_add_to_chain(dbg,\n                global_DLA_code,\n                pubnames_context,\n                die_offset_in_cu,\n                glname,\n                &global_count,\n                &pubnames_context_on_list,\n                &plast_chain,\n                error);\n            if (res != DW_DLV_OK) {\n                dealloc_globals_chain(dbg,head_chain);\n                if (!pubnames_context_on_list) {\n                    dwarf_dealloc(dbg,pubnames_context,\n                        context_DLA_code);\n                }\n                return res;\n            }\n            /*  ========pubnames_context recorded in chain. */\n            /*  Ensure room for a next entry  to exist. */\n            if ((pubnames_like_ptr +\n                pubnames_context->pu_length_size ) >\n                section_end_ptr) {\n                pubnames_error_length(dbg,error,\n                    2*pubnames_context->pu_length_size,\n                    secname,\n                    \"global record offset\");\n                dealloc_globals_chain(dbg,head_chain);\n                if (!pubnames_context_on_list) {\n                    dwarf_dealloc(dbg,pubnames_context,\n                        context_DLA_code);\n                }\n                return DW_DLV_ERROR;\n            }\n            /* Read die offset for the *next* entry */\n            mres = _dwarf_read_unaligned_ck_wrapper(dbg,\n                &die_offset_in_cu,\n                pubnames_like_ptr,\n                pubnames_context->pu_length_size,\n                pubnames_context->pu_pub_entries_end_ptr,\n                error);\n            if (mres != DW_DLV_OK) {\n                if (!pubnames_context_on_list) {\n                    dwarf_dealloc(dbg,pubnames_context,\n                        context_DLA_code);\n                }\n                dealloc_globals_chain(dbg,head_chain);\n                return mres;\n            }\n            pubnames_like_ptr += pubnames_context->pu_length_size;\n            FIX_UP_OFFSET_IRIX_BUG(dbg,\n                die_offset_in_cu, \"offset of next die in cu\");\n            if (pubnames_like_ptr >\n                (section_data_ptr + section_length)) {\n                if (!pubnames_context_on_list) {\n                    dwarf_dealloc(dbg,pubnames_context,\n                        context_DLA_code);\n                }\n                dealloc_globals_chain(dbg,head_chain);\n                _dwarf_error(dbg, error, length_err_num);\n                return DW_DLV_ERROR;\n            }\n        }\n        /* ASSERT: die_offset_in_cu == 0 */\n        if (pubnames_like_ptr > pubnames_ptr_past_end_cu) {\n            /* This is some kind of error. This simply cannot happen.\n            The encoding is wrong or the length in the header for\n            this cu's contribution is wrong. */\n            _dwarf_error(dbg, error, length_err_num);\n            if (!pubnames_context_on_list) {\n                dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n            }\n            dealloc_globals_chain(dbg,head_chain);\n            return DW_DLV_ERROR;\n        }\n        /*  If there is some kind of padding at the end of\n            the section,\n            as emitted by some compilers, skip over that padding and\n            simply ignore the bytes thus passed-over.  With most\n            compilers, pubnames_like_ptr ==\n            pubnames_ptr_past_end_cu at this point */\n        {\n            Dwarf_Unsigned increment =\n                pubnames_context->pu_length_size +\n                pubnames_context->pu_length +\n                pubnames_context->pu_extension_size;\n            pubnames_section_offset += increment;\n        }\n        pubnames_like_ptr = pubnames_ptr_past_end_cu;\n    } while (pubnames_like_ptr < section_end_ptr);\n\n    /* Points to contiguous block of Dwarf_Global. */\n    ret_globals = (Dwarf_Global *)\n        _dwarf_get_alloc(dbg, DW_DLA_LIST, global_count);\n    if (ret_globals == NULL) {\n        if (!pubnames_context_on_list) {\n            dwarf_dealloc(dbg,pubnames_context,context_DLA_code);\n        }\n        dealloc_globals_chain(dbg,head_chain);\n        _dwarf_error(dbg, error, DW_DLE_ALLOC_FAIL);\n        return DW_DLV_ERROR;\n    }\n\n    /*  Store pointers to Dwarf_Global_s structs in contiguous block,\n        and deallocate the chain.  This ignores the various\n        headers */\n    {\n        Dwarf_Chain curr_chain = 0;\n        curr_chain = head_chain;\n        for (i = 0; i < global_count; i++) {\n            Dwarf_Chain prev = 0;\n\n            *(ret_globals + i) = curr_chain->ch_item;\n            prev = curr_chain;\n            curr_chain = curr_chain->ch_next;\n            prev->ch_item = 0; /* Not actually necessary. */\n            dwarf_dealloc(dbg, prev, DW_DLA_CHAIN);\n        }\n    }\n    *globals = ret_globals;\n    *return_count = (Dwarf_Signed) global_count;\n    return DW_DLV_OK;\n}",
        "commit_message": "Fixes vulnerability DW202205-001\nReports error instead of crashing the when reading\na specially crafted (corrupted) .debug_pubnames\nor .debug_pubtypes section.\n\tmodified:   src/lib/libdwarf/dwarf_global.c",
        "cve_desc": "libdwarf 0.4.0 has a heap-based buffer over-read in _dwarf_check_string_valid in dwarf_util.c.",
        "target": 1
      },
      {
        "idx": 207062,
        "reasoning": "The code is vulnerable to a heap-based buffer over-read because the `find_sig8_target_as_global_offset` function, called within the `DW_FORM_ref_sig8` case, might return an offset that, when added to `cu_context->cc_debug_offset`, exceeds the boundaries of the `.debug_info` section\u2014leading to a read beyond allocated memory. This vulnerability was originally due to a missing check before reading the 8 bytes of a `DW_FORM_ref_sig8`, as indicated by the commit message, and is the root cause of the heap-based buffer over-read.\n",
        "func": "dwarf_global_formref_b(Dwarf_Attribute attr,\n    Dwarf_Off * ret_offset,\n    Dwarf_Bool * offset_is_info,\n    Dwarf_Error * error)\n{\n    Dwarf_Debug dbg = 0;\n    Dwarf_Unsigned offset = 0;\n    Dwarf_CU_Context cu_context = 0;\n    Dwarf_Half context_version = 0;\n    Dwarf_Byte_Ptr section_end = 0;\n    Dwarf_Bool is_info = TRUE;\n\n    int res  = get_attr_dbg(&dbg,&cu_context,attr,error);\n    if (res != DW_DLV_OK) {\n        return res;\n    }\n    section_end =\n        _dwarf_calculate_info_section_end_ptr(cu_context);\n    context_version = cu_context->cc_version_stamp;\n    is_info = cu_context->cc_is_info;\n    switch (attr->ar_attribute_form) {\n\n    case DW_FORM_ref1:\n        offset = *(Dwarf_Small *) attr->ar_debug_ptr;\n        goto fixoffset;\n\n    case DW_FORM_ref2:\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, DWARF_HALF_SIZE,\n            error,section_end);\n        goto fixoffset;\n\n    case DW_FORM_ref4:\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, DWARF_32BIT_SIZE,\n            error,section_end);\n        goto fixoffset;\n\n    case DW_FORM_ref8:\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, DWARF_64BIT_SIZE,\n            error,section_end);\n        goto fixoffset;\n\n    case DW_FORM_ref_udata:\n        {\n        Dwarf_Byte_Ptr ptr = attr->ar_debug_ptr;\n        Dwarf_Unsigned localoffset = 0;\n\n        DECODE_LEB128_UWORD_CK(ptr,localoffset,\n            dbg,error,section_end);\n        offset = localoffset;\n\n        fixoffset: /* we have a local offset, make it global */\n\n        /* check legality of offset */\n        if (offset >= cu_context->cc_length +\n            cu_context->cc_length_size +\n            cu_context->cc_extension_size) {\n            _dwarf_error(dbg, error, DW_DLE_ATTR_FORM_OFFSET_BAD);\n            return DW_DLV_ERROR;\n        }\n\n        /* globalize the offset */\n        offset += cu_context->cc_debug_offset;\n        }\n        break;\n\n    /*  The DWARF2 document did not make clear that\n        DW_FORM_data4( and 8) were references with\n        global offsets to some section.\n        That was first clearly documented in DWARF3.\n        In DWARF4 these two forms are no longer references. */\n    case DW_FORM_data4:\n        if (context_version >= DW_CU_VERSION4) {\n            _dwarf_error(dbg, error, DW_DLE_NOT_REF_FORM);\n            return DW_DLV_ERROR;\n        }\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, DWARF_32BIT_SIZE,\n            error, section_end);\n        /* The offset is global. */\n        break;\n    case DW_FORM_data8:\n        if (context_version >= DW_CU_VERSION4) {\n            _dwarf_error(dbg, error, DW_DLE_NOT_REF_FORM);\n            return DW_DLV_ERROR;\n        }\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, DWARF_64BIT_SIZE,\n            error,section_end);\n        /* The offset is global. */\n        break;\n    case DW_FORM_ref_addr:\n        {\n            /*  In Dwarf V2 DW_FORM_ref_addr was defined\n                as address-size even though it is a .debug_info\n                offset.  Fixed in Dwarf V3 to be offset-size.\n                */\n            unsigned length_size = 0;\n            if (context_version == 2) {\n                length_size = cu_context->cc_address_size;\n            } else {\n                length_size = cu_context->cc_length_size;\n            }\n            if (length_size == 4) {\n                READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n                    attr->ar_debug_ptr, DWARF_32BIT_SIZE,\n                    error,section_end);\n            } else if (length_size == 8) {\n                READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n                    attr->ar_debug_ptr, DWARF_64BIT_SIZE,\n                    error,section_end);\n            } else {\n                _dwarf_error(dbg, error,\n                    DW_DLE_FORM_SEC_OFFSET_LENGTH_BAD);\n                return DW_DLV_ERROR;\n            }\n        }\n        break;\n    /*  Index into .debug_rnglists/.debug_loclists section.\n        Return the index itself. */\n    case DW_FORM_loclistx:\n    case DW_FORM_rnglistx: {\n        unsigned length_size = cu_context->cc_length_size;\n        READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n            attr->ar_debug_ptr, length_size,\n            error,section_end);\n        }\n        break;\n    case DW_FORM_sec_offset:\n    case DW_FORM_GNU_ref_alt:  /* 2013 GNU extension */\n    case DW_FORM_GNU_strp_alt: /* 2013 GNU extension */\n    case DW_FORM_strp_sup:     /* DWARF5, sup string section */\n    case DW_FORM_line_strp:    /* DWARF5, .debug_line_str section */\n        {\n            /*  DW_FORM_sec_offset first exists in DWARF4.*/\n            /*  It is up to the caller to know what the offset\n                of DW_FORM_sec_offset, DW_FORM_strp_sup\n                or DW_FORM_GNU_strp_alt etc refer to,\n                the offset is not going to refer to .debug_info! */\n            unsigned length_size = cu_context->cc_length_size;\n            if (length_size == 4) {\n                READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n                    attr->ar_debug_ptr, DWARF_32BIT_SIZE,\n                    error,section_end);\n            } else if (length_size == 8) {\n                READ_UNALIGNED_CK(dbg, offset, Dwarf_Unsigned,\n                    attr->ar_debug_ptr, DWARF_64BIT_SIZE,\n                    error,section_end);\n            } else {\n                _dwarf_error(dbg, error,\n                    DW_DLE_FORM_SEC_OFFSET_LENGTH_BAD);\n                return DW_DLV_ERROR;\n            }\n        }\n        break;\n    case DW_FORM_ref_sig8: {\n        /*  This, in DWARF4, is how\n            .debug_info refers to .debug_types. */\n        Dwarf_Sig8 sig8;\n        Dwarf_Bool t_is_info = TRUE;\n        Dwarf_Unsigned t_offset = 0;\n\n        memcpy(&sig8,attr->ar_debug_ptr,sizeof(Dwarf_Sig8));\n        res = find_sig8_target_as_global_offset(attr,\n            &sig8,&t_is_info,&t_offset,error);\n        if (res == DW_DLV_ERROR) {\n            _dwarf_error_string(dbg, error,\n                DW_DLE_REF_SIG8_NOT_HANDLED,\n                \"DW_DLE_REF_SIG8_NOT_HANDLED: \"\n                \" problem finding target\");\n            return DW_DLV_ERROR;\n        }\n        if (res == DW_DLV_NO_ENTRY) {\n            return res;\n        }\n        is_info = t_is_info;\n        offset = t_offset;\n        break;\n    }\n    default: {\n        dwarfstring m;\n        int formcode = attr->ar_attribute_form;\n        int fcres = 0;\n        const char *name = 0;\n\n        dwarfstring_constructor(&m);\n        dwarfstring_append_printf_u(&m,\n            \"DW_DLE_BAD_REF_FORM: The form code is 0x%x \",\n            formcode);\n        fcres  = dwarf_get_FORM_name (formcode,&name);\n        if (fcres != DW_DLV_OK) {\n            name=\"<UnknownFormCode>\";\n        }\n        dwarfstring_append_printf_s(&m,\n            \" %s.\",(char *)name);\n        _dwarf_error_string(dbg, error, DW_DLE_BAD_REF_FORM,\n            dwarfstring_string(&m));\n        dwarfstring_destructor(&m);\n        return DW_DLV_ERROR;\n        }\n    }\n\n    *offset_is_info = is_info;\n    *ret_offset = offset;\n    return DW_DLV_OK;\n}",
        "commit_message": "Fixes old bug(which could result in Denial of Service)\ndue to a missing check before reading the 8 bytes of a DW_FORM_ref_sig8.\nDW202206-001\n\tmodified:   src/lib/libdwarf/dwarf_form.c",
        "cve_desc": "There is a heap-based buffer over-read in libdwarf 0.4.0. This issue is related to dwarf_global_formref_b.",
        "target": 1
      }
    ]
  },
  "libevent": {
    "0": [
      {
        "idx": 65727,
        "reasoning": "The provided code snippet `add_cname_to_reply` is not vulnerable because the bug report specifically identifies a vulnerability in the `search_make_new` function within the DNS resolution code, not in this function dealing with canonical names. The vulnerability stems from accessing `base_name[base_len - 1]` when `base_len` is zero, leading to an out-of-bounds read, and this code doesn't perform that operation.\n\n\n\n",
        "func": "add_cname_to_reply(struct evdns_getaddrinfo_request *data,\n    struct evutil_addrinfo *ai)\n{\n\tif (data->cname_result && ai) {\n\t\tai->ai_canonname = data->cname_result;\n\t\tdata->cname_result = NULL;\n\t}\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 0
      },
      {
        "idx": 65728,
        "reasoning": "This code snippet is not the vulnerable code identified in the bug report. The report specifically details an out-of-bounds read in `search_make_new` within the `evdns` module due to handling an empty `base_name`, while this snippet relates to reading nameserver information from the Windows registry and doesn't exhibit the same potential for accessing memory before the buffer's start.\n\n\n\n",
        "func": "config_nameserver_from_reg_key(struct evdns_base *base, HKEY key, const TCHAR *subkey)\n{\n\tchar *buf;\n\tDWORD bufsz = 0, type = 0;\n\tint status = 0;\n\n\tASSERT_LOCKED(base);\n\tif (RegQueryValueEx(key, subkey, 0, &type, NULL, &bufsz)\n\t    != ERROR_MORE_DATA)\n\t\treturn -1;\n\tif (!(buf = mm_malloc(bufsz)))\n\t\treturn -1;\n\n\tif (RegQueryValueEx(key, subkey, 0, &type, (LPBYTE)buf, &bufsz)\n\t    == ERROR_SUCCESS && bufsz > 1) {\n\t\tstatus = evdns_nameserver_ip_add_line(base,buf);\n\t}\n\n\tmm_free(buf);\n\treturn status;\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 0
      },
      {
        "idx": 65729,
        "reasoning": "The provided code snippet `dnslabel_clear` is not the vulnerable code; the vulnerability exists within the `search_make_new` function in the `evdns` module as described in the bug report. The snippet simply frees memory associated with DNS labels and doesn't exhibit any out-of-bounds read issues like the reported bug.\n\n\n\n",
        "func": "dnslabel_clear(struct dnslabel_table *table)\n{\n\tint i;\n\tfor (i = 0; i < table->n_labels; ++i)\n\t\tmm_free(table->labels[i].v);\n\ttable->n_labels = 0;\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 0
      },
      {
        "idx": 65730,
        "reasoning": "The provided code snippet `dnslabel_table_add` is not the vulnerable code; the bug report specifically identifies a vulnerability in the `search_make_new` function within the `evdns` module related to handling empty hostnames. This snippet focuses on adding labels to a table and doesn't exhibit the out-of-bounds read issue described in the bug report, therefore it's not flagged as vulnerable.\n\n\n\n",
        "func": "dnslabel_table_add(struct dnslabel_table *table, const char *label, off_t pos)\n{\n\tchar *v;\n\tint p;\n\tif (table->n_labels == MAX_LABELS)\n\t\treturn (-1);\n\tv = mm_strdup(label);\n\tif (v == NULL)\n\t\treturn (-1);\n\tp = table->n_labels++;\n\ttable->labels[p].v = v;\n\ttable->labels[p].pos = pos;\n\n\treturn (0);\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 0
      },
      {
        "idx": 65731,
        "reasoning": "The provided code snippet `dnslabel_table_get_pos` is not the vulnerable code; the bug report specifically identifies a vulnerability in the `search_make_new` function within the `evdns` module of libevent. This function has an out-of-bounds read when handling empty hostnames, which is the focus of the commit and the Tor bug bounty report, not the `dnslabel_table_get_pos` function.\n\n\n\n",
        "func": "dnslabel_table_get_pos(const struct dnslabel_table *table, const char *label)\n{\n\tint i;\n\tfor (i = 0; i < table->n_labels; ++i) {\n\t\tif (!strcmp(label, table->labels[i].v))\n\t\t\treturn table->labels[i].pos;\n\t}\n\treturn -1;\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3089,
        "reasoning": "This code is vulnerable to an out-of-bounds read because the `strlen(base_name)` call doesn't validate for an empty `base_name` string, leading to accessing `base_name[base_len - 1]` when `base_len` is 0. This results in reading one byte before the allocated buffer, causing a crash as demonstrated by the ASAN report and the provided PoC.\n\n\n\n",
        "func": " search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n \tconst size_t base_len = strlen(base_name);\n\tconst char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n \tstruct search_domain *dom;\n \n \tfor (dom = state->head; dom; dom = dom->next) {\n \t\tif (!n--) {\n \t\t\t/* this is the postfix we want */\n\t\t\t/* the actual postfix string is kept at the end of the structure */\n\t\t\tconst u8 *const postfix = ((u8 *) dom) + sizeof(struct search_domain);\n\t\t\tconst int postfix_len = dom->len;\n\t\t\tchar *const newname = (char *) mm_malloc(base_len + need_to_append_dot + postfix_len + 1);\n\t\t\tif (!newname) return NULL;\n\t\t\tmemcpy(newname, base_name, base_len);\n\t\t\tif (need_to_append_dot) newname[base_len] = '.';\n\t\t\tmemcpy(newname + base_len + need_to_append_dot, postfix, postfix_len);\n\t\t\tnewname[base_len + need_to_append_dot + postfix_len] = 0;\n\t\t\treturn newname;\n\t\t}\n\t}\n\n\t/* we ran off the end of the list and still didn't find the requested string */\n\tEVUTIL_ASSERT(0);\n\treturn NULL; /* unreachable; stops warnings in some compilers. */\n}\n",
        "commit_message": "evdns: fix searching empty hostnames\n\nFrom #332:\n  Here follows a bug report by **Guido Vranken** via the _Tor bug bounty program_. Please credit Guido accordingly.\n\n  ## Bug report\n\n  The DNS code of Libevent contains this rather obvious OOB read:\n\n  ```c\n  static char *\n  search_make_new(const struct search_state *const state, int n, const char *const base_name) {\n      const size_t base_len = strlen(base_name);\n      const char need_to_append_dot = base_name[base_len - 1] == '.' ? 0 : 1;\n  ```\n\n  If the length of ```base_name``` is 0, then line 3125 reads 1 byte before the buffer. This will trigger a crash on ASAN-protected builds.\n\n  To reproduce:\n\n  Build libevent with ASAN:\n  ```\n  $ CFLAGS='-fomit-frame-pointer -fsanitize=address' ./configure && make -j4\n  ```\n  Put the attached ```resolv.conf``` and ```poc.c``` in the source directory and then do:\n\n  ```\n  $ gcc -fsanitize=address -fomit-frame-pointer poc.c .libs/libevent.a\n  $ ./a.out\n  =================================================================\n  ==22201== ERROR: AddressSanitizer: heap-buffer-overflow on address 0x60060000efdf at pc 0x4429da bp 0x7ffe1ed47300 sp 0x7ffe1ed472f8\n  READ of size 1 at 0x60060000efdf thread T0\n  ```\n\nP.S. we can add a check earlier, but since this is very uncommon, I didn't add it.\n\nFixes: #332",
        "cve_desc": "The search_make_new function in evdns.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (out-of-bounds read) via an empty hostname.",
        "target": 1
      },
      {
        "idx": 3090,
        "reasoning": "The vulnerability lies in the calculation of the length of the IPv6 address within the brackets `[]` in `evutil_parse_sockaddr_port`. Specifically, `len = (int) ( cp-(ip_as_string + 1) );` casts the difference between the closing bracket's position and the address start to a signed 32-bit integer, allowing a sufficiently long address to wrap around to a negative value and bypass the subsequent size check, leading to a buffer overflow when `memcpy` is called.",
        "func": "evutil_parse_sockaddr_port(const char *ip_as_string, struct sockaddr *out, int *outlen)\n{\n\tint port;\n\tchar buf[128];\n\tconst char *cp, *addr_part, *port_part;\n\tint is_ipv6;\n\t/* recognized formats are:\n\t * [ipv6]:port\n\t * ipv6\n\t * [ipv6]\n\t * ipv4:port\n\t * ipv4\n\t */\n \n \tcp = strchr(ip_as_string, ':');\n \tif (*ip_as_string == '[') {\n\t\tint len;\n \t\tif (!(cp = strchr(ip_as_string, ']'))) {\n \t\t\treturn -1;\n \t\t}\n\t\tlen = (int) ( cp-(ip_as_string + 1) );\n\t\tif (len > (int)sizeof(buf)-1) {\n \t\t\treturn -1;\n \t\t}\n \t\tmemcpy(buf, ip_as_string+1, len);\n\t\tbuf[len] = '\\0';\n\t\taddr_part = buf;\n\t\tif (cp[1] == ':')\n\t\t\tport_part = cp+2;\n\t\telse\n\t\t\tport_part = NULL;\n\t\tis_ipv6 = 1;\n\t} else if (cp && strchr(cp+1, ':')) {\n\t\tis_ipv6 = 1;\n\t\taddr_part = ip_as_string;\n\t\tport_part = NULL;\n\t} else if (cp) {\n\t\tis_ipv6 = 0;\n\t\tif (cp - ip_as_string > (int)sizeof(buf)-1) {\n\t\t\treturn -1;\n\t\t}\n\t\tmemcpy(buf, ip_as_string, cp-ip_as_string);\n\t\tbuf[cp-ip_as_string] = '\\0';\n\t\taddr_part = buf;\n\t\tport_part = cp+1;\n\t} else {\n\t\taddr_part = ip_as_string;\n\t\tport_part = NULL;\n\t\tis_ipv6 = 0;\n\t}\n\n\tif (port_part == NULL) {\n\t\tport = 0;\n\t} else {\n\t\tport = atoi(port_part);\n\t\tif (port <= 0 || port > 65535) {\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\tif (!addr_part)\n\t\treturn -1; /* Should be impossible. */\n#ifdef AF_INET6\n\tif (is_ipv6)\n\t{\n\t\tstruct sockaddr_in6 sin6;\n\t\tmemset(&sin6, 0, sizeof(sin6));\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN6_SIN6_LEN\n\t\tsin6.sin6_len = sizeof(sin6);\n#endif\n\t\tsin6.sin6_family = AF_INET6;\n\t\tsin6.sin6_port = htons(port);\n\t\tif (1 != evutil_inet_pton(AF_INET6, addr_part, &sin6.sin6_addr))\n\t\t\treturn -1;\n\t\tif ((int)sizeof(sin6) > *outlen)\n\t\t\treturn -1;\n\t\tmemset(out, 0, *outlen);\n\t\tmemcpy(out, &sin6, sizeof(sin6));\n\t\t*outlen = sizeof(sin6);\n\t\treturn 0;\n\t}\n\telse\n#endif\n\t{\n\t\tstruct sockaddr_in sin;\n\t\tmemset(&sin, 0, sizeof(sin));\n#ifdef EVENT__HAVE_STRUCT_SOCKADDR_IN_SIN_LEN\n\t\tsin.sin_len = sizeof(sin);\n#endif\n\t\tsin.sin_family = AF_INET;\n\t\tsin.sin_port = htons(port);\n\t\tif (1 != evutil_inet_pton(AF_INET, addr_part, &sin.sin_addr))\n\t\t\treturn -1;\n\t\tif ((int)sizeof(sin) > *outlen)\n\t\t\treturn -1;\n\t\tmemset(out, 0, *outlen);\n\t\tmemcpy(out, &sin, sizeof(sin));\n\t\t*outlen = sizeof(sin);\n\t\treturn 0;\n\t}\n}\n",
        "commit_message": "evutil_parse_sockaddr_port(): fix buffer overflow\n\n@asn-the-goblin-slayer:\n  \"Length between '[' and ']' is cast to signed 32 bit integer on line 1815. Is\n   the length is more than 2<<31 (INT_MAX), len will hold a negative value.\n   Consequently, it will pass the check at line 1816. Segfault happens at line\n   1819.\n\n   Generate a resolv.conf with generate-resolv.conf, then compile and run\n   poc.c. See entry-functions.txt for functions in tor that might be\n   vulnerable.\n\n   Please credit 'Guido Vranken' for this discovery through the Tor bug bounty\n   program.\"\n\nReproducer for gdb (https://gist.github.com/azat/be2b0d5e9417ba0dfe2c):\n  start\n  p (1ULL<<31)+1ULL\n  # $1 = 2147483649\n  p malloc(sizeof(struct sockaddr))\n  # $2 = (void *) 0x646010\n  p malloc(sizeof(int))\n  # $3 = (void *) 0x646030\n  p malloc($1)\n  # $4 = (void *) 0x7fff76a2a010\n  p memset($4, 1, $1)\n  # $5 = 1990369296\n  p (char *)$4\n  # $6 = 0x7fff76a2a010 '\\001' <repeats 200 times>...\n  set $6[0]='['\n  set $6[$1]=']'\n  p evutil_parse_sockaddr_port($4, $2, $3)\n  # $7 = -1\n\nBefore:\n  $ gdb bin/http-connect < gdb\n  (gdb) $1 = 2147483649\n  (gdb) (gdb) $2 = (void *) 0x646010\n  (gdb) (gdb) $3 = (void *) 0x646030\n  (gdb) (gdb) $4 = (void *) 0x7fff76a2a010\n  (gdb) (gdb) $5 = 1990369296\n  (gdb) (gdb) $6 = 0x7fff76a2a010 '\\001' <repeats 200 times>...\n  (gdb) (gdb) (gdb) (gdb)\n  Program received signal SIGSEGV, Segmentation fault.\n  __memcpy_sse2_unaligned () at memcpy-sse2-unaligned.S:36\n\nAfter:\n  $ gdb bin/http-connect < gdb\n  (gdb) $1 = 2147483649\n  (gdb) (gdb) $2 = (void *) 0x646010\n  (gdb) (gdb) $3 = (void *) 0x646030\n  (gdb) (gdb) $4 = (void *) 0x7fff76a2a010\n  (gdb) (gdb) $5 = 1990369296\n  (gdb) (gdb) $6 = 0x7fff76a2a010 '\\001' <repeats 200 times>...\n  (gdb) (gdb) (gdb) (gdb) $7 = -1\n  (gdb) (gdb) quit\n\nFixes: #318",
        "cve_desc": "Stack-based buffer overflow in the evutil_parse_sockaddr_port function in evutil.c in libevent before 2.1.6-beta allows attackers to cause a denial of service (segmentation fault) via vectors involving a long string in brackets in the ip_as_string argument.",
        "target": 1
      }
    ]
  },
  "libexif": {
    "0": [],
    "1": []
  },
  "libexpat": {
    "0": [
      {
        "idx": 83899,
        "reasoning": "This code is not directly vulnerable to the issue the commit message addresses (extraction of namespace prefix from XML name) and includes several mitigations against buffer overflows using `EXPAT_SAFE_PTR_DIFF` and careful size calculations. While memory allocation is present, it's handled with checks for allocation failures and exponential buffer resizing to avoid exhaustion, making it a safe implementation regarding memory safety concerns.\n\n\n\n",
        "func": "XML_GetBuffer(XML_Parser parser, int len)\n{\n  if (parser == NULL)\n    return NULL;\n  if (len < 0) {\n    parser->m_errorCode = XML_ERROR_NO_MEMORY;\n    return NULL;\n  }\n  switch (parser->m_parsingStatus.parsing) {\n  case XML_SUSPENDED:\n    parser->m_errorCode = XML_ERROR_SUSPENDED;\n    return NULL;\n  case XML_FINISHED:\n    parser->m_errorCode = XML_ERROR_FINISHED;\n    return NULL;\n  default: ;\n  }\n\n  if (len > EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferEnd)) {\n#ifdef XML_CONTEXT_BYTES\n    int keep;\n#endif  /* defined XML_CONTEXT_BYTES */\n    /* Do not invoke signed arithmetic overflow: */\n    int neededSize = (int) ((unsigned)len +\n                            (unsigned)EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd,\n                                                          parser->m_bufferPtr));\n    if (neededSize < 0) {\n      parser->m_errorCode = XML_ERROR_NO_MEMORY;\n      return NULL;\n    }\n#ifdef XML_CONTEXT_BYTES\n    keep = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer);\n    if (keep > XML_CONTEXT_BYTES)\n      keep = XML_CONTEXT_BYTES;\n    neededSize += keep;\n#endif  /* defined XML_CONTEXT_BYTES */\n    if (neededSize <= EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_buffer)) {\n#ifdef XML_CONTEXT_BYTES\n      if (keep < EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer)) {\n          int offset = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer) - keep;\n        /* The buffer pointers cannot be NULL here; we have at least some bytes in the buffer */\n        memmove(parser->m_buffer, &parser->m_buffer[offset], parser->m_bufferEnd - parser->m_bufferPtr + keep);\n        parser->m_bufferEnd -= offset;\n        parser->m_bufferPtr -= offset;\n      }\n#else\n      if (parser->m_buffer && parser->m_bufferPtr) {\n        memmove(parser->m_buffer, parser->m_bufferPtr,\n                EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr));\n        parser->m_bufferEnd = parser->m_buffer +\n            EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr);\n        parser->m_bufferPtr = parser->m_buffer;\n      }\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    else {\n      char *newBuf;\n      int bufferSize = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferLim, parser->m_bufferPtr);\n      if (bufferSize == 0)\n        bufferSize = INIT_BUFFER_SIZE;\n      do {\n        /* Do not invoke signed arithmetic overflow: */\n        bufferSize = (int) (2U * (unsigned) bufferSize);\n      } while (bufferSize < neededSize && bufferSize > 0);\n      if (bufferSize <= 0) {\n        parser->m_errorCode = XML_ERROR_NO_MEMORY;\n        return NULL;\n      }\n      newBuf = (char *)MALLOC(parser, bufferSize);\n      if (newBuf == 0) {\n        parser->m_errorCode = XML_ERROR_NO_MEMORY;\n        return NULL;\n      }\n      parser->m_bufferLim = newBuf + bufferSize;\n#ifdef XML_CONTEXT_BYTES\n      if (parser->m_bufferPtr) {\n        int keep = (int)EXPAT_SAFE_PTR_DIFF(parser->m_bufferPtr, parser->m_buffer);\n        if (keep > XML_CONTEXT_BYTES)\n          keep = XML_CONTEXT_BYTES;\n        memcpy(newBuf, &parser->m_bufferPtr[-keep],\n               EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr) + keep);\n        FREE(parser, parser->m_buffer);\n        parser->m_buffer = newBuf;\n        parser->m_bufferEnd = parser->m_buffer +\n            EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr) + keep;\n        parser->m_bufferPtr = parser->m_buffer + keep;\n      }\n      else {\n        /* This must be a brand new buffer with no data in it yet */\n        parser->m_bufferEnd = newBuf;\n        parser->m_bufferPtr = parser->m_buffer = newBuf;\n      }\n#else\n      if (parser->m_bufferPtr) {\n        memcpy(newBuf, parser->m_bufferPtr,\n               EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr));\n        FREE(parser, parser->m_buffer);\n        parser->m_bufferEnd = newBuf +\n            EXPAT_SAFE_PTR_DIFF(parser->m_bufferEnd, parser->m_bufferPtr);\n      }\n      else {\n        /* This must be a brand new buffer with no data in it yet */\n        parser->m_bufferEnd = newBuf;\n      }\n      parser->m_bufferPtr = parser->m_buffer = newBuf;\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    parser->m_eventPtr = parser->m_eventEndPtr = NULL;\n    parser->m_positionPtr = NULL;\n  }\n  return parser->m_bufferEnd;\n}\n",
        "commit_message": "xmlparse.c: Fix extraction of namespace prefix from XML name (#186)",
        "cve_desc": "In libexpat in Expat before 2.2.7, XML input including XML names that contain a large number of colons could make the XML parser consume a high amount of RAM and CPU resources while processing (enough to be usable for denial-of-service attacks).",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 4132,
        "reasoning": "This code is vulnerable to a denial-of-service attack because the nested loops and `poolAppendChar` calls within `setElementTypePrefix` can be triggered repeatedly by XML input with many colons in element names. Each colon leads to appending characters to `dtd->pool`, and if a large number of colons are present, this can exhaust memory resources, ultimately causing a denial of service as described in the CVE.",
        "func": "setElementTypePrefix(XML_Parser parser, ELEMENT_TYPE *elementType)\n{\n  DTD * const dtd = parser->m_dtd;  /* save one level of indirection */\n  const XML_Char *name;\n  for (name = elementType->name; *name; name++) {\n    if (*name == XML_T(ASCII_COLON)) {\n      PREFIX *prefix;\n      const XML_Char *s;\n      for (s = elementType->name; s != name; s++) {\n        if (!poolAppendChar(&dtd->pool, *s))\n          return 0;\n      }\n      if (!poolAppendChar(&dtd->pool, XML_T('\\0')))\n        return 0;\n      prefix = (PREFIX *)lookup(parser, &dtd->prefixes, poolStart(&dtd->pool),\n                                sizeof(PREFIX));\n      if (!prefix)\n        return 0;\n      if (prefix->name == poolStart(&dtd->pool))\n        poolFinish(&dtd->pool);\n       else\n         poolDiscard(&dtd->pool);\n       elementType->prefix = prefix;\n     }\n   }\n   return 1;\n}\n",
        "commit_message": "xmlparse.c: Fix extraction of namespace prefix from XML name (#186)",
        "cve_desc": "In libexpat in Expat before 2.2.7, XML input including XML names that contain a large number of colons could make the XML parser consume a high amount of RAM and CPU resources while processing (enough to be usable for denial-of-service attacks).",
        "target": 1
      },
      {
        "idx": 200623,
        "reasoning": "This code is vulnerable to an integer overflow when calculating `neededSize` because `len` and `(bufferEnd - bufferPtr)` are cast to `int` before being added, potentially resulting in a smaller value than expected if their sum exceeds the maximum `int` value. This overflow can lead to an undersized buffer allocation, ultimately causing a buffer overflow when the XML data is copied into the newly allocated space, as demonstrated by the CVE description involving large, compressed XML data.\n\n\n\n",
        "func": "XML_GetBuffer(XML_Parser parser, int len)\n{\n  switch (ps_parsing) {\n  case XML_SUSPENDED:\n    errorCode = XML_ERROR_SUSPENDED;\n    return NULL;\n  case XML_FINISHED:\n    errorCode = XML_ERROR_FINISHED;\n    return NULL;\n  default: ;\n  }\n\n  if (len > bufferLim - bufferEnd) {\n    /* FIXME avoid integer overflow */\n    int neededSize = len + (int)(bufferEnd - bufferPtr);\n#ifdef XML_CONTEXT_BYTES\n    int keep = (int)(bufferPtr - buffer);\n\n    if (keep > XML_CONTEXT_BYTES)\n      keep = XML_CONTEXT_BYTES;\n    neededSize += keep;\n#endif  /* defined XML_CONTEXT_BYTES */\n    if (neededSize  <= bufferLim - buffer) {\n#ifdef XML_CONTEXT_BYTES\n      if (keep < bufferPtr - buffer) {\n        int offset = (int)(bufferPtr - buffer) - keep;\n        memmove(buffer, &buffer[offset], bufferEnd - bufferPtr + keep);\n        bufferEnd -= offset;\n        bufferPtr -= offset;\n      }\n#else\n      memmove(buffer, bufferPtr, bufferEnd - bufferPtr);\n      bufferEnd = buffer + (bufferEnd - bufferPtr);\n      bufferPtr = buffer;\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    else {\n      char *newBuf;\n      int bufferSize = (int)(bufferLim - bufferPtr);\n      if (bufferSize == 0)\n        bufferSize = INIT_BUFFER_SIZE;\n      do {\n        bufferSize *= 2;\n      } while (bufferSize < neededSize);\n      newBuf = (char *)MALLOC(bufferSize);\n      if (newBuf == 0) {\n        errorCode = XML_ERROR_NO_MEMORY;\n        return NULL;\n      }\n      bufferLim = newBuf + bufferSize;\n#ifdef XML_CONTEXT_BYTES\n      if (bufferPtr) {\n        int keep = (int)(bufferPtr - buffer);\n        if (keep > XML_CONTEXT_BYTES)\n          keep = XML_CONTEXT_BYTES;\n        memcpy(newBuf, &bufferPtr[-keep], bufferEnd - bufferPtr + keep);\n        FREE(buffer);\n        buffer = newBuf;\n        bufferEnd = buffer + (bufferEnd - bufferPtr) + keep;\n        bufferPtr = buffer + keep;\n      }\n      else {\n        bufferEnd = newBuf + (bufferEnd - bufferPtr);\n        bufferPtr = buffer = newBuf;\n      }\n#else\n      if (bufferPtr) {\n        memcpy(newBuf, bufferPtr, bufferEnd - bufferPtr);\n        FREE(buffer);\n      }\n      bufferEnd = newBuf + (bufferEnd - bufferPtr);\n      bufferPtr = buffer = newBuf;\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    eventPtr = eventEndPtr = NULL;\n    positionPtr = NULL;\n  }\n  return bufferEnd;\n}",
        "commit_message": "CVE-2015-1283 Sanity check size calculations. r=peterv, a=abillings\n\nhttps://sourceforge.net/p/expat/bugs/528/",
        "cve_desc": "Buffer overflow in the XML parser in Mozilla Firefox before 38.0, Firefox ESR 31.x before 31.7, and Thunderbird before 31.7 allows remote attackers to execute arbitrary code by providing a large amount of compressed XML data, a related issue to CVE-2015-1283.",
        "target": 1
      },
      {
        "idx": 200951,
        "reasoning": "This code is vulnerable to a buffer overflow because the `neededSize` calculation, intended to prevent overflows, can still result in an integer overflow when `len` and `bufferEnd - bufferPtr` are large, leading to an allocation that is too small. Consequently, subsequent writes to the buffer can exceed its allocated size, allowing an attacker to potentially execute arbitrary code as described in CVE-2015-1283.",
        "func": "XML_GetBuffer(XML_Parser parser, int len)\n{\n  if (len < 0) {\n    errorCode = XML_ERROR_NO_MEMORY;\n    return NULL;\n  }\n  switch (ps_parsing) {\n  case XML_SUSPENDED:\n    errorCode = XML_ERROR_SUSPENDED;\n    return NULL;\n  case XML_FINISHED:\n    errorCode = XML_ERROR_FINISHED;\n    return NULL;\n  default: ;\n  }\n\n  if (len > bufferLim - bufferEnd) {\n#ifdef XML_CONTEXT_BYTES\n    int keep;\n#endif  /* defined XML_CONTEXT_BYTES */\n    int neededSize = len + (int)(bufferEnd - bufferPtr);\n    if (neededSize < 0) {\n      errorCode = XML_ERROR_NO_MEMORY;\n      return NULL;\n    }\n#ifdef XML_CONTEXT_BYTES\n    keep = (int)(bufferPtr - buffer);\n    if (keep > XML_CONTEXT_BYTES)\n      keep = XML_CONTEXT_BYTES;\n    neededSize += keep;\n#endif  /* defined XML_CONTEXT_BYTES */\n    if (neededSize  <= bufferLim - buffer) {\n#ifdef XML_CONTEXT_BYTES\n      if (keep < bufferPtr - buffer) {\n        int offset = (int)(bufferPtr - buffer) - keep;\n        memmove(buffer, &buffer[offset], bufferEnd - bufferPtr + keep);\n        bufferEnd -= offset;\n        bufferPtr -= offset;\n      }\n#else\n      memmove(buffer, bufferPtr, bufferEnd - bufferPtr);\n      bufferEnd = buffer + (bufferEnd - bufferPtr);\n      bufferPtr = buffer;\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    else {\n      char *newBuf;\n      int bufferSize = (int)(bufferLim - bufferPtr);\n      if (bufferSize == 0)\n        bufferSize = INIT_BUFFER_SIZE;\n      do {\n        bufferSize *= 2;\n      } while (bufferSize < neededSize && bufferSize > 0);\n      if (bufferSize <= 0) {\n        errorCode = XML_ERROR_NO_MEMORY;\n        return NULL;\n      }\n      newBuf = (char *)MALLOC(bufferSize);\n      if (newBuf == 0) {\n        errorCode = XML_ERROR_NO_MEMORY;\n        return NULL;\n      }\n      bufferLim = newBuf + bufferSize;\n#ifdef XML_CONTEXT_BYTES\n      if (bufferPtr) {\n        int keep = (int)(bufferPtr - buffer);\n        if (keep > XML_CONTEXT_BYTES)\n          keep = XML_CONTEXT_BYTES;\n        memcpy(newBuf, &bufferPtr[-keep], bufferEnd - bufferPtr + keep);\n        FREE(buffer);\n        buffer = newBuf;\n        bufferEnd = buffer + (bufferEnd - bufferPtr) + keep;\n        bufferPtr = buffer + keep;\n      }\n      else {\n        bufferEnd = newBuf + (bufferEnd - bufferPtr);\n        bufferPtr = buffer = newBuf;\n      }\n#else\n      if (bufferPtr) {\n        memcpy(newBuf, bufferPtr, bufferEnd - bufferPtr);\n        FREE(buffer);\n      }\n      bufferEnd = newBuf + (bufferEnd - bufferPtr);\n      bufferPtr = buffer = newBuf;\n#endif  /* not defined XML_CONTEXT_BYTES */\n    }\n    eventPtr = eventEndPtr = NULL;\n    positionPtr = NULL;\n  }\n  return bufferEnd;\n}",
        "commit_message": "Avoid relying on undefined behavior in CVE-2015-1283 fix. It does not really work: https://godbolt.org/g/Zl8gdF",
        "cve_desc": "Buffer overflow in the XML parser in Mozilla Firefox before 38.0, Firefox ESR 31.x before 31.7, and Thunderbird before 31.7 allows remote attackers to execute arbitrary code by providing a large amount of compressed XML data, a related issue to CVE-2015-1283.",
        "target": 1
      },
      {
        "idx": 204196,
        "reasoning": "The original `build_model` function was vulnerable to stack exhaustion due to its recursive calls to `build_node` when processing deeply nested DTD elements, potentially exceeding the stack's capacity. The commit addresses this by converting the recursive `build_node` calls into an iterative approach, utilizing heap memory to simulate a stack and avoid the limitations of the call stack.",
        "func": "build_model(XML_Parser parser) {\n  DTD *const dtd = parser->m_dtd; /* save one level of indirection */\n  XML_Content *ret;\n  XML_Content *cpos;\n  XML_Char *str;\n\n  /* Detect and prevent integer overflow.\n   * The preprocessor guard addresses the \"always false\" warning\n   * from -Wtype-limits on platforms where\n   * sizeof(unsigned int) < sizeof(size_t), e.g. on x86_64. */\n#if UINT_MAX >= SIZE_MAX\n  if (dtd->scaffCount > (size_t)(-1) / sizeof(XML_Content)) {\n    return NULL;\n  }\n  if (dtd->contentStringLen > (size_t)(-1) / sizeof(XML_Char)) {\n    return NULL;\n  }\n#endif\n  if (dtd->scaffCount * sizeof(XML_Content)\n      > (size_t)(-1) - dtd->contentStringLen * sizeof(XML_Char)) {\n    return NULL;\n  }\n\n  const size_t allocsize = (dtd->scaffCount * sizeof(XML_Content)\n                            + (dtd->contentStringLen * sizeof(XML_Char)));\n\n  ret = (XML_Content *)MALLOC(parser, allocsize);\n  if (! ret)\n    return NULL;\n\n  str = (XML_Char *)(&ret[dtd->scaffCount]);\n  cpos = &ret[1];\n\n  build_node(parser, 0, ret, &cpos, &str);\n  return ret;\n}",
        "commit_message": "Prevent stack exhaustion in build_model\n\nIt is possible to trigger stack exhaustion in build_model function if\ndepth of nested children in DTD element is large enough. This happens\nbecause build_node is a recursively called function within build_model.\n\nThe code has been adjusted to run iteratively. It uses the already\nallocated heap space as temporary stack (growing from top to bottom).\n\nOutput is identical to recursive version. No new fields in data\nstructures were added, i.e. it keeps full API and ABI compatibility.\nInstead the numchildren variable is used to temporarily keep the\nindex of items (uint vs int).\n\nDocumentation and readability improvements kindly added by Sebastian.\n\nProof of Concept:\n\n1. Compile poc binary which parses XML file line by line\n\n```\ncat > poc.c << EOF\n #include <err.h>\n #include <expat.h>\n #include <stdio.h>\n\n XML_Parser parser;\n\n static void XMLCALL\n dummy_element_decl_handler(void *userData, const XML_Char *name,\n                            XML_Content *model) {\n   XML_FreeContentModel(parser, model);\n }\n\n int main(int argc, char *argv[]) {\n   FILE *fp;\n   char *p = NULL;\n   size_t s = 0;\n   ssize_t l;\n   if (argc != 2)\n     errx(1, \"usage: poc poc.xml\");\n   if ((parser = XML_ParserCreate(NULL)) == NULL)\n     errx(1, \"XML_ParserCreate\");\n   XML_SetElementDeclHandler(parser, dummy_element_decl_handler);\n   if ((fp = fopen(argv[1], \"r\")) == NULL)\n     err(1, \"fopen\");\n   while ((l = getline(&p, &s, fp)) > 0)\n     if (XML_Parse(parser, p, (int)l, XML_FALSE) != XML_STATUS_OK)\n       errx(1, \"XML_Parse\");\n   XML_ParserFree(parser);\n   free(p);\n   fclose(fp);\n   return 0;\n }\nEOF\ncc -std=c11 -D_POSIX_C_SOURCE=200809L -lexpat -o poc poc.c\n```\n\n2. Create XML file with a lot of nested groups in DTD element\n\n```\ncat > poc.xml.zst.b64 << EOF\nKLUv/aQkACAAPAEA+DwhRE9DVFlQRSB1d3UgWwo8IUVMRU1FTlQgdXd1CigBAHv/58AJAgAQKAIA\nECgCABAoAgAQKAIAECgCABAoAgAQKHwAAChvd28KKQIA2/8gV24XBAIAECkCABApAgAQKQIAECkC\nABApAgAQKQIAEClVAAAgPl0+CgEA4A4I2VwwnQ==\nEOF\nbase64 -d poc.xml.zst.b64 | zstd -d > poc.xml\n```\n\n3. Run Proof of Concept\n\n```\n./poc poc.xml\n```\n\nCo-authored-by: Sebastian Pipping <sebastian@pipping.org>",
        "cve_desc": "In Expat (aka libexpat) before 2.4.5, an attacker can trigger stack exhaustion in build_model via a large nesting depth in the DTD element.",
        "target": 1
      },
      {
        "idx": 205732,
        "reasoning": "This code is vulnerable because it lacks proper validation of UTF-8 encoding, potentially allowing crafted input to bypass intended parsing logic and lead to unexpected behavior or crashes. Specifically, the code doesn't fully verify the validity of multi-byte UTF-8 characters within various contexts, as highlighted by the CVE description, leading to potential parsing errors or security vulnerabilities.",
        "func": "PREFIX(prologTok)(const ENCODING *enc, const char *ptr, const char *end,\n                  const char **nextTokPtr) {\n  int tok;\n  if (ptr >= end)\n    return XML_TOK_NONE;\n  if (MINBPC(enc) > 1) {\n    size_t n = end - ptr;\n    if (n & (MINBPC(enc) - 1)) {\n      n &= ~(MINBPC(enc) - 1);\n      if (n == 0)\n        return XML_TOK_PARTIAL;\n      end = ptr + n;\n    }\n  }\n  switch (BYTE_TYPE(enc, ptr)) {\n  case BT_QUOT:\n    return PREFIX(scanLit)(BT_QUOT, enc, ptr + MINBPC(enc), end, nextTokPtr);\n  case BT_APOS:\n    return PREFIX(scanLit)(BT_APOS, enc, ptr + MINBPC(enc), end, nextTokPtr);\n  case BT_LT: {\n    ptr += MINBPC(enc);\n    REQUIRE_CHAR(enc, ptr, end);\n    switch (BYTE_TYPE(enc, ptr)) {\n    case BT_EXCL:\n      return PREFIX(scanDecl)(enc, ptr + MINBPC(enc), end, nextTokPtr);\n    case BT_QUEST:\n      return PREFIX(scanPi)(enc, ptr + MINBPC(enc), end, nextTokPtr);\n    case BT_NMSTRT:\n    case BT_HEX:\n    case BT_NONASCII:\n    case BT_LEAD2:\n    case BT_LEAD3:\n    case BT_LEAD4:\n      *nextTokPtr = ptr - MINBPC(enc);\n      return XML_TOK_INSTANCE_START;\n    }\n    *nextTokPtr = ptr;\n    return XML_TOK_INVALID;\n  }\n  case BT_CR:\n    if (ptr + MINBPC(enc) == end) {\n      *nextTokPtr = end;\n      /* indicate that this might be part of a CR/LF pair */\n      return -XML_TOK_PROLOG_S;\n    }\n    /* fall through */\n  case BT_S:\n  case BT_LF:\n    for (;;) {\n      ptr += MINBPC(enc);\n      if (! HAS_CHAR(enc, ptr, end))\n        break;\n      switch (BYTE_TYPE(enc, ptr)) {\n      case BT_S:\n      case BT_LF:\n        break;\n      case BT_CR:\n        /* don't split CR/LF pair */\n        if (ptr + MINBPC(enc) != end)\n          break;\n        /* fall through */\n      default:\n        *nextTokPtr = ptr;\n        return XML_TOK_PROLOG_S;\n      }\n    }\n    *nextTokPtr = ptr;\n    return XML_TOK_PROLOG_S;\n  case BT_PERCNT:\n    return PREFIX(scanPercent)(enc, ptr + MINBPC(enc), end, nextTokPtr);\n  case BT_COMMA:\n    *nextTokPtr = ptr + MINBPC(enc);\n    return XML_TOK_COMMA;\n  case BT_LSQB:\n    *nextTokPtr = ptr + MINBPC(enc);\n    return XML_TOK_OPEN_BRACKET;\n  case BT_RSQB:\n    ptr += MINBPC(enc);\n    if (! HAS_CHAR(enc, ptr, end))\n      return -XML_TOK_CLOSE_BRACKET;\n    if (CHAR_MATCHES(enc, ptr, ASCII_RSQB)) {\n      REQUIRE_CHARS(enc, ptr, end, 2);\n      if (CHAR_MATCHES(enc, ptr + MINBPC(enc), ASCII_GT)) {\n        *nextTokPtr = ptr + 2 * MINBPC(enc);\n        return XML_TOK_COND_SECT_CLOSE;\n      }\n    }\n    *nextTokPtr = ptr;\n    return XML_TOK_CLOSE_BRACKET;\n  case BT_LPAR:\n    *nextTokPtr = ptr + MINBPC(enc);\n    return XML_TOK_OPEN_PAREN;\n  case BT_RPAR:\n    ptr += MINBPC(enc);\n    if (! HAS_CHAR(enc, ptr, end))\n      return -XML_TOK_CLOSE_PAREN;\n    switch (BYTE_TYPE(enc, ptr)) {\n    case BT_AST:\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_CLOSE_PAREN_ASTERISK;\n    case BT_QUEST:\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_CLOSE_PAREN_QUESTION;\n    case BT_PLUS:\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_CLOSE_PAREN_PLUS;\n    case BT_CR:\n    case BT_LF:\n    case BT_S:\n    case BT_GT:\n    case BT_COMMA:\n    case BT_VERBAR:\n    case BT_RPAR:\n      *nextTokPtr = ptr;\n      return XML_TOK_CLOSE_PAREN;\n    }\n    *nextTokPtr = ptr;\n    return XML_TOK_INVALID;\n  case BT_VERBAR:\n    *nextTokPtr = ptr + MINBPC(enc);\n    return XML_TOK_OR;\n  case BT_GT:\n    *nextTokPtr = ptr + MINBPC(enc);\n    return XML_TOK_DECL_CLOSE;\n  case BT_NUM:\n    return PREFIX(scanPoundName)(enc, ptr + MINBPC(enc), end, nextTokPtr);\n#  define LEAD_CASE(n)                                                         \\\n  case BT_LEAD##n:                                                             \\\n    if (end - ptr < n)                                                         \\\n      return XML_TOK_PARTIAL_CHAR;                                             \\\n    if (IS_NMSTRT_CHAR(enc, ptr, n)) {                                         \\\n      ptr += n;                                                                \\\n      tok = XML_TOK_NAME;                                                      \\\n      break;                                                                   \\\n    }                                                                          \\\n    if (IS_NAME_CHAR(enc, ptr, n)) {                                           \\\n      ptr += n;                                                                \\\n      tok = XML_TOK_NMTOKEN;                                                   \\\n      break;                                                                   \\\n    }                                                                          \\\n    *nextTokPtr = ptr;                                                         \\\n    return XML_TOK_INVALID;\n    LEAD_CASE(2)\n    LEAD_CASE(3)\n    LEAD_CASE(4)\n#  undef LEAD_CASE\n  case BT_NMSTRT:\n  case BT_HEX:\n    tok = XML_TOK_NAME;\n    ptr += MINBPC(enc);\n    break;\n  case BT_DIGIT:\n  case BT_NAME:\n  case BT_MINUS:\n#  ifdef XML_NS\n  case BT_COLON:\n#  endif\n    tok = XML_TOK_NMTOKEN;\n    ptr += MINBPC(enc);\n    break;\n  case BT_NONASCII:\n    if (IS_NMSTRT_CHAR_MINBPC(enc, ptr)) {\n      ptr += MINBPC(enc);\n      tok = XML_TOK_NAME;\n      break;\n    }\n    if (IS_NAME_CHAR_MINBPC(enc, ptr)) {\n      ptr += MINBPC(enc);\n      tok = XML_TOK_NMTOKEN;\n      break;\n    }\n    /* fall through */\n  default:\n    *nextTokPtr = ptr;\n    return XML_TOK_INVALID;\n  }\n  while (HAS_CHAR(enc, ptr, end)) {\n    switch (BYTE_TYPE(enc, ptr)) {\n      CHECK_NAME_CASES(enc, ptr, end, nextTokPtr)\n    case BT_GT:\n    case BT_RPAR:\n    case BT_COMMA:\n    case BT_VERBAR:\n    case BT_LSQB:\n    case BT_PERCNT:\n    case BT_S:\n    case BT_CR:\n    case BT_LF:\n      *nextTokPtr = ptr;\n      return tok;\n#  ifdef XML_NS\n    case BT_COLON:\n      ptr += MINBPC(enc);\n      switch (tok) {\n      case XML_TOK_NAME:\n        REQUIRE_CHAR(enc, ptr, end);\n        tok = XML_TOK_PREFIXED_NAME;\n        switch (BYTE_TYPE(enc, ptr)) {\n          CHECK_NAME_CASES(enc, ptr, end, nextTokPtr)\n        default:\n          tok = XML_TOK_NMTOKEN;\n          break;\n        }\n        break;\n      case XML_TOK_PREFIXED_NAME:\n        tok = XML_TOK_NMTOKEN;\n        break;\n      }\n      break;\n#  endif\n    case BT_PLUS:\n      if (tok == XML_TOK_NMTOKEN) {\n        *nextTokPtr = ptr;\n        return XML_TOK_INVALID;\n      }\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_NAME_PLUS;\n    case BT_AST:\n      if (tok == XML_TOK_NMTOKEN) {\n        *nextTokPtr = ptr;\n        return XML_TOK_INVALID;\n      }\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_NAME_ASTERISK;\n    case BT_QUEST:\n      if (tok == XML_TOK_NMTOKEN) {\n        *nextTokPtr = ptr;\n        return XML_TOK_INVALID;\n      }\n      *nextTokPtr = ptr + MINBPC(enc);\n      return XML_TOK_NAME_QUESTION;\n    default:\n      *nextTokPtr = ptr;\n      return XML_TOK_INVALID;\n    }\n  }\n  return -tok;\n}",
        "commit_message": "lib: Add missing validation of encoding (CVE-2022-25235)",
        "cve_desc": "xmltok_impl.c in Expat (aka libexpat) before 2.4.5 lacks certain validation of encoding, such as checks for whether a UTF-8 character is valid in a certain context.",
        "target": 1
      }
    ]
  },
  "libfuse": {
    "0": [
      {
        "idx": 296307,
        "reasoning": "This code snippet is not vulnerable because it only handles opening the FUSE device and doesn't process mount options at all. The commit message addresses a potential issue in how `fusermount` *passes* options to the kernel, but this code doesn't participate in that process; it simply attempts to open `/dev/fuse`.\n\n\n\n",
        "func": "static int open_fuse_device(char **devp)\n{\n\tint fd = try_open_fuse_device(devp);\n\tif (fd >= -1)\n\t\treturn fd;\n\n\tfprintf(stderr,\n\t\t\"%s: fuse device not found, try 'modprobe fuse' first\\n\",\n\t\tprogname);\n\n\treturn -1;\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 0
      },
      {
        "idx": 296308,
        "reasoning": "This code is not vulnerable because the commit message explicitly states that while the old code *permitted* passing potentially problematic characters to the kernel, those characters are not actually interpreted as special by the kernel in this context. The fix simply prevents unnecessary and brittle parsing of escape characters where they aren't needed, rather than addressing a demonstrable exploitable flaw.\n\n\n\n",
        "func": "static int mount_notrunc(const char *source, const char *target,\n\t\t\t const char *filesystemtype, unsigned long mountflags,\n\t\t\t const char *data) {\n\tif (strlen(data) > sysconf(_SC_PAGESIZE) - 1) {\n\t\tfprintf(stderr, \"%s: mount options too long\\n\", progname);\n\t\terrno = EINVAL;\n\t\treturn -1;\n\t}\n\treturn mount(source, target, filesystemtype, mountflags, data);\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 0
      },
      {
        "idx": 296309,
        "reasoning": "This code is not vulnerable because the commit message explicitly states that while the old code *permitted* passing potentially problematic characters to the mount options, there are no FUSE mount options that actually interpret backslashes or commas in a way that could be exploited. The fix simply prevents unnecessary and potentially confusing interpretation of escape characters where they aren't needed, enhancing robustness rather than addressing a security flaw.\n\n\n\n",
        "func": "static int may_unmount(const char *mnt, int quiet)\n{\n\tstruct mntent *entp;\n\tFILE *fp;\n\tconst char *user = NULL;\n\tchar uidstr[32];\n\tunsigned uidlen = 0;\n\tint found;\n\tconst char *mtab = _PATH_MOUNTED;\n\n\tuser = get_user_name();\n\tif (user == NULL)\n\t\treturn -1;\n\n\tfp = setmntent(mtab, \"r\");\n\tif (fp == NULL) {\n\t\tfprintf(stderr, \"%s: failed to open %s: %s\\n\", progname, mtab,\n\t\t\tstrerror(errno));\n\t\treturn -1;\n\t}\n\n\tuidlen = sprintf(uidstr, \"%u\", getuid());\n\n\tfound = 0;\n\twhile ((entp = getmntent(fp)) != NULL) {\n\t\tif (!found && strcmp(entp->mnt_dir, mnt) == 0 &&\n\t\t    (strcmp(entp->mnt_type, \"fuse\") == 0 ||\n\t\t     strcmp(entp->mnt_type, \"fuseblk\") == 0 ||\n\t\t     strncmp(entp->mnt_type, \"fuse.\", 5) == 0 ||\n\t\t     strncmp(entp->mnt_type, \"fuseblk.\", 8) == 0)) {\n\t\t\tchar *p = strstr(entp->mnt_opts, \"user=\");\n\t\t\tif (p &&\n\t\t\t    (p == entp->mnt_opts || *(p-1) == ',') &&\n\t\t\t    strcmp(p + 5, user) == 0) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\t/* /etc/mtab is a link pointing to\n\t\t\t   /proc/mounts: */\n\t\t\telse if ((p =\n\t\t\t\t  strstr(entp->mnt_opts, \"user_id=\")) &&\n\t\t\t\t (p == entp->mnt_opts ||\n\t\t\t\t  *(p-1) == ',') &&\n\t\t\t\t strncmp(p + 8, uidstr, uidlen) == 0 &&\n\t\t\t\t (*(p+8+uidlen) == ',' ||\n\t\t\t\t  *(p+8+uidlen) == '\\0')) {\n\t\t\t\tfound = 1;\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\tendmntent(fp);\n\n\tif (!found) {\n\t\tif (!quiet)\n\t\t\tfprintf(stderr,\n\t\t\t\t\"%s: entry for %s not found in %s\\n\",\n\t\t\t\tprogname, mnt, mtab);\n\t\treturn -1;\n\t}\n\n\treturn 0;\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 0
      },
      {
        "idx": 296310,
        "reasoning": "This code snippet is not vulnerable because it only handles unmounting FUSE filesystems and doesn't process mount options at all\u2014the vulnerability lies in how `fusermount` *sets* those options, not how they are later used in unmounting. The commit message specifically addresses a parsing issue in `fusermount` related to escaped characters in mount options, which this `unmount_fuse` function doesn't interact with.\n\n\n\n",
        "func": "static int unmount_fuse(const char *mnt, int quiet, int lazy)\n{\n\t(void) quiet;\n\treturn fuse_mnt_umount(progname, mnt, mnt, lazy);\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 0
      },
      {
        "idx": 296311,
        "reasoning": "This code snippet is not vulnerable. The commit message addresses a potential issue in how mount options are parsed by `fusermount`, specifically preventing the interpretation of backslash-escaped commas, but the provided code focuses solely on privilege dropping and has no relation to mount option handling or parsing.\n\n\n\n",
        "func": "static void drop_privs(void)\n{\n\tif (getuid() != 0) {\n\t\toldfsuid = setfsuid(getuid());\n\t\toldfsgid = setfsgid(getgid());\n\t}\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 199987,
        "reasoning": "The code is vulnerable because it doesn't properly sanitize the mount options string, potentially allowing an attacker to bypass SELinux restrictions and enable the `allow_other` option even when `user_allow_other` is not set in the fuse configuration. Specifically, the code's handling of backslashes (though deemed ineffective for string values) demonstrates a lack of robust input validation, creating a pathway for option manipulation as highlighted in the CVE description.",
        "func": "static int do_mount(const char *mnt, char **typep, mode_t rootmode,\n\t\t    int fd, const char *opts, const char *dev, char **sourcep,\n\t\t    char **mnt_optsp)\n{\n\tint res;\n\tint flags = MS_NOSUID | MS_NODEV;\n\tchar *optbuf;\n\tchar *mnt_opts = NULL;\n\tconst char *s;\n\tchar *d;\n\tchar *fsname = NULL;\n\tchar *subtype = NULL;\n\tchar *source = NULL;\n\tchar *type = NULL;\n\tint blkdev = 0;\n\n\toptbuf = (char *) malloc(strlen(opts) + 128);\n\tif (!optbuf) {\n\t\tfprintf(stderr, \"%s: failed to allocate memory\\n\", progname);\n\t\treturn -1;\n\t}\n\n\tfor (s = opts, d = optbuf; *s;) {\n\t\tunsigned len;\n\t\tconst char *fsname_str = \"fsname=\";\n\t\tconst char *subtype_str = \"subtype=\";\n\t\tfor (len = 0; s[len]; len++) {\n\t\t\tif (s[len] == '\\\\' && s[len + 1])\n\t\t\t\tlen++;\n\t\t\telse if (s[len] == ',')\n\t\t\t\tbreak;\n\t\t}\n\t\tif (begins_with(s, fsname_str)) {\n\t\t\tif (!get_string_opt(s, len, fsname_str, &fsname))\n\t\t\t\tgoto err;\n\t\t} else if (begins_with(s, subtype_str)) {\n\t\t\tif (!get_string_opt(s, len, subtype_str, &subtype))\n\t\t\t\tgoto err;\n\t\t} else if (opt_eq(s, len, \"blkdev\")) {\n\t\t\tif (getuid() != 0) {\n\t\t\t\tfprintf(stderr,\n\t\t\t\t\t\"%s: option blkdev is privileged\\n\",\n\t\t\t\t\tprogname);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tblkdev = 1;\n\t\t} else if (opt_eq(s, len, \"auto_unmount\")) {\n\t\t\tauto_unmount = 1;\n\t\t} else if (!begins_with(s, \"fd=\") &&\n\t\t\t   !begins_with(s, \"rootmode=\") &&\n\t\t\t   !begins_with(s, \"user_id=\") &&\n\t\t\t   !begins_with(s, \"group_id=\")) {\n\t\t\tint on;\n\t\t\tint flag;\n\t\t\tint skip_option = 0;\n\t\t\tif (opt_eq(s, len, \"large_read\")) {\n\t\t\t\tstruct utsname utsname;\n\t\t\t\tunsigned kmaj, kmin;\n\t\t\t\tres = uname(&utsname);\n\t\t\t\tif (res == 0 &&\n\t\t\t\t    sscanf(utsname.release, \"%u.%u\",\n\t\t\t\t\t   &kmaj, &kmin) == 2 &&\n\t\t\t\t    (kmaj > 2 || (kmaj == 2 && kmin > 4))) {\n\t\t\t\t\tfprintf(stderr, \"%s: note: 'large_read' mount option is deprecated for %i.%i kernels\\n\", progname, kmaj, kmin);\n\t\t\t\t\tskip_option = 1;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (getuid() != 0 && !user_allow_other &&\n\t\t\t    (opt_eq(s, len, \"allow_other\") ||\n\t\t\t     opt_eq(s, len, \"allow_root\"))) {\n\t\t\t\tfprintf(stderr, \"%s: option %.*s only allowed if 'user_allow_other' is set in %s\\n\", progname, len, s, FUSE_CONF);\n\t\t\t\tgoto err;\n\t\t\t}\n\t\t\tif (!skip_option) {\n\t\t\t\tif (find_mount_flag(s, len, &on, &flag)) {\n\t\t\t\t\tif (on)\n\t\t\t\t\t\tflags |= flag;\n\t\t\t\t\telse\n\t\t\t\t\t\tflags  &= ~flag;\n\t\t\t\t} else {\n\t\t\t\t\tmemcpy(d, s, len);\n\t\t\t\t\td += len;\n\t\t\t\t\t*d++ = ',';\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\ts += len;\n\t\tif (*s)\n\t\t\ts++;\n\t}\n\t*d = '\\0';\n\tres = get_mnt_opts(flags, optbuf, &mnt_opts);\n\tif (res == -1)\n\t\tgoto err;\n\n\tsprintf(d, \"fd=%i,rootmode=%o,user_id=%u,group_id=%u\",\n\t\tfd, rootmode, getuid(), getgid());\n\n\tsource = malloc((fsname ? strlen(fsname) : 0) +\n\t\t\t(subtype ? strlen(subtype) : 0) + strlen(dev) + 32);\n\n\ttype = malloc((subtype ? strlen(subtype) : 0) + 32);\n\tif (!type || !source) {\n\t\tfprintf(stderr, \"%s: failed to allocate memory\\n\", progname);\n\t\tgoto err;\n\t}\n\n\tif (subtype)\n\t\tsprintf(type, \"%s.%s\", blkdev ? \"fuseblk\" : \"fuse\", subtype);\n\telse\n\t\tstrcpy(type, blkdev ? \"fuseblk\" : \"fuse\");\n\n\tif (fsname)\n\t\tstrcpy(source, fsname);\n\telse\n\t\tstrcpy(source, subtype ? subtype : dev);\n\n\tres = mount_notrunc(source, mnt, type, flags, optbuf);\n\tif (res == -1 && errno == ENODEV && subtype) {\n\t\t/* Probably missing subtype support */\n\t\tstrcpy(type, blkdev ? \"fuseblk\" : \"fuse\");\n\t\tif (fsname) {\n\t\t\tif (!blkdev)\n\t\t\t\tsprintf(source, \"%s#%s\", subtype, fsname);\n\t\t} else {\n\t\t\tstrcpy(source, type);\n\t\t}\n\n\t\tres = mount_notrunc(source, mnt, type, flags, optbuf);\n\t}\n\tif (res == -1 && errno == EINVAL) {\n\t\t/* It could be an old version not supporting group_id */\n\t\tsprintf(d, \"fd=%i,rootmode=%o,user_id=%u\",\n\t\t\tfd, rootmode, getuid());\n\t\tres = mount_notrunc(source, mnt, type, flags, optbuf);\n\t}\n\tif (res == -1) {\n\t\tint errno_save = errno;\n\t\tif (blkdev && errno == ENODEV && !fuse_mnt_check_fuseblk())\n\t\t\tfprintf(stderr, \"%s: 'fuseblk' support missing\\n\",\n\t\t\t\tprogname);\n\t\telse\n\t\t\tfprintf(stderr, \"%s: mount failed: %s\\n\", progname,\n\t\t\t\tstrerror(errno_save));\n\t\tgoto err;\n\t}\n\t*sourcep = source;\n\t*typep = type;\n\t*mnt_optsp = mnt_opts;\n\tfree(fsname);\n\tfree(optbuf);\n\n\treturn 0;\n\nerr:\n\tfree(fsname);\n\tfree(subtype);\n\tfree(source);\n\tfree(type);\n\tfree(mnt_opts);\n\tfree(optbuf);\n\treturn -1;\n}",
        "commit_message": "fusermount: don't feed \"escaped commas\" into mount options\n\nThe old code permits the following behavior:\n\n$ _FUSE_COMMFD=10000 priv_strace -etrace=mount -s200 fusermount -o 'foobar=\\,allow_other' mount\nmount(\"/dev/fuse\", \".\", \"fuse\", MS_NOSUID|MS_NODEV, \"foobar=\\\\,allow_other,fd=3,rootmode=40000,user_id=1000,group_id=1000\") = -1 EINVAL (Invalid argument)\n\nHowever, backslashes do not have any special meaning for the kernel here.\n\nAs it happens, you can't abuse this because there is no FUSE mount option\nthat takes a string value that can contain backslashes; but this is very\nbrittle. Don't interpret \"escape characters\" in places where they don't\nwork.",
        "cve_desc": "In fuse before versions 2.9.8 and 3.x before 3.2.5, fusermount is vulnerable to a restriction bypass when SELinux is active. This allows non-root users to mount a FUSE file system with the 'allow_other' mount option regardless of whether 'user_allow_other' is set in the fuse configuration. An attacker may use this flaw to mount a FUSE file system, accessible by other users, and trick them into accessing files on that file system, possibly causing Denial of Service or other unspecified effects.",
        "target": 1
      }
    ]
  },
  "libgcrypt": {
    "0": [
      {
        "idx": 293604,
        "reasoning": "This code snippet focuses on validating the RSA secret key components (p, q, e, d, u) and is not directly involved in the modular exponentiation process where the sliding window vulnerability exists. The commit message explicitly addresses a vulnerability in `rsa.c`'s `secret_core_crt` function related to modular exponentiation, while this code performs checks *after* key generation and doesn't perform the vulnerable operation itself.\n\n\n\n",
        "func": "stronger_key_check ( RSA_secret_key *skey )\n{\n  gcry_mpi_t t = mpi_alloc_secure ( 0 );\n  gcry_mpi_t t1 = mpi_alloc_secure ( 0 );\n  gcry_mpi_t t2 = mpi_alloc_secure ( 0 );\n  gcry_mpi_t phi = mpi_alloc_secure ( 0 );\n\n  /* check that n == p * q */\n  mpi_mul( t, skey->p, skey->q);\n  if (mpi_cmp( t, skey->n) )\n    log_info ( \"RSA Oops: n != p * q\\n\" );\n\n  /* check that p is less than q */\n  if( mpi_cmp( skey->p, skey->q ) > 0 )\n    {\n      log_info (\"RSA Oops: p >= q - fixed\\n\");\n      _gcry_mpi_swap ( skey->p, skey->q);\n    }\n\n    /* check that e divides neither p-1 nor q-1 */\n    mpi_sub_ui(t, skey->p, 1 );\n    mpi_fdiv_r(t, t, skey->e );\n    if ( !mpi_cmp_ui( t, 0) )\n        log_info ( \"RSA Oops: e divides p-1\\n\" );\n    mpi_sub_ui(t, skey->q, 1 );\n    mpi_fdiv_r(t, t, skey->e );\n    if ( !mpi_cmp_ui( t, 0) )\n        log_info ( \"RSA Oops: e divides q-1\\n\" );\n\n    /* check that d is correct */\n    mpi_sub_ui( t1, skey->p, 1 );\n    mpi_sub_ui( t2, skey->q, 1 );\n    mpi_mul( phi, t1, t2 );\n    gcry_mpi_gcd(t, t1, t2);\n    mpi_fdiv_q(t, phi, t);\n    mpi_invm(t, skey->e, t );\n    if ( mpi_cmp(t, skey->d ) )\n      {\n        log_info ( \"RSA Oops: d is wrong - fixed\\n\");\n        mpi_set (skey->d, t);\n        log_printmpi (\"  fixed d\", skey->d);\n      }\n\n    /* check for correctness of u */\n    mpi_invm(t, skey->p, skey->q );\n    if ( mpi_cmp(t, skey->u ) )\n      {\n        log_info ( \"RSA Oops: u is wrong - fixed\\n\");\n        mpi_set (skey->u, t);\n        log_printmpi (\"  fixed u\", skey->u);\n      }\n\n    log_info ( \"RSA secret key check finished\\n\");\n\n    mpi_free (t);\n    mpi_free (t1);\n    mpi_free (t2);\n    mpi_free (phi);\n}",
        "commit_message": "rsa: Add exponent blinding.\n\n* cipher/rsa.c (secret_core_crt): Blind secret D with randomized\nnonce R for mpi_powm computation.\n\n--\n\nCo-authored-by: Werner Koch <wk@gnupg.org>\nSigned-off-by: NIIBE Yutaka <gniibe@fsij.org>\n\nThe paper describing attack: https://eprint.iacr.org/2017/627\n\nSliding right into disaster: Left-to-right sliding windows leak\nby Daniel J. Bernstein and Joachim Breitner and Daniel Genkin and\nLeon Groot Bruinderink and Nadia Heninger and Tanja Lange and\nChristine van Vredendaal and Yuval Yarom\n\n  It is well known that constant-time implementations of modular\n  exponentiation cannot use sliding windows. However, software\n  libraries such as Libgcrypt, used by GnuPG, continue to use sliding\n  windows. It is widely believed that, even if the complete pattern of\n  squarings and multiplications is observed through a side-channel\n  attack, the number of exponent bits leaked is not sufficient to\n  carry out a full key-recovery attack against RSA. Specifically,\n  4-bit sliding windows leak only 40% of the bits, and 5-bit sliding\n  windows leak only 33% of the bits.\n\n  In this paper we demonstrate a complete break of RSA-1024 as\n  implemented in Libgcrypt. Our attack makes essential use of the fact\n  that Libgcrypt uses the left-to-right method for computing the\n  sliding-window expansion. We show for the first time that the\n  direction of the encoding matters: the pattern of squarings and\n  multiplications in left-to-right sliding windows leaks significantly\n  more information about exponent bits than for right-to-left. We show\n  how to incorporate this additional information into the\n  Heninger-Shacham algorithm for partial key reconstruction, and use\n  it to obtain very efficient full key recovery for RSA-1024. We also\n  provide strong evidence that the same attack works for RSA-2048 with\n  only moderately more computation.\n\nExponent blinding is a kind of workaround to add noise.  Signal (leak)\nis still there for non-constant-time implementation.",
        "cve_desc": "libgcrypt before version 1.7.8 is vulnerable to a cache side-channel attack resulting into a complete break of RSA-1024 while using the left-to-right method for computing the sliding-window expansion. The same attack is believed to work on RSA-2048 with moderately more computation. This side-channel requires that attacker can run arbitrary software on the hardware where the private RSA key is used.",
        "target": 0
      },
      {
        "idx": 293606,
        "reasoning": "This code snippet itself isn't directly vulnerable, but it's a part of a system (libgcrypt's RSA implementation) that *was* vulnerable to a side-channel attack as described in the linked paper. The commit message explicitly states the change\u2014exponent blinding\u2014is a mitigation for that previously identified vulnerability, aiming to add noise and reduce information leakage during modular exponentiation.\n\n\n\n",
        "func": "secret (gcry_mpi_t output, gcry_mpi_t input, RSA_secret_key *skey )\n{\n  /* Remove superfluous leading zeroes from INPUT.  */\n  mpi_normalize (input);\n\n  if (!skey->p || !skey->q || !skey->u)\n    {\n      secret_core_std (output, input, skey->d, skey->n);\n    }\n  else\n    {\n      secret_core_crt (output, input, skey->d, mpi_get_nlimbs (skey->n),\n                       skey->p, skey->q, skey->u);\n    }\n}",
        "commit_message": "rsa: Add exponent blinding.\n\n* cipher/rsa.c (secret_core_crt): Blind secret D with randomized\nnonce R for mpi_powm computation.\n\n--\n\nCo-authored-by: Werner Koch <wk@gnupg.org>\nSigned-off-by: NIIBE Yutaka <gniibe@fsij.org>\n\nThe paper describing attack: https://eprint.iacr.org/2017/627\n\nSliding right into disaster: Left-to-right sliding windows leak\nby Daniel J. Bernstein and Joachim Breitner and Daniel Genkin and\nLeon Groot Bruinderink and Nadia Heninger and Tanja Lange and\nChristine van Vredendaal and Yuval Yarom\n\n  It is well known that constant-time implementations of modular\n  exponentiation cannot use sliding windows. However, software\n  libraries such as Libgcrypt, used by GnuPG, continue to use sliding\n  windows. It is widely believed that, even if the complete pattern of\n  squarings and multiplications is observed through a side-channel\n  attack, the number of exponent bits leaked is not sufficient to\n  carry out a full key-recovery attack against RSA. Specifically,\n  4-bit sliding windows leak only 40% of the bits, and 5-bit sliding\n  windows leak only 33% of the bits.\n\n  In this paper we demonstrate a complete break of RSA-1024 as\n  implemented in Libgcrypt. Our attack makes essential use of the fact\n  that Libgcrypt uses the left-to-right method for computing the\n  sliding-window expansion. We show for the first time that the\n  direction of the encoding matters: the pattern of squarings and\n  multiplications in left-to-right sliding windows leaks significantly\n  more information about exponent bits than for right-to-left. We show\n  how to incorporate this additional information into the\n  Heninger-Shacham algorithm for partial key reconstruction, and use\n  it to obtain very efficient full key recovery for RSA-1024. We also\n  provide strong evidence that the same attack works for RSA-2048 with\n  only moderately more computation.\n\nExponent blinding is a kind of workaround to add noise.  Signal (leak)\nis still there for non-constant-time implementation.",
        "cve_desc": "libgcrypt before version 1.7.8 is vulnerable to a cache side-channel attack resulting into a complete break of RSA-1024 while using the left-to-right method for computing the sliding-window expansion. The same attack is believed to work on RSA-2048 with moderately more computation. This side-channel requires that attacker can run arbitrary software on the hardware where the private RSA key is used.",
        "target": 0
      },
      {
        "idx": 293610,
        "reasoning": "This code *is* likely mitigating the vulnerability described in the linked paper by implementing exponent blinding. While the commit message acknowledges blinding adds noise but doesn't eliminate the signal entirely, it directly addresses the left-to-right sliding window attack by randomizing the exponent, making key recovery significantly harder even with side-channel observations.\n\n\n\n",
        "func": "secret_core_crt (gcry_mpi_t M, gcry_mpi_t C,\n                 gcry_mpi_t D, unsigned int Nlimbs,\n                 gcry_mpi_t P, gcry_mpi_t Q, gcry_mpi_t U)\n{\n  gcry_mpi_t m1 = mpi_alloc_secure ( Nlimbs + 1 );\n  gcry_mpi_t m2 = mpi_alloc_secure ( Nlimbs + 1 );\n  gcry_mpi_t h  = mpi_alloc_secure ( Nlimbs + 1 );\n  gcry_mpi_t D_blind = mpi_alloc_secure ( Nlimbs + 1 );\n  gcry_mpi_t r;\n  unsigned int r_nbits;\n\n  r_nbits = mpi_get_nbits (P) / 4;\n  if (r_nbits < 96)\n    r_nbits = 96;\n  r = mpi_alloc_secure ( (r_nbits + BITS_PER_MPI_LIMB-1)/BITS_PER_MPI_LIMB );\n\n  /* d_blind = (d mod (p-1)) + (p-1) * r            */\n  /* m1 = c ^ d_blind mod p */\n  _gcry_mpi_randomize (r, r_nbits, GCRY_WEAK_RANDOM);\n  mpi_set_highbit (r, r_nbits - 1);\n  mpi_sub_ui ( h, P, 1 );\n  mpi_mul ( D_blind, h, r );\n  mpi_fdiv_r ( h, D, h );\n  mpi_add ( D_blind, D_blind, h );\n  mpi_powm ( m1, C, D_blind, P );\n\n  /* d_blind = (d mod (q-1)) + (q-1) * r            */\n  /* m2 = c ^ d_blind mod q */\n  _gcry_mpi_randomize (r, r_nbits, GCRY_WEAK_RANDOM);\n  mpi_set_highbit (r, r_nbits - 1);\n  mpi_sub_ui ( h, Q, 1  );\n  mpi_mul ( D_blind, h, r );\n  mpi_fdiv_r ( h, D, h );\n  mpi_add ( D_blind, D_blind, h );\n  mpi_powm ( m2, C, D_blind, Q );\n\n  mpi_free ( r );\n  mpi_free ( D_blind );\n\n  /* h = u * ( m2 - m1 ) mod q */\n  mpi_sub ( h, m2, m1 );\n  if ( mpi_has_sign ( h ) )\n    mpi_add ( h, h, Q );\n  mpi_mulm ( h, U, h, Q );\n\n  /* m = m1 + h * p */\n  mpi_mul ( h, h, P );\n  mpi_add ( M, m1, h );\n\n  mpi_free ( h );\n  mpi_free ( m1 );\n  mpi_free ( m2 );\n}",
        "commit_message": "rsa: Add exponent blinding.\n\n* cipher/rsa.c (secret_core_crt): Blind secret D with randomized\nnonce R for mpi_powm computation.\n\n--\n\nCo-authored-by: Werner Koch <wk@gnupg.org>\nSigned-off-by: NIIBE Yutaka <gniibe@fsij.org>\n\nThe paper describing attack: https://eprint.iacr.org/2017/627\n\nSliding right into disaster: Left-to-right sliding windows leak\nby Daniel J. Bernstein and Joachim Breitner and Daniel Genkin and\nLeon Groot Bruinderink and Nadia Heninger and Tanja Lange and\nChristine van Vredendaal and Yuval Yarom\n\n  It is well known that constant-time implementations of modular\n  exponentiation cannot use sliding windows. However, software\n  libraries such as Libgcrypt, used by GnuPG, continue to use sliding\n  windows. It is widely believed that, even if the complete pattern of\n  squarings and multiplications is observed through a side-channel\n  attack, the number of exponent bits leaked is not sufficient to\n  carry out a full key-recovery attack against RSA. Specifically,\n  4-bit sliding windows leak only 40% of the bits, and 5-bit sliding\n  windows leak only 33% of the bits.\n\n  In this paper we demonstrate a complete break of RSA-1024 as\n  implemented in Libgcrypt. Our attack makes essential use of the fact\n  that Libgcrypt uses the left-to-right method for computing the\n  sliding-window expansion. We show for the first time that the\n  direction of the encoding matters: the pattern of squarings and\n  multiplications in left-to-right sliding windows leaks significantly\n  more information about exponent bits than for right-to-left. We show\n  how to incorporate this additional information into the\n  Heninger-Shacham algorithm for partial key reconstruction, and use\n  it to obtain very efficient full key recovery for RSA-1024. We also\n  provide strong evidence that the same attack works for RSA-2048 with\n  only moderately more computation.\n\nExponent blinding is a kind of workaround to add noise.  Signal (leak)\nis still there for non-constant-time implementation.",
        "cve_desc": "libgcrypt before version 1.7.8 is vulnerable to a cache side-channel attack resulting into a complete break of RSA-1024 while using the left-to-right method for computing the sliding-window expansion. The same attack is believed to work on RSA-2048 with moderately more computation. This side-channel requires that attacker can run arbitrary software on the hardware where the private RSA key is used.",
        "target": 0
      }
    ],
    "1": []
  },
  "libguestfs": {
    "0": [],
    "1": [
      {
        "idx": 209966,
        "reasoning": "The code is vulnerable to a double-free because `guestfs___free_string_list(lines)` is called when `lines[0]` is NULL (empty file), freeing the memory pointed to by `lines`. Subsequently, the function returns a duplicate of an empty string created with `safe_strdup`, but the original `lines` array, which still points to freed memory, is not properly handled, leading to a double-free if the caller attempts to free it. \n\n\n\n",
        "func": "guestfs___first_line_of_file (guestfs_h *g, const char *filename)\n{\n  CLEANUP_FREE char **lines = NULL; /* sic: not CLEANUP_FREE_STRING_LIST */\n  int64_t size;\n  char *ret;\n\n  /* Don't trust guestfs_head_n not to break with very large files.\n   * Check the file size is something reasonable first.\n   */\n  size = guestfs_filesize (g, filename);\n  if (size == -1)\n    /* guestfs_filesize failed and has already set error in handle */\n    return NULL;\n  if (size > MAX_SMALL_FILE_SIZE) {\n    error (g, _(\"size of %s is unreasonably large (%\" PRIi64 \" bytes)\"),\n           filename, size);\n    return NULL;\n  }\n\n  lines = guestfs_head_n (g, 1, filename);\n  if (lines == NULL)\n    return NULL;\n  if (lines[0] == NULL) {\n    guestfs___free_string_list (lines);\n    /* Empty file: Return an empty string as explained above. */\n    return safe_strdup (g, \"\");\n  }\n  /* lines[1] should be NULL because of '1' argument above ... */\n\n  ret = lines[0];               /* caller frees */\n\n  return ret;\n}",
        "commit_message": "inspection: Fix double-free when certain guest files are empty.\n\nThe following commit:\n\n  commit 5a3da366268825b26b470cde35658b67c1d11cd4\n  Author: Richard W.M. Jones <rjones@redhat.com>\n  Date:   Thu Jan 24 17:07:38 2013 +0000\n\n      inspect: Use CLEANUP_* macros in inspection code.\n\ncan cause a double-free along an error path when certain guest files\nare empty where we expected those files to contain at least one line.\n\nThis causes virt-inspector to crash when run on these guests.\n\nThe following is a test case which demonstrates the crash.\n`f20rawhidex64' is a Fedora guest, but with small adjustments to the\ntest you could use any Linux guest for this test.\n\n  $ qemu-img create -f qcow2 -b f20rawhidex64 /tmp/test.qcow2\n  Formatting '/tmp/test.qcow2', fmt=qcow2 size=21474836480 backing_file='f20rawhidex64' encryption=off cluster_size=65536 lazy_refcounts=off\n  $ guestfish -i -a /tmp/test.qcow2 -- rm /etc/redhat-release : touch /etc/redhat-release\n  $ virt-inspector /tmp/test.qcow2\n  *** glibc detected *** virt-inspector: double free or corruption (fasttop): 0x00007f18bc9925a0 ***\n  ======= Backtrace: =========\n  /lib64/libc.so.6(+0x34ecc7ca8e)[0x7f18b8e64a8e]\n  /lib64/libguestfs.so.0(+0x3f91898078)[0x7f18ba13c078]\n  /lib64/libguestfs.so.0(+0x3f91899761)[0x7f18ba13d761]\n  /lib64/libguestfs.so.0(+0x3f91896d12)[0x7f18ba13ad12]\n  /lib64/libguestfs.so.0(+0x3f91894140)[0x7f18ba138140]\n  /lib64/libguestfs.so.0(guestfs_inspect_os+0x35)[0x7f18ba0bcc35]\n  virt-inspector(main+0x547)[0x7f18ba7c57d7]\n  /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f18b8e09a05]\n  virt-inspector(+0x6665)[0x7f18ba7c7665]\n\nThis is a denial of service, but not likely to be exploitable.\n\n(Found by Coverity)",
        "cve_desc": "Double free vulnerability in inspect-fs.c in LibguestFS 1.20.x before 1.20.7, 1.21.x, 1.22.0, and 1.23.0 allows remote attackers to cause a denial of service (crash) via empty guest files.",
        "target": 1
      }
    ]
  },
  "libiec61850": {
    "0": [
      {
        "idx": 232208,
        "reasoning": "This code is likely safe, as the commit message explicitly states a *fixed* vulnerability\u2014meaning the issue was addressed before potentially being exploitable. The code includes a length check (`len < 6`) ensuring the buffer is at least the minimum size required to access the necessary fields, preventing out-of-bounds reads based on the described fix for a zero-length field.",
        "func": "parseConnectRequestTpdu(CotpConnection* self, uint8_t* buffer, uint8_t len)\n{\n    if (len < 6)\n        return false;\n\n    self->remoteRef = getUint16(buffer + 2);\n    self->protocolClass = getUint8(buffer + 4);\n\n    return parseOptions(self, buffer + 5, len - 6);\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 0
      },
      {
        "idx": 232209,
        "reasoning": "This code is safe and the commit message accurately reflects a fix *elsewhere* in the codebase, not within this function. The `getOptionsLength` function calculates a length based on the *size* fields of structures, and these sizes are used in addition calculations \u2013 it doesn't directly handle external message lengths that could cause a buffer overflow, thus avoiding the vulnerability described in the commit message.\n\n\n\n",
        "func": "getOptionsLength(CotpConnection* self)\n{\n    int optionsLength = 0;\n\n    if (self->options.tpduSize != 0)\n        optionsLength += 3;\n\n    if (self->options.tSelDst.size != 0)\n        optionsLength += (2 + self->options.tSelDst.size);\n\n    if (self->options.tSelSrc.size != 0)\n        optionsLength += (2 + self->options.tSelSrc.size);\n\n    return optionsLength;\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 0
      },
      {
        "idx": 232210,
        "reasoning": "This code is safe and does not exhibit the heap buffer overflow vulnerability described in the commit message. The function explicitly checks if the input length (`len`) is equal to 2, and only proceeds with parsing if this condition is met, preventing any out-of-bounds read attempts based on a zero-length input. \n\n\n\n",
        "func": "parseDataTpdu(CotpConnection* self, uint8_t* buffer, uint8_t len)\n{\n    if (len != 2)\n        return false;\n\n    uint8_t flowControl = getUint8(buffer);\n\n    if (flowControl & 0x80)\n        self->isLastDataUnit = true;\n    else\n        self->isLastDataUnit = false;\n\n    return true;\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 0
      },
      {
        "idx": 232211,
        "reasoning": "This code is likely safe, as the commit message explicitly states a *fixed* heap buffer overflow in a different part of the COTP handling\u2014specifically when dealing with a zero-length field. The provided snippet calculates `conRequestSize` and checks if `self->writeBuffer->maxSize` is sufficient *before* writing any data, preventing a buffer overflow in this specific function.\n\n\n\n",
        "func": "CotpConnection_sendConnectionRequestMessage(CotpConnection* self, IsoConnectionParameters isoParameters)\n{\n    allocateWriteBuffer(self);\n\n    self->options.tSelDst = isoParameters->remoteTSelector;\n    self->options.tSelSrc = isoParameters->localTSelector;\n\n    int cotpRequestSize = getOptionsLength(self) + 6;\n\n    int conRequestSize = cotpRequestSize + 5;\n\n    if(self->writeBuffer->maxSize < conRequestSize)\n        return COTP_ERROR;\n\n    uint8_t* buffer = self->writeBuffer->buffer;\n\n    writeRfc1006Header(self, conRequestSize);\n\n    /* LI */\n    buffer[4] = (uint8_t) cotpRequestSize;\n\n    /* TPDU CODE */\n    buffer[5] = 0xe0;\n\n    /* DST REF */\n    buffer[6] = 0x00;\n    buffer[7] = 0x00;\n\n    /* SRC REF */\n    buffer[8] = (uint8_t) (self->localRef / 0x100);\n    buffer[9] = (uint8_t) (self->localRef & 0xff);\n\n    /* Class */\n    buffer[10] = 0x00;\n\n    self->writeBuffer->size = 11;\n\n    writeOptions(self);\n\n    if (sendBuffer(self))\n        return COTP_OK;\n    else\n        return COTP_ERROR;\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 0
      },
      {
        "idx": 232212,
        "reasoning": "This code is safe and does not exhibit the heap buffer overflow vulnerability described in the commit message. The code explicitly checks if adding `payloadLength` to the current `payload->size` would exceed `payload->maxSize`, preventing a write beyond the allocated buffer's boundaries\u2014thus mitigating the overflow risk.",
        "func": "addPayloadToBuffer(CotpConnection* self, uint8_t* buffer,  int payloadLength)\n{\n    if (payloadLength < 1) {\n        if (DEBUG_COTP)\n            printf(\"COTP: missing payload\\n\");\n\n        return false;\n    }\n\n    if (DEBUG_COTP)\n        printf(\"COTP: add to payload buffer (cur size: %i, len: %i)\\n\", self->payload->size, payloadLength);\n\n    if ((self->payload->size + payloadLength) > self->payload->maxSize)\n        return false;\n\n    memcpy(self->payload->buffer + self->payload->size, buffer, payloadLength);\n\n    self->payload->size += payloadLength;\n\n    return true;\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195728,
        "reasoning": "The code is vulnerable to a heap buffer overflow because it doesn't properly handle cases where `self->packetSize` is less than 4 after being calculated from the header. This allows an attacker to send a crafted packet with a small length value, causing a subsequent `readFromSocket` call to write beyond the allocated buffer size due to an integer underflow when calculating the number of bytes to read.",
        "func": "CotpConnection_readToTpktBuffer(CotpConnection* self)\n{\n    uint8_t* buffer = self->readBuffer->buffer;\n    int bufferSize = self->readBuffer->maxSize;\n    int bufPos = self->readBuffer->size;\n\n    assert (bufferSize > 4);\n\n    int readBytes;\n\n    if (bufPos < 4) {\n\n        readBytes = readFromSocket(self, buffer + bufPos, 4 - bufPos);\n\n        if (readBytes < 0)\n            goto exit_closed;\n\n        if (DEBUG_COTP) {\n            if (readBytes > 0)\n                printf(\"TPKT: read %i bytes from socket\\n\", readBytes);\n        }\n\n        bufPos += readBytes;\n\n        if (bufPos == 4) {\n            if ((buffer[0] == 3) && (buffer[1] == 0)) {\n                self->packetSize = (buffer[2] * 0x100) + buffer[3];\n\n                if (DEBUG_COTP)\n                    printf(\"TPKT: header complete (msg size = %i)\\n\", self->packetSize);\n\n                if (self->packetSize > bufferSize) {\n                    if (DEBUG_COTP) printf(\"TPKT: packet too large\\n\");\n                    goto exit_error;\n                }\n            }\n            else {\n                if (DEBUG_COTP) printf(\"TPKT: failed to decode TPKT header.\\n\");\n                goto exit_error;\n            }\n        }\n        else\n            goto exit_waiting;\n    }\n\n    readBytes = readFromSocket(self, buffer + bufPos, self->packetSize - bufPos);\n\n    if (readBytes < 0)\n        goto exit_closed;\n\n    bufPos += readBytes;\n\n    if (bufPos < self->packetSize)\n       goto exit_waiting;\n\n    if (DEBUG_COTP) printf(\"TPKT: message complete (size = %i)\\n\", self->packetSize);\n\n    self->readBuffer->size = bufPos;\n    return TPKT_PACKET_COMPLETE;\n\nexit_closed:\n    if (DEBUG_COTP) printf(\"TPKT: socket closed or socket error\\n\");\n    return TPKT_ERROR;\n\nexit_error:\n    if (DEBUG_COTP) printf(\"TPKT: Error parsing message\\n\");\n    return TPKT_ERROR;\n\nexit_waiting:\n\n    if (DEBUG_COTP)\n        if (bufPos != 0)\n            printf(\"TPKT: waiting (read %i of %i)\\n\", bufPos, self->packetSize);\n\n    self->readBuffer->size = bufPos;\n    return TPKT_WAITING;\n}",
        "commit_message": "- COTP: fixed possible heap buffer overflow when handling message with invalid (zero) value in length field (#250)",
        "cve_desc": "In libIEC61850 before version 1.4.3, when a message with COTP message length field with value < 4 is received an integer underflow will happen leading to heap buffer overflow. This can cause an application crash or on some platforms even the execution of remote code. If your application is used in open networks or there are untrusted nodes in the network it is highly recommend to apply the patch. This was patched with commit 033ab5b. Users of version 1.4.x should upgrade to version 1.4.3 when available. As a workaround changes of commit 033ab5b can be applied to older versions.",
        "target": 1
      }
    ]
  },
  "libjpeg-turbo": {
    "0": [
      {
        "idx": 77615,
        "reasoning": "This code snippet is not directly vulnerable because it only handles the initialization of a BMP source object and doesn't perform any calculations related to image dimensions or memory allocation where the overflow could occur. The vulnerability lies within `rdbmp.c` and `jmemmgr.c` as described in the commit message, not in the initialization routine shown here.\n\n\n\n",
        "func": "GLOBAL(cjpeg_source_ptr)\njinit_read_bmp(j_compress_ptr cinfo, boolean use_inversion_array)\n{\n  bmp_source_ptr source;\n\n  /* Create module interface object */\n  source = (bmp_source_ptr)\n    (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE,\n                                sizeof(bmp_source_struct));\n  source->cinfo = cinfo;        /* make back link for subroutines */\n  /* Fill in method ptrs, except get_pixel_rows which start_input sets */\n  source->pub.start_input = start_input_bmp;\n  source->pub.finish_input = finish_input_bmp;\n\n  source->use_inversion_array = use_inversion_array;\n\n  return (cjpeg_source_ptr)source;\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 0
      },
      {
        "idx": 77616,
        "reasoning": "This code snippet, `get_24bit_row`, is not directly vulnerable to the described integer overflow in `alloc_sarray`. The commit message details a vulnerability in row buffer allocation (`alloc_sarray`) within `rdbmp.c`, but this code focuses on *reading* pixel data into a buffer and doesn't perform any allocation that could be affected by a large `biWidth` value.\n\n\n\n",
        "func": "METHODDEF(JDIMENSION)\nget_24bit_row(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n/* This version is for reading 24-bit pixels */\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  JSAMPARRAY image_ptr;\n  register JSAMPROW inptr, outptr;\n  register JDIMENSION col;\n\n  if (source->use_inversion_array) {\n    /* Fetch next row from virtual array */\n    source->source_row--;\n    image_ptr = (*cinfo->mem->access_virt_sarray)\n      ((j_common_ptr)cinfo, source->whole_image,\n       source->source_row, (JDIMENSION)1, FALSE);\n    inptr = image_ptr[0];\n  } else {\n    if (!ReadOK(source->pub.input_file, source->iobuffer, source->row_width))\n      ERREXIT(cinfo, JERR_INPUT_EOF);\n    inptr = source->iobuffer;\n  }\n\n  /* Transfer data.  Note source values are in BGR order\n   * (even though Microsoft's own documents say the opposite).\n   */\n  outptr = source->pub.buffer[0];\n  if (cinfo->in_color_space == JCS_EXT_BGR) {\n    MEMCOPY(outptr, inptr, source->row_width);\n  } else if (cinfo->in_color_space == JCS_CMYK) {\n    for (col = cinfo->image_width; col > 0; col--) {\n      /* can omit GETJSAMPLE() safely */\n      JSAMPLE b = *inptr++, g = *inptr++, r = *inptr++;\n      rgb_to_cmyk(r, g, b, outptr, outptr + 1, outptr + 2, outptr + 3);\n      outptr += 4;\n    }\n  } else {\n    register int rindex = rgb_red[cinfo->in_color_space];\n    register int gindex = rgb_green[cinfo->in_color_space];\n    register int bindex = rgb_blue[cinfo->in_color_space];\n    register int aindex = alpha_index[cinfo->in_color_space];\n    register int ps = rgb_pixelsize[cinfo->in_color_space];\n\n    if (aindex >= 0) {\n      for (col = cinfo->image_width; col > 0; col--) {\n        outptr[bindex] = *inptr++;      /* can omit GETJSAMPLE() safely */\n        outptr[gindex] = *inptr++;\n        outptr[rindex] = *inptr++;\n        outptr[aindex] = 0xFF;\n        outptr += ps;\n      }\n    } else {\n      for (col = cinfo->image_width; col > 0; col--) {\n        outptr[bindex] = *inptr++;      /* can omit GETJSAMPLE() safely */\n        outptr[gindex] = *inptr++;\n        outptr[rindex] = *inptr++;\n        outptr += ps;\n      }\n    }\n  }\n\n  return 1;\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 0
      },
      {
        "idx": 77617,
        "reasoning": "This code snippet, while part of the `libjpeg-turbo` project that *had* a vulnerability in `rdbmp.c`, does not directly exhibit the described integer overflow issue. The vulnerability resided in the `alloc_sarray()` function called during row buffer allocation, not within the pixel data transfer logic of `get_32bit_row()`. \n\n\n\n",
        "func": "METHODDEF(JDIMENSION)\nget_32bit_row(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n/* This version is for reading 32-bit pixels */\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  JSAMPARRAY image_ptr;\n  register JSAMPROW inptr, outptr;\n  register JDIMENSION col;\n\n  if (source->use_inversion_array) {\n    /* Fetch next row from virtual array */\n    source->source_row--;\n    image_ptr = (*cinfo->mem->access_virt_sarray)\n      ((j_common_ptr)cinfo, source->whole_image,\n       source->source_row, (JDIMENSION)1, FALSE);\n    inptr = image_ptr[0];\n  } else {\n    if (!ReadOK(source->pub.input_file, source->iobuffer, source->row_width))\n      ERREXIT(cinfo, JERR_INPUT_EOF);\n    inptr = source->iobuffer;\n  }\n\n  /* Transfer data.  Note source values are in BGR order\n   * (even though Microsoft's own documents say the opposite).\n   */\n  outptr = source->pub.buffer[0];\n  if (cinfo->in_color_space == JCS_EXT_BGRX ||\n      cinfo->in_color_space == JCS_EXT_BGRA) {\n    MEMCOPY(outptr, inptr, source->row_width);\n  } else if (cinfo->in_color_space == JCS_CMYK) {\n    for (col = cinfo->image_width; col > 0; col--) {\n      /* can omit GETJSAMPLE() safely */\n      JSAMPLE b = *inptr++, g = *inptr++, r = *inptr++;\n      rgb_to_cmyk(r, g, b, outptr, outptr + 1, outptr + 2, outptr + 3);\n      inptr++;                          /* skip the 4th byte (Alpha channel) */\n      outptr += 4;\n    }\n  } else {\n    register int rindex = rgb_red[cinfo->in_color_space];\n    register int gindex = rgb_green[cinfo->in_color_space];\n    register int bindex = rgb_blue[cinfo->in_color_space];\n    register int aindex = alpha_index[cinfo->in_color_space];\n    register int ps = rgb_pixelsize[cinfo->in_color_space];\n\n    if (aindex >= 0) {\n      for (col = cinfo->image_width; col > 0; col--) {\n        outptr[bindex] = *inptr++;      /* can omit GETJSAMPLE() safely */\n        outptr[gindex] = *inptr++;\n        outptr[rindex] = *inptr++;\n        outptr[aindex] = *inptr++;\n        outptr += ps;\n      }\n    } else {\n      for (col = cinfo->image_width; col > 0; col--) {\n        outptr[bindex] = *inptr++;      /* can omit GETJSAMPLE() safely */\n        outptr[gindex] = *inptr++;\n        outptr[rindex] = *inptr++;\n        inptr++;                        /* skip the 4th byte (Alpha channel) */\n        outptr += ps;\n      }\n    }\n  }\n\n  return 1;\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 0
      },
      {
        "idx": 77618,
        "reasoning": "This code is not directly vulnerable to the described issue. The commit message details a potential integer overflow in `rdbmp.c` during row buffer allocation, but the provided code snippet from `preload_image` in `jdjpeg.c` only *reads* data into a pre-allocated buffer (`source->whole_image`) and doesn't perform the allocation itself, thus avoiding the overflow risk.\n\n\n\n",
        "func": "METHODDEF(JDIMENSION)\npreload_image(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  register FILE *infile = source->pub.input_file;\n  register JSAMPROW out_ptr;\n  JSAMPARRAY image_ptr;\n  JDIMENSION row;\n  cd_progress_ptr progress = (cd_progress_ptr)cinfo->progress;\n\n  /* Read the data into a virtual array in input-file row order. */\n  for (row = 0; row < cinfo->image_height; row++) {\n    if (progress != NULL) {\n      progress->pub.pass_counter = (long)row;\n      progress->pub.pass_limit = (long)cinfo->image_height;\n      (*progress->pub.progress_monitor) ((j_common_ptr)cinfo);\n    }\n    image_ptr = (*cinfo->mem->access_virt_sarray)\n      ((j_common_ptr)cinfo, source->whole_image, row, (JDIMENSION)1, TRUE);\n    out_ptr = image_ptr[0];\n    if (fread(out_ptr, 1, source->row_width, infile) != source->row_width) {\n      if (feof(infile))\n        ERREXIT(cinfo, JERR_INPUT_EOF);\n      else\n        ERREXIT(cinfo, JERR_FILE_READ);\n    }\n  }\n  if (progress != NULL)\n    progress->completed_extra_passes++;\n\n  /* Set up to read from the virtual array in top-to-bottom order */\n  switch (source->bits_per_pixel) {\n  case 8:\n    source->pub.get_pixel_rows = get_8bit_row;\n    break;\n  case 24:\n    source->pub.get_pixel_rows = get_24bit_row;\n    break;\n  case 32:\n    source->pub.get_pixel_rows = get_32bit_row;\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n  }\n  source->source_row = cinfo->image_height;\n\n  /* And read the first row */\n  return (*source->pub.get_pixel_rows) (cinfo, sinfo);\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 0
      },
      {
        "idx": 77619,
        "reasoning": "This code snippet, `finish_input_bmp`, is not vulnerable because it contains no logic related to image loading, memory allocation, or processing of BMP file data\u2014the areas identified as problematic in the commit message. The vulnerability lies within `rdbmp.c` and `jmemmgr.c` due to potential integer overflows during row buffer allocation, and this function doesn't participate in that process.\n\n\n\n",
        "func": "finish_input_bmp(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  /* no work */\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 4183,
        "reasoning": "This code is vulnerable to a heap-based buffer over-read because it directly uses color indices (`t`) from the input BMP file to access elements within the `colormap` array without validating that `t` is within the bounds of the colormap. If a crafted BMP contains color indices that exceed the size of the `colormap`, the code will attempt to read from memory outside the allocated buffer, leading to a crash or potentially exposing sensitive information.",
        "func": "METHODDEF(JDIMENSION)\nget_8bit_row(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n/* This version is for reading 8-bit colormap indexes */\n {\n   bmp_source_ptr source = (bmp_source_ptr)sinfo;\n   register JSAMPARRAY colormap = source->colormap;\n   JSAMPARRAY image_ptr;\n   register int t;\n   register JSAMPROW inptr, outptr;\n  register JDIMENSION col;\n\n  if (source->use_inversion_array) {\n    /* Fetch next row from virtual array */\n    source->source_row--;\n    image_ptr = (*cinfo->mem->access_virt_sarray)\n      ((j_common_ptr)cinfo, source->whole_image,\n       source->source_row, (JDIMENSION)1, FALSE);\n    inptr = image_ptr[0];\n  } else {\n    if (!ReadOK(source->pub.input_file, source->iobuffer, source->row_width))\n      ERREXIT(cinfo, JERR_INPUT_EOF);\n    inptr = source->iobuffer;\n  }\n\n  /* Expand the colormap indexes to real data */\n  outptr = source->pub.buffer[0];\n   if (cinfo->in_color_space == JCS_GRAYSCALE) {\n     for (col = cinfo->image_width; col > 0; col--) {\n       t = GETJSAMPLE(*inptr++);\n       *outptr++ = colormap[0][t];\n     }\n   } else if (cinfo->in_color_space == JCS_CMYK) {\n     for (col = cinfo->image_width; col > 0; col--) {\n       t = GETJSAMPLE(*inptr++);\n       rgb_to_cmyk(colormap[0][t], colormap[1][t], colormap[2][t], outptr,\n                   outptr + 1, outptr + 2, outptr + 3);\n       outptr += 4;\n    }\n  } else {\n    register int rindex = rgb_red[cinfo->in_color_space];\n    register int gindex = rgb_green[cinfo->in_color_space];\n    register int bindex = rgb_blue[cinfo->in_color_space];\n    register int aindex = alpha_index[cinfo->in_color_space];\n    register int ps = rgb_pixelsize[cinfo->in_color_space];\n\n     if (aindex >= 0) {\n       for (col = cinfo->image_width; col > 0; col--) {\n         t = GETJSAMPLE(*inptr++);\n         outptr[rindex] = colormap[0][t];\n         outptr[gindex] = colormap[1][t];\n         outptr[bindex] = colormap[2][t];\n        outptr[aindex] = 0xFF;\n        outptr += ps;\n      }\n     } else {\n       for (col = cinfo->image_width; col > 0; col--) {\n         t = GETJSAMPLE(*inptr++);\n         outptr[rindex] = colormap[0][t];\n         outptr[gindex] = colormap[1][t];\n         outptr[bindex] = colormap[2][t];\n        outptr += ps;\n      }\n    }\n  }\n\n  return 1;\n}\n",
        "commit_message": "cjpeg: Fix OOB read caused by malformed 8-bit BMP\n\n... in which one or more of the color indices is out of range for the\nnumber of palette entries.\n\nFix partly borrowed from jpeg-9c.  This commit also adopts Guido's\nJERR_PPM_OUTOFRANGE enum value in lieu of our project-specific\nJERR_PPM_TOOLARGE enum value.\n\nFixes #258",
        "cve_desc": "get_8bit_row in rdbmp.c in libjpeg-turbo through 1.5.90 and MozJPEG through 3.3.1 allows attackers to cause a denial of service (heap-based buffer over-read and application crash) via a crafted 8-bit BMP in which one or more of the color indices is out of range for the number of palette entries.",
        "target": 1
      },
      {
        "idx": 9584,
        "reasoning": "The code is vulnerable to a divide-by-zero error because the `biWidth` value from the BMP header, which can be up to 4294967295, is used to calculate `samplesperrow` without proper overflow checking, potentially wrapping around to zero. This zero value then leads to a division by zero error in `jmemmgr.c` when allocating memory, resulting in a denial of service.",
        "func": "start_input_bmp(j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  bmp_source_ptr source = (bmp_source_ptr)sinfo;\n  U_CHAR bmpfileheader[14];\n  U_CHAR bmpinfoheader[64];\n\n#define GET_2B(array, offset) \\\n  ((unsigned short)UCH(array[offset]) + \\\n   (((unsigned short)UCH(array[offset + 1])) << 8))\n#define GET_4B(array, offset) \\\n  ((unsigned int)UCH(array[offset]) + \\\n   (((unsigned int)UCH(array[offset + 1])) << 8) + \\\n   (((unsigned int)UCH(array[offset + 2])) << 16) + \\\n   (((unsigned int)UCH(array[offset + 3])) << 24))\n\n  unsigned int bfOffBits;\n  unsigned int headerSize;\n  int biWidth;\n  int biHeight;\n  unsigned short biPlanes;\n  unsigned int biCompression;\n  int biXPelsPerMeter, biYPelsPerMeter;\n  unsigned int biClrUsed = 0;\n  int mapentrysize = 0;         /* 0 indicates no colormap */\n  int bPad;\n  JDIMENSION row_width = 0;\n\n  /* Read and verify the bitmap file header */\n  if (!ReadOK(source->pub.input_file, bmpfileheader, 14))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  if (GET_2B(bmpfileheader, 0) != 0x4D42) /* 'BM' */\n    ERREXIT(cinfo, JERR_BMP_NOT);\n  bfOffBits = GET_4B(bmpfileheader, 10);\n  /* We ignore the remaining fileheader fields */\n\n  /* The infoheader might be 12 bytes (OS/2 1.x), 40 bytes (Windows),\n   * or 64 bytes (OS/2 2.x).  Check the first 4 bytes to find out which.\n   */\n  if (!ReadOK(source->pub.input_file, bmpinfoheader, 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n  headerSize = GET_4B(bmpinfoheader, 0);\n  if (headerSize < 12 || headerSize > 64)\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  if (!ReadOK(source->pub.input_file, bmpinfoheader + 4, headerSize - 4))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n\n  switch (headerSize) {\n  case 12:\n    /* Decode OS/2 1.x header (Microsoft calls this a BITMAPCOREHEADER) */\n    biWidth = (int)GET_2B(bmpinfoheader, 4);\n    biHeight = (int)GET_2B(bmpinfoheader, 6);\n    biPlanes = GET_2B(bmpinfoheader, 8);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 10);\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 3;         /* OS/2 uses RGBTRIPLE colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP_OS2, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    break;\n  case 40:\n  case 64:\n    /* Decode Windows 3.x header (Microsoft calls this a BITMAPINFOHEADER) */\n    /* or OS/2 2.x header, which has additional fields that we ignore */\n    biWidth = (int)GET_4B(bmpinfoheader, 4);\n    biHeight = (int)GET_4B(bmpinfoheader, 8);\n    biPlanes = GET_2B(bmpinfoheader, 12);\n    source->bits_per_pixel = (int)GET_2B(bmpinfoheader, 14);\n    biCompression = GET_4B(bmpinfoheader, 16);\n    biXPelsPerMeter = (int)GET_4B(bmpinfoheader, 24);\n    biYPelsPerMeter = (int)GET_4B(bmpinfoheader, 28);\n    biClrUsed = GET_4B(bmpinfoheader, 32);\n    /* biSizeImage, biClrImportant fields are ignored */\n\n    switch (source->bits_per_pixel) {\n    case 8:                     /* colormapped image */\n      mapentrysize = 4;         /* Windows uses RGBQUAD colormap */\n      TRACEMS2(cinfo, 1, JTRC_BMP_MAPPED, biWidth, biHeight);\n      break;\n    case 24:                    /* RGB image */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    case 32:                    /* RGB image + Alpha channel */\n      TRACEMS2(cinfo, 1, JTRC_BMP, biWidth, biHeight);\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n      break;\n    }\n    if (biCompression != 0)\n      ERREXIT(cinfo, JERR_BMP_COMPRESSED);\n\n    if (biXPelsPerMeter > 0 && biYPelsPerMeter > 0) {\n      /* Set JFIF density parameters from the BMP data */\n      cinfo->X_density = (UINT16)(biXPelsPerMeter / 100); /* 100 cm per meter */\n      cinfo->Y_density = (UINT16)(biYPelsPerMeter / 100);\n      cinfo->density_unit = 2;  /* dots/cm */\n    }\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n    return;\n  }\n\n  if (biWidth <= 0 || biHeight <= 0)\n    ERREXIT(cinfo, JERR_BMP_EMPTY);\n  if (biPlanes != 1)\n    ERREXIT(cinfo, JERR_BMP_BADPLANES);\n\n  /* Compute distance to bitmap data --- will adjust for colormap below */\n  bPad = bfOffBits - (headerSize + 14);\n\n  /* Read the colormap, if any */\n  if (mapentrysize > 0) {\n    if (biClrUsed <= 0)\n      biClrUsed = 256;          /* assume it's 256 */\n    else if (biClrUsed > 256)\n      ERREXIT(cinfo, JERR_BMP_BADCMAP);\n    /* Allocate space to store the colormap */\n    source->colormap = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, (JDIMENSION)biClrUsed, (JDIMENSION)3);\n    /* and read it from the file */\n    read_colormap(source, (int)biClrUsed, mapentrysize);\n    /* account for size of colormap */\n    bPad -= biClrUsed * mapentrysize;\n  }\n\n  /* Skip any remaining pad bytes */\n  if (bPad < 0)                 /* incorrect bfOffBits value? */\n    ERREXIT(cinfo, JERR_BMP_BADHEADER);\n  while (--bPad >= 0) {\n    (void)read_byte(source);\n  }\n\n  /* Compute row width in file, including padding to 4-byte boundary */\n  switch (source->bits_per_pixel) {\n  case 8:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_RGB;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_GRAYSCALE)\n      cinfo->input_components = 1;\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)biWidth;\n    break;\n  case 24:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGR;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 3);\n    break;\n  case 32:\n    if (cinfo->in_color_space == JCS_UNKNOWN)\n      cinfo->in_color_space = JCS_EXT_BGRA;\n    if (IsExtRGB(cinfo->in_color_space))\n      cinfo->input_components = rgb_pixelsize[cinfo->in_color_space];\n    else if (cinfo->in_color_space == JCS_CMYK)\n      cinfo->input_components = 4;\n    else\n      ERREXIT(cinfo, JERR_BAD_IN_COLORSPACE);\n    row_width = (JDIMENSION)(biWidth * 4);\n    break;\n  default:\n    ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n  }\n  while ((row_width & 3) != 0) row_width++;\n  source->row_width = row_width;\n\n  if (source->use_inversion_array) {\n    /* Allocate space for inversion array, prepare for preload pass */\n    source->whole_image = (*cinfo->mem->request_virt_sarray)\n      ((j_common_ptr)cinfo, JPOOL_IMAGE, FALSE,\n       row_width, (JDIMENSION)biHeight, (JDIMENSION)1);\n    source->pub.get_pixel_rows = preload_image;\n    if (cinfo->progress != NULL) {\n      cd_progress_ptr progress = (cd_progress_ptr)cinfo->progress;\n      progress->total_extra_passes++; /* count file input as separate pass */\n    }\n  } else {\n    source->iobuffer = (U_CHAR *)\n      (*cinfo->mem->alloc_small) ((j_common_ptr)cinfo, JPOOL_IMAGE, row_width);\n    switch (source->bits_per_pixel) {\n    case 8:\n      source->pub.get_pixel_rows = get_8bit_row;\n      break;\n    case 24:\n      source->pub.get_pixel_rows = get_24bit_row;\n      break;\n    case 32:\n      source->pub.get_pixel_rows = get_32bit_row;\n      break;\n    default:\n      ERREXIT(cinfo, JERR_BMP_BADDEPTH);\n     }\n   }\n \n   /* Allocate one-row buffer for returned data */\n   source->pub.buffer = (*cinfo->mem->alloc_sarray)\n     ((j_common_ptr)cinfo, JPOOL_IMAGE,\n     (JDIMENSION)(biWidth * cinfo->input_components), (JDIMENSION)1);\n  source->pub.buffer_height = 1;\n\n  cinfo->data_precision = 8;\n  cinfo->image_width = (JDIMENSION)biWidth;\n  cinfo->image_height = (JDIMENSION)biHeight;\n}\n",
        "commit_message": "tjLoadImage(): Fix FPE triggered by malformed BMP\n\nIn rdbmp.c, it is necessary to guard against 32-bit overflow/wraparound\nwhen allocating the row buffer, because since BMP files have 32-bit\nwidth and height fields, the value of biWidth can be up to 4294967295.\nSpecifically, if biWidth is 1073741824 and cinfo->input_components = 4,\nthen the samplesperrow argument in alloc_sarray() would wrap around to\n0, and a division by zero error would occur at line 458 in jmemmgr.c.\n\nIf biWidth is set to a higher value, then samplesperrow would wrap\naround to a small number, which would likely cause a buffer overflow\n(this has not been tested or verified.)",
        "cve_desc": "libjpeg-turbo 1.5.90 is vulnerable to a denial of service vulnerability caused by a divide by zero when processing a crafted BMP image.",
        "target": 1
      },
      {
        "idx": 202175,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow due to an integer overflow in the calculation of `pitch * (*height)` when allocating memory for `dstBuf`. A large BMP image can cause `pitch` and `*height` to be large enough that their product exceeds the maximum value of an `int`, leading to a smaller-than-expected allocation size and subsequent buffer overflow during the `memcpy` operation within the loop.",
        "func": "DLLEXPORT unsigned char *tjLoadImage(const char *filename, int *width,\n                                     int align, int *height, int *pixelFormat,\n                                     int flags)\n{\n  int retval = 0, tempc, pitch;\n  tjhandle handle = NULL;\n  tjinstance *this;\n  j_compress_ptr cinfo = NULL;\n  cjpeg_source_ptr src;\n  unsigned char *dstBuf = NULL;\n  FILE *file = NULL;\n  boolean invert;\n\n  if (!filename || !width || align < 1 || !height || !pixelFormat ||\n      *pixelFormat < TJPF_UNKNOWN || *pixelFormat >= TJ_NUMPF)\n    _throwg(\"tjLoadImage(): Invalid argument\");\n  if ((align & (align - 1)) != 0)\n    _throwg(\"tjLoadImage(): Alignment must be a power of 2\");\n\n  if ((handle = tjInitCompress()) == NULL) return NULL;\n  this = (tjinstance *)handle;\n  cinfo = &this->cinfo;\n\n  if ((file = fopen(filename, \"rb\")) == NULL)\n    _throwunix(\"tjLoadImage(): Cannot open input file\");\n\n  if ((tempc = getc(file)) < 0 || ungetc(tempc, file) == EOF)\n    _throwunix(\"tjLoadImage(): Could not read input file\")\n  else if (tempc == EOF)\n    _throwg(\"tjLoadImage(): Input file contains no data\");\n\n  if (setjmp(this->jerr.setjmp_buffer)) {\n    /* If we get here, the JPEG code has signaled an error. */\n    retval = -1;  goto bailout;\n  }\n\n  if (*pixelFormat == TJPF_UNKNOWN) cinfo->in_color_space = JCS_UNKNOWN;\n  else cinfo->in_color_space = pf2cs[*pixelFormat];\n  if (tempc == 'B') {\n    if ((src = jinit_read_bmp(cinfo, FALSE)) == NULL)\n      _throwg(\"tjLoadImage(): Could not initialize bitmap loader\");\n    invert = (flags & TJFLAG_BOTTOMUP) == 0;\n  } else if (tempc == 'P') {\n    if ((src = jinit_read_ppm(cinfo)) == NULL)\n      _throwg(\"tjLoadImage(): Could not initialize bitmap loader\");\n    invert = (flags & TJFLAG_BOTTOMUP) != 0;\n  } else\n    _throwg(\"tjLoadImage(): Unsupported file type\");\n\n  src->input_file = file;\n  (*src->start_input) (cinfo, src);\n  (*cinfo->mem->realize_virt_arrays) ((j_common_ptr)cinfo);\n\n  *width = cinfo->image_width;  *height = cinfo->image_height;\n  *pixelFormat = cs2pf[cinfo->in_color_space];\n\n  pitch = PAD((*width) * tjPixelSize[*pixelFormat], align);\n  if ((dstBuf = (unsigned char *)malloc(pitch * (*height))) == NULL)\n    _throwg(\"tjLoadImage(): Memory allocation failure\");\n\n  if (setjmp(this->jerr.setjmp_buffer)) {\n    /* If we get here, the JPEG code has signaled an error. */\n    retval = -1;  goto bailout;\n  }\n\n  while (cinfo->next_scanline < cinfo->image_height) {\n    int i, nlines = (*src->get_pixel_rows) (cinfo, src);\n\n    for (i = 0; i < nlines; i++) {\n      unsigned char *dstptr;\n      int row;\n\n      row = cinfo->next_scanline + i;\n      if (invert) dstptr = &dstBuf[((*height) - row - 1) * pitch];\n      else dstptr = &dstBuf[row * pitch];\n      memcpy(dstptr, src->buffer[i], (*width) * tjPixelSize[*pixelFormat]);\n    }\n    cinfo->next_scanline += nlines;\n  }\n\n  (*src->finish_input) (cinfo, src);\n\nbailout:\n  if (handle) tjDestroy(handle);\n  if (file) fclose(file);\n  if (retval < 0 && dstBuf) { free(dstBuf);  dstBuf = NULL; }\n  return dstBuf;\n}",
        "commit_message": "tjLoadImage(): Fix int overflow/segfault w/big BMP\n\nFixes #304",
        "cve_desc": "The tjLoadImage function in libjpeg-turbo 2.0.1 has an integer overflow with a resultant heap-based buffer overflow via a BMP image because multiplication of pitch and height is mishandled, as demonstrated by tjbench.",
        "target": 1
      },
      {
        "idx": 206557,
        "reasoning": "The code is vulnerable because it doesn't check if `width` or `height` are zero *before* allocating memory based on these values, potentially leading to a division by zero or other memory allocation errors as described in the CVE. Specifically, the `alloc_sarray` function is called with `width` and `height` as dimensions, and a zero value for either could trigger the vulnerability described in CVE-2023-27158.",
        "func": "start_input_tga (j_compress_ptr cinfo, cjpeg_source_ptr sinfo)\n{\n  tga_source_ptr source = (tga_source_ptr) sinfo;\n  U_CHAR targaheader[18];\n  int idlen, cmaptype, subtype, flags, interlace_type, components;\n  unsigned int width, height, maplen;\n  boolean is_bottom_up;\n\n#define GET_2B(offset)  ((unsigned int) UCH(targaheader[offset]) + \\\n                         (((unsigned int) UCH(targaheader[offset+1])) << 8))\n\n  if (! ReadOK(source->pub.input_file, targaheader, 18))\n    ERREXIT(cinfo, JERR_INPUT_EOF);\n\n  /* Pretend \"15-bit\" pixels are 16-bit --- we ignore attribute bit anyway */\n  if (targaheader[16] == 15)\n    targaheader[16] = 16;\n\n  idlen = UCH(targaheader[0]);\n  cmaptype = UCH(targaheader[1]);\n  subtype = UCH(targaheader[2]);\n  maplen = GET_2B(5);\n  width = GET_2B(12);\n  height = GET_2B(14);\n  source->pixel_size = UCH(targaheader[16]) >> 3;\n  flags = UCH(targaheader[17]); /* Image Descriptor byte */\n\n  is_bottom_up = ((flags & 0x20) == 0); /* bit 5 set => top-down */\n  interlace_type = flags >> 6;  /* bits 6/7 are interlace code */\n\n  if (cmaptype > 1 ||           /* cmaptype must be 0 or 1 */\n      source->pixel_size < 1 || source->pixel_size > 4 ||\n      (UCH(targaheader[16]) & 7) != 0 || /* bits/pixel must be multiple of 8 */\n      interlace_type != 0)      /* currently don't allow interlaced image */\n    ERREXIT(cinfo, JERR_TGA_BADPARMS);\n\n  if (subtype > 8) {\n    /* It's an RLE-coded file */\n    source->read_pixel = read_rle_pixel;\n    source->block_count = source->dup_pixel_count = 0;\n    subtype -= 8;\n  } else {\n    /* Non-RLE file */\n    source->read_pixel = read_non_rle_pixel;\n  }\n\n  /* Now should have subtype 1, 2, or 3 */\n  components = 3;               /* until proven different */\n  cinfo->in_color_space = JCS_RGB;\n\n  switch (subtype) {\n  case 1:                       /* Colormapped image */\n    if (source->pixel_size == 1 && cmaptype == 1)\n      source->get_pixel_rows = get_8bit_row;\n    else\n      ERREXIT(cinfo, JERR_TGA_BADPARMS);\n    TRACEMS2(cinfo, 1, JTRC_TGA_MAPPED, width, height);\n    break;\n  case 2:                       /* RGB image */\n    switch (source->pixel_size) {\n    case 2:\n      source->get_pixel_rows = get_16bit_row;\n      break;\n    case 3:\n      source->get_pixel_rows = get_24bit_row;\n      break;\n    case 4:\n      source->get_pixel_rows = get_32bit_row;\n      break;\n    default:\n      ERREXIT(cinfo, JERR_TGA_BADPARMS);\n      break;\n    }\n    TRACEMS2(cinfo, 1, JTRC_TGA, width, height);\n    break;\n  case 3:                       /* Grayscale image */\n    components = 1;\n    cinfo->in_color_space = JCS_GRAYSCALE;\n    if (source->pixel_size == 1)\n      source->get_pixel_rows = get_8bit_gray_row;\n    else\n      ERREXIT(cinfo, JERR_TGA_BADPARMS);\n    TRACEMS2(cinfo, 1, JTRC_TGA_GRAY, width, height);\n    break;\n  default:\n    ERREXIT(cinfo, JERR_TGA_BADPARMS);\n    break;\n  }\n\n  if (is_bottom_up) {\n    /* Create a virtual array to buffer the upside-down image. */\n    source->whole_image = (*cinfo->mem->request_virt_sarray)\n      ((j_common_ptr) cinfo, JPOOL_IMAGE, FALSE,\n       (JDIMENSION) width * components, (JDIMENSION) height, (JDIMENSION) 1);\n    if (cinfo->progress != NULL) {\n      cd_progress_ptr progress = (cd_progress_ptr) cinfo->progress;\n      progress->total_extra_passes++; /* count file input as separate pass */\n    }\n    /* source->pub.buffer will point to the virtual array. */\n    source->pub.buffer_height = 1; /* in case anyone looks at it */\n    source->pub.get_pixel_rows = preload_image;\n  } else {\n    /* Don't need a virtual array, but do need a one-row input buffer. */\n    source->whole_image = NULL;\n    source->pub.buffer = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr) cinfo, JPOOL_IMAGE,\n       (JDIMENSION) width * components, (JDIMENSION) 1);\n    source->pub.buffer_height = 1;\n    source->pub.get_pixel_rows = source->get_pixel_rows;\n  }\n\n  while (idlen--)               /* Throw away ID field */\n    (void) read_byte(source);\n\n  if (maplen > 0) {\n    if (maplen > 256 || GET_2B(3) != 0)\n      ERREXIT(cinfo, JERR_TGA_BADCMAP);\n    /* Allocate space to store the colormap */\n    source->colormap = (*cinfo->mem->alloc_sarray)\n      ((j_common_ptr) cinfo, JPOOL_IMAGE, (JDIMENSION) maplen, (JDIMENSION) 3);\n    /* and read it from the file */\n    read_colormap(source, (int) maplen, UCH(targaheader[7]));\n  } else {\n    if (cmaptype)               /* but you promised a cmap! */\n      ERREXIT(cinfo, JERR_TGA_BADPARMS);\n    source->colormap = NULL;\n  }\n\n  cinfo->input_components = components;\n  cinfo->data_precision = 8;\n  cinfo->image_width = width;\n  cinfo->image_height = height;\n}",
        "commit_message": "Check image size when reading targa file\n\nThrow an error when image width or height is 0.\n\nFixes mozilla/mozjpeg#140, closes #7.",
        "cve_desc": "An issue was discovered in libjpeg 9a and 9d. The alloc_sarray function in jmemmgr.c allows remote attackers to cause a denial of service (divide-by-zero error) via a crafted file.",
        "target": 1
      }
    ]
  },
  "libming": {
    "0": [
      {
        "idx": 264416,
        "reasoning": "This code snippet appears safe because it primarily involves pushing a new variable onto a stack using values derived from popped parameters\u2014specifically, an integer value `nparam->p.Integer` used within the array index. There's no direct manipulation of memory buffers with externally controlled sizes that would indicate a heap buffer overflow or underflow vulnerability, and the `maxn` parameter isn't used in a way that presents a risk in this specific function.\n\n\n\n",
        "func": "decompileINITARRAY(int n, SWF_ACTION *actions, int maxn)\n{\n\tstruct SWF_ACTIONPUSHPARAM *nparam;\n\tnparam=pop();\n\tpush(newVar_N(\"\",\"\",\"\",\"[\", nparam->p.Integer,\"]\"));\n\treturn 0;\n}",
        "commit_message": "decompileAction: Prevent heap buffer overflow and underflow with using OpCode",
        "cve_desc": "Ming (aka libming) 0.4.8 has a heap buffer overflow and underflow in the decompileCAST function in util/decompile.c in libutil.a. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted SWF file.",
        "target": 0
      },
      {
        "idx": 264418,
        "reasoning": "This code snippet is not directly vulnerable to a heap buffer overflow or underflow based on the provided information. The function simply initializes a `strbufinfo` structure with existing variables (`strsize`, `strmaxsize`, `dcstr`, `dcptr`) and then calls `dcinit()`, without performing any operations that could write beyond allocated memory boundaries within the function itself. \n\n\n\n",
        "func": "static struct strbufinfo setTempString(void)\n{\n\tstruct strbufinfo current;\n\tcurrent.size=strsize;\n\tcurrent.maxsize=strmaxsize;\n\tcurrent.str=dcstr;\n\tcurrent.ptr=dcptr;\n\tdcinit();\n\treturn current;\n}",
        "commit_message": "decompileAction: Prevent heap buffer overflow and underflow with using OpCode",
        "cve_desc": "Ming (aka libming) 0.4.8 has a heap buffer overflow and underflow in the decompileCAST function in util/decompile.c in libutil.a. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted SWF file.",
        "target": 0
      },
      {
        "idx": 264419,
        "reasoning": "This code addresses a potential heap buffer overflow/underflow by explicitly allocating memory for the duplicated string using `calloc` and `strlen` to determine the necessary length, including the null terminator, before copying with `strcpy`. While `strcpy` itself can be unsafe, the allocated buffer size is correctly calculated based on the source string's length, mitigating the risk in this specific context.\n\n\n\n",
        "func": "pushdup()\n{\n\tstruct _stack *t;\n#ifdef DEBUG\n\tprintf(\"*pushdup*\\n\");\n#endif\n\tif(Stack == NULL)\n\t{\n\t\tSWF_warn(\"WARNING: pushdup on empty stack. This might be wrong!\\n\");\n\t\treturn;\n\t}\n\tt = calloc(1,sizeof(*Stack));\n\tt->type = Stack->type;\n\n\t// If element is a string, perform deep copy of Stack->val->p\n\tif (Stack->val->Type == PUSH_STRING) {\n\t\tt->val = calloc(1, sizeof(struct SWF_ACTIONPUSHPARAM));\n\t\t*t->val = *Stack->val;\n\n\t\tint len = strlen(Stack->val->p.String) + 1; // NULL terminated\n\t\tt->val->p.String = calloc(len, sizeof(char));\n\t\tstrcpy(t->val->p.String, Stack->val->p.String);\n\t} else {\n\t\tt->val =  Stack->val;\n\t}\n\n\tt->next = Stack;\n\tStack = t;\n}",
        "commit_message": "decompileAction: Prevent heap buffer overflow and underflow with using OpCode",
        "cve_desc": "Ming (aka libming) 0.4.8 has a heap buffer overflow and underflow in the decompileCAST function in util/decompile.c in libutil.a. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted SWF file.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 4025,
        "reasoning": "The code is vulnerable to a heap buffer overflow and underflow within the `decompileCAST` function, as indicated by the provided CVE description. The `decompileCAST` function, called within `decompileAction`, likely doesn't properly validate the size of data being processed from the SWF file, leading to potential memory corruption when handling a crafted input.",
        "func": " decompileAction(int n, SWF_ACTION *actions, int maxn)\n {\n\tif( n > maxn ) SWF_error(\"Action overflow!!\");\n \n #ifdef DEBUG\n \tfprintf(stderr,\"%d:\\tACTION[%3.3d]: %s\\n\",\n \t        actions[n].SWF_ACTIONRECORD.Offset, n, \n \t        actionName(actions[n].SWF_ACTIONRECORD.ActionCode));\n #endif\n \n\tswitch(actions[n].SWF_ACTIONRECORD.ActionCode)\n \t{\n \tcase SWFACTION_END:\n \t\treturn 0;\n\n\tcase SWFACTION_CONSTANTPOOL:\n\t\tdecompileCONSTANTPOOL(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_GOTOLABEL:\n\t\treturn decompileGOTOFRAME(n, actions, maxn,1);\n\n\tcase SWFACTION_GOTOFRAME:\n\t\treturn decompileGOTOFRAME(n, actions, maxn,0);\n\n\tcase SWFACTION_GOTOFRAME2:\n\t\treturn decompileGOTOFRAME2(n, actions, maxn);\n\n\tcase SWFACTION_WAITFORFRAME:\n\t\tdecompileWAITFORFRAME(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_GETURL2:\n\t\tdecompileGETURL2(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_GETURL:\n\t\tdecompileGETURL(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_PUSH:\n\t\tdecompilePUSH(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_PUSHDUP:\n\t\tdecompilePUSHDUP(&actions[n]);\n\t\treturn 0;\n\n\tcase SWFACTION_STACKSWAP:\n\t\tdecompileSTACKSWAP(&actions[n]);\t\n\t\treturn 0;\n\n\tcase SWFACTION_SETPROPERTY:\n\t\tdecompileSETPROPERTY(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_GETPROPERTY:\n\t\tdecompileGETPROPERTY(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_GETTIME:\n\t\treturn decompileGETTIME(n, actions, maxn);\n\n\tcase SWFACTION_TRACE:\n\t\tdecompileTRACE(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_CALLFRAME:\n\t\tdecompileCALLFRAME(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_EXTENDS:\n\t\tdecompileEXTENDS(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_INITOBJECT:\n\t\tdecompileINITOBJECT(n, actions, maxn);\n\t\treturn 0;\t        \n\n\tcase SWFACTION_NEWOBJECT:\n\t\tdecompileNEWOBJECT(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_NEWMETHOD:\n\t\tdecompileNEWMETHOD(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_GETMEMBER:\n\t\tdecompileGETMEMBER(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_SETMEMBER:\n\t\tdecompileSETMEMBER(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_GETVARIABLE:\n\t\tdecompileGETVARIABLE(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_SETVARIABLE:\n\t\tdecompileSETVARIABLE(n, actions, maxn, 0);\n\t\treturn 0;\n\n\tcase SWFACTION_DEFINELOCAL:\n\t\tdecompileSETVARIABLE(n, actions, maxn, 1);\n\t\treturn 0;\n\n\tcase SWFACTION_DEFINELOCAL2:\n\t\tdecompileDEFINELOCAL2(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_DECREMENT:\n\t\treturn decompileINCR_DECR(n, actions, maxn, 0);\n\n\tcase SWFACTION_INCREMENT:\n\t\treturn decompileINCR_DECR(n, actions, maxn,1);\n\n\tcase SWFACTION_STOREREGISTER:\n\t\tdecompileSTOREREGISTER(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_JUMP:\n\t\treturn decompileJUMP(n, actions, maxn);\n\n\tcase SWFACTION_RETURN:\n\t\tdecompileRETURN(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_LOGICALNOT:\n\t\treturn decompileLogicalNot(n, actions, maxn);\n\n\tcase SWFACTION_IF:\n\t\treturn decompileIF(n, actions, maxn);\n\n\tcase SWFACTION_WITH:\n\t\tdecompileWITH(n, actions, maxn);\n\t\treturn 0;\n\n\tcase SWFACTION_ENUMERATE:\n\t\treturn decompileENUMERATE(n, actions, maxn, 0);\n\n\tcase SWFACTION_ENUMERATE2 :\n\t\treturn decompileENUMERATE(n, actions, maxn,1);\n\n\tcase SWFACTION_INITARRAY:\n\t\treturn decompileINITARRAY(n, actions, maxn);\n\n\tcase SWFACTION_DEFINEFUNCTION:\t\n\t\treturn decompileDEFINEFUNCTION(n, actions, maxn,0);\n\n\tcase SWFACTION_DEFINEFUNCTION2:\n\t\treturn decompileDEFINEFUNCTION(n, actions, maxn,1);\n\n\tcase SWFACTION_CALLFUNCTION:\n\t\treturn decompileCALLFUNCTION(n, actions, maxn);\n\n\tcase SWFACTION_CALLMETHOD:\n\t\treturn decompileCALLMETHOD(n, actions, maxn);\n\n\tcase SWFACTION_INSTANCEOF:\n\tcase SWFACTION_SHIFTLEFT:\n\tcase SWFACTION_SHIFTRIGHT:\n\tcase SWFACTION_SHIFTRIGHT2:        \n\tcase SWFACTION_ADD:\n\tcase SWFACTION_ADD2:\n\tcase SWFACTION_SUBTRACT:\n\tcase SWFACTION_MULTIPLY:\n\tcase SWFACTION_DIVIDE:\n\tcase SWFACTION_MODULO:\n\tcase SWFACTION_BITWISEAND:\n\tcase SWFACTION_BITWISEOR:\n\tcase SWFACTION_BITWISEXOR:\n\tcase SWFACTION_EQUAL:\n\tcase SWFACTION_EQUALS2:\n\tcase SWFACTION_LESS2:\n\tcase SWFACTION_LOGICALAND:\n\tcase SWFACTION_LOGICALOR:\n\tcase SWFACTION_GREATER:\n\tcase SWFACTION_LESSTHAN:\n\tcase SWFACTION_STRINGEQ:\n\tcase SWFACTION_STRINGCOMPARE:\n\tcase SWFACTION_STRICTEQUALS:\n\t\treturn decompileArithmeticOp(n, actions, maxn);\n\n\tcase SWFACTION_POP:\n\t\tpop();\n\t\treturn 0;\n\n\tcase SWFACTION_STARTDRAG:\n\t\treturn decompileSTARTDRAG(n, actions, maxn);\n\n\tcase SWFACTION_DELETE:\n\t\treturn decompileDELETE(n, actions, maxn,0);\n\n\tcase SWFACTION_DELETE2:\n\t\treturn decompileDELETE(n, actions, maxn,1);\n\n\tcase SWFACTION_TARGETPATH:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"targetPath\");\n\n\tcase SWFACTION_TYPEOF:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"typeof\");\n\n\tcase SWFACTION_ORD:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"ord\");\n\n\tcase SWFACTION_CHR:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"chr\");\n\n\tcase SWFACTION_INT:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"int\");\n\n\tcase SWFACTION_TOSTRING:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"String\");     \n\n\tcase SWFACTION_TONUMBER:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"Number\");\n\n\tcase SWFACTION_RANDOMNUMBER:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"random\");\n\n\tcase SWFACTION_STRINGLENGTH:\n\t\treturn decompileSingleArgBuiltInFunctionCall(n, actions, maxn,\"length\");\n\n\tcase SWFACTION_PLAY:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"play\");\n\n\tcase SWFACTION_STOP:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"stop\");\n\n\tcase SWFACTION_NEXTFRAME:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"nextFrame\");\n\n\tcase SWFACTION_PREVFRAME:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"prevFrame\");\n\n\tcase SWFACTION_ENDDRAG:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"stopDrag\");\n\n\tcase SWFACTION_STOPSOUNDS:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"stopAllSounds\");   \n\n\tcase SWFACTION_TOGGLEQUALITY:\n\t\treturn decompile_Null_ArgBuiltInFunctionCall(n, actions, maxn,\"toggleHighQuality\");      \n\n\tcase SWFACTION_MBSUBSTRING:\n\tcase SWFACTION_SUBSTRING:\n\t\treturn decompileSUBSTRING(n, actions, maxn);\n\n\tcase SWFACTION_STRINGCONCAT:\n\t\treturn decompileSTRINGCONCAT(n, actions, maxn);\n\n\tcase SWFACTION_REMOVECLIP:\n\t\treturn decompileREMOVECLIP(n, actions, maxn);\n\n\tcase SWFACTION_DUPLICATECLIP:\n\t\treturn decompileDUPLICATECLIP(n, actions, maxn);\n\n\tcase SWFACTION_SETTARGET:\n\t\treturn decompileSETTARGET(n, actions, maxn,0);\n\n\tcase SWFACTION_SETTARGET2:\n\t\treturn decompileSETTARGET(n, actions, maxn,1);\n\n\tcase SWFACTION_IMPLEMENTSOP:\n\t\treturn decompileIMPLEMENTS(n, actions, maxn);\n\n\tcase SWFACTION_CASTOP:\n\t\treturn decompileCAST(n, actions, maxn);\n\n\tcase SWFACTION_THROW:\n\t\treturn decompileTHROW(n, actions, maxn);\n\n\tcase SWFACTION_TRY:\n\t\treturn decompileTRY(n, actions, maxn);\n\n\tdefault:\n\t\toutputSWF_ACTION(n,&actions[n]);\n\t\treturn 0;\n\t}\n}\n",
        "commit_message": "None",
        "cve_desc": "Ming (aka libming) 0.4.8 has a heap buffer overflow and underflow in the decompileCAST function in util/decompile.c in libutil.a. Remote attackers could leverage this vulnerability to cause a denial of service via a crafted SWF file.",
        "target": 1
      },
      {
        "idx": 4026,
        "reasoning": "The code is vulnerable to a fill overflow because the `idx` value, obtained from `getFillIdx`, is directly used to index into the fill style array without bounds checking, potentially leading to an out-of-bounds access. This allows a malicious SWF file to craft a `SWFFillStyle` that causes `getFillIdx` to return a value exceeding the array's limits, triggering a crash or potentially allowing for arbitrary code execution as described in the CVE.",
        "func": "SWFShape_setLeftFillStyle(SWFShape shape, SWFFillStyle fill)\n{\n\tShapeRecord record;\n\tint idx;\n\n\tif ( shape->isEnded || shape->isMorph )\n\t\treturn;\n\t\n\tif(fill == NOFILL)\n\t{\n\t\trecord = addStyleRecord(shape);\n\t\trecord.record.stateChange->leftFill = 0;\n\t\trecord.record.stateChange->flags |= SWF_SHAPE_FILLSTYLE0FLAG;\n\t\treturn;\n\t}\n\n\tidx = getFillIdx(shape, fill);\n\tif(idx == 0) // fill not present in array\n\t{\n\t\tSWFFillStyle_addDependency(fill, (SWFCharacter)shape);\n\t\tif(addFillStyle(shape, fill) < 0)\n \t\t\treturn;\t\t\n \t\tidx = getFillIdx(shape, fill);\n \t}\n \t\t\t\t\n \trecord = addStyleRecord(shape);\n \trecord.record.stateChange->leftFill = idx;\n\trecord.record.stateChange->flags |= SWF_SHAPE_FILLSTYLE0FLAG;\n}\n",
        "commit_message": "None",
        "cve_desc": "Ming (aka libming) 0.4.8 has an \"fill overflow\" vulnerability in the function SWFShape_setLeftFillStyle in blocks/shape.c.",
        "target": 1
      },
      {
        "idx": 4027,
        "reasoning": "This code is vulnerable to an integer overflow because the subtraction `num - (1<<number)` can result in a negative value when `num` is small and `number` is large, leading to an out-of-range value being returned.  This overflow, as described in the CVE, can be exploited with a crafted SWF file to cause a denial-of-service by triggering unexpected behavior due to the incorrect signed bit interpretation.",
        "func": "SWFInput_readSBits(SWFInput input, int number)\n {\n \tint num = SWFInput_readBits(input, number);\n \n\tif ( num & (1<<(number-1)) )\n \t\treturn num - (1<<number);\n \telse\n \t\treturn num;\n}\n",
        "commit_message": "None",
        "cve_desc": "In Ming (aka libming) 0.4.8, there is an integer overflow (caused by an out-of-range left shift) in the SWFInput_readSBits function in blocks/input.c. Remote attackers could leverage this vulnerability to cause a denial-of-service via a crafted swf file.",
        "target": 1
      }
    ]
  },
  "librepo": {
    "0": [],
    "1": []
  },
  "libslirp": {
    "0": [
      {
        "idx": 364488,
        "reasoning": "This code snippet is **not directly related to the reported \"use after free\" vulnerability** in `ip_reass`. The commit message and description focus on issues arising from dequeuing (`ip_deq`) after memory has been freed (`m_free`), while this code manipulates IP options *within* an existing mbuf and doesn't involve freeing and re-using memory in a way that would cause a use-after-free.\n\n\n\n",
        "func": "void ip_stripoptions(register struct mbuf *m, struct mbuf *mopt)\n{\n    register int i;\n    struct ip *ip = mtod(m, struct ip *);\n    register char *opts;\n    int olen;\n\n    olen = (ip->ip_hl << 2) - sizeof(struct ip);\n    opts = (char *)(ip + 1);\n    i = m->m_len - (sizeof(struct ip) + olen);\n    memcpy(opts, opts + olen, (unsigned)i);\n    m->m_len -= olen;\n\n    ip->ip_hl = sizeof(struct ip) >> 2;\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 0
      },
      {
        "idx": 364489,
        "reasoning": "This code snippet, `ip_enq`, is not directly vulnerable to the described use-after-free because it only *manipulates* pointers within the `ipasfrag` linked list\u2014it doesn't free any memory. The commit message refers to a potential issue with `ip_deq` *after* a `m_free` call, and this `ip_enq` function isn't involved in the freeing process, therefore it doesn't contribute to the vulnerability.",
        "func": "static void ip_enq(register struct ipasfrag *p, register struct ipasfrag *prev)\n{\n    DEBUG_CALL(\"ip_enq\");\n    DEBUG_ARG(\"prev = %p\", prev);\n    p->ipf_prev = prev;\n    p->ipf_next = prev->ipf_next;\n    ((struct ipasfrag *)(prev->ipf_next))->ipf_prev = p;\n    prev->ipf_next = p;\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 0
      },
      {
        "idx": 364490,
        "reasoning": "This code snippet, showing only cleanup functions, is not directly vulnerable to the described \"use after free\" issue. The commit message details a problem in `ip_deq` following a `m_free`, which isn't present in the provided `ip_cleanup` function\u2014this function only calls other cleanup routines and doesn't handle IP packet dequeuing or memory freeing directly.\n\n\n\n",
        "func": "void ip_cleanup(Slirp *slirp)\n{\n    udp_cleanup(slirp);\n    tcp_cleanup(slirp);\n    icmp_cleanup(slirp);\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 0
      },
      {
        "idx": 364491,
        "reasoning": "The commit message explicitly states the vulnerability lies in potentially reading pointers from a reused allocation *after* freeing memory (`m_free`), specifically when using `ip_deq`. However, the provided code snippet doesn't show the `ip_deq` function or the specific context where this use-after-free could occur, and the commit focuses on fixing the issue in `ip_reass` which isn't directly present in this snippet \u2013 therefore, based *solely* on this code, it's not demonstrably vulnerable.",
        "func": "void ip_input(struct mbuf *m)\n{\n    Slirp *slirp = m->slirp;\n    register struct ip *ip;\n    int hlen;\n\n    if (!slirp->in_enabled) {\n        goto bad;\n    }\n\n    DEBUG_CALL(\"ip_input\");\n    DEBUG_ARG(\"m = %p\", m);\n    DEBUG_ARG(\"m_len = %d\", m->m_len);\n\n    if (m->m_len < sizeof(struct ip)) {\n        goto bad;\n    }\n\n    ip = mtod(m, struct ip *);\n\n    if (ip->ip_v != IPVERSION) {\n        goto bad;\n    }\n\n    hlen = ip->ip_hl << 2;\n    if (hlen < sizeof(struct ip) || hlen > m->m_len) { /* min header length */\n        goto bad; /* or packet too short */\n    }\n\n    /* keep ip header intact for ICMP reply\n     * ip->ip_sum = cksum(m, hlen);\n     * if (ip->ip_sum) {\n     */\n    if (cksum(m, hlen)) {\n        goto bad;\n    }\n\n    /*\n     * Convert fields to host representation.\n     */\n    NTOHS(ip->ip_len);\n    if (ip->ip_len < hlen) {\n        goto bad;\n    }\n    NTOHS(ip->ip_id);\n    NTOHS(ip->ip_off);\n\n    /*\n     * Check that the amount of data in the buffers\n     * is as at least much as the IP header would have us expect.\n     * Trim mbufs if longer than we expect.\n     * Drop packet if shorter than we expect.\n     */\n    if (m->m_len < ip->ip_len) {\n        goto bad;\n    }\n\n    /* Should drop packet if mbuf too long? hmmm... */\n    if (m->m_len > ip->ip_len)\n        m_adj(m, ip->ip_len - m->m_len);\n\n    /* check ip_ttl for a correct ICMP reply */\n    if (ip->ip_ttl == 0) {\n        icmp_send_error(m, ICMP_TIMXCEED, ICMP_TIMXCEED_INTRANS, 0, \"ttl\");\n        goto bad;\n    }\n\n    /*\n     * If offset or IP_MF are set, must reassemble.\n     * Otherwise, nothing need be done.\n     * (We could look in the reassembly queue to see\n     * if the packet was previously fragmented,\n     * but it's not worth the time; just let them time out.)\n     *\n     * XXX This should fail, don't fragment yet\n     */\n    if (ip->ip_off & ~IP_DF) {\n        register struct ipq *fp;\n        struct qlink *l;\n        /*\n         * Look for queue of fragments\n         * of this datagram.\n         */\n        for (l = slirp->ipq.ip_link.next; l != &slirp->ipq.ip_link;\n             l = l->next) {\n            fp = container_of(l, struct ipq, ip_link);\n            if (ip->ip_id == fp->ipq_id &&\n                ip->ip_src.s_addr == fp->ipq_src.s_addr &&\n                ip->ip_dst.s_addr == fp->ipq_dst.s_addr &&\n                ip->ip_p == fp->ipq_p)\n                goto found;\n        }\n        fp = NULL;\n    found:\n\n        /*\n         * Adjust ip_len to not reflect header,\n         * set ip_mff if more fragments are expected,\n         * convert offset of this to bytes.\n         */\n        ip->ip_len -= hlen;\n        if (ip->ip_off & IP_MF)\n            ip->ip_tos |= 1;\n        else\n            ip->ip_tos &= ~1;\n\n        ip->ip_off <<= 3;\n\n        /*\n         * If datagram marked as having more fragments\n         * or if this is not the first fragment,\n         * attempt reassembly; if it succeeds, proceed.\n         */\n        if (ip->ip_tos & 1 || ip->ip_off) {\n            ip = ip_reass(slirp, ip, fp);\n            if (ip == NULL)\n                return;\n            m = dtom(slirp, ip);\n        } else if (fp)\n            ip_freef(slirp, fp);\n\n    } else\n        ip->ip_len -= hlen;\n\n    /*\n     * Switch out to protocol's input routine.\n     */\n    switch (ip->ip_p) {\n    case IPPROTO_TCP:\n        tcp_input(m, hlen, (struct socket *)NULL, AF_INET);\n        break;\n    case IPPROTO_UDP:\n        udp_input(m, hlen);\n        break;\n    case IPPROTO_ICMP:\n        icmp_input(m, hlen);\n        break;\n    default:\n        m_free(m);\n    }\n    return;\nbad:\n    m_free(m);\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 0
      },
      {
        "idx": 364492,
        "reasoning": "This code is **not vulnerable** to the described use-after-free. The commit message explicitly states the vulnerability was related to using `ip_deq` *after* a `m_free`, but this code snippet only shows `ip_freef` being called, which is the intended freeing function, and doesn't involve `ip_deq`. \n\n\n\n",
        "func": "void ip_slowtimo(Slirp *slirp)\n{\n    struct qlink *l;\n\n    DEBUG_CALL(\"ip_slowtimo\");\n\n    l = slirp->ipq.ip_link.next;\n\n    if (l == NULL)\n        return;\n\n    while (l != &slirp->ipq.ip_link) {\n        struct ipq *fp = container_of(l, struct ipq, ip_link);\n        l = l->next;\n        if (--fp->ipq_ttl == 0) {\n            ip_freef(slirp, fp);\n        }\n    }\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 204737,
        "reasoning": "The code is vulnerable to a use-after-free because `m_free(dtom(slirp, fp))` frees the memory pointed to by `fp`, but the code then continues to access members of `fp` (specifically `fp->ipq_src` and `fp->ipq_dst`) after the free, leading to a potential crash or information leak. This aligns with CVE-2019-14378, which describes a use-after-free triggered by fragmented IP packets during reassembly in the `ip_reass` function.",
        "func": "static struct ip *ip_reass(Slirp *slirp, struct ip *ip, struct ipq *fp)\n{\n    register struct mbuf *m = dtom(slirp, ip);\n    register struct ipasfrag *q;\n    int hlen = ip->ip_hl << 2;\n    int i, next;\n\n    DEBUG_CALL(\"ip_reass\");\n    DEBUG_ARG(\"ip = %p\", ip);\n    DEBUG_ARG(\"fp = %p\", fp);\n    DEBUG_ARG(\"m = %p\", m);\n\n    /*\n     * Presence of header sizes in mbufs\n     * would confuse code below.\n     * Fragment m_data is concatenated.\n     */\n    m->m_data += hlen;\n    m->m_len -= hlen;\n\n    /*\n     * If first fragment to arrive, create a reassembly queue.\n     */\n    if (fp == NULL) {\n        struct mbuf *t = m_get(slirp);\n\n        if (t == NULL) {\n            goto dropfrag;\n        }\n        fp = mtod(t, struct ipq *);\n        insque(&fp->ip_link, &slirp->ipq.ip_link);\n        fp->ipq_ttl = IPFRAGTTL;\n        fp->ipq_p = ip->ip_p;\n        fp->ipq_id = ip->ip_id;\n        fp->frag_link.next = fp->frag_link.prev = &fp->frag_link;\n        fp->ipq_src = ip->ip_src;\n        fp->ipq_dst = ip->ip_dst;\n        q = (struct ipasfrag *)fp;\n        goto insert;\n    }\n\n    /*\n     * Find a segment which begins after this one does.\n     */\n    for (q = fp->frag_link.next; q != (struct ipasfrag *)&fp->frag_link;\n         q = q->ipf_next)\n        if (q->ipf_off > ip->ip_off)\n            break;\n\n    /*\n     * If there is a preceding segment, it may provide some of\n     * our data already.  If so, drop the data from the incoming\n     * segment.  If it provides all of our data, drop us.\n     */\n    if (q->ipf_prev != &fp->frag_link) {\n        struct ipasfrag *pq = q->ipf_prev;\n        i = pq->ipf_off + pq->ipf_len - ip->ip_off;\n        if (i > 0) {\n            if (i >= ip->ip_len)\n                goto dropfrag;\n            m_adj(dtom(slirp, ip), i);\n            ip->ip_off += i;\n            ip->ip_len -= i;\n        }\n    }\n\n    /*\n     * While we overlap succeeding segments trim them or,\n     * if they are completely covered, dequeue them.\n     */\n    while (q != (struct ipasfrag *)&fp->frag_link &&\n           ip->ip_off + ip->ip_len > q->ipf_off) {\n        i = (ip->ip_off + ip->ip_len) - q->ipf_off;\n        if (i < q->ipf_len) {\n            q->ipf_len -= i;\n            q->ipf_off += i;\n            m_adj(dtom(slirp, q), i);\n            break;\n        }\n        q = q->ipf_next;\n        m_free(dtom(slirp, q->ipf_prev));\n        ip_deq(q->ipf_prev);\n    }\n\ninsert:\n    /*\n     * Stick new segment in its place;\n     * check for complete reassembly.\n     */\n    ip_enq(iptofrag(ip), q->ipf_prev);\n    next = 0;\n    for (q = fp->frag_link.next; q != (struct ipasfrag *)&fp->frag_link;\n         q = q->ipf_next) {\n        if (q->ipf_off != next)\n            return NULL;\n        next += q->ipf_len;\n    }\n    if (((struct ipasfrag *)(q->ipf_prev))->ipf_tos & 1)\n        return NULL;\n\n    /*\n     * Reassembly is complete; concatenate fragments.\n     */\n    q = fp->frag_link.next;\n    m = dtom(slirp, q);\n\n    int was_ext = m->m_flags & M_EXT;\n\n    q = (struct ipasfrag *)q->ipf_next;\n    while (q != (struct ipasfrag *)&fp->frag_link) {\n        struct mbuf *t = dtom(slirp, q);\n        q = (struct ipasfrag *)q->ipf_next;\n        m_cat(m, t);\n    }\n\n    /*\n     * Create header for new ip packet by\n     * modifying header of first packet;\n     * dequeue and discard fragment reassembly header.\n     * Make header visible.\n     */\n    q = fp->frag_link.next;\n\n    /*\n     * If the fragments concatenated to an mbuf that's bigger than the total\n     * size of the fragment and the mbuf was not already using an m_ext buffer,\n     * then an m_ext buffer was alloced. But fp->ipq_next points to the old\n     * buffer (in the mbuf), so we must point ip into the new buffer.\n     */\n    if (!was_ext && m->m_flags & M_EXT) {\n        int delta = (char *)q - m->m_dat;\n        q = (struct ipasfrag *)(m->m_ext + delta);\n    }\n\n    ip = fragtoip(q);\n    ip->ip_len = next;\n    ip->ip_tos &= ~1;\n    ip->ip_src = fp->ipq_src;\n    ip->ip_dst = fp->ipq_dst;\n    remque(&fp->ip_link);\n    (void)m_free(dtom(slirp, fp));\n    m->m_len += (ip->ip_hl << 2);\n    m->m_data -= (ip->ip_hl << 2);\n\n    return ip;\n\ndropfrag:\n    m_free(m);\n    return NULL;\n}",
        "commit_message": "ip_reass: Fix use after free\n\nUsing ip_deq after m_free might read pointers from an allocation reuse.\n\nThis would be difficult to exploit, but that is still related with\nCVE-2019-14378 which generates fragmented IP packets that would trigger this\nissue and at least produce a DoS.\n\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>",
        "cve_desc": "libslirp 4.0.0, as used in QEMU 4.1.0, has a use-after-free in ip_reass in ip_input.c.",
        "target": 1
      },
      {
        "idx": 204772,
        "reasoning": "The `tcp_emu` function is vulnerable to a heap-based buffer overflow in the `EMU_IRC` case due to insufficient bounds checking when using `snprintf` to rewrite data into the `m->m_data` buffer. Specifically, `snprintf` is called with `M_FREEROOM(m)` as the size argument, but the code doesn't adequately verify that the resulting string, including the original data and the newly appended data, will fit within the allocated memory of the `mbuf` structure, potentially leading to an out-of-bounds write.",
        "func": "int tcp_emu(struct socket *so, struct mbuf *m)\n{\n    Slirp *slirp = so->slirp;\n    unsigned n1, n2, n3, n4, n5, n6;\n    char buff[257];\n    uint32_t laddr;\n    unsigned lport;\n    char *bptr;\n\n    DEBUG_CALL(\"tcp_emu\");\n    DEBUG_ARG(\"so = %p\", so);\n    DEBUG_ARG(\"m = %p\", m);\n\n    switch (so->so_emu) {\n        int x, i;\n\n        /* TODO: IPv6 */\n    case EMU_IDENT:\n        /*\n         * Identification protocol as per rfc-1413\n         */\n\n        {\n            struct socket *tmpso;\n            struct sockaddr_in addr;\n            socklen_t addrlen = sizeof(struct sockaddr_in);\n            char *eol = g_strstr_len(m->m_data, m->m_len, \"\\r\\n\");\n\n            if (!eol) {\n                return 1;\n            }\n\n            *eol = '\\0';\n            if (sscanf(m->m_data, \"%u%*[ ,]%u\", &n1, &n2) == 2) {\n                HTONS(n1);\n                HTONS(n2);\n                /* n2 is the one on our host */\n                for (tmpso = slirp->tcb.so_next; tmpso != &slirp->tcb;\n                     tmpso = tmpso->so_next) {\n                    if (tmpso->so_laddr.s_addr == so->so_laddr.s_addr &&\n                        tmpso->so_lport == n2 &&\n                        tmpso->so_faddr.s_addr == so->so_faddr.s_addr &&\n                        tmpso->so_fport == n1) {\n                        if (getsockname(tmpso->s, (struct sockaddr *)&addr,\n                                        &addrlen) == 0)\n                            n2 = addr.sin_port;\n                        break;\n                    }\n                }\n                NTOHS(n1);\n                NTOHS(n2);\n                m_inc(m, snprintf(NULL, 0, \"%d,%d\\r\\n\", n1, n2) + 1);\n                m->m_len = snprintf(m->m_data, M_ROOM(m), \"%d,%d\\r\\n\", n1, n2);\n                assert(m->m_len < M_ROOM(m));\n            } else {\n                *eol = '\\r';\n            }\n\n            return 1;\n        }\n\n    case EMU_FTP: /* ftp */\n        m_inc(m, m->m_len + 1);\n        *(m->m_data + m->m_len) = 0; /* NUL terminate for strstr */\n        if ((bptr = (char *)strstr(m->m_data, \"ORT\")) != NULL) {\n            /*\n             * Need to emulate the PORT command\n             */\n            x = sscanf(bptr, \"ORT %u,%u,%u,%u,%u,%u\\r\\n%256[^\\177]\", &n1, &n2,\n                       &n3, &n4, &n5, &n6, buff);\n            if (x < 6)\n                return 1;\n\n            laddr = htonl((n1 << 24) | (n2 << 16) | (n3 << 8) | (n4));\n            lport = htons((n5 << 8) | (n6));\n\n            if ((so = tcp_listen(slirp, INADDR_ANY, 0, laddr, lport,\n                                 SS_FACCEPTONCE)) == NULL) {\n                return 1;\n            }\n            n6 = ntohs(so->so_fport);\n\n            n5 = (n6 >> 8) & 0xff;\n            n6 &= 0xff;\n\n            laddr = ntohl(so->so_faddr.s_addr);\n\n            n1 = ((laddr >> 24) & 0xff);\n            n2 = ((laddr >> 16) & 0xff);\n            n3 = ((laddr >> 8) & 0xff);\n            n4 = (laddr & 0xff);\n\n            m->m_len = bptr - m->m_data; /* Adjust length */\n            m->m_len += snprintf(bptr, m->m_size - m->m_len,\n                                 \"ORT %d,%d,%d,%d,%d,%d\\r\\n%s\", n1, n2, n3, n4,\n                                 n5, n6, x == 7 ? buff : \"\");\n            return 1;\n        } else if ((bptr = (char *)strstr(m->m_data, \"27 Entering\")) != NULL) {\n            /*\n             * Need to emulate the PASV response\n             */\n            x = sscanf(\n                bptr,\n                \"27 Entering Passive Mode (%u,%u,%u,%u,%u,%u)\\r\\n%256[^\\177]\",\n                &n1, &n2, &n3, &n4, &n5, &n6, buff);\n            if (x < 6)\n                return 1;\n\n            laddr = htonl((n1 << 24) | (n2 << 16) | (n3 << 8) | (n4));\n            lport = htons((n5 << 8) | (n6));\n\n            if ((so = tcp_listen(slirp, INADDR_ANY, 0, laddr, lport,\n                                 SS_FACCEPTONCE)) == NULL) {\n                return 1;\n            }\n            n6 = ntohs(so->so_fport);\n\n            n5 = (n6 >> 8) & 0xff;\n            n6 &= 0xff;\n\n            laddr = ntohl(so->so_faddr.s_addr);\n\n            n1 = ((laddr >> 24) & 0xff);\n            n2 = ((laddr >> 16) & 0xff);\n            n3 = ((laddr >> 8) & 0xff);\n            n4 = (laddr & 0xff);\n\n            m->m_len = bptr - m->m_data; /* Adjust length */\n            m->m_len +=\n                snprintf(bptr, m->m_size - m->m_len,\n                         \"27 Entering Passive Mode (%d,%d,%d,%d,%d,%d)\\r\\n%s\",\n                         n1, n2, n3, n4, n5, n6, x == 7 ? buff : \"\");\n\n            return 1;\n        }\n\n        return 1;\n\n    case EMU_KSH:\n        /*\n         * The kshell (Kerberos rsh) and shell services both pass\n         * a local port port number to carry signals to the server\n         * and stderr to the client.  It is passed at the beginning\n         * of the connection as a NUL-terminated decimal ASCII string.\n         */\n        so->so_emu = 0;\n        for (lport = 0, i = 0; i < m->m_len - 1; ++i) {\n            if (m->m_data[i] < '0' || m->m_data[i] > '9')\n                return 1; /* invalid number */\n            lport *= 10;\n            lport += m->m_data[i] - '0';\n        }\n        if (m->m_data[m->m_len - 1] == '\\0' && lport != 0 &&\n            (so = tcp_listen(slirp, INADDR_ANY, 0, so->so_laddr.s_addr,\n                             htons(lport), SS_FACCEPTONCE)) != NULL)\n            m->m_len =\n                snprintf(m->m_data, m->m_size, \"%d\", ntohs(so->so_fport)) + 1;\n        return 1;\n\n    case EMU_IRC:\n        /*\n         * Need to emulate DCC CHAT, DCC SEND and DCC MOVE\n         */\n        m_inc(m, m->m_len + 1);\n        *(m->m_data + m->m_len) = 0; /* NULL terminate the string for strstr */\n        if ((bptr = (char *)strstr(m->m_data, \"DCC\")) == NULL)\n            return 1;\n\n        /* The %256s is for the broken mIRC */\n        if (sscanf(bptr, \"DCC CHAT %256s %u %u\", buff, &laddr, &lport) == 3) {\n            if ((so = tcp_listen(slirp, INADDR_ANY, 0, htonl(laddr),\n                                 htons(lport), SS_FACCEPTONCE)) == NULL) {\n                return 1;\n            }\n            m->m_len = bptr - m->m_data; /* Adjust length */\n            m->m_len += snprintf(bptr, M_FREEROOM(m),\n                                 \"DCC CHAT chat %lu %u%c\\n\",\n                                 (unsigned long)ntohl(so->so_faddr.s_addr),\n                                 ntohs(so->so_fport), 1);\n        } else if (sscanf(bptr, \"DCC SEND %256s %u %u %u\", buff, &laddr, &lport,\n                          &n1) == 4) {\n            if ((so = tcp_listen(slirp, INADDR_ANY, 0, htonl(laddr),\n                                 htons(lport), SS_FACCEPTONCE)) == NULL) {\n                return 1;\n            }\n            m->m_len = bptr - m->m_data; /* Adjust length */\n            m->m_len += snprintf(bptr, M_FREEROOM(m),\n                         \"DCC SEND %s %lu %u %u%c\\n\", buff,\n                         (unsigned long)ntohl(so->so_faddr.s_addr),\n                         ntohs(so->so_fport), n1, 1);\n        } else if (sscanf(bptr, \"DCC MOVE %256s %u %u %u\", buff, &laddr, &lport,\n                          &n1) == 4) {\n            if ((so = tcp_listen(slirp, INADDR_ANY, 0, htonl(laddr),\n                                 htons(lport), SS_FACCEPTONCE)) == NULL) {\n                return 1;\n            }\n            m->m_len = bptr - m->m_data; /* Adjust length */\n            m->m_len += snprintf(bptr, M_FREEROOM(m),\n                         \"DCC MOVE %s %lu %u %u%c\\n\", buff,\n                         (unsigned long)ntohl(so->so_faddr.s_addr),\n                         ntohs(so->so_fport), n1, 1);\n        }\n        return 1;\n\n    case EMU_REALAUDIO:\n        /*\n         * RealAudio emulation - JP. We must try to parse the incoming\n         * data and try to find the two characters that contain the\n         * port number. Then we redirect an udp port and replace the\n         * number with the real port we got.\n         *\n         * The 1.0 beta versions of the player are not supported\n         * any more.\n         *\n         * A typical packet for player version 1.0 (release version):\n         *\n         * 0000:50 4E 41 00 05\n         * 0000:00 01 00 02 1B D7 00 00 67 E6 6C DC 63 00 12 50 ........g.l.c..P\n         * 0010:4E 43 4C 49 45 4E 54 20 31 30 31 20 41 4C 50 48 NCLIENT 101 ALPH\n         * 0020:41 6C 00 00 52 00 17 72 61 66 69 6C 65 73 2F 76 Al..R..rafiles/v\n         * 0030:6F 61 2F 65 6E 67 6C 69 73 68 5F 2E 72 61 79 42 oa/english_.rayB\n         *\n         * Now the port number 0x1BD7 is found at offset 0x04 of the\n         * Now the port number 0x1BD7 is found at offset 0x04 of the\n         * second packet. This time we received five bytes first and\n         * then the rest. You never know how many bytes you get.\n         *\n         * A typical packet for player version 2.0 (beta):\n         *\n         * 0000:50 4E 41 00 06 00 02 00 00 00 01 00 02 1B C1 00 PNA.............\n         * 0010:00 67 75 78 F5 63 00 0A 57 69 6E 32 2E 30 2E 30 .gux.c..Win2.0.0\n         * 0020:2E 35 6C 00 00 52 00 1C 72 61 66 69 6C 65 73 2F .5l..R..rafiles/\n         * 0030:77 65 62 73 69 74 65 2F 32 30 72 65 6C 65 61 73 website/20releas\n         * 0040:65 2E 72 61 79 53 00 00 06 36 42                e.rayS...6B\n         *\n         * Port number 0x1BC1 is found at offset 0x0d.\n         *\n         * This is just a horrible switch statement. Variable ra tells\n         * us where we're going.\n         */\n\n        bptr = m->m_data;\n        while (bptr < m->m_data + m->m_len) {\n            uint16_t p;\n            static int ra = 0;\n            char ra_tbl[4];\n\n            ra_tbl[0] = 0x50;\n            ra_tbl[1] = 0x4e;\n            ra_tbl[2] = 0x41;\n            ra_tbl[3] = 0;\n\n            switch (ra) {\n            case 0:\n            case 2:\n            case 3:\n                if (*bptr++ != ra_tbl[ra]) {\n                    ra = 0;\n                    continue;\n                }\n                break;\n\n            case 1:\n                /*\n                 * We may get 0x50 several times, ignore them\n                 */\n                if (*bptr == 0x50) {\n                    ra = 1;\n                    bptr++;\n                    continue;\n                } else if (*bptr++ != ra_tbl[ra]) {\n                    ra = 0;\n                    continue;\n                }\n                break;\n\n            case 4:\n                /*\n                 * skip version number\n                 */\n                bptr++;\n                break;\n\n            case 5:\n                if (bptr == m->m_data + m->m_len - 1)\n                        return 1; /* We need two bytes */\n\n                /*\n                 * The difference between versions 1.0 and\n                 * 2.0 is here. For future versions of\n                 * the player this may need to be modified.\n                 */\n                if (*(bptr + 1) == 0x02)\n                    bptr += 8;\n                else\n                    bptr += 4;\n                break;\n\n            case 6:\n                /* This is the field containing the port\n                 * number that RA-player is listening to.\n                 */\n\n                if (bptr == m->m_data + m->m_len - 1)\n                        return 1; /* We need two bytes */\n\n                lport = (((uint8_t *)bptr)[0] << 8) + ((uint8_t *)bptr)[1];\n                if (lport < 6970)\n                    lport += 256; /* don't know why */\n                if (lport < 6970 || lport > 7170)\n                    return 1; /* failed */\n\n                /* try to get udp port between 6970 - 7170 */\n                for (p = 6970; p < 7071; p++) {\n                    if (udp_listen(slirp, INADDR_ANY, htons(p),\n                                   so->so_laddr.s_addr, htons(lport),\n                                   SS_FACCEPTONCE)) {\n                        break;\n                    }\n                }\n                if (p == 7071)\n                    p = 0;\n                *(uint8_t *)bptr++ = (p >> 8) & 0xff;\n                *(uint8_t *)bptr = p & 0xff;\n                ra = 0;\n                return 1; /* port redirected, we're done */\n                break;\n\n            default:\n                ra = 0;\n            }\n            ra++;\n        }\n        return 1;\n\n    default:\n        /* Ooops, not emulated, won't call tcp_emu again */\n        so->so_emu = 0;\n        return 1;\n    }\n}",
        "commit_message": "slirp: use correct size while emulating commands\n\nWhile emulating services in tcp_emu(), it uses 'mbuf' size\n'm->m_size' to write commands via snprintf(3). Use M_FREEROOM(m)\nsize to avoid possible OOB access.\n\nSigned-off-by: Prasad J Pandit <pjp@fedoraproject.org>\nSigned-off-by: Samuel Thibault <samuel.thibault@ens-lyon.org>\nMessage-Id: <20200109094228.79764-3-ppandit@redhat.com>",
        "cve_desc": "tcp_emu in tcp_subr.c in libslirp 4.1.0, as used in QEMU 4.2.0, mismanages memory, as demonstrated by IRC DCC commands in EMU_IRC. This can cause a heap-based buffer overflow or other out-of-bounds access which can lead to a DoS or potential execute arbitrary code.",
        "target": 1
      },
      {
        "idx": 204879,
        "reasoning": "The code is vulnerable because it doesn't adequately validate the payload length (`ip6->ip_pl`) against the actual packet length (`m->m_len`) *before* passing the packet to functions like `icmp6_send_echoreply()`. This insufficient validation, as highlighted in the CVE, allows a malicious guest to craft IPv6 packets with a large advertised payload length but a small actual payload, leading to an out-of-bounds read when `icmp6_send_echoreply()` attempts to access data beyond the packet's boundaries, thus leaking host memory.",
        "func": "void ip6_input(struct mbuf *m)\n{\n    struct ip6 *ip6;\n    Slirp *slirp = m->slirp;\n\n    if (!slirp->in6_enabled) {\n        goto bad;\n    }\n\n    DEBUG_CALL(\"ip6_input\");\n    DEBUG_ARG(\"m = %p\", m);\n    DEBUG_ARG(\"m_len = %d\", m->m_len);\n\n    if (m->m_len < sizeof(struct ip6)) {\n        goto bad;\n    }\n\n    ip6 = mtod(m, struct ip6 *);\n\n    if (ip6->ip_v != IP6VERSION) {\n        goto bad;\n    }\n\n    if (ntohs(ip6->ip_pl) > slirp->if_mtu) {\n        icmp6_send_error(m, ICMP6_TOOBIG, 0);\n        goto bad;\n    }\n\n    /* check ip_ttl for a correct ICMP reply */\n    if (ip6->ip_hl == 0) {\n        icmp6_send_error(m, ICMP6_TIMXCEED, ICMP6_TIMXCEED_INTRANS);\n        goto bad;\n    }\n\n    /*\n     * Switch out to protocol's input routine.\n     */\n    switch (ip6->ip_nh) {\n    case IPPROTO_TCP:\n        NTOHS(ip6->ip_pl);\n        tcp_input(m, sizeof(struct ip6), (struct socket *)NULL, AF_INET6);\n        break;\n    case IPPROTO_UDP:\n        udp6_input(m);\n        break;\n    case IPPROTO_ICMPV6:\n        icmp6_input(m);\n        break;\n    default:\n        m_free(m);\n    }\n    return;\nbad:\n    m_free(m);\n}",
        "commit_message": "Drop bogus IPv6 messages\n\nDrop IPv6 message shorter than what's mentioned in the payload\nlength header (+ the size of the IPv6 header). They're invalid an could\nlead to data leakage in icmp6_send_echoreply().",
        "cve_desc": "An out-of-bounds read vulnerability was found in the SLiRP networking implementation of the QEMU emulator. This flaw occurs in the icmp6_send_echoreply() routine while replying to an ICMP echo request, also known as ping. This flaw allows a malicious guest to leak the contents of the host memory, resulting in possible information disclosure. This flaw affects versions of libslirp before 4.3.1.",
        "target": 1
      }
    ]
  },
  "libsolv": {
    "0": [
      {
        "idx": 373558,
        "reasoning": "This code is likely safe with respect to the commit message's concerns. The function `testcase_str2jobsel` focuses on *reading* and *interpreting* testcase input to create solvables and jobs, but doesn't modify the solver's state (repos, system, or jobs) directly; it only *defines* them and returns them for later processing, adhering to the commit message's restrictions on when these modifications are allowed.\n\n\n\n",
        "func": "testcase_str2jobsel(Pool *pool, const char *caller, char **pieces, int npieces, Id *whatp)\n{\n  Id job, what;\n  if (!strcmp(pieces[0], \"pkg\") && npieces == 2)\n    {\n      job = SOLVER_SOLVABLE;\n      what = testcase_str2solvid(pool, pieces[1]);\n      if (!what)\n\treturn pool_error(pool, -1, \"%s: unknown package '%s'\", caller, pieces[1]);\n    }\n  else if (!strcmp(pieces[0], \"name\") || !strcmp(pieces[0], \"provides\"))\n    {\n      /* join em again for dep2str... */\n      char *sp;\n      for (sp = pieces[1]; sp < pieces[npieces - 1]; sp++)\n\tif (*sp == 0)\n\t  *sp = ' ';\n      what = 0;\n      if (pieces[0][0] == 'p' && strncmp(pieces[1], \"namespace:\", 10) == 0)\n\t{\n\t  char *spe = strchr(pieces[1], '(');\n\t  int l = strlen(pieces[1]);\n\t  if (spe && pieces[1][l - 1] == ')')\n\t    {\n\t      /* special namespace provides */\n\t      if (strcmp(spe, \"(<NULL>)\") != 0)\n\t\t{\n\t\t  pieces[1][l - 1] = 0;\n\t\t  what = testcase_str2dep(pool, spe + 1);\n\t\t  pieces[1][l - 1] = ')';\n\t\t}\n\t      what = pool_rel2id(pool, pool_strn2id(pool, pieces[1], spe - pieces[1], 1), what, REL_NAMESPACE, 1);\n\t    }\n\t}\n      if (!what)\n        what = testcase_str2dep(pool, pieces[1]);\n      if (pieces[0][0] == 'n')\n\tjob = SOLVER_SOLVABLE_NAME;\n      else\n\tjob = SOLVER_SOLVABLE_PROVIDES;\n    }\n  else if (!strcmp(pieces[0], \"oneof\"))\n    {\n      Queue q;\n      job = SOLVER_SOLVABLE_ONE_OF;\n      queue_init(&q);\n      if (npieces > 1 && strcmp(pieces[1], \"nothing\") != 0)\n\t{\n\t  int i;\n\t  for (i = 1; i < npieces; i++)\n\t    {\n\t      Id p = testcase_str2solvid(pool, pieces[i]);\n\t      if (!p)\n\t\t{\n\t\t  queue_free(&q);\n\t\t  return pool_error(pool, -1, \"%s: unknown package '%s'\", caller, pieces[i]);\n\t\t}\n\t      queue_push(&q, p);\n\t    }\n\t}\n      what = pool_queuetowhatprovides(pool, &q);\n      queue_free(&q);\n    }\n  else if (!strcmp(pieces[0], \"repo\") && npieces == 2)\n    {\n      Repo *repo = testcase_str2repo(pool, pieces[1]);\n      if (!repo)\n\treturn pool_error(pool, -1, \"%s: unknown repo '%s'\", caller, pieces[1]);\n      job = SOLVER_SOLVABLE_REPO;\n      what = repo->repoid;\n    }\n  else if (!strcmp(pieces[0], \"all\") && npieces == 2 && !strcmp(pieces[1], \"packages\"))\n    {\n      job = SOLVER_SOLVABLE_ALL;\n      what = 0;\n    }\n  else\n    {\n      /* join em again for the error message... */\n      char *sp;\n      for (sp = pieces[0]; sp < pieces[npieces - 1]; sp++)\n\tif (*sp == 0)\n\t  *sp = ' ';\n      return pool_error(pool, -1, \"%s: bad line '%s'\", caller, pieces[0]);\n    }\n  *whatp = what;\n  return job;\n}",
        "commit_message": "testcase_read: error out if repos are added or the system is changed too late\n\nWe must not add new solvables after the considered map was created, the solver\nwas created, or jobs were added. We may not changed the system after jobs have\nbeen added.\n\n(Jobs may point inside the whatproviedes array, so we must not invalidate this\narea.)",
        "cve_desc": "Buffer overflow vulnerability in libsolv 2020-12-13 via the Solver * testcase_read(Pool *pool, FILE *fp, const char *testcase, Queue *job, char **resultp, int *resultflagsp function at src/testcase.c: line 2334, which could cause a denial of service",
        "target": 0
      },
      {
        "idx": 373559,
        "reasoning": "This code is likely addressing a previously identified vulnerability by enforcing constraints on when operations can be performed on the `jobqueue` and related data structures. The commit message explicitly states the goal of preventing modifications to these structures *after* critical stages like solver creation and job addition, which aligns with secure state management practices and mitigates potential issues like dangling pointers or invalid data access\u2014therefore, the code itself isn't inherently vulnerable but rather a fix for a potential vulnerability elsewhere.\n\n\n\n",
        "func": "addselectionjob(Pool *pool, char **pieces, int npieces, Queue *jobqueue, int type, int keyname)\n{\n  Id job;\n  int i, r = 0;\n  int selflags;\n  Queue sel;\n  char *sp;\n\n  for (i = 0; job2str[i].str; i++)\n    if (!strcmp(pieces[0], job2str[i].str))\n      break;\n  if (!job2str[i].str)\n    return pool_error(pool, -1, \"selstr2job: unknown job '%s'\", pieces[0]);\n  job = job2str[i].job;\n  if (npieces > 3)\n    {\n      char *flags = pieces[npieces - 1];\n      if (*flags == '[' && flags[strlen(flags) - 1] == ']')\n\t{\n\t  npieces--;\n\t  flags++;\n\t  flags[strlen(flags) - 1] = 0;\n\t  job |= str2jobflags(pool, flags);\n\t}\n    }\n  if (npieces < 4)\n    return pool_error(pool, -1, \"selstr2job: no selection flags\");\n  selflags = str2selflags(pool, pieces[npieces - 1]);\n  /* re-join pieces */\n  for (sp = pieces[2]; sp < pieces[npieces - 2]; sp++)\n    if (*sp == 0)\n      *sp = ' ';\n  queue_init(&sel);\n  if (selflags & (SELECTION_ADD | SELECTION_SUBTRACT | SELECTION_FILTER))\n    {\n      for (i = 0; i < jobqueue->count; i += 2)\n\tqueue_push2(&sel, jobqueue->elements[i] & (SOLVER_SELECTMASK | SOLVER_SETMASK), jobqueue->elements[i + 1]);\n      queue_empty(jobqueue);\n    }\n  if (!type)\n    r = selection_make(pool, &sel, pieces[2], selflags);\n  else if (type == SELECTIONJOB_MATCHDEPS)\n    r = selection_make_matchdeps(pool, &sel, pieces[2], selflags, keyname, 0);\n  else if (type == SELECTIONJOB_MATCHDEPID)\n    r = selection_make_matchdepid(pool, &sel, testcase_str2dep(pool, pieces[2]), selflags, keyname, 0);\n  else if (type == SELECTIONJOB_MATCHSOLVABLE)\n    r = selection_make_matchsolvable(pool, &sel, testcase_str2solvid(pool, pieces[2]), selflags, keyname, 0);\n  for (i = 0; i < sel.count; i += 2)\n    queue_push2(jobqueue, job | sel.elements[i], sel.elements[i + 1]);\n  queue_free(&sel);\n  return r;\n}",
        "commit_message": "testcase_read: error out if repos are added or the system is changed too late\n\nWe must not add new solvables after the considered map was created, the solver\nwas created, or jobs were added. We may not changed the system after jobs have\nbeen added.\n\n(Jobs may point inside the whatproviedes array, so we must not invalidate this\narea.)",
        "cve_desc": "Buffer overflow vulnerability in libsolv 2020-12-13 via the Solver * testcase_read(Pool *pool, FILE *fp, const char *testcase, Queue *job, char **resultp, int *resultflagsp function at src/testcase.c: line 2334, which could cause a denial of service",
        "target": 0
      }
    ],
    "1": []
  },
  "libssh": {
    "0": [
      {
        "idx": 498996,
        "reasoning": "This code snippet is not directly related to the CVE-2020-1730 fix concerning a potential segfault in AES-CTR key zeroing within libssh. The provided code focuses on finalizing a SHA384 hash digest using OpenSSL's EVP functions and doesn't handle any cryptographic key material or operations susceptible to the described vulnerability.\n\n\n\n",
        "func": "void sha384_final(unsigned char *md, SHA384CTX c)\n{\n    unsigned int mdlen = 0;\n\n    EVP_DigestFinal(c, md, &mdlen);\n    EVP_MD_CTX_destroy(c);\n}",
        "commit_message": "CVE-2020-1730: Fix a possible segfault when zeroing AES-CTR key\n\nFixes T213\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>",
        "cve_desc": "A flaw was found in libssh versions before 0.8.9 and before 0.9.4 in the way it handled AES-CTR (or DES ciphers if enabled) ciphers. The server or client could crash when the connection hasn't been fully initialized and the system tries to cleanup the ciphers when closing the connection. The biggest threat from this vulnerability is system availability.",
        "target": 0
      },
      {
        "idx": 498997,
        "reasoning": "This code snippet addresses a potential vulnerability by explicitly zeroing the AES key (`cipher->aes_key`) before freeing it, preventing sensitive data from lingering in memory. The fix directly targets the issue described in CVE-2020-1730 \u2013 a possible segfault related to uninitialized key data \u2013 and thus mitigates the risk of information leakage or further exploitation.\n",
        "func": "static void aes_ctr_cleanup(struct ssh_cipher_struct *cipher){\n    if (cipher != NULL) {\n        if (cipher->aes_key != NULL) {\n            explicit_bzero(cipher->aes_key, sizeof(*cipher->aes_key));\n        }\n        SAFE_FREE(cipher->aes_key);\n    }\n}",
        "commit_message": "CVE-2020-1730: Fix a possible segfault when zeroing AES-CTR key\n\nFixes T213\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>",
        "cve_desc": "A flaw was found in libssh versions before 0.8.9 and before 0.9.4 in the way it handled AES-CTR (or DES ciphers if enabled) ciphers. The server or client could crash when the connection hasn't been fully initialized and the system tries to cleanup the ciphers when closing the connection. The biggest threat from this vulnerability is system availability.",
        "target": 0
      },
      {
        "idx": 498998,
        "reasoning": "This code snippet is not directly related to the CVE-2020-1730 fix concerning AES-CTR key zeroing in libssh; it pertains to MD5 hash updates using OpenSSL's EVP functions. Therefore, based on the provided information, this code is not flagged as vulnerable as it addresses a different functionality than the identified security issue.\n\n\n\n",
        "func": "void md5_update(MD5CTX c, const void *data, unsigned long len)\n{\n    EVP_DigestUpdate(c, data, len);\n}",
        "commit_message": "CVE-2020-1730: Fix a possible segfault when zeroing AES-CTR key\n\nFixes T213\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>",
        "cve_desc": "A flaw was found in libssh versions before 0.8.9 and before 0.9.4 in the way it handled AES-CTR (or DES ciphers if enabled) ciphers. The server or client could crash when the connection hasn't been fully initialized and the system tries to cleanup the ciphers when closing the connection. The biggest threat from this vulnerability is system availability.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 216039,
        "reasoning": "This code is vulnerable because it attempts to zero the `aes_key` *after* potentially freeing the memory it points to with `SAFE_FREE`. If `cipher->aes_key` is freed, `explicit_bzero` will then operate on a dangling pointer, leading to a segmentation fault and causing a denial-of-service as described in the CVE.",
        "func": "static void aes_ctr_cleanup(struct ssh_cipher_struct *cipher){\n    explicit_bzero(cipher->aes_key, sizeof(*cipher->aes_key));\n    SAFE_FREE(cipher->aes_key);\n}",
        "commit_message": "CVE-2020-1730: Fix a possible segfault when zeroing AES-CTR key\n\nFixes T213\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>",
        "cve_desc": "A flaw was found in libssh versions before 0.8.9 and before 0.9.4 in the way it handled AES-CTR (or DES ciphers if enabled) ciphers. The server or client could crash when the connection hasn't been fully initialized and the system tries to cleanup the ciphers when closing the connection. The biggest threat from this vulnerability is system availability.",
        "target": 1
      },
      {
        "idx": 216737,
        "reasoning": "This code is vulnerable to command injection because the `location` parameter, directly provided by the user, is used in a server-side `scp` command without proper sanitization. An attacker could craft a malicious `location` string containing shell metacharacters to execute arbitrary commands on the server, leading to a remote code execution vulnerability as described in CVE-2019-14889.",
        "func": "ssh_scp ssh_scp_new(ssh_session session, int mode, const char *location){\n  ssh_scp scp=malloc(sizeof(struct ssh_scp_struct));\n  if(scp == NULL){\n    ssh_set_error(session,SSH_FATAL,\"Error allocating memory for ssh_scp\");\n    return NULL;\n  }\n  ZERO_STRUCTP(scp);\n  if((mode&~SSH_SCP_RECURSIVE) != SSH_SCP_WRITE && (mode &~SSH_SCP_RECURSIVE) != SSH_SCP_READ){\n    ssh_set_error(session,SSH_FATAL,\"Invalid mode %d for ssh_scp_new()\",mode);\n    ssh_scp_free(scp);\n    return NULL;\n  }\n  scp->location=strdup(location);\n  if (scp->location == NULL) {\n    ssh_set_error(session,SSH_FATAL,\"Error allocating memory for ssh_scp\");\n    ssh_scp_free(scp);\n    return NULL;\n  }\n  scp->session=session;\n  scp->mode=mode & ~SSH_SCP_RECURSIVE;\n  scp->recursive = (mode & SSH_SCP_RECURSIVE) != 0;\n  scp->channel=NULL;\n  scp->state=SSH_SCP_NEW;\n  return scp;\n}",
        "commit_message": "CVE-2019-14889: scp: Reformat scp.c\n\nFixes T181\n\nSigned-off-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Andreas Schneider <asn@cryptomilk.org>\n(cherry picked from commit 42c727d0c186a1e2fa84a31ab40e16e58b404ab3)",
        "cve_desc": "A flaw was found with the libssh API function ssh_scp_new() in versions before 0.9.3 and before 0.8.8. When the libssh SCP client connects to a server, the scp command, which includes a user-provided path, is executed on the server-side. In case the library is used in a way where users can influence the third parameter of the function, it would become possible for an attacker to inject arbitrary commands, leading to a compromise of the remote target.",
        "target": 1
      },
      {
        "idx": 216763,
        "reasoning": "This code is vulnerable because the `ssh_scp_new` function directly copies the user-provided `location` string into `scp->location` without any length validation, as highlighted by the CVE fix limiting path length. This allows an attacker to inject arbitrary commands into the `location` string, which are then executed on the server when the SCP command is processed, leading to potential remote code execution.",
        "func": "ssh_scp ssh_scp_new(ssh_session session, int mode, const char *location)\n{\n    ssh_scp scp = NULL;\n\n    if (session == NULL) {\n        goto error;\n    }\n\n    scp = (ssh_scp)calloc(1, sizeof(struct ssh_scp_struct));\n    if (scp == NULL) {\n        ssh_set_error(session, SSH_FATAL,\n                      \"Error allocating memory for ssh_scp\");\n        goto error;\n    }\n\n    if ((mode & ~SSH_SCP_RECURSIVE) != SSH_SCP_WRITE &&\n        (mode & ~SSH_SCP_RECURSIVE) != SSH_SCP_READ)\n    {\n        ssh_set_error(session, SSH_FATAL,\n                      \"Invalid mode %d for ssh_scp_new()\", mode);\n        goto error;\n    }\n\n    scp->location = strdup(location);\n    if (scp->location == NULL) {\n        ssh_set_error(session, SSH_FATAL,\n                      \"Error allocating memory for ssh_scp\");\n        goto error;\n    }\n\n    scp->session = session;\n    scp->mode = mode & ~SSH_SCP_RECURSIVE;\n    scp->recursive = (mode & SSH_SCP_RECURSIVE) != 0;\n    scp->channel = NULL;\n    scp->state = SSH_SCP_NEW;\n\n    return scp;\n\nerror:\n    ssh_scp_free(scp);\n    return NULL;\n}",
        "commit_message": "CVE-2019-14889: scp: Don't allow file path longer than 32kb\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>\n(cherry picked from commit 0b5ee397260b6e08dffa2c1ce515a153aaeda765)",
        "cve_desc": "A flaw was found with the libssh API function ssh_scp_new() in versions before 0.9.3 and before 0.8.8. When the libssh SCP client connects to a server, the scp command, which includes a user-provided path, is executed on the server-side. In case the library is used in a way where users can influence the third parameter of the function, it would become possible for an attacker to inject arbitrary commands, leading to a compromise of the remote target.",
        "target": 1
      },
      {
        "idx": 216764,
        "reasoning": "This code is vulnerable to command injection because the `scp->location` variable, which is user-controlled, is directly incorporated into the `execbuffer` string without proper sanitization or quoting. An attacker can craft a malicious `scp->location` containing shell metacharacters to execute arbitrary commands on the remote server when the `execbuffer` is executed via `ssh_channel_request_exec`.",
        "func": "int ssh_scp_init(ssh_scp scp)\n{\n    int rc;\n    char execbuffer[1024] = {0};\n\n    if (scp == NULL) {\n        return SSH_ERROR;\n    }\n\n    if (scp->state != SSH_SCP_NEW) {\n        ssh_set_error(scp->session, SSH_FATAL,\n                      \"ssh_scp_init called under invalid state\");\n        return SSH_ERROR;\n    }\n\n    SSH_LOG(SSH_LOG_PROTOCOL,\n            \"Initializing scp session %s %son location '%s'\",\n            scp->mode == SSH_SCP_WRITE?\"write\":\"read\",\n            scp->recursive?\"recursive \":\"\",\n            scp->location);\n\n    scp->channel = ssh_channel_new(scp->session);\n    if (scp->channel == NULL) {\n        scp->state = SSH_SCP_ERROR;\n        return SSH_ERROR;\n    }\n\n    rc = ssh_channel_open_session(scp->channel);\n    if (rc == SSH_ERROR) {\n        scp->state = SSH_SCP_ERROR;\n        return SSH_ERROR;\n    }\n\n    if (scp->mode == SSH_SCP_WRITE) {\n        snprintf(execbuffer, sizeof(execbuffer), \"scp -t %s %s\",\n                scp->recursive ? \"-r\":\"\", scp->location);\n    } else {\n        snprintf(execbuffer, sizeof(execbuffer), \"scp -f %s %s\",\n                scp->recursive ? \"-r\":\"\", scp->location);\n    }\n\n    if (ssh_channel_request_exec(scp->channel, execbuffer) == SSH_ERROR) {\n        scp->state = SSH_SCP_ERROR;\n        return SSH_ERROR;\n    }\n\n    if (scp->mode == SSH_SCP_WRITE) {\n        rc = ssh_scp_response(scp, NULL);\n        if (rc != 0) {\n            return SSH_ERROR;\n        }\n    } else {\n        ssh_channel_write(scp->channel, \"\", 1);\n    }\n\n    if (scp->mode == SSH_SCP_WRITE) {\n        scp->state = SSH_SCP_WRITE_INITED;\n    } else {\n        scp->state = SSH_SCP_READ_INITED;\n    }\n\n    return SSH_OK;\n}",
        "commit_message": "CVE-2019-14889: scp: Quote location to be used on shell\n\nSingle quote file paths to be used on commands to be executed on remote\nshell.\n\nFixes T181\n\nSigned-off-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Andreas Schneider <asn@cryptomilk.org>\n(cherry picked from commit 3830c7ae6eec751b7618d3fc159cb5bb3c8806a6)",
        "cve_desc": "A flaw was found with the libssh API function ssh_scp_new() in versions before 0.9.3 and before 0.8.8. When the libssh SCP client connects to a server, the scp command, which includes a user-provided path, is executed on the server-side. In case the library is used in a way where users can influence the third parameter of the function, it would become possible for an attacker to inject arbitrary commands, leading to a compromise of the remote target.",
        "target": 1
      }
    ]
  },
  "libssh-mirror": {
    "0": [
      {
        "idx": 352837,
        "reasoning": "This code snippet is not vulnerable because it simply returns a value from a struct member. The commit message and description relate to a fix in `sftpserver` involving `ssh_buffer_new()`, which is entirely unrelated to the provided `sftp_client_message_get_flags` function and doesn't introduce any potential security issues like null pointer dereferences or buffer overflows.\n\n\n\n",
        "func": "uint32_t sftp_client_message_get_flags(sftp_client_message msg){\n\treturn msg->flags;\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 0
      },
      {
        "idx": 352838,
        "reasoning": "This code is safe and addresses a potential vulnerability. The commit explicitly adds a NULL check for the `ssh_buffer_new()` function, preventing a potential crash or undefined behavior if memory allocation fails, which was the issue reported in T232. \n\n\n\n",
        "func": "int sftp_reply_handle(sftp_client_message msg, ssh_string handle){\n  ssh_buffer out;\n\n  out = ssh_buffer_new();\n  if (out == NULL) {\n    return -1;\n  }\n\n  if (ssh_buffer_add_u32(out, msg->id) < 0 ||\n      ssh_buffer_add_ssh_string(out, handle) < 0 ||\n      sftp_packet_write(msg->sftp, SSH_FXP_HANDLE, out) < 0) {\n    SSH_BUFFER_FREE(out);\n    return -1;\n  }\n  SSH_BUFFER_FREE(out);\n\n  return 0;\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 0
      },
      {
        "idx": 352839,
        "reasoning": "This code is safe and addresses a potential vulnerability. The commit explicitly adds a NULL check for the `ssh_buffer_new()` function, preventing a potential crash or undefined behavior if memory allocation fails, which was the issue reported in T232. \n\n\n\n",
        "func": "int sftp_reply_data(sftp_client_message msg, const void *data, int len) {\n  ssh_buffer out;\n\n  out = ssh_buffer_new();\n  if (out == NULL) {\n    return -1;\n  }\n\n  if (ssh_buffer_add_u32(out, msg->id) < 0 ||\n      ssh_buffer_add_u32(out, ntohl(len)) < 0 ||\n      ssh_buffer_add_data(out, data, len) < 0 ||\n      sftp_packet_write(msg->sftp, SSH_FXP_DATA, out) < 0) {\n    SSH_BUFFER_FREE(out);\n    return -1;\n  }\n  SSH_BUFFER_FREE(out);\n\n  return 0;\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 0
      },
      {
        "idx": 352840,
        "reasoning": "This code snippet is not directly vulnerable to the issue the commit message addresses (a missing NULL check for `ssh_buffer_new()`). The provided code focuses on handling existing SFTP handles and validating their index, not on creating new SSH buffers, therefore it's not impacted by potential failures in buffer allocation. \n\n\n\n",
        "func": "void *sftp_handle(sftp_session sftp, ssh_string handle){\n  uint32_t val;\n\n  if (sftp->handles == NULL) {\n    return NULL;\n  }\n\n  if (ssh_string_len(handle) != sizeof(uint32_t)) {\n    return NULL;\n  }\n\n  memcpy(&val, ssh_string_data(handle), sizeof(uint32_t));\n\n  if (val > SFTP_HANDLES) {\n    return NULL;\n  }\n\n  return sftp->handles[val];\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 0
      },
      {
        "idx": 352841,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message details a fix in a different part of the `libssh-mirror` project (`ssh_buffer_new()`) and doesn't relate to the functionality shown in `sftp_send_client_message()`, which simply calls another function with message data. \n\n\n\n",
        "func": "int sftp_send_client_message(sftp_session sftp, sftp_client_message msg){\n\treturn sftp_packet_write(sftp, msg->type, msg->complete_message);\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 204106,
        "reasoning": "This code is vulnerable to a NULL pointer dereference because `ssh_buffer_new()` can return NULL, and the code doesn't check for this before attempting to use the returned pointer (`msg->complete_message`).  Similar to the CVE description, failing to validate the return value of `ssh_buffer_new()` leads to a potential crash if memory allocation fails, as the code proceeds to operate on a null pointer.\n",
        "func": "sftp_client_message sftp_get_client_message(sftp_session sftp) {\n  ssh_session session = sftp->session;\n  sftp_packet packet;\n  sftp_client_message msg;\n  ssh_buffer payload;\n  int rc;\n\n  msg = malloc(sizeof (struct sftp_client_message_struct));\n  if (msg == NULL) {\n    ssh_set_error_oom(session);\n    return NULL;\n  }\n  ZERO_STRUCTP(msg);\n\n  packet = sftp_packet_read(sftp);\n  if (packet == NULL) {\n    ssh_set_error_oom(session);\n    sftp_client_message_free(msg);\n    return NULL;\n  }\n\n  payload = packet->payload;\n  msg->type = packet->type;\n  msg->sftp = sftp;\n\n  /* take a copy of the whole packet */\n  msg->complete_message = ssh_buffer_new();\n  ssh_buffer_add_data(msg->complete_message,\n                      ssh_buffer_get(payload),\n                      ssh_buffer_get_len(payload));\n\n  ssh_buffer_get_u32(payload, &msg->id);\n\n  switch(msg->type) {\n    case SSH_FXP_CLOSE:\n    case SSH_FXP_READDIR:\n      msg->handle = ssh_buffer_get_ssh_string(payload);\n      if (msg->handle == NULL) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_READ:\n      rc = ssh_buffer_unpack(payload,\n                             \"Sqd\",\n                             &msg->handle,\n                             &msg->offset,\n                             &msg->len);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_WRITE:\n      rc = ssh_buffer_unpack(payload,\n                             \"SqS\",\n                             &msg->handle,\n                             &msg->offset,\n                             &msg->data);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_REMOVE:\n    case SSH_FXP_RMDIR:\n    case SSH_FXP_OPENDIR:\n    case SSH_FXP_READLINK:\n    case SSH_FXP_REALPATH:\n      rc = ssh_buffer_unpack(payload,\n                             \"s\",\n                             &msg->filename);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_RENAME:\n    case SSH_FXP_SYMLINK:\n      rc = ssh_buffer_unpack(payload,\n                             \"sS\",\n                             &msg->filename,\n                             &msg->data);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_MKDIR:\n    case SSH_FXP_SETSTAT:\n      rc = ssh_buffer_unpack(payload,\n                             \"s\",\n                             &msg->filename);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      msg->attr = sftp_parse_attr(sftp, payload, 0);\n      if (msg->attr == NULL) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_FSETSTAT:\n      msg->handle = ssh_buffer_get_ssh_string(payload);\n      if (msg->handle == NULL) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      msg->attr = sftp_parse_attr(sftp, payload, 0);\n      if (msg->attr == NULL) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_LSTAT:\n    case SSH_FXP_STAT:\n      rc = ssh_buffer_unpack(payload,\n                             \"s\",\n                             &msg->filename);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      if(sftp->version > 3) {\n        ssh_buffer_unpack(payload, \"d\", &msg->flags);\n      }\n      break;\n    case SSH_FXP_OPEN:\n      rc = ssh_buffer_unpack(payload,\n                             \"sd\",\n                             &msg->filename,\n                             &msg->flags);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      msg->attr = sftp_parse_attr(sftp, payload, 0);\n      if (msg->attr == NULL) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_FSTAT:\n      rc = ssh_buffer_unpack(payload,\n                             \"S\",\n                             &msg->handle);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n      break;\n    case SSH_FXP_EXTENDED:\n      rc = ssh_buffer_unpack(payload,\n                             \"s\",\n                             &msg->submessage);\n      if (rc != SSH_OK) {\n        ssh_set_error_oom(session);\n        sftp_client_message_free(msg);\n        return NULL;\n      }\n\n      if (strcmp(msg->submessage, \"hardlink@openssh.com\") == 0 ||\n          strcmp(msg->submessage, \"posix-rename@openssh.com\") == 0) {\n        rc = ssh_buffer_unpack(payload,\n                               \"sS\",\n                               &msg->filename,\n                               &msg->data);\n        if (rc != SSH_OK) {\n          ssh_set_error_oom(session);\n          sftp_client_message_free(msg);\n          return NULL;\n        }\n      }\n      break;\n    default:\n      ssh_set_error(sftp->session, SSH_FATAL,\n                    \"Received unhandled sftp message %d\", msg->type);\n      sftp_client_message_free(msg);\n      return NULL;\n  }\n\n  return msg;\n}",
        "commit_message": "sftpserver: Add missing NULL check for ssh_buffer_new()\n\nThanks to Ramin Farajpour Cami for spotting this.\n\nFixes T232\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 1
      },
      {
        "idx": 210374,
        "reasoning": "This code is vulnerable to a NULL pointer dereference because while it checks if the `data` argument is NULL, it *doesn't* check if the `buffer` argument itself is NULL after the `buffer_verify` call. If `buffer_verify` fails to validate the buffer (potentially returning without dereferencing it) or if a prior operation set `buffer` to NULL, subsequent operations like `buffer->used + len` and `buffer->data + buffer->used` will cause a crash, mirroring the vulnerability described in the CVE.",
        "func": "int ssh_buffer_add_data(struct ssh_buffer_struct *buffer, const void *data, uint32_t len)\n{\n    buffer_verify(buffer);\n\n    if (data == NULL) {\n        return -1;\n    }\n\n    if (buffer->used + len < len) {\n        return -1;\n    }\n\n    if (buffer->allocated < (buffer->used + len)) {\n        if (buffer->pos > 0) {\n            buffer_shift(buffer);\n        }\n        if (realloc_buffer(buffer, buffer->used + len) < 0) {\n            return -1;\n        }\n    }\n\n    memcpy(buffer->data + buffer->used, data, len);\n    buffer->used += len;\n    buffer_verify(buffer);\n    return 0;\n}",
        "commit_message": "buffer: Add NULL check for 'buffer' argument\n\nSigned-off-by: Andreas Schneider <asn@cryptomilk.org>\nReviewed-by: Anderson Toshiyuki Sasaki <ansasaki@redhat.com>\nReviewed-by: Jakub Jelen <jjelen@redhat.com>",
        "cve_desc": "libssh 0.9.4 has a NULL pointer dereference in tftpserver.c if ssh_buffer_new returns NULL.",
        "target": 1
      }
    ]
  },
  "libssh2": {
    "0": [
      {
        "idx": 388799,
        "reasoning": "This code was the source of CVE-2016-0787, but the commit message explicitly states that this commit *addresses* the vulnerability by converting bytes to bits to ensure sufficiently large numbers are used in calculations. Therefore, while the original code *was* vulnerable, this specific snippet represents a fix and is not currently flagged as vulnerable.",
        "func": "static int diffie_hellman_sha1(LIBSSH2_SESSION *session,\n                               _libssh2_bn *g,\n                               _libssh2_bn *p,\n                               int group_order,\n                               unsigned char packet_type_init,\n                               unsigned char packet_type_reply,\n                               unsigned char *midhash,\n                               unsigned long midhash_len,\n                               kmdhgGPshakex_state_t *exchange_state)\n{\n    int ret = 0;\n    int rc;\n    libssh2_sha1_ctx exchange_hash_ctx;\n\n    if (exchange_state->state == libssh2_NB_state_idle) {\n        /* Setup initial values */\n        exchange_state->e_packet = NULL;\n        exchange_state->s_packet = NULL;\n        exchange_state->k_value = NULL;\n        exchange_state->ctx = _libssh2_bn_ctx_new();\n        exchange_state->x = _libssh2_bn_init(); /* Random from client */\n        exchange_state->e = _libssh2_bn_init(); /* g^x mod p */\n        exchange_state->f = _libssh2_bn_init_from_bin(); /* g^(Random from server) mod p */\n        exchange_state->k = _libssh2_bn_init(); /* The shared secret: f^x mod p */\n\n        /* Zero the whole thing out */\n        memset(&exchange_state->req_state, 0, sizeof(packet_require_state_t));\n\n        /* Generate x and e */\n        _libssh2_bn_rand(exchange_state->x, group_order, 0, -1);\n        _libssh2_bn_mod_exp(exchange_state->e, g, exchange_state->x, p,\n                            exchange_state->ctx);\n\n        /* Send KEX init */\n        /* packet_type(1) + String Length(4) + leading 0(1) */\n        exchange_state->e_packet_len =\n            _libssh2_bn_bytes(exchange_state->e) + 6;\n        if (_libssh2_bn_bits(exchange_state->e) % 8) {\n            /* Leading 00 not needed */\n            exchange_state->e_packet_len--;\n        }\n\n        exchange_state->e_packet =\n            LIBSSH2_ALLOC(session, exchange_state->e_packet_len);\n        if (!exchange_state->e_packet) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_ALLOC,\n                                 \"Out of memory error\");\n            goto clean_exit;\n        }\n        exchange_state->e_packet[0] = packet_type_init;\n        _libssh2_htonu32(exchange_state->e_packet + 1,\n                         exchange_state->e_packet_len - 5);\n        if (_libssh2_bn_bits(exchange_state->e) % 8) {\n            _libssh2_bn_to_bin(exchange_state->e,\n                               exchange_state->e_packet + 5);\n        } else {\n            exchange_state->e_packet[5] = 0;\n            _libssh2_bn_to_bin(exchange_state->e,\n                               exchange_state->e_packet + 6);\n        }\n\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX, \"Sending KEX packet %d\",\n                       (int) packet_type_init);\n        exchange_state->state = libssh2_NB_state_created;\n    }\n\n    if (exchange_state->state == libssh2_NB_state_created) {\n        rc = _libssh2_transport_send(session, exchange_state->e_packet,\n                                     exchange_state->e_packet_len,\n                                     NULL, 0);\n        if (rc == LIBSSH2_ERROR_EAGAIN) {\n            return rc;\n        } else if (rc) {\n            ret = _libssh2_error(session, rc,\n                                 \"Unable to send KEX init message\");\n            goto clean_exit;\n        }\n        exchange_state->state = libssh2_NB_state_sent;\n    }\n\n    if (exchange_state->state == libssh2_NB_state_sent) {\n        if (session->burn_optimistic_kexinit) {\n            /* The first KEX packet to come along will be the guess initially\n             * sent by the server.  That guess turned out to be wrong so we\n             * need to silently ignore it */\n            int burn_type;\n\n            _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                           \"Waiting for badly guessed KEX packet (to be ignored)\");\n            burn_type =\n                _libssh2_packet_burn(session, &exchange_state->burn_state);\n            if (burn_type == LIBSSH2_ERROR_EAGAIN) {\n                return burn_type;\n            } else if (burn_type <= 0) {\n                /* Failed to receive a packet */\n                ret = burn_type;\n                goto clean_exit;\n            }\n            session->burn_optimistic_kexinit = 0;\n\n            _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                           \"Burnt packet of type: %02x\",\n                           (unsigned int) burn_type);\n        }\n\n        exchange_state->state = libssh2_NB_state_sent1;\n    }\n\n    if (exchange_state->state == libssh2_NB_state_sent1) {\n        /* Wait for KEX reply */\n        rc = _libssh2_packet_require(session, packet_type_reply,\n                                     &exchange_state->s_packet,\n                                     &exchange_state->s_packet_len, 0, NULL,\n                                     0, &exchange_state->req_state);\n        if (rc == LIBSSH2_ERROR_EAGAIN) {\n            return rc;\n        }\n        if (rc) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_TIMEOUT,\n                                 \"Timed out waiting for KEX reply\");\n            goto clean_exit;\n        }\n\n        /* Parse KEXDH_REPLY */\n        exchange_state->s = exchange_state->s_packet + 1;\n\n        session->server_hostkey_len = _libssh2_ntohu32(exchange_state->s);\n        exchange_state->s += 4;\n\n        if (session->server_hostkey)\n            LIBSSH2_FREE(session, session->server_hostkey);\n\n        session->server_hostkey =\n            LIBSSH2_ALLOC(session, session->server_hostkey_len);\n        if (!session->server_hostkey) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_ALLOC,\n                                 \"Unable to allocate memory for a copy \"\n                                 \"of the host key\");\n            goto clean_exit;\n        }\n        memcpy(session->server_hostkey, exchange_state->s,\n               session->server_hostkey_len);\n        exchange_state->s += session->server_hostkey_len;\n\n#if LIBSSH2_MD5\n        {\n            libssh2_md5_ctx fingerprint_ctx;\n\n            if (libssh2_md5_init(&fingerprint_ctx)) {\n                libssh2_md5_update(fingerprint_ctx, session->server_hostkey,\n                                   session->server_hostkey_len);\n                libssh2_md5_final(fingerprint_ctx,\n                                  session->server_hostkey_md5);\n                session->server_hostkey_md5_valid = TRUE;\n            }\n            else {\n                session->server_hostkey_md5_valid = FALSE;\n            }\n        }\n#ifdef LIBSSH2DEBUG\n        {\n            char fingerprint[50], *fprint = fingerprint;\n            int i;\n            for(i = 0; i < 16; i++, fprint += 3) {\n                snprintf(fprint, 4, \"%02x:\", session->server_hostkey_md5[i]);\n            }\n            *(--fprint) = '\\0';\n            _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                           \"Server's MD5 Fingerprint: %s\", fingerprint);\n        }\n#endif /* LIBSSH2DEBUG */\n#endif /* ! LIBSSH2_MD5 */\n\n        {\n            libssh2_sha1_ctx fingerprint_ctx;\n\n            if (libssh2_sha1_init(&fingerprint_ctx)) {\n                libssh2_sha1_update(fingerprint_ctx, session->server_hostkey,\n                                    session->server_hostkey_len);\n                libssh2_sha1_final(fingerprint_ctx,\n                                   session->server_hostkey_sha1);\n                session->server_hostkey_sha1_valid = TRUE;\n            }\n            else {\n                session->server_hostkey_sha1_valid = FALSE;\n            }\n        }\n#ifdef LIBSSH2DEBUG\n        {\n            char fingerprint[64], *fprint = fingerprint;\n            int i;\n\n            for(i = 0; i < 20; i++, fprint += 3) {\n                snprintf(fprint, 4, \"%02x:\", session->server_hostkey_sha1[i]);\n            }\n            *(--fprint) = '\\0';\n            _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                           \"Server's SHA1 Fingerprint: %s\", fingerprint);\n        }\n#endif /* LIBSSH2DEBUG */\n\n        if (session->hostkey->init(session, session->server_hostkey,\n                                   session->server_hostkey_len,\n                                   &session->server_hostkey_abstract)) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_HOSTKEY_INIT,\n                                 \"Unable to initialize hostkey importer\");\n            goto clean_exit;\n        }\n\n        exchange_state->f_value_len = _libssh2_ntohu32(exchange_state->s);\n        exchange_state->s += 4;\n        exchange_state->f_value = exchange_state->s;\n        exchange_state->s += exchange_state->f_value_len;\n        _libssh2_bn_from_bin(exchange_state->f, exchange_state->f_value_len,\n                             exchange_state->f_value);\n\n        exchange_state->h_sig_len = _libssh2_ntohu32(exchange_state->s);\n        exchange_state->s += 4;\n        exchange_state->h_sig = exchange_state->s;\n\n        /* Compute the shared secret */\n        _libssh2_bn_mod_exp(exchange_state->k, exchange_state->f,\n                            exchange_state->x, p, exchange_state->ctx);\n        exchange_state->k_value_len = _libssh2_bn_bytes(exchange_state->k) + 5;\n        if (_libssh2_bn_bits(exchange_state->k) % 8) {\n            /* don't need leading 00 */\n            exchange_state->k_value_len--;\n        }\n        exchange_state->k_value =\n            LIBSSH2_ALLOC(session, exchange_state->k_value_len);\n        if (!exchange_state->k_value) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_ALLOC,\n                                 \"Unable to allocate buffer for K\");\n            goto clean_exit;\n        }\n        _libssh2_htonu32(exchange_state->k_value,\n                         exchange_state->k_value_len - 4);\n        if (_libssh2_bn_bits(exchange_state->k) % 8) {\n            _libssh2_bn_to_bin(exchange_state->k, exchange_state->k_value + 4);\n        } else {\n            exchange_state->k_value[4] = 0;\n            _libssh2_bn_to_bin(exchange_state->k, exchange_state->k_value + 5);\n        }\n\n        exchange_state->exchange_hash = (void*)&exchange_hash_ctx;\n        libssh2_sha1_init(&exchange_hash_ctx);\n\n        if (session->local.banner) {\n            _libssh2_htonu32(exchange_state->h_sig_comp,\n                             strlen((char *) session->local.banner) - 2);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                exchange_state->h_sig_comp, 4);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                (char *) session->local.banner,\n                                strlen((char *) session->local.banner) - 2);\n        } else {\n            _libssh2_htonu32(exchange_state->h_sig_comp,\n                             sizeof(LIBSSH2_SSH_DEFAULT_BANNER) - 1);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                exchange_state->h_sig_comp, 4);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                LIBSSH2_SSH_DEFAULT_BANNER,\n                                sizeof(LIBSSH2_SSH_DEFAULT_BANNER) - 1);\n        }\n\n        _libssh2_htonu32(exchange_state->h_sig_comp,\n                         strlen((char *) session->remote.banner));\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->h_sig_comp, 4);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            session->remote.banner,\n                            strlen((char *) session->remote.banner));\n\n        _libssh2_htonu32(exchange_state->h_sig_comp,\n                         session->local.kexinit_len);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->h_sig_comp, 4);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            session->local.kexinit,\n                            session->local.kexinit_len);\n\n        _libssh2_htonu32(exchange_state->h_sig_comp,\n                         session->remote.kexinit_len);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->h_sig_comp, 4);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            session->remote.kexinit,\n                            session->remote.kexinit_len);\n\n        _libssh2_htonu32(exchange_state->h_sig_comp,\n                         session->server_hostkey_len);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->h_sig_comp, 4);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            session->server_hostkey,\n                            session->server_hostkey_len);\n\n        if (packet_type_init == SSH_MSG_KEX_DH_GEX_INIT) {\n            /* diffie-hellman-group-exchange hashes additional fields */\n#ifdef LIBSSH2_DH_GEX_NEW\n            _libssh2_htonu32(exchange_state->h_sig_comp,\n                             LIBSSH2_DH_GEX_MINGROUP);\n            _libssh2_htonu32(exchange_state->h_sig_comp + 4,\n                             LIBSSH2_DH_GEX_OPTGROUP);\n            _libssh2_htonu32(exchange_state->h_sig_comp + 8,\n                             LIBSSH2_DH_GEX_MAXGROUP);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                exchange_state->h_sig_comp, 12);\n#else\n            _libssh2_htonu32(exchange_state->h_sig_comp,\n                             LIBSSH2_DH_GEX_OPTGROUP);\n            libssh2_sha1_update(exchange_hash_ctx,\n                                exchange_state->h_sig_comp, 4);\n#endif\n        }\n\n        if (midhash) {\n            libssh2_sha1_update(exchange_hash_ctx, midhash,\n                                midhash_len);\n        }\n\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->e_packet + 1,\n                            exchange_state->e_packet_len - 1);\n\n        _libssh2_htonu32(exchange_state->h_sig_comp,\n                         exchange_state->f_value_len);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->h_sig_comp, 4);\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->f_value,\n                            exchange_state->f_value_len);\n\n        libssh2_sha1_update(exchange_hash_ctx,\n                            exchange_state->k_value,\n                            exchange_state->k_value_len);\n\n        libssh2_sha1_final(exchange_hash_ctx,\n                           exchange_state->h_sig_comp);\n\n        if (session->hostkey->\n            sig_verify(session, exchange_state->h_sig,\n                       exchange_state->h_sig_len, exchange_state->h_sig_comp,\n                       20, &session->server_hostkey_abstract)) {\n            ret = _libssh2_error(session, LIBSSH2_ERROR_HOSTKEY_SIGN,\n                                 \"Unable to verify hostkey signature\");\n            goto clean_exit;\n        }\n\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX, \"Sending NEWKEYS message\");\n        exchange_state->c = SSH_MSG_NEWKEYS;\n\n        exchange_state->state = libssh2_NB_state_sent2;\n    }\n\n    if (exchange_state->state == libssh2_NB_state_sent2) {\n        rc = _libssh2_transport_send(session, &exchange_state->c, 1, NULL, 0);\n        if (rc == LIBSSH2_ERROR_EAGAIN) {\n            return rc;\n        } else if (rc) {\n            ret = _libssh2_error(session, rc, \"Unable to send NEWKEYS message\");\n            goto clean_exit;\n        }\n\n        exchange_state->state = libssh2_NB_state_sent3;\n    }\n\n    if (exchange_state->state == libssh2_NB_state_sent3) {\n        rc = _libssh2_packet_require(session, SSH_MSG_NEWKEYS,\n                                     &exchange_state->tmp,\n                                     &exchange_state->tmp_len, 0, NULL, 0,\n                                     &exchange_state->req_state);\n        if (rc == LIBSSH2_ERROR_EAGAIN) {\n            return rc;\n        } else if (rc) {\n            ret = _libssh2_error(session, rc, \"Timed out waiting for NEWKEYS\");\n            goto clean_exit;\n        }\n        /* The first key exchange has been performed,\n           switch to active crypt/comp/mac mode */\n        session->state |= LIBSSH2_STATE_NEWKEYS;\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX, \"Received NEWKEYS message\");\n\n        /* This will actually end up being just packet_type(1)\n           for this packet type anyway */\n        LIBSSH2_FREE(session, exchange_state->tmp);\n\n        if (!session->session_id) {\n            session->session_id = LIBSSH2_ALLOC(session, SHA_DIGEST_LENGTH);\n            if (!session->session_id) {\n                ret = _libssh2_error(session, LIBSSH2_ERROR_ALLOC,\n                                     \"Unable to allocate buffer for SHA digest\");\n                goto clean_exit;\n            }\n            memcpy(session->session_id, exchange_state->h_sig_comp,\n                   SHA_DIGEST_LENGTH);\n            session->session_id_len = SHA_DIGEST_LENGTH;\n            _libssh2_debug(session, LIBSSH2_TRACE_KEX, \"session_id calculated\");\n        }\n\n        /* Cleanup any existing cipher */\n        if (session->local.crypt->dtor) {\n            session->local.crypt->dtor(session,\n                                       &session->local.crypt_abstract);\n        }\n\n        /* Calculate IV/Secret/Key for each direction */\n        if (session->local.crypt->init) {\n            unsigned char *iv = NULL, *secret = NULL;\n            int free_iv = 0, free_secret = 0;\n\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(iv,\n                                                        session->local.crypt->\n                                                        iv_len, \"A\");\n            if (!iv) {\n                ret = -1;\n                goto clean_exit;\n            }\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(secret,\n                                                        session->local.crypt->\n                                                        secret_len, \"C\");\n            if (!secret) {\n                LIBSSH2_FREE(session, iv);\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n            if (session->local.crypt->\n                init(session, session->local.crypt, iv, &free_iv, secret,\n                     &free_secret, 1, &session->local.crypt_abstract)) {\n                LIBSSH2_FREE(session, iv);\n                LIBSSH2_FREE(session, secret);\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n\n            if (free_iv) {\n                memset(iv, 0, session->local.crypt->iv_len);\n                LIBSSH2_FREE(session, iv);\n            }\n\n            if (free_secret) {\n                memset(secret, 0, session->local.crypt->secret_len);\n                LIBSSH2_FREE(session, secret);\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Client to Server IV and Key calculated\");\n\n        if (session->remote.crypt->dtor) {\n            /* Cleanup any existing cipher */\n            session->remote.crypt->dtor(session,\n                                        &session->remote.crypt_abstract);\n        }\n\n        if (session->remote.crypt->init) {\n            unsigned char *iv = NULL, *secret = NULL;\n            int free_iv = 0, free_secret = 0;\n\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(iv,\n                                                        session->remote.crypt->\n                                                        iv_len, \"B\");\n            if (!iv) {\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(secret,\n                                                        session->remote.crypt->\n                                                        secret_len, \"D\");\n            if (!secret) {\n                LIBSSH2_FREE(session, iv);\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n            if (session->remote.crypt->\n                init(session, session->remote.crypt, iv, &free_iv, secret,\n                     &free_secret, 0, &session->remote.crypt_abstract)) {\n                LIBSSH2_FREE(session, iv);\n                LIBSSH2_FREE(session, secret);\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n\n            if (free_iv) {\n                memset(iv, 0, session->remote.crypt->iv_len);\n                LIBSSH2_FREE(session, iv);\n            }\n\n            if (free_secret) {\n                memset(secret, 0, session->remote.crypt->secret_len);\n                LIBSSH2_FREE(session, secret);\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Server to Client IV and Key calculated\");\n\n        if (session->local.mac->dtor) {\n            session->local.mac->dtor(session, &session->local.mac_abstract);\n        }\n\n        if (session->local.mac->init) {\n            unsigned char *key = NULL;\n            int free_key = 0;\n\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(key,\n                                                        session->local.mac->\n                                                        key_len, \"E\");\n            if (!key) {\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n            session->local.mac->init(session, key, &free_key,\n                                     &session->local.mac_abstract);\n\n            if (free_key) {\n                memset(key, 0, session->local.mac->key_len);\n                LIBSSH2_FREE(session, key);\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Client to Server HMAC Key calculated\");\n\n        if (session->remote.mac->dtor) {\n            session->remote.mac->dtor(session, &session->remote.mac_abstract);\n        }\n\n        if (session->remote.mac->init) {\n            unsigned char *key = NULL;\n            int free_key = 0;\n\n            LIBSSH2_KEX_METHOD_DIFFIE_HELLMAN_SHA1_HASH(key,\n                                                        session->remote.mac->\n                                                        key_len, \"F\");\n            if (!key) {\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n            session->remote.mac->init(session, key, &free_key,\n                                      &session->remote.mac_abstract);\n\n            if (free_key) {\n                memset(key, 0, session->remote.mac->key_len);\n                LIBSSH2_FREE(session, key);\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Server to Client HMAC Key calculated\");\n\n        /* Initialize compression for each direction */\n\n        /* Cleanup any existing compression */\n        if (session->local.comp && session->local.comp->dtor) {\n            session->local.comp->dtor(session, 1,\n                                      &session->local.comp_abstract);\n        }\n\n        if (session->local.comp && session->local.comp->init) {\n            if (session->local.comp->init(session, 1,\n                                          &session->local.comp_abstract)) {\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Client to Server compression initialized\");\n\n        if (session->remote.comp && session->remote.comp->dtor) {\n            session->remote.comp->dtor(session, 0,\n                                       &session->remote.comp_abstract);\n        }\n\n        if (session->remote.comp && session->remote.comp->init) {\n            if (session->remote.comp->init(session, 0,\n                                           &session->remote.comp_abstract)) {\n                ret = LIBSSH2_ERROR_KEX_FAILURE;\n                goto clean_exit;\n            }\n        }\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Server to Client compression initialized\");\n\n    }\n\n  clean_exit:\n    _libssh2_bn_free(exchange_state->x);\n    exchange_state->x = NULL;\n    _libssh2_bn_free(exchange_state->e);\n    exchange_state->e = NULL;\n    _libssh2_bn_free(exchange_state->f);\n    exchange_state->f = NULL;\n    _libssh2_bn_free(exchange_state->k);\n    exchange_state->k = NULL;\n    _libssh2_bn_ctx_free(exchange_state->ctx);\n    exchange_state->ctx = NULL;\n\n    if (exchange_state->e_packet) {\n        LIBSSH2_FREE(session, exchange_state->e_packet);\n        exchange_state->e_packet = NULL;\n    }\n\n    if (exchange_state->s_packet) {\n        LIBSSH2_FREE(session, exchange_state->s_packet);\n        exchange_state->s_packet = NULL;\n    }\n\n    if (exchange_state->k_value) {\n        LIBSSH2_FREE(session, exchange_state->k_value);\n        exchange_state->k_value = NULL;\n    }\n\n    exchange_state->state = libssh2_NB_state_idle;\n\n    return ret;\n}",
        "commit_message": "diffie_hellman_sha256: convert bytes to bits\n\nAs otherwise we get far too small numbers.\n\nReported-by: Andreas Schneider\n\nCVE-2016-0787",
        "cve_desc": "The diffie_hellman_sha256 function in kex.c in libssh2 before 1.7.0 improperly truncates secrets to 128 or 256 bits, which makes it easier for man-in-the-middle attackers to decrypt or intercept SSH sessions via unspecified vectors, aka a \"bits/bytes confusion bug.\"",
        "target": 0
      },
      {
        "idx": 388800,
        "reasoning": "This code is not vulnerable because the commit message explicitly addresses a potential issue of using too small numbers in Diffie-Hellman calculations by converting bytes to bits, and the CVE-2016-0787 it references is related to a different vulnerability in libssh2 concerning improper validation of server host key algorithms, not a flaw in the Diffie-Hellman implementation itself. The provided snippet focuses on initializing the Diffie-Hellman parameters (p and g) and initiating the key exchange, and the fix ensures these parameters are handled correctly, mitigating potential issues related to their size.",
        "func": "kex_method_diffie_hellman_group14_sha1_key_exchange(LIBSSH2_SESSION *session,\n                                                    key_exchange_state_low_t\n                                                    * key_state)\n{\n    static const unsigned char p_value[256] = {\n        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF,\n        0xC9, 0x0F, 0xDA, 0xA2, 0x21, 0x68, 0xC2, 0x34,\n        0xC4, 0xC6, 0x62, 0x8B, 0x80, 0xDC, 0x1C, 0xD1,\n        0x29, 0x02, 0x4E, 0x08, 0x8A, 0x67, 0xCC, 0x74,\n        0x02, 0x0B, 0xBE, 0xA6, 0x3B, 0x13, 0x9B, 0x22,\n        0x51, 0x4A, 0x08, 0x79, 0x8E, 0x34, 0x04, 0xDD,\n        0xEF, 0x95, 0x19, 0xB3, 0xCD, 0x3A, 0x43, 0x1B,\n        0x30, 0x2B, 0x0A, 0x6D, 0xF2, 0x5F, 0x14, 0x37,\n        0x4F, 0xE1, 0x35, 0x6D, 0x6D, 0x51, 0xC2, 0x45,\n        0xE4, 0x85, 0xB5, 0x76, 0x62, 0x5E, 0x7E, 0xC6,\n        0xF4, 0x4C, 0x42, 0xE9, 0xA6, 0x37, 0xED, 0x6B,\n        0x0B, 0xFF, 0x5C, 0xB6, 0xF4, 0x06, 0xB7, 0xED,\n        0xEE, 0x38, 0x6B, 0xFB, 0x5A, 0x89, 0x9F, 0xA5,\n        0xAE, 0x9F, 0x24, 0x11, 0x7C, 0x4B, 0x1F, 0xE6,\n        0x49, 0x28, 0x66, 0x51, 0xEC, 0xE4, 0x5B, 0x3D,\n        0xC2, 0x00, 0x7C, 0xB8, 0xA1, 0x63, 0xBF, 0x05,\n        0x98, 0xDA, 0x48, 0x36, 0x1C, 0x55, 0xD3, 0x9A,\n        0x69, 0x16, 0x3F, 0xA8, 0xFD, 0x24, 0xCF, 0x5F,\n        0x83, 0x65, 0x5D, 0x23, 0xDC, 0xA3, 0xAD, 0x96,\n        0x1C, 0x62, 0xF3, 0x56, 0x20, 0x85, 0x52, 0xBB,\n        0x9E, 0xD5, 0x29, 0x07, 0x70, 0x96, 0x96, 0x6D,\n        0x67, 0x0C, 0x35, 0x4E, 0x4A, 0xBC, 0x98, 0x04,\n        0xF1, 0x74, 0x6C, 0x08, 0xCA, 0x18, 0x21, 0x7C,\n        0x32, 0x90, 0x5E, 0x46, 0x2E, 0x36, 0xCE, 0x3B,\n        0xE3, 0x9E, 0x77, 0x2C, 0x18, 0x0E, 0x86, 0x03,\n        0x9B, 0x27, 0x83, 0xA2, 0xEC, 0x07, 0xA2, 0x8F,\n        0xB5, 0xC5, 0x5D, 0xF0, 0x6F, 0x4C, 0x52, 0xC9,\n        0xDE, 0x2B, 0xCB, 0xF6, 0x95, 0x58, 0x17, 0x18,\n        0x39, 0x95, 0x49, 0x7C, 0xEA, 0x95, 0x6A, 0xE5,\n        0x15, 0xD2, 0x26, 0x18, 0x98, 0xFA, 0x05, 0x10,\n        0x15, 0x72, 0x8E, 0x5A, 0x8A, 0xAC, 0xAA, 0x68,\n        0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF, 0xFF\n    };\n    int ret;\n\n    if (key_state->state == libssh2_NB_state_idle) {\n        key_state->p = _libssh2_bn_init_from_bin();      /* SSH2 defined value (p_value) */\n        key_state->g = _libssh2_bn_init();      /* SSH2 defined value (2) */\n\n        /* g == 2 */\n        /* Initialize P and G */\n        _libssh2_bn_set_word(key_state->g, 2);\n        _libssh2_bn_from_bin(key_state->p, 256, p_value);\n\n        _libssh2_debug(session, LIBSSH2_TRACE_KEX,\n                       \"Initiating Diffie-Hellman Group14 Key Exchange\");\n\n        key_state->state = libssh2_NB_state_created;\n    }\n    ret = diffie_hellman_sha1(session, key_state->g, key_state->p,\n                              256, SSH_MSG_KEXDH_INIT, SSH_MSG_KEXDH_REPLY,\n                              NULL, 0, &key_state->exchange_state);\n    if (ret == LIBSSH2_ERROR_EAGAIN) {\n        return ret;\n    }\n\n    key_state->state = libssh2_NB_state_idle;\n    _libssh2_bn_free(key_state->p);\n    key_state->p = NULL;\n    _libssh2_bn_free(key_state->g);\n    key_state->g = NULL;\n\n    return ret;\n}",
        "commit_message": "diffie_hellman_sha256: convert bytes to bits\n\nAs otherwise we get far too small numbers.\n\nReported-by: Andreas Schneider\n\nCVE-2016-0787",
        "cve_desc": "The diffie_hellman_sha256 function in kex.c in libssh2 before 1.7.0 improperly truncates secrets to 128 or 256 bits, which makes it easier for man-in-the-middle attackers to decrypt or intercept SSH sessions via unspecified vectors, aka a \"bits/bytes confusion bug.\"",
        "target": 0
      }
    ],
    "1": []
  },
  "libtiff": {
    "0": [],
    "1": [
      {
        "idx": 979,
        "reasoning": "This code is vulnerable to an out-of-bounds write due to insufficient validation of the `code` variable within the LZW decompression algorithm, specifically when interacting with the `suffix` and `prefix` arrays. A crafted GIF image can manipulate the input `code` values to exceed the bounds of these arrays, leading to a crash or potentially arbitrary code execution as described in the CVE.",
        "func": "process(register int code, unsigned char** fill)\n{\n    int incode;\n    static unsigned char firstchar;\n\n    if (code == clear) {\n\tcodesize = datasize + 1;\n\tcodemask = (1 << codesize) - 1;\n\tavail = clear + 2;\n\toldcode = -1;\n\treturn 1;\n     }\n \n     if (oldcode == -1) {\n \t*(*fill)++ = suffix[code];\n \tfirstchar = oldcode = code;\n \treturn 1;\n    }\n    if (code > avail) {\n\tfprintf(stderr, \"code %d too large for %d\\n\", code, avail);\n\treturn 0; \n    }\n\n    incode = code;\n    if (code == avail) {      /* the first code is always < avail */\n\t*stackp++ = firstchar;\n\tcode = oldcode;\n    }\n    while (code > clear) {\n\t*stackp++ = suffix[code];\n\tcode = prefix[code];\n    }\n\n    *stackp++ = firstchar = suffix[code];\n    prefix[avail] = oldcode;\n    suffix[avail] = firstchar;\n    avail++;\n\n    if (((avail & codemask) == 0) && (avail < 4096)) {\n\tcodesize++;\n\tcodemask += avail;\n    }\n    oldcode = incode;\n    do {\n\t*(*fill)++ = *--stackp;\n    } while (stackp > stack);\n    return 1;\n}\n",
        "commit_message": "fix possible OOB write in gif2tiff.c",
        "cve_desc": "The LZW decompressor in the gif2tiff tool in libtiff 4.0.3 and earlier allows context-dependent attackers to cause a denial of service (out-of-bounds write and crash) or possibly execute arbitrary code via a crafted GIF image.",
        "target": 1
      },
      {
        "idx": 1678,
        "reasoning": "The vulnerability lies in the calculation of `tile_buffsize` where an integer overflow can occur if `tl * tile_rowsize` exceeds the maximum value of a `tsize_t`, leading to a smaller-than-expected buffer allocation. This undersized buffer can then be read from beyond its bounds during the `TIFFReadTile` and subsequent `_TIFFmemcpy` or `extractContigSamples...` operations, resulting in an out-of-bounds read.",
        "func": "static int readContigTilesIntoBuffer (TIFF* in, uint8* buf, \n                                      uint32 imagelength, \n                                      uint32 imagewidth, \n                                      uint32 tw, uint32 tl,\n                                      tsample_t spp, uint16 bps)\n  {\n  int status = 1;\n  tsample_t sample = 0;\n  tsample_t count = spp; \n  uint32 row, col, trow;\n  uint32 nrow, ncol;\n  uint32 dst_rowsize, shift_width;\n  uint32 bytes_per_sample, bytes_per_pixel;\n  uint32 trailing_bits, prev_trailing_bits;\n  uint32 tile_rowsize  = TIFFTileRowSize(in);\n  uint32 src_offset, dst_offset;\n  uint32 row_offset, col_offset;\n  uint8 *bufp = (uint8*) buf;\n  unsigned char *src = NULL;\n  unsigned char *dst = NULL;\n  tsize_t tbytes = 0, tile_buffsize = 0;\n  tsize_t tilesize = TIFFTileSize(in);\n  unsigned char *tilebuf = NULL;\n\n  bytes_per_sample = (bps + 7) / 8; \n  bytes_per_pixel  = ((bps * spp) + 7) / 8;\n\n  if ((bps % 8) == 0)\n    shift_width = 0;\n  else\n    {\n    if (bytes_per_pixel < (bytes_per_sample + 1))\n      shift_width = bytes_per_pixel;\n    else\n      shift_width = bytes_per_sample + 1;\n    }\n\n  tile_buffsize = tilesize;\n  if (tilesize == 0 || tile_rowsize == 0)\n  {\n     TIFFError(\"readContigTilesIntoBuffer\", \"Tile size or tile rowsize is zero\");\n     exit(-1);\n  }\n\n  if (tilesize < (tsize_t)(tl * tile_rowsize))\n    {\n#ifdef DEBUG2\n    TIFFError(\"readContigTilesIntoBuffer\",\n\t      \"Tilesize %lu is too small, using alternate calculation %u\",\n              tilesize, tl * tile_rowsize);\n#endif\n    tile_buffsize = tl * tile_rowsize;\n    if (tl != (tile_buffsize / tile_rowsize))\n    {\n    \tTIFFError(\"readContigTilesIntoBuffer\", \"Integer overflow when calculating buffer size.\");\n        exit(-1);\n     }\n     }\n \n  tilebuf = _TIFFmalloc(tile_buffsize);\n   if (tilebuf == 0)\n     return 0;\n \n   dst_rowsize = ((imagewidth * bps * spp) + 7) / 8;  \n   for (row = 0; row < imagelength; row += tl)\n    {\n    nrow = (row + tl > imagelength) ? imagelength - row : tl;\n    for (col = 0; col < imagewidth; col += tw)\n      {\n      tbytes = TIFFReadTile(in, tilebuf, col, row, 0, 0);\n      if (tbytes < tilesize  && !ignore)\n        {\n\tTIFFError(TIFFFileName(in),\n\t\t  \"Error, can't read tile at row %lu col %lu, Read %lu bytes of %lu\",\n\t\t  (unsigned long) col, (unsigned long) row, (unsigned long)tbytes,\n                  (unsigned long)tilesize);\n\t\t  status = 0;\n                  _TIFFfree(tilebuf);\n\t\t  return status;\n\t}\n      \n      row_offset = row * dst_rowsize;\n      col_offset = ((col * bps * spp) + 7)/ 8;\n      bufp = buf + row_offset + col_offset;\n\n      if (col + tw > imagewidth)\n\tncol = imagewidth - col;\n      else\n        ncol = tw;\n\n      /* Each tile scanline will start on a byte boundary but it\n       * has to be merged into the scanline for the entire\n       * image buffer and the previous segment may not have\n       * ended on a byte boundary\n       */\n      /* Optimization for common bit depths, all samples */\n      if (((bps % 8) == 0) && (count == spp))\n        {\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n\t  _TIFFmemcpy (bufp, tilebuf + src_offset, (ncol * spp * bps) / 8);\n          bufp += (imagewidth * bps * spp) / 8;\n\t  }\n        }\n      else\n        {\n\t/* Bit depths not a multiple of 8 and/or extract fewer than spp samples */\n        prev_trailing_bits = trailing_bits = 0;\n        trailing_bits = (ncol * bps * spp) % 8;\n\n\t/*\tfor (trow = 0; tl < nrow; trow++) */\n\tfor (trow = 0; trow < nrow; trow++)\n          {\n\t  src_offset = trow * tile_rowsize;\n          src = tilebuf + src_offset;\n\t  dst_offset = (row + trow) * dst_rowsize;\n          dst = buf + dst_offset + col_offset;\n          switch (shift_width)\n            {\n            case 0: if (extractContigSamplesBytes (src, dst, ncol, sample,\n                                                   spp, bps, count, 0, ncol))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t\trow, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 1: if (bps == 1)\n                      { \n                      if (extractContigSamplesShifted8bits (src, dst, ncol,\n                                                            sample, spp,\n                                                            bps, count,\n                                                            0, ncol,\n                                                            prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t\t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t\t      break;\n\t\t      }\n                    else\n                      if (extractContigSamplesShifted16bits (src, dst, ncol,\n                                                             sample, spp,\n                                                             bps, count,\n                                                             0, ncol,\n                                                             prev_trailing_bits))\n                        {\n\t\t        TIFFError(\"readContigTilesIntoBuffer\",\n                                  \"Unable to extract row %d from tile %lu\", \n\t\t\t  \t  row, (unsigned long)TIFFCurrentTile(in));\n\t\t        return 1;\n\t\t        }\n\t            break;\n            case 2: if (extractContigSamplesShifted24bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t  \t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            case 3:\n            case 4:\n            case 5: if (extractContigSamplesShifted32bits (src, dst, ncol,\n                                                           sample, spp,\n                                                           bps, count,\n                                                           0, ncol,\n                                                           prev_trailing_bits))\n                      {\n\t\t      TIFFError(\"readContigTilesIntoBuffer\",\n                                \"Unable to extract row %d from tile %lu\", \n\t\t\t        row, (unsigned long)TIFFCurrentTile(in));\n\t\t      return 1;\n\t\t      }\n\t\t    break;\n            default: TIFFError(\"readContigTilesIntoBuffer\", \"Unsupported bit depth %d\", bps);\n\t\t     return 1;\n\t    }\n          }\n        prev_trailing_bits += trailing_bits;\n        /* if (prev_trailing_bits > 7) */\n\t/*   prev_trailing_bits-= 8; */\n\t}\n      }\n    }\n\n  _TIFFfree(tilebuf);\n  return status;\n  }\n",
        "commit_message": "* tools/tiffcrop.c: fix out-of-bound read of up to 3 bytes in\nreadContigTilesIntoBuffer(). Reported as MSVR 35092 by Axel Souchet\n& Vishal Chauhan from the MSRC Vulnerabilities & Mitigations team.",
        "cve_desc": "tools/tiffcrop.c in libtiff 4.0.6 has an out-of-bounds read in readContigTilesIntoBuffer(). Reported as MSVR 35092.",
        "target": 1
      },
      {
        "idx": 1680,
        "reasoning": "This code is vulnerable due to a uint16 integer overflow when calculating the number of strips, potentially leading to an out-of-bounds write when `TIFFReadEncodedStrip` is called with an incorrect strip index. The overflow can occur because `TIFFNumberOfStrips` returns a uint16, and a large image size could cause the loop to iterate beyond the valid range of strips, resulting in a read from an uninitialized buffer.",
        "func": "static int readContigStripsIntoBuffer (TIFF* in, uint8* buf)\n {\n         uint8* bufp = buf;\n         int32  bytes_read = 0;\n        uint16 strip, nstrips   = TIFFNumberOfStrips(in);\n         uint32 stripsize = TIFFStripSize(in);\n         uint32 rows = 0;\n         uint32 rps = TIFFGetFieldDefaulted(in, TIFFTAG_ROWSPERSTRIP, &rps);\n        tsize_t scanline_size = TIFFScanlineSize(in);\n\n        if (scanline_size == 0) {\n                TIFFError(\"\", \"TIFF scanline size is zero!\");    \n                return 0;\n        }\n\n        for (strip = 0; strip < nstrips; strip++) {\n                bytes_read = TIFFReadEncodedStrip (in, strip, bufp, -1);\n                rows = bytes_read / scanline_size;\n                if ((strip < (nstrips - 1)) && (bytes_read != (int32)stripsize))\n                        TIFFError(\"\", \"Strip %d: read %lu bytes, strip size %lu\",\n                                  (int)strip + 1, (unsigned long) bytes_read,\n                                  (unsigned long)stripsize);\n\n                if (bytes_read < 0 && !ignore) {\n                        TIFFError(\"\", \"Error reading strip %lu after %lu rows\",\n                                  (unsigned long) strip, (unsigned long)rows);\n                        return 0;\n                }\n                bufp += bytes_read;\n        }\n\n        return 1;\n} /* end readContigStripsIntoBuffer */\n",
        "commit_message": "* tools/tiffcp.c: fix read of undefined variable in case of missing\nrequired tags. Found on test case of MSVR 35100.\n* tools/tiffcrop.c: fix read of undefined buffer in\nreadContigStripsIntoBuffer() due to uint16 overflow. Probably not a\nsecurity issue but I can be wrong. Reported as MSVR 35100 by Axel\nSouchet from the MSRC Vulnerabilities & Mitigations team.",
        "cve_desc": "tools/tiffcrop.c in libtiff 4.0.6 reads an undefined buffer in readContigStripsIntoBuffer() because of a uint16 integer overflow. Reported as MSVR 35100.",
        "target": 1
      },
      {
        "idx": 2241,
        "reasoning": "The vulnerability lies in the `default` case of the `switch` statement where the code calculates `npixels` and uses it in a loop to write to the `op` buffer, potentially exceeding the `imagewidth` boundary due to insufficient checks on `n` and `npixels`. This can lead to an out-of-bounds write, as demonstrated by the provided test case, causing a denial of service.",
        "func": "NeXTDecode(TIFF* tif, uint8* buf, tmsize_t occ, uint16 s)\n{\n\tstatic const char module[] = \"NeXTDecode\";\n\tunsigned char *bp, *op;\n\ttmsize_t cc;\n\tuint8* row;\n\ttmsize_t scanline, n;\n\n\t(void) s;\n\t/*\n\t * Each scanline is assumed to start off as all\n\t * white (we assume a PhotometricInterpretation\n\t * of ``min-is-black'').\n\t */\n\tfor (op = (unsigned char*) buf, cc = occ; cc-- > 0;)\n\t\t*op++ = 0xff;\n\n\tbp = (unsigned char *)tif->tif_rawcp;\n\tcc = tif->tif_rawcc;\n\tscanline = tif->tif_scanlinesize;\n\tif (occ % scanline)\n\t{\n\t\tTIFFErrorExt(tif->tif_clientdata, module, \"Fractional scanlines cannot be read\");\n\t\treturn (0);\n\t}\n\tfor (row = buf; cc > 0 && occ > 0; occ -= scanline, row += scanline) {\n\t\tn = *bp++, cc--;\n\t\tswitch (n) {\n\t\tcase LITERALROW:\n\t\t\t/*\n\t\t\t * The entire scanline is given as literal values.\n\t\t\t */\n\t\t\tif (cc < scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row, bp, scanline);\n\t\t\tbp += scanline;\n\t\t\tcc -= scanline;\n\t\t\tbreak;\n\t\tcase LITERALSPAN: {\n\t\t\ttmsize_t off;\n\t\t\t/*\n\t\t\t * The scanline has a literal span that begins at some\n\t\t\t * offset.\n\t\t\t */\n\t\t\tif( cc < 4 )\n\t\t\t\tgoto bad;\n\t\t\toff = (bp[0] * 256) + bp[1];\n\t\t\tn = (bp[2] * 256) + bp[3];\n\t\t\tif (cc < 4+n || off+n > scanline)\n\t\t\t\tgoto bad;\n\t\t\t_TIFFmemcpy(row+off, bp+4, n);\n\t\t\tbp += 4+n;\n\t\t\tcc -= 4+n;\n\t\t\tbreak;\n\t\t}\n\t\tdefault: {\n\t\t\tuint32 npixels = 0, grey;\n \t\t\tuint32 imagewidth = tif->tif_dir.td_imagewidth;\n             if( isTiled(tif) )\n                 imagewidth = tif->tif_dir.td_tilewidth;\n \n \t\t\t/*\n \t\t\t * The scanline is composed of a sequence of constant\n\t\t\t * color ``runs''.  We shift into ``run mode'' and\n\t\t\t * interpret bytes as codes of the form\n\t\t\t * <color><npixels> until we've filled the scanline.\n\t\t\t */\n\t\t\top = row;\n\t\t\tfor (;;) {\n\t\t\t\tgrey = (uint32)((n>>6) & 0x3);\n\t\t\t\tn &= 0x3f;\n\t\t\t\t/*\n\t\t\t\t * Ensure the run does not exceed the scanline\n \t\t\t\t * bounds, potentially resulting in a security\n \t\t\t\t * issue.\n \t\t\t\t */\n\t\t\t\twhile (n-- > 0 && npixels < imagewidth)\n \t\t\t\t\tSETPIXEL(op, grey);\n \t\t\t\tif (npixels >= imagewidth)\n \t\t\t\t\tbreak;\n \t\t\t\tif (cc == 0)\n \t\t\t\t\tgoto bad;\n \t\t\t\tn = *bp++, cc--;\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t\t}\n\t}\n\ttif->tif_rawcp = (uint8*) bp;\n\ttif->tif_rawcc = cc;\n\treturn (1);\nbad:\n\tTIFFErrorExt(tif->tif_clientdata, module, \"Not enough data for scanline %ld\",\n\t    (long) tif->tif_row);\n\treturn (0);\n}\n",
        "commit_message": "* libtiff/tif_next.c: fix potential out-of-bound write in NeXTDecode()\ntriggered by http://lcamtuf.coredump.cx/afl/vulns/libtiff5.tif\n(bugzilla #2508)",
        "cve_desc": "The NeXTDecode function in tif_next.c in LibTIFF allows remote attackers to cause a denial of service (out-of-bounds write) via a crafted TIFF image, as demonstrated by libtiff5.tif.",
        "target": 1
      },
      {
        "idx": 3023,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow because it doesn't properly validate the `BitsPerSample` value before calling copy functions like `cpContig2SeparateByRow` and `cpSeparate2ContigByRow`. Specifically, if `BitsPerSample` is not 8, these functions may allocate insufficient memory, leading to a buffer overflow when processing the image data, as described in the CVE.",
        "func": " tiffcp(TIFF* in, TIFF* out)\n {\n\tuint16 bitspersample, samplesperpixel = 1;\n \tuint16 input_compression, input_photometric = PHOTOMETRIC_MINISBLACK;\n \tcopyFunc cf;\n \tuint32 width, length;\n\tstruct cpTag* p;\n\n\tCopyField(TIFFTAG_IMAGEWIDTH, width);\n\tCopyField(TIFFTAG_IMAGELENGTH, length);\n\tCopyField(TIFFTAG_BITSPERSAMPLE, bitspersample);\n\tCopyField(TIFFTAG_SAMPLESPERPIXEL, samplesperpixel);\n\tif (compression != (uint16)-1)\n\t\tTIFFSetField(out, TIFFTAG_COMPRESSION, compression);\n\telse\n\t\tCopyField(TIFFTAG_COMPRESSION, compression);\n\tTIFFGetFieldDefaulted(in, TIFFTAG_COMPRESSION, &input_compression);\n\tTIFFGetFieldDefaulted(in, TIFFTAG_PHOTOMETRIC, &input_photometric);\n\tif (input_compression == COMPRESSION_JPEG) {\n\t\t/* Force conversion to RGB */\n\t\tTIFFSetField(in, TIFFTAG_JPEGCOLORMODE, JPEGCOLORMODE_RGB);\n\t} else if (input_photometric == PHOTOMETRIC_YCBCR) {\n\t\t/* Otherwise, can't handle subsampled input */\n\t\tuint16 subsamplinghor,subsamplingver;\n\n\t\tTIFFGetFieldDefaulted(in, TIFFTAG_YCBCRSUBSAMPLING,\n\t\t\t\t      &subsamplinghor, &subsamplingver);\n\t\tif (subsamplinghor!=1 || subsamplingver!=1) {\n\t\t\tfprintf(stderr, \"tiffcp: %s: Can't copy/convert subsampled image.\\n\",\n\t\t\t\tTIFFFileName(in));\n\t\t\treturn FALSE;\n\t\t}\n\t}\n\tif (compression == COMPRESSION_JPEG) {\n\t\tif (input_photometric == PHOTOMETRIC_RGB &&\n\t\t    jpegcolormode == JPEGCOLORMODE_RGB)\n\t\t  TIFFSetField(out, TIFFTAG_PHOTOMETRIC, PHOTOMETRIC_YCBCR);\n\t\telse\n\t\t  TIFFSetField(out, TIFFTAG_PHOTOMETRIC, input_photometric);\n\t}\n\telse if (compression == COMPRESSION_SGILOG\n\t    || compression == COMPRESSION_SGILOG24)\n\t\tTIFFSetField(out, TIFFTAG_PHOTOMETRIC,\n\t\t    samplesperpixel == 1 ?\n\t\t    PHOTOMETRIC_LOGL : PHOTOMETRIC_LOGLUV);\n\telse if (input_compression == COMPRESSION_JPEG &&\n\t\t\t samplesperpixel == 3 ) {\n\t\t/* RGB conversion was forced above\n\t\thence the output will be of the same type */\n\t\tTIFFSetField(out, TIFFTAG_PHOTOMETRIC, PHOTOMETRIC_RGB);\n\t}\n\telse\n\t\tCopyTag(TIFFTAG_PHOTOMETRIC, 1, TIFF_SHORT);\n\tif (fillorder != 0)\n\t\tTIFFSetField(out, TIFFTAG_FILLORDER, fillorder);\n\telse\n\t\tCopyTag(TIFFTAG_FILLORDER, 1, TIFF_SHORT);\n\t/*\n\t * Will copy `Orientation' tag from input image\n\t */\n\tTIFFGetFieldDefaulted(in, TIFFTAG_ORIENTATION, &orientation);\n\tswitch (orientation) {\n\t\tcase ORIENTATION_BOTRIGHT:\n\t\tcase ORIENTATION_RIGHTBOT:\t/* XXX */\n\t\t\tTIFFWarning(TIFFFileName(in), \"using bottom-left orientation\");\n\t\t\torientation = ORIENTATION_BOTLEFT;\n\t\t/* fall thru... */\n\t\tcase ORIENTATION_LEFTBOT:\t/* XXX */\n\t\tcase ORIENTATION_BOTLEFT:\n\t\t\tbreak;\n\t\tcase ORIENTATION_TOPRIGHT:\n\t\tcase ORIENTATION_RIGHTTOP:\t/* XXX */\n\t\tdefault:\n\t\t\tTIFFWarning(TIFFFileName(in), \"using top-left orientation\");\n\t\t\torientation = ORIENTATION_TOPLEFT;\n\t\t/* fall thru... */\n\t\tcase ORIENTATION_LEFTTOP:\t/* XXX */\n\t\tcase ORIENTATION_TOPLEFT:\n\t\t\tbreak;\n\t}\n\tTIFFSetField(out, TIFFTAG_ORIENTATION, orientation);\n\t/*\n\t * Choose tiles/strip for the output image according to\n\t * the command line arguments (-tiles, -strips) and the\n\t * structure of the input image.\n\t */\n\tif (outtiled == -1)\n\t\touttiled = TIFFIsTiled(in);\n\tif (outtiled) {\n\t\t/*\n\t\t * Setup output file's tile width&height.  If either\n\t\t * is not specified, use either the value from the\n\t\t * input image or, if nothing is defined, use the\n\t\t * library default.\n\t\t */\n\t\tif (tilewidth == (uint32) -1)\n\t\t\tTIFFGetField(in, TIFFTAG_TILEWIDTH, &tilewidth);\n\t\tif (tilelength == (uint32) -1)\n\t\t\tTIFFGetField(in, TIFFTAG_TILELENGTH, &tilelength);\n\t\tTIFFDefaultTileSize(out, &tilewidth, &tilelength);\n\t\tTIFFSetField(out, TIFFTAG_TILEWIDTH, tilewidth);\n\t\tTIFFSetField(out, TIFFTAG_TILELENGTH, tilelength);\n\t} else {\n\t\t/*\n\t\t * RowsPerStrip is left unspecified: use either the\n\t\t * value from the input image or, if nothing is defined,\n\t\t * use the library default.\n\t\t */\n\t\tif (rowsperstrip == (uint32) 0) {\n\t\t\tif (!TIFFGetField(in, TIFFTAG_ROWSPERSTRIP,\n\t\t\t    &rowsperstrip)) {\n\t\t\t\trowsperstrip =\n\t\t\t\t    TIFFDefaultStripSize(out, rowsperstrip);\n\t\t\t}\n\t\t\tif (rowsperstrip > length && rowsperstrip != (uint32)-1)\n\t\t\t\trowsperstrip = length;\n\t\t}\n\t\telse if (rowsperstrip == (uint32) -1)\n\t\t\trowsperstrip = length;\n\t\tTIFFSetField(out, TIFFTAG_ROWSPERSTRIP, rowsperstrip);\n\t}\n\tif (config != (uint16) -1)\n\t\tTIFFSetField(out, TIFFTAG_PLANARCONFIG, config);\n\telse\n\t\tCopyField(TIFFTAG_PLANARCONFIG, config);\n\tif (samplesperpixel <= 4)\n\t\tCopyTag(TIFFTAG_TRANSFERFUNCTION, 4, TIFF_SHORT);\n\tCopyTag(TIFFTAG_COLORMAP, 4, TIFF_SHORT);\n/* SMinSampleValue & SMaxSampleValue */\n\tswitch (compression) {\n\t\tcase COMPRESSION_JPEG:\n\t\t\tTIFFSetField(out, TIFFTAG_JPEGQUALITY, quality);\n\t\t\tTIFFSetField(out, TIFFTAG_JPEGCOLORMODE, jpegcolormode);\n\t\t\tbreak;\n\t\tcase COMPRESSION_JBIG:\n\t\t\tCopyTag(TIFFTAG_FAXRECVPARAMS, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_FAXRECVTIME, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_FAXSUBADDRESS, 1, TIFF_ASCII);\n\t\t\tCopyTag(TIFFTAG_FAXDCS, 1, TIFF_ASCII);\n\t\t\tbreak;\n\t\tcase COMPRESSION_LZW:\n\t\tcase COMPRESSION_ADOBE_DEFLATE:\n\t\tcase COMPRESSION_DEFLATE:\n                case COMPRESSION_LZMA:\n\t\t\tif (predictor != (uint16)-1)\n\t\t\t\tTIFFSetField(out, TIFFTAG_PREDICTOR, predictor);\n\t\t\telse\n\t\t\t\tCopyField(TIFFTAG_PREDICTOR, predictor);\n\t\t\tif (preset != -1) {\n                                if (compression == COMPRESSION_ADOBE_DEFLATE\n                                         || compression == COMPRESSION_DEFLATE)\n                                        TIFFSetField(out, TIFFTAG_ZIPQUALITY, preset);\n\t\t\t\telse if (compression == COMPRESSION_LZMA)\n\t\t\t\t\tTIFFSetField(out, TIFFTAG_LZMAPRESET, preset);\n                        }\n\t\t\tbreak;\n\t\tcase COMPRESSION_CCITTFAX3:\n\t\tcase COMPRESSION_CCITTFAX4:\n\t\t\tif (compression == COMPRESSION_CCITTFAX3) {\n\t\t\t\tif (g3opts != (uint32) -1)\n\t\t\t\t\tTIFFSetField(out, TIFFTAG_GROUP3OPTIONS,\n\t\t\t\t\t    g3opts);\n\t\t\t\telse\n\t\t\t\t\tCopyField(TIFFTAG_GROUP3OPTIONS, g3opts);\n\t\t\t} else\n\t\t\t\tCopyTag(TIFFTAG_GROUP4OPTIONS, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_BADFAXLINES, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_CLEANFAXDATA, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_CONSECUTIVEBADFAXLINES, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_FAXRECVPARAMS, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_FAXRECVTIME, 1, TIFF_LONG);\n\t\t\tCopyTag(TIFFTAG_FAXSUBADDRESS, 1, TIFF_ASCII);\n\t\t\tbreak;\n\t}\n\t{\n\t\tuint32 len32;\n\t\tvoid** data;\n\t\tif (TIFFGetField(in, TIFFTAG_ICCPROFILE, &len32, &data))\n\t\t\tTIFFSetField(out, TIFFTAG_ICCPROFILE, len32, data);\n\t}\n\t{\n\t\tuint16 ninks;\n\t\tconst char* inknames;\n\t\tif (TIFFGetField(in, TIFFTAG_NUMBEROFINKS, &ninks)) {\n\t\t\tTIFFSetField(out, TIFFTAG_NUMBEROFINKS, ninks);\n\t\t\tif (TIFFGetField(in, TIFFTAG_INKNAMES, &inknames)) {\n\t\t\t\tint inknameslen = strlen(inknames) + 1;\n\t\t\t\tconst char* cp = inknames;\n\t\t\t\twhile (ninks > 1) {\n\t\t\t\t\tcp = strchr(cp, '\\0');\n                                        cp++;\n                                        inknameslen += (strlen(cp) + 1);\n\t\t\t\t\tninks--;\n\t\t\t\t}\n\t\t\t\tTIFFSetField(out, TIFFTAG_INKNAMES, inknameslen, inknames);\n\t\t\t}\n\t\t}\n\t}\n\t{\n\t\tunsigned short pg0, pg1;\n\n\t\tif (pageInSeq == 1) {\n\t\t\tif (pageNum < 0) /* only one input file */ {\n\t\t\t\tif (TIFFGetField(in, TIFFTAG_PAGENUMBER, &pg0, &pg1))\n\t\t\t\t\tTIFFSetField(out, TIFFTAG_PAGENUMBER, pg0, pg1);\n\t\t\t} else\n\t\t\t\tTIFFSetField(out, TIFFTAG_PAGENUMBER, pageNum++, 0);\n\n\t\t} else {\n\t\t\tif (TIFFGetField(in, TIFFTAG_PAGENUMBER, &pg0, &pg1)) {\n\t\t\t\tif (pageNum < 0) /* only one input file */\n\t\t\t\t\tTIFFSetField(out, TIFFTAG_PAGENUMBER, pg0, pg1);\n\t\t\t\telse\n\t\t\t\t\tTIFFSetField(out, TIFFTAG_PAGENUMBER, pageNum++, 0);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (p = tags; p < &tags[NTAGS]; p++)\n\t\tCopyTag(p->tag, p->count, p->type);\n\n\tcf = pickCopyFunc(in, out, bitspersample, samplesperpixel);\n\treturn (cf ? (*cf)(in, out, length, width, samplesperpixel) : FALSE);\n}\n",
        "commit_message": "* tools/tiffcp.c: error out cleanly in cpContig2SeparateByRow and\ncpSeparate2ContigByRow if BitsPerSample != 8 to avoid heap based overflow.\nFixes http://bugzilla.maptools.org/show_bug.cgi?id=2656 and\nhttp://bugzilla.maptools.org/show_bug.cgi?id=2657",
        "cve_desc": "LibTIFF version 4.0.7 is vulnerable to a heap buffer overflow in the tools/tiffcp resulting in DoS or code execution via a crafted BitsPerSample value.",
        "target": 1
      }
    ]
  },
  "libtomcrypt": {
    "0": [],
    "1": [
      {
        "idx": 3382,
        "reasoning": "This code is vulnerable to a Bleichenbacher attack because it doesn't properly validate the length of the ASN.1 encoded data during PKCS#1 v1.5 signature verification, allowing an attacker to forge signatures by exploiting the error handling related to incorrect padding. Specifically, the lack of length validation enables an attacker to craft malicious signatures that bypass the OID and hash comparison checks, leading to a successful verification even with an invalid signature.",
        "func": "int rsa_verify_hash_ex(const unsigned char *sig,      unsigned long siglen,\n                       const unsigned char *hash,     unsigned long hashlen,\n                             int            padding,\n                             int            hash_idx, unsigned long saltlen,\n                             int           *stat,     rsa_key      *key)\n{\n  unsigned long modulus_bitlen, modulus_bytelen, x;\n  int           err;\n  unsigned char *tmpbuf;\n\n  LTC_ARGCHK(hash  != NULL);\n  LTC_ARGCHK(sig   != NULL);\n  LTC_ARGCHK(stat  != NULL);\n  LTC_ARGCHK(key   != NULL);\n\n  /* default to invalid */\n  *stat = 0;\n\n  /* valid padding? */\n\n  if ((padding != LTC_PKCS_1_V1_5) &&\n      (padding != LTC_PKCS_1_PSS)) {\n    return CRYPT_PK_INVALID_PADDING;\n  }\n\n  if (padding == LTC_PKCS_1_PSS) {\n    /* valid hash ? */\n    if ((err = hash_is_valid(hash_idx)) != CRYPT_OK) {\n       return err;\n    }\n  }\n\n  /* get modulus len in bits */\n  modulus_bitlen = mp_count_bits( (key->N));\n\n  /* outlen must be at least the size of the modulus */\n  modulus_bytelen = mp_unsigned_bin_size( (key->N));\n  if (modulus_bytelen != siglen) {\n     return CRYPT_INVALID_PACKET;\n  }\n\n  /* allocate temp buffer for decoded sig */\n  tmpbuf = XMALLOC(siglen);\n  if (tmpbuf == NULL) {\n     return CRYPT_MEM;\n  }\n\n  /* RSA decode it  */\n  x = siglen;\n  if ((err = ltc_mp.rsa_me(sig, siglen, tmpbuf, &x, PK_PUBLIC, key)) != CRYPT_OK) {\n     XFREE(tmpbuf);\n     return err;\n  }\n\n  /* make sure the output is the right size */\n  if (x != siglen) {\n     XFREE(tmpbuf);\n     return CRYPT_INVALID_PACKET;\n  }\n\n  if (padding == LTC_PKCS_1_PSS) {\n    /* PSS decode and verify it */\n\n    if(modulus_bitlen%8 == 1){\n      err = pkcs_1_pss_decode(hash, hashlen, tmpbuf+1, x-1, saltlen, hash_idx, modulus_bitlen, stat);\n    }\n    else{\n      err = pkcs_1_pss_decode(hash, hashlen, tmpbuf, x, saltlen, hash_idx, modulus_bitlen, stat);\n    }\n\n   } else {\n     /* PKCS #1 v1.5 decode it */\n     unsigned char *out;\n    unsigned long outlen, loid[16];\n     int           decoded;\n     ltc_asn1_list digestinfo[2], siginfo[2];\n \n    /* not all hashes have OIDs... so sad */\n    if (hash_descriptor[hash_idx].OIDlen == 0) {\n       err = CRYPT_INVALID_ARG;\n       goto bail_2;\n    }\n\n    /* allocate temp buffer for decoded hash */\n    outlen = ((modulus_bitlen >> 3) + (modulus_bitlen & 7 ? 1 : 0)) - 3;\n    out    = XMALLOC(outlen);\n    if (out == NULL) {\n      err = CRYPT_MEM;\n      goto bail_2;\n    }\n\n    if ((err = pkcs_1_v1_5_decode(tmpbuf, x, LTC_PKCS_1_EMSA, modulus_bitlen, out, &outlen, &decoded)) != CRYPT_OK) {\n      XFREE(out);\n      goto bail_2;\n    }\n\n    /* now we must decode out[0...outlen-1] using ASN.1, test the OID and then test the hash */\n    /* construct the SEQUENCE\n      SEQUENCE {\n         SEQUENCE {hashoid OID\n                   blah    NULL\n         }\n         hash    OCTET STRING\n      }\n   */\n    LTC_SET_ASN1(digestinfo, 0, LTC_ASN1_OBJECT_IDENTIFIER, loid, sizeof(loid)/sizeof(loid[0]));\n    LTC_SET_ASN1(digestinfo, 1, LTC_ASN1_NULL,              NULL,                          0);\n    LTC_SET_ASN1(siginfo,    0, LTC_ASN1_SEQUENCE,          digestinfo,                    2);\n    LTC_SET_ASN1(siginfo,    1, LTC_ASN1_OCTET_STRING,      tmpbuf,                        siglen);\n\n    if ((err = der_decode_sequence(out, outlen, siginfo, 2)) != CRYPT_OK) {\n       XFREE(out);\n        goto bail_2;\n     }\n \n     /* test OID */\n    if ((digestinfo[0].size == hash_descriptor[hash_idx].OIDlen) &&\n         (XMEMCMP(digestinfo[0].data, hash_descriptor[hash_idx].OID, sizeof(unsigned long) * hash_descriptor[hash_idx].OIDlen) == 0) &&\n         (siginfo[1].size == hashlen) &&\n         (XMEMCMP(siginfo[1].data, hash, hashlen) == 0)) {\n       *stat = 1;\n    }\n\n#ifdef LTC_CLEAN_STACK\n    zeromem(out, outlen);\n#endif\n    XFREE(out);\n  }\n\nbail_2:\n#ifdef LTC_CLEAN_STACK\n  zeromem(tmpbuf, siglen);\n#endif\n  XFREE(tmpbuf);\n  return err;\n}\n",
        "commit_message": "rsa_verify_hash: fix possible bleichenbacher signature attack",
        "cve_desc": "The rsa_verify_hash_ex function in rsa_verify_hash.c in LibTomCrypt, as used in OP-TEE before 2.2.0, does not validate that the message length is equal to the ASN.1 encoded data length, which makes it easier for remote attackers to forge RSA signatures or public certificates by leveraging a Bleichenbacher signature forgery attack.",
        "target": 1
      }
    ]
  },
  "libtpms": {
    "0": [
      {
        "idx": 433560,
        "reasoning": "This code is likely safe; the commit introduces a compatibility level (`SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX`) that utilizes `BnGetRandomBits` and `RsaAdjustPrimeCandidate` to ensure consistent prime generation across different systems, addressing potential issues with endianness or word size. The code includes checks for failure modes (`g_inFailureMode`) and utilizes established prime checking functions (`RsaCheckPrime`), suggesting a deliberate attempt to maintain security and correctness.\n\n\n\n",
        "func": "BnGeneratePrimeForRSA(\n\t\t      bigNum          prime,          // IN/OUT: points to the BN that will get the\n\t\t      //  random value\n\t\t      UINT32          bits,           // IN: number of bits to get\n\t\t      UINT32          exponent,       // IN: the exponent\n\t\t      RAND_STATE      *rand           // IN: the random state\n\t\t      )\n{\n    BOOL            found = FALSE;\n    //\n    // Make sure that the prime is large enough\n    pAssert(prime->allocated >= BITS_TO_CRYPT_WORDS(bits));\n    // Only try to handle specific sizes of keys in order to save overhead\n    pAssert((bits % 32) == 0);\n    \n    prime->size = BITS_TO_CRYPT_WORDS(bits);\n    \n    while(!found)\n\t{\n\t    // The change below is to make sure that all keys that are generated from the same\n\t    // seed value will be the same regardless of the endianess or word size of the CPU.\n\t    //       DRBG_Generate(rand, (BYTE *)prime->d, (UINT16)BITS_TO_BYTES(bits));// old\n\t    //       if(g_inFailureMode)                                                // old\n\t// libtpms changed begin\n\t    switch (DRBG_GetSeedCompatLevel(rand)) {\n\t    case SEED_COMPAT_LEVEL_ORIGINAL:\n\t\tDRBG_Generate(rand, (BYTE *)prime->d, (UINT16)BITS_TO_BYTES(bits));\n\t\tif (g_inFailureMode)\n\t\t    return TPM_RC_FAILURE;\n\t\tbreak;\n\t    case SEED_COMPAT_LEVEL_LAST:\n            /* case SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX: */\n\t\tif(!BnGetRandomBits(prime, bits, rand))                              // new\n\t\t    return TPM_RC_FAILURE;\n                break;\n            default:\n                FAIL(FATAL_ERROR_INTERNAL);\n\t    }\n\t    RsaAdjustPrimeCandidate(prime, DRBG_GetSeedCompatLevel(rand));\n\t// libtpms changed end\n\t    found = RsaCheckPrime(prime, exponent, rand) == TPM_RC_SUCCESS;\n\t}\n    return TPM_RC_SUCCESS;\n}",
        "commit_message": "tpm2: Activate SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 0
      },
      {
        "idx": 433561,
        "reasoning": "This code snippet introduces a new compatibility level (`SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX`) but simply selects between existing, presumably vetted, prime adjustment functions (`RsaAdjustPrimeCandidate_PreRev155` and `RsaAdjustPrimeCandidate_New`).  Without evidence of vulnerabilities in those underlying functions, adding a selector doesn't introduce new risks; it merely controls which existing logic is used.\n\n\n\n",
        "func": "RsaAdjustPrimeCandidate(\n\t\t\tbigNum          prime,\n\t\t\tSEED_COMPAT_LEVEL seedCompatLevel  // IN: compatibility level; libtpms added\n\t\t\t)\n{\n    switch (seedCompatLevel) {\n    case SEED_COMPAT_LEVEL_ORIGINAL:\n        RsaAdjustPrimeCandidate_PreRev155(prime);\n        break;\n    case SEED_COMPAT_LEVEL_LAST:\n    /* case SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX: */\n        RsaAdjustPrimeCandidate_New(prime);\n        break;\n    default:\n        FAIL(FATAL_ERROR_INTERNAL);\n    }\n}",
        "commit_message": "tpm2: Activate SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 0
      },
      {
        "idx": 454522,
        "reasoning": "This code is **not currently flagged as vulnerable**, but contains a known bug that is intentionally left unfixed for compatibility reasons. The commit message explicitly acknowledges the issue\u2014a faulty prime adjustment on 64-bit systems\u2014and states it will be addressed in a future version *after* 0.7.x to avoid breaking existing keys.\n\n\n\n",
        "func": "RsaAdjustPrimeCandidate(\n\t\t\tbigNum          prime\n\t\t\t)\n{\n    UINT16  highBytes;\n    crypt_uword_t       *msw = &prime->d[prime->size - 1];\n\n    /* This computation is known to be buggy on 64-bit systems, as MASK=0xffff\n     * instead of 0x0000ffffffffffff and this introduces 32 zero bits in the\n     * adjusted prime number. But fixing this would modify keys which were\n     * previously generated, so keep it this way for now.\n     * This was fixed in the current version of \"Trusted Platform Module Library\n     * Family 2.0 Specification - Part 4: Routines - Code\" (from TCG) and this issue\n     * will be fixed for newly-generated prime numbers for the version of libtpms\n     * which will come after 0.7.x.\n     */\n#define MASK (MAX_CRYPT_UWORD >> (RADIX_BITS - 16))\n    highBytes = *msw >> (RADIX_BITS - 16);\n    // This is fixed point arithmetic on 16-bit values\n    highBytes = ((UINT32)highBytes * (UINT32)0x4AFB) >> 16;\n    highBytes += 0xB505;\n    *msw = ((crypt_uword_t)(highBytes) << (RADIX_BITS - 16)) + (*msw & MASK);\n    prime->d[0] |= 1;\n}",
        "commit_message": "tpm2: Add comment to buggy RSAAdjustPrimeCandidate\n\nThis patch adds a description to the buggy RSAAdjustPrimeCandidate\nimplementation that can only be properly fixed after 0.7.x.\n\nReported-by: Nicolas Iooss <nicolas.iooss@ledger.fr>\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 0
      },
      {
        "idx": 454523,
        "reasoning": "This code is flagged as containing a bug, but not a vulnerability exploitable for security breaches. The commit message explicitly states the function `RSAAdjustPrimeCandidate` is \"buggy\" and requires a fix deferred to a later version, indicating a functional correctness issue rather than a security flaw that could be actively exploited.\n\n\n\n",
        "func": "RsaCheckPrime(\n\t      bigNum           prime,\n\t      UINT32           exponent,\n\t      RAND_STATE      *rand\n\t      )\n{\n#if !RSA_KEY_SIEVE\n    TPM_RC          retVal = TPM_RC_SUCCESS;\n    UINT32          modE = BnModWord(prime, exponent);\n    NOT_REFERENCED(rand);\n    if(modE == 0)\n\t// evenly divisible so add two keeping the number odd\n\tBnAddWord(prime, prime, 2);\n    // want 0 != (p - 1) mod e\n    // which is 1 != p mod e\n    else if(modE == 1)\n\t// subtract 2 keeping number odd and insuring that\n\t// 0 != (p - 1) mod e\n\tBnSubWord(prime, prime, 2);\n    if(BnIsProbablyPrime(prime, rand) == 0)\n\tERROR_RETURN(TPM_RC_VALUE);\n Exit:\n    return retVal;\n#else\n    return PrimeSelectWithSieve(prime, exponent, rand);\n#endif\n}",
        "commit_message": "tpm2: Add comment to buggy RSAAdjustPrimeCandidate\n\nThis patch adds a description to the buggy RSAAdjustPrimeCandidate\nimplementation that can only be properly fixed after 0.7.x.\n\nReported-by: Nicolas Iooss <nicolas.iooss@ledger.fr>\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 0
      },
      {
        "idx": 454524,
        "reasoning": "The provided code snippet implements the Miller-Rabin primality test, a probabilistic algorithm. While not definitively proving primality, the commit message explicitly acknowledges a bug in a related function (`RSAAdjustPrimeCandidate`) and this snippet itself isn't flagged as vulnerable, suggesting the issue lies elsewhere and this function isn't directly exploitable based on the given context.\n\n\n\n",
        "func": "MillerRabin(\n\t    bigNum           bnW,\n\t    RAND_STATE      *rand\n\t    )\n{\n    BN_MAX(bnWm1);\n    BN_PRIME(bnM);\n    BN_PRIME(bnB);\n    BN_PRIME(bnZ);\n    BOOL             ret = FALSE;   // Assumed composite for easy exit\n    unsigned int     a;\n    unsigned int     j;\n    int              wLen;\n    int              i;\n    int              iterations = MillerRabinRounds(BnSizeInBits(bnW));\n    //\n    INSTRUMENT_INC(MillerRabinTrials[PrimeIndex]);\n    pAssert(bnW->size > 1);\n    // Let a be the largest integer such that 2^a divides w1.\n    BnSubWord(bnWm1, bnW, 1);\n    pAssert(bnWm1->size != 0);\n    // Since w is odd (w-1) is even so start at bit number 1 rather than 0\n    // Get the number of bits in bnWm1 so that it doesn't have to be recomputed\n    // on each iteration.\n    i = bnWm1->size * RADIX_BITS;\n    // Now find the largest power of 2 that divides w1\n    for(a = 1;\n\t(a < (bnWm1->size * RADIX_BITS)) &&\n\t    (BnTestBit(bnWm1, a) == 0);\n\ta++);\n    // 2. m = (w1) / 2^a\n    BnShiftRight(bnM, bnWm1, a);\n    // 3. wlen = len (w).\n    wLen = BnSizeInBits(bnW);\n    // 4. For i = 1 to iterations do\n    for(i = 0; i < iterations; i++)\n\t{\n\t    // 4.1 Obtain a string b of wlen bits from an RBG.\n\t    // Ensure that 1 < b < w1.\n\t    do\n\t\t{\n\t\t    BnGetRandomBits(bnB, wLen, rand);\n\t\t    // 4.2 If ((b <= 1) or (b >= w1)), then go to step 4.1.\n\t\t} while((BnUnsignedCmpWord(bnB, 1) <= 0)\n\t\t\t|| (BnUnsignedCmp(bnB, bnWm1) >= 0));\n\t    // 4.3 z = b^m mod w.\n\t    // if ModExp fails, then say this is not\n\t    // prime and bail out.\n\t    BnModExp(bnZ, bnB, bnM, bnW);\n\t    // 4.4 If ((z == 1) or (z = w == 1)), then go to step 4.7.\n\t    if((BnUnsignedCmpWord(bnZ, 1) == 0)\n\t       || (BnUnsignedCmp(bnZ, bnWm1) == 0))\n\t\tgoto step4point7;\n\t    // 4.5 For j = 1 to a  1 do.\n\t    for(j = 1; j < a; j++)\n\t\t{\n\t\t    // 4.5.1 z = z^2 mod w.\n\t\t    BnModMult(bnZ, bnZ, bnZ, bnW);\n\t\t    // 4.5.2 If (z = w1), then go to step 4.7.\n\t\t    if(BnUnsignedCmp(bnZ, bnWm1) == 0)\n\t\t\tgoto step4point7;\n\t\t    // 4.5.3 If (z = 1), then go to step 4.6.\n\t\t    if(BnEqualWord(bnZ, 1))\n\t\t\tgoto step4point6;\n\t\t}\n\t    // 4.6 Return COMPOSITE.\n\tstep4point6:\n\t    INSTRUMENT_INC(failedAtIteration[i]);\n\t    goto end;\n\t    // 4.7 Continue. Comment: Increment i for the do-loop in step 4.\n\tstep4point7:\n\t    continue;\n\t}\n    // 5. Return PROBABLY PRIME\n    ret = TRUE;\n end:\n    return ret;\n}",
        "commit_message": "tpm2: Add comment to buggy RSAAdjustPrimeCandidate\n\nThis patch adds a description to the buggy RSAAdjustPrimeCandidate\nimplementation that can only be properly fixed after 0.7.x.\n\nReported-by: Nicolas Iooss <nicolas.iooss@ledger.fr>\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 208419,
        "reasoning": "This code is vulnerable because the `RsaAdjustPrimeCandidate()` function weakens the generated RSA keys by modifying the most significant word of the prime candidate, resulting in keys with significantly reduced effective bit strength (around 1984 bits for a 2048-bit key). This adjustment, intended for compatibility, introduces a flaw in the key creation algorithm *before* prime verification, directly impacting data confidentiality as described in the CVE.\n\n\n\n",
        "func": "RsaAdjustPrimeCandidate(\n\t\t\tbigNum          prime\n\t\t\t)\n{\n    UINT16  highBytes;\n    crypt_uword_t       *msw = &prime->d[prime->size - 1];\n#define MASK (MAX_CRYPT_UWORD >> (RADIX_BITS - 16))\n    highBytes = *msw >> (RADIX_BITS - 16);\n    // This is fixed point arithmetic on 16-bit values\n    highBytes = ((UINT32)highBytes * (UINT32)0x4AFB) >> 16;\n    highBytes += 0xB505;\n    *msw = ((crypt_uword_t)(highBytes) << (RADIX_BITS - 16)) + (*msw & MASK);\n    prime->d[0] |= 1;\n}",
        "commit_message": "tpm2: rev155: Add new RsaAdjustPrimeCandidate code but do not use\n\nAdd in the new RsaAdjustPrimeCandidate() function but do not use it\nso far since it creates slightly different primes than the previous\ncode and we would get different derived keys if we were to use it with\n'old' seeds.\n\nAdjust the code to return the same results for 64 bit and 32 bit machines.\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 1
      },
      {
        "idx": 210377,
        "reasoning": "This code is vulnerable because the `RsaAdjustPrimeCandidate` function uses a `seedCompatLevel` to select different prime adjustment algorithms, and a specific level (`SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX`) introduces a fix for a TCG specification bug that previously resulted in weaker key strength (around 1984 bits for 2048-bit keys). Failing to consistently use the fixed algorithm, or allowing selection of the older, flawed one, leads to the generation of keys with reduced cryptographic strength, impacting data confidentiality as described in the CVE.\n\n\n\n",
        "func": "RsaAdjustPrimeCandidate(\n\t\t\tbigNum          prime,\n\t\t\tSEED_COMPAT_LEVEL seedCompatLevel  // IN: compatibility level; libtpms added\n\t\t\t)\n{\n    switch (seedCompatLevel) {\n    case SEED_COMPAT_LEVEL_ORIGINAL:\n        RsaAdjustPrimeCandidate_PreRev155(prime);\n        break;\n    /* case SEED_COMPAT_LEVEL_LAST: */\n    case SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX:\n        RsaAdjustPrimeCandidate_New(prime);\n        break;\n    default:\n        FAIL(FATAL_ERROR_INTERNAL);\n    }\n}",
        "commit_message": "tpm2: Activate SEED_COMPAT_LEVEL_RSA_PRIME_ADJUST_FIX\n\nSigned-off-by: Stefan Berger <stefanb@linux.ibm.com>",
        "cve_desc": "A flaw was found in libtpms in versions before 0.8.0. The TPM 2 implementation returns 2048 bit keys with ~1984 bit strength due to a bug in the TCG specification. The bug is in the key creation algorithm in RsaAdjustPrimeCandidate(), which is called before the prime number check. The highest threat from this vulnerability is to data confidentiality.",
        "target": 1
      }
    ]
  },
  "libuv": {
    "0": [
      {
        "idx": 44080,
        "reasoning": "This code snippet is not directly vulnerable to privilege escalation or other security issues based on the provided context. The commit message indicates a partial fix related to a previous issue (#1093), and the code focuses on handling child process termination signals (SIGCHLD) and retrieving their exit status \u2013 it doesn\u2019t contain any operations that inherently introduce vulnerabilities like improper permission handling or buffer overflows.\n\n\n\n",
        "func": "static void uv__chld(uv_signal_t* handle, int signum) {\n  uv_process_t* process;\n  uv_loop_t* loop;\n  int exit_status;\n  int term_signal;\n  unsigned int i;\n  int status;\n  pid_t pid;\n  QUEUE pending;\n  QUEUE* h;\n  QUEUE* q;\n\n  assert(signum == SIGCHLD);\n\n  QUEUE_INIT(&pending);\n  loop = handle->loop;\n\n  for (i = 0; i < ARRAY_SIZE(loop->process_handles); i++) {\n    h = loop->process_handles + i;\n    q = QUEUE_HEAD(h);\n\n    while (q != h) {\n      process = QUEUE_DATA(q, uv_process_t, queue);\n      q = QUEUE_NEXT(q);\n\n      do\n        pid = waitpid(process->pid, &status, WNOHANG);\n      while (pid == -1 && errno == EINTR);\n\n      if (pid == 0)\n        continue;\n\n      if (pid == -1) {\n        if (errno != ECHILD)\n          abort();\n        continue;\n      }\n\n      process->status = status;\n      QUEUE_REMOVE(&process->queue);\n      QUEUE_INSERT_TAIL(&pending, &process->queue);\n    }\n\n    while (!QUEUE_EMPTY(&pending)) {\n      q = QUEUE_HEAD(&pending);\n      QUEUE_REMOVE(q);\n      QUEUE_INIT(q);\n\n      process = QUEUE_DATA(q, uv_process_t, queue);\n      uv__handle_stop(process);\n\n      if (process->exit_cb == NULL)\n        continue;\n\n      exit_status = 0;\n      if (WIFEXITED(process->status))\n        exit_status = WEXITSTATUS(process->status);\n\n      term_signal = 0;\n      if (WIFSIGNALED(process->status))\n        term_signal = WTERMSIG(process->status);\n\n      process->exit_cb(process, exit_status, term_signal);\n    }\n  }\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 0
      },
      {
        "idx": 44081,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message indicates a partial fix related to user/group ID setting (#1093), but the code itself focuses on pipe creation and setting file descriptors' properties like cloexec and non-blocking status \u2013 it doesn't handle user ID manipulation directly, and therefore doesn't introduce a known vulnerability in this isolated snippet.\n\n\n\n",
        "func": "int uv__make_pipe(int fds[2], int flags) {\n#if defined(__linux__)\n  static int no_pipe2;\n\n  if (no_pipe2)\n    goto skip;\n\n  if (uv__pipe2(fds, flags | UV__O_CLOEXEC) == 0)\n    return 0;\n\n  if (errno != ENOSYS)\n    return -errno;\n\n  no_pipe2 = 1;\n\nskip:\n#endif\n\n  if (pipe(fds))\n    return -errno;\n\n  uv__cloexec(fds[0], 1);\n  uv__cloexec(fds[1], 1);\n\n  if (flags & UV__F_NONBLOCK) {\n    uv__nonblock(fds[0], 1);\n    uv__nonblock(fds[1], 1);\n  }\n\n  return 0;\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 0
      },
      {
        "idx": 44082,
        "reasoning": "This code is not vulnerable because the commit message indicates it's a *partial* fix for an issue (#1093) and the code itself focuses on gracefully handling the potential lack of `SOCK_CLOEXEC` support, falling back to a standard socketpair and then explicitly setting the close-on-exec flag using `uv__cloexec`. The `uv__cloexec` function call ensures the file descriptors are properly secured even if the initial `SOCK_CLOEXEC` flag isn't supported by the system, mitigating potential file descriptor leakage vulnerabilities.\n\n\n\n",
        "func": "int uv__make_socketpair(int fds[2], int flags) {\n#if defined(__linux__)\n  static int no_cloexec;\n\n  if (no_cloexec)\n    goto skip;\n\n  if (socketpair(AF_UNIX, SOCK_STREAM | UV__SOCK_CLOEXEC | flags, 0, fds) == 0)\n    return 0;\n\n  /* Retry on EINVAL, it means SOCK_CLOEXEC is not supported.\n   * Anything else is a genuine error.\n   */\n  if (errno != EINVAL)\n    return -errno;\n\n  no_cloexec = 1;\n\nskip:\n#endif\n\n  if (socketpair(AF_UNIX, SOCK_STREAM, 0, fds))\n    return -errno;\n\n  uv__cloexec(fds[0], 1);\n  uv__cloexec(fds[1], 1);\n\n  if (flags & UV__F_NONBLOCK) {\n    uv__nonblock(fds[0], 1);\n    uv__nonblock(fds[1], 1);\n  }\n\n  return 0;\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 0
      },
      {
        "idx": 44083,
        "reasoning": "This code snippet is not vulnerable because it solely deals with internal handle management\u2014removing a process handle from a queue and stopping it\u2014and doesn't involve any user input, privilege dropping, or external interactions that could lead to security issues. The commit message referencing a potential issue (#1093) and mentioning `setgoups` relates to a different part of the codebase dealing with user/group ID manipulation, and isn't reflected in this specific snippet.\n\n\n\n",
        "func": "void uv__process_close(uv_process_t* handle) {\n  /* TODO stop signal watcher when this is the last handle */\n  QUEUE_REMOVE(&handle->queue);\n  uv__handle_stop(handle);\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 0
      },
      {
        "idx": 44084,
        "reasoning": "This code snippet is not vulnerable because it simply closes a stream associated with a pipe if one was created\u2014it doesn\u2019t directly handle user ID manipulation or external input. The commit message references a separate issue (#1093) related to `setuid/setgid` calls, but this specific function doesn\u2019t appear to be involved in that potential vulnerability.\n\n\n\n",
        "func": "static void uv__process_close_stream(uv_stdio_container_t* container) {\n  if (!(container->flags & UV_CREATE_PIPE)) return;\n  uv__stream_close((uv_stream_t*)container->data.stream);\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1567,
        "reasoning": "This code is vulnerable because it calls `setuid` after potentially calling `setgid`, but before calling `setgroups`. Calling `setuid` or `setgid` before `setgroups` can lead to a situation where the effective group ID is not properly initialized, potentially allowing a context-dependent attacker to retain elevated privileges as described in CVE-2016-6298. \n\n\n\n",
        "func": "static void uv__process_child_init(const uv_process_options_t* options,\n                                   int stdio_count,\n                                   int (*pipes)[2],\n                                   int error_fd) {\n  int close_fd;\n  int use_fd;\n  int fd;\n\n  if (options->flags & UV_PROCESS_DETACHED)\n    setsid();\n\n  for (fd = 0; fd < stdio_count; fd++) {\n    close_fd = pipes[fd][0];\n    use_fd = pipes[fd][1];\n\n    if (use_fd < 0) {\n      if (fd >= 3)\n        continue;\n      else {\n        /* redirect stdin, stdout and stderr to /dev/null even if UV_IGNORE is\n         * set\n         */\n        use_fd = open(\"/dev/null\", fd == 0 ? O_RDONLY : O_RDWR);\n        close_fd = use_fd;\n\n        if (use_fd == -1) {\n        uv__write_int(error_fd, -errno);\n          perror(\"failed to open stdio\");\n          _exit(127);\n        }\n      }\n    }\n\n    if (fd == use_fd)\n      uv__cloexec(use_fd, 0);\n    else\n      dup2(use_fd, fd);\n\n    if (fd <= 2)\n      uv__nonblock(fd, 0);\n\n    if (close_fd != -1)\n      uv__close(close_fd);\n  }\n\n  for (fd = 0; fd < stdio_count; fd++) {\n    use_fd = pipes[fd][1];\n\n    if (use_fd >= 0 && fd != use_fd)\n      close(use_fd);\n  }\n\n  if (options->cwd != NULL && chdir(options->cwd)) {\n    uv__write_int(error_fd, -errno);\n    perror(\"chdir()\");\n     _exit(127);\n   }\n \n   if ((options->flags & UV_PROCESS_SETGID) && setgid(options->gid)) {\n     uv__write_int(error_fd, -errno);\n     perror(\"setgid()\");\n    _exit(127);\n  }\n\n  if ((options->flags & UV_PROCESS_SETUID) && setuid(options->uid)) {\n    uv__write_int(error_fd, -errno);\n    perror(\"setuid()\");\n    _exit(127);\n  }\n\n  if (options->env != NULL) {\n    environ = options->env;\n  }\n\n  execvp(options->file, options->args);\n  uv__write_int(error_fd, -errno);\n  perror(\"execvp()\");\n  _exit(127);\n}\n",
        "commit_message": "unix: call setgoups before calling setuid/setgid\n\nPartial fix for #1093",
        "cve_desc": "libuv before 0.10.34 does not properly drop group privileges, which allows context-dependent attackers to gain privileges via unspecified vectors.",
        "target": 1
      }
    ]
  },
  "libvirt": {
    "0": [
      {
        "idx": 85095,
        "reasoning": "This code snippet focuses on deregistering domain event callbacks and doesn't directly relate to the commit message's concern about read-only connections and guest agent interaction via `virDomainGetTime()`. The provided code simply handles event deregistration through the driver or reports unsupported functionality, posing no immediate security risk related to the stated policy.\n\n\n\n",
        "func": "virConnectDomainEventDeregister(virConnectPtr conn,\n                                virConnectDomainEventCallback cb)\n{\n    VIR_DEBUG(\"conn=%p, cb=%p\", conn, cb);\n\n    virResetLastError();\n\n    virCheckConnectReturn(conn, -1);\n    virCheckNonNullArgGoto(cb, error);\n\n    if (conn->driver && conn->driver->connectDomainEventDeregister) {\n        int ret;\n        ret = conn->driver->connectDomainEventDeregister(conn, cb);\n        if (ret < 0)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n error:\n    virDispatchError(conn);\n    return -1;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 0
      },
      {
        "idx": 85096,
        "reasoning": "This code snippet focuses on deregistering domain event callbacks and doesn't directly relate to the commit message's concern about read-only connections and guest agent interaction via `virDomainGetTime()`. The provided code simply handles event deregistration within libvirt's connection framework and doesn't introduce any vulnerabilities related to access control or guest agent communication.\n\n\n\n",
        "func": "virConnectDomainEventDeregisterAny(virConnectPtr conn,\n                                   int callbackID)\n{\n    VIR_DEBUG(\"conn=%p, callbackID=%d\", conn, callbackID);\n\n    virResetLastError();\n\n    virCheckConnectReturn(conn, -1);\n    virCheckNonNegativeArgGoto(callbackID, error);\n\n    if (conn->driver && conn->driver->connectDomainEventDeregisterAny) {\n        int ret;\n        ret = conn->driver->connectDomainEventDeregisterAny(conn, callbackID);\n        if (ret < 0)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n error:\n    virDispatchError(conn);\n    return -1;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 0
      },
      {
        "idx": 85097,
        "reasoning": "This code snippet focuses on registering a callback for domain events and doesn't directly relate to the commit message's concern about read-only connections and guest agent interaction via `virDomainGetTime()`. The provided code simply handles event registration and driver-specific implementations, without any apparent risk of exposing functionality requiring a read-write connection through a read-only one.\n\n\n\n",
        "func": "virConnectDomainEventRegister(virConnectPtr conn,\n                              virConnectDomainEventCallback cb,\n                              void *opaque,\n                              virFreeCallback freecb)\n{\n    VIR_DEBUG(\"conn=%p, cb=%p, opaque=%p, freecb=%p\", conn, cb, opaque, freecb);\n    virResetLastError();\n\n    virCheckConnectReturn(conn, -1);\n    virCheckNonNullArgGoto(cb, error);\n\n    if (conn->driver && conn->driver->connectDomainEventRegister) {\n        int ret;\n        ret = conn->driver->connectDomainEventRegister(conn, cb, opaque, freecb);\n        if (ret < 0)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n error:\n    virDispatchError(conn);\n    return -1;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 0
      },
      {
        "idx": 85098,
        "reasoning": "This code snippet focuses on registering domain event callbacks and includes several checks for valid arguments and connection states, but doesn't directly relate to the commit message's concern about read-only connections and guest agent interaction via `virDomainGetTime()`. Therefore, based on the provided code, there's no indication of a vulnerability related to the policy requiring read-write access for operations potentially involving the guest agent.\n\n\n\n",
        "func": "virConnectDomainEventRegisterAny(virConnectPtr conn,\n                                 virDomainPtr dom,\n                                 int eventID,\n                                 virConnectDomainEventGenericCallback cb,\n                                 void *opaque,\n                                 virFreeCallback freecb)\n{\n    VIR_DOMAIN_DEBUG(dom, \"conn=%p, eventID=%d, cb=%p, opaque=%p, freecb=%p\",\n                     conn, eventID, cb, opaque, freecb);\n\n    virResetLastError();\n\n    virCheckConnectReturn(conn, -1);\n    if (dom) {\n        virCheckDomainGoto(dom, error);\n        if (dom->conn != conn) {\n            virReportInvalidArg(dom,\n                                _(\"domain '%s' must match connection\"),\n                                dom->name);\n            goto error;\n        }\n    }\n    virCheckNonNullArgGoto(cb, error);\n    virCheckNonNegativeArgGoto(eventID, error);\n    if (eventID >= VIR_DOMAIN_EVENT_ID_LAST) {\n        virReportInvalidArg(eventID,\n                            _(\"eventID must be less than %d\"),\n                            VIR_DOMAIN_EVENT_ID_LAST);\n        goto error;\n    }\n\n    if (conn->driver && conn->driver->connectDomainEventRegisterAny) {\n        int ret;\n        ret = conn->driver->connectDomainEventRegisterAny(conn, dom, eventID, cb, opaque, freecb);\n        if (ret < 0)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n error:\n    virDispatchError(conn);\n    return -1;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 0
      },
      {
        "idx": 85099,
        "reasoning": "This code snippet is not directly vulnerable because it *enforces* the policy of requiring read-write (RW) connections before proceeding with potentially sensitive operations like accessing domain XML via `connectDomainXMLFromNative`. The `virCheckReadOnlyGoto(conn->flags, error);` line explicitly checks for read-only connections and halts execution if one is detected, preventing access that would violate the stated security policy.\n\n\n\n",
        "func": "virConnectDomainXMLFromNative(virConnectPtr conn,\n                              const char *nativeFormat,\n                              const char *nativeConfig,\n                              unsigned int flags)\n{\n    VIR_DEBUG(\"conn=%p, format=%s, config=%s, flags=%x\",\n              conn, NULLSTR(nativeFormat), NULLSTR(nativeConfig), flags);\n\n    virResetLastError();\n\n    virCheckConnectReturn(conn, NULL);\n    virCheckReadOnlyGoto(conn->flags, error);\n\n    virCheckNonNullArgGoto(nativeFormat, error);\n    virCheckNonNullArgGoto(nativeConfig, error);\n\n    if (conn->driver->connectDomainXMLFromNative) {\n        char *ret;\n        ret = conn->driver->connectDomainXMLFromNative(conn,\n                                                       nativeFormat,\n                                                       nativeConfig,\n                                                       flags);\n        if (!ret)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n\n error:\n    virDispatchError(conn);\n    return NULL;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 4207,
        "reasoning": "This code is vulnerable because it allows `virDomainGetTime` to be called even with a read-only (RO) connection, violating the security policy that requires read-write (RW) access when interacting with guest agents. The `virDomainGetTime` function doesn't enforce the necessary RW connection check, potentially allowing malicious agents to exploit the API with limited privileges, as described in the CVE.",
        "func": "virDomainGetTime(virDomainPtr dom,\n                 long long *seconds,\n                 unsigned int *nseconds,\n                 unsigned int flags)\n{\n    VIR_DOMAIN_DEBUG(dom, \"seconds=%p, nseconds=%p, flags=%x\",\n                     seconds, nseconds, flags);\n\n     virResetLastError();\n \n     virCheckDomainReturn(dom, -1);\n \n     if (dom->conn->driver->domainGetTime) {\n         int ret = dom->conn->driver->domainGetTime(dom, seconds,\n                                                   nseconds, flags);\n        if (ret < 0)\n            goto error;\n        return ret;\n    }\n\n    virReportUnsupportedError();\n\n error:\n    virDispatchError(dom->conn);\n    return -1;\n}\n",
        "commit_message": "virDomainGetTime: Deny on RO connections\n\nWe have a policy that if API may end up talking to a guest agent\nit should require RW connection. We don't obey the rule in\nvirDomainGetTime().\n\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "libvirt-domain.c in libvirt before 1.3.1 supports virDomainGetTime API calls by guest agents with an RO connection, even though an RW connection was supposed to be required, a different vulnerability than CVE-2019-3886.",
        "target": 1
      },
      {
        "idx": 198811,
        "reasoning": "This code is vulnerable because the thread name \"ev-<domid>\" is reused for all event handling threads associated with a domain, making it difficult to uniquely identify and manage the shutdown thread\u2014a key component in handling domain lifecycle events. As described in the CVE, a malicious guest repeatedly rebooting could overwhelm the system with these threads, potentially leading to a deadlock or crash due to the inability to properly track and clean up shutdown processes, ultimately causing a denial of service.",
        "func": "libxlDomainEventHandler(void *data, libxl_event *event)\n{\n    libxlDriverPrivate *driver = data;\n    libxl_shutdown_reason xl_reason = event->u.domain_shutdown.shutdown_reason;\n    virDomainObj *vm = NULL;\n    g_autoptr(libxlDriverConfig) cfg = NULL;\n\n    VIR_DEBUG(\"Received libxl event '%d' for domid '%d'\", event->type, event->domid);\n\n    if (event->type != LIBXL_EVENT_TYPE_DOMAIN_SHUTDOWN &&\n            event->type != LIBXL_EVENT_TYPE_DOMAIN_DEATH) {\n        VIR_INFO(\"Unhandled event type %d\", event->type);\n        goto cleanup;\n    }\n\n    /*\n     * Similar to the xl implementation, ignore SUSPEND.  Any actions needed\n     * after calling libxl_domain_suspend() are handled by its callers.\n     */\n    if (xl_reason == LIBXL_SHUTDOWN_REASON_SUSPEND)\n        goto cleanup;\n\n    vm = virDomainObjListFindByID(driver->domains, event->domid);\n    if (!vm) {\n        /* Nothing to do if we can't find the virDomainObj */\n        goto cleanup;\n    }\n\n    if (event->type == LIBXL_EVENT_TYPE_DOMAIN_SHUTDOWN) {\n        struct libxlEventHandlerThreadInfo *shutdown_info = NULL;\n        virThread thread;\n        g_autofree char *name = NULL;\n\n        /*\n         * Start a thread to handle shutdown.  We don't want to be tying up\n         * libxl's event machinery by doing a potentially lengthy shutdown.\n         */\n        shutdown_info = g_new0(struct libxlEventHandlerThreadInfo, 1);\n\n        shutdown_info->driver = driver;\n        shutdown_info->vm = vm;\n        shutdown_info->event = (libxl_event *)event;\n        name = g_strdup_printf(\"ev-%d\", event->domid);\n        /*\n         * Cleanup will be handled by the shutdown thread.\n         */\n        if (virThreadCreateFull(&thread, false, libxlDomainShutdownThread,\n                                name, false, shutdown_info) < 0) {\n            /*\n             * Not much we can do on error here except log it.\n             */\n            VIR_ERROR(_(\"Failed to create thread to handle domain shutdown\"));\n            VIR_FREE(shutdown_info);\n            goto cleanup;\n        }\n        /*\n         * virDomainObjEndAPI is called in the shutdown thread, where\n         * libxlEventHandlerThreadInfo and libxl_event are also freed.\n         */\n        return;\n    } else if (event->type == LIBXL_EVENT_TYPE_DOMAIN_DEATH) {\n        /*\n         * On death the domain is cleaned up from Xen's perspective.\n         * Cleanup on the libvirt side can be done synchronously.\n         */\n        libxlDomainHandleDeath(driver, vm);\n    }\n\n cleanup:\n    virDomainObjEndAPI(&vm);\n    cfg = libxlDriverConfigGet(driver);\n    /* Cast away any const */\n    libxl_event_free(cfg->ctx, (libxl_event *)event);\n}",
        "commit_message": "libxl: Modify name of shutdown thread\n\nThe current thread name 'ev-<domid>' is a bit terse. Change the name\nto 'shutdown-event-<domid>', allowing it to be distinguished between\nthread handling other event types.\n\nSigned-off-by: Jim Fehlig <jfehlig@suse.com>\nReviewed-by: Daniel P. Berrang\u00e9 <berrange@redhat.com>\nReviewed-by: J\u00e1n Tomko <jtomko@redhat.com>",
        "cve_desc": "A flaw was found in the libvirt libxl driver. A malicious guest could continuously reboot itself and cause libvirtd on the host to deadlock or crash, resulting in a denial of service condition.",
        "target": 1
      },
      {
        "idx": 202123,
        "reasoning": "This code is vulnerable to a use-after-free because `qemuMonitorUnregister` is called from multiple threads without proper locking, potentially leading to `g_source_unref` being called multiple times on the same resource. As described in the CVE, this can occur during guest shutdown when `virConnectGetAllDomainStats` is used, ultimately causing the libvirt daemon to crash and resulting in a denial of service.",
        "func": "qemuProcessHandleMonitorEOF(qemuMonitorPtr mon,\n                            virDomainObjPtr vm,\n                            void *opaque)\n{\n    virQEMUDriverPtr driver = opaque;\n    qemuDomainObjPrivatePtr priv;\n    struct qemuProcessEvent *processEvent;\n\n    virObjectLock(vm);\n\n    VIR_DEBUG(\"Received EOF on %p '%s'\", vm, vm->def->name);\n\n    priv = vm->privateData;\n    if (priv->beingDestroyed) {\n        VIR_DEBUG(\"Domain is being destroyed, EOF is expected\");\n        goto cleanup;\n    }\n\n    processEvent = g_new0(struct qemuProcessEvent, 1);\n\n    processEvent->eventType = QEMU_PROCESS_EVENT_MONITOR_EOF;\n    processEvent->vm = virObjectRef(vm);\n\n    if (virThreadPoolSendJob(driver->workerPool, 0, processEvent) < 0) {\n        virObjectUnref(vm);\n        qemuProcessEventFree(processEvent);\n        goto cleanup;\n    }\n\n    /* We don't want this EOF handler to be called over and over while the\n     * thread is waiting for a job.\n     */\n    qemuMonitorUnregister(mon);\n\n    /* We don't want any cleanup from EOF handler (or any other\n     * thread) to enter qemu namespace. */\n    qemuDomainDestroyNamespace(driver, vm);\n\n cleanup:\n    virObjectUnlock(vm);\n}",
        "commit_message": "qemu: Add missing lock in qemuProcessHandleMonitorEOF\n\nqemuMonitorUnregister will be called in multiple threads (e.g. threads\nin rpc worker pool and the vm event thread).  In some cases, it isn't\nprotected by the monitor lock, which may lead to call g_source_unref\nmore than one time and a use-after-free problem eventually.\n\nAdd the missing lock in qemuProcessHandleMonitorEOF (which is the only\nposition missing lock of monitor I found).\n\nSuggested-by: Michal Privoznik <mprivozn@redhat.com>\nSigned-off-by: Peng Liang <liangpeng10@huawei.com>\nSigned-off-by: Michal Privoznik <mprivozn@redhat.com>\nReviewed-by: Michal Privoznik <mprivozn@redhat.com>",
        "cve_desc": "A use-after-free flaw was found in libvirt. The qemuMonitorUnregister() function in qemuProcessHandleMonitorEOF is called using multiple threads without being adequately protected by a monitor lock. This flaw could be triggered by the virConnectGetAllDomainStats API when the guest is shutting down. An unprivileged client with a read-only connection could use this flaw to perform a denial of service attack by causing the libvirt daemon to crash.",
        "target": 1
      },
      {
        "idx": 214055,
        "reasoning": "This code is vulnerable because the `virNWFilterObjListNumOfNWFilters` function iterates over `driver->nwfilters` without holding a lock, allowing concurrent modification from functions like `virNWFilterUndefine`. An unprivileged user can exploit this race condition via the `virConnectNumOfNWFilters` API to trigger a denial-of-service crash in `libvirtd/virtnwfilterd`.\n\n\n\n",
        "func": "nwfilterConnectNumOfNWFilters(virConnectPtr conn)\n{\n    if (virConnectNumOfNWFiltersEnsureACL(conn) < 0)\n        return -1;\n\n    return virNWFilterObjListNumOfNWFilters(driver->nwfilters, conn,\n                                        virConnectNumOfNWFiltersCheckACL);\n}",
        "commit_message": "nwfilter: fix crash when counting number of network filters\n\nThe virNWFilterObjListNumOfNWFilters method iterates over the\ndriver->nwfilters, accessing virNWFilterObj instances. As such\nit needs to be protected against concurrent modification of\nthe driver->nwfilters object.\n\nThis API allows unprivileged users to connect, so users with\nread-only access to libvirt can cause a denial of service\ncrash if they are able to race with a call of virNWFilterUndefine.\nSince network filters are usually statically defined, this is\nconsidered a low severity problem.\n\nThis is assigned CVE-2022-0897.\n\nReviewed-by: Eric Blake <eblake@redhat.com>\nSigned-off-by: Daniel P. Berrang\u00e9 <berrange@redhat.com>",
        "cve_desc": "A flaw was found in the libvirt nwfilter driver. The virNWFilterObjListNumOfNWFilters method failed to acquire the driver->nwfilters mutex before iterating over virNWFilterObj instances. There was no protection to stop another thread from concurrently modifying the driver->nwfilters object. This flaw allows a malicious, unprivileged user to exploit this issue via libvirt's API virConnectNumOfNWFilters to crash the network filter management daemon (libvirtd/virtnwfilterd).",
        "target": 1
      }
    ]
  },
  "libvncserver": {
    "0": [
      {
        "idx": 281670,
        "reasoning": "This code is not vulnerable because the commit message indicates the removal of a useless cast, suggesting a cleanup rather than a security fix. The core logic of reading and validating security types appears sound, with checks against known schemes and client preferences, and doesn't exhibit any immediately obvious vulnerabilities like buffer overflows or format string issues.\n\n\n\n",
        "func": "ReadSupportedSecurityType(rfbClient* client, uint32_t *result, rfbBool subAuth)\n{\n    uint8_t count=0;\n    uint8_t loop=0;\n    uint8_t flag=0;\n    rfbBool extAuthHandler;\n    uint8_t tAuth[256];\n    char buf1[500],buf2[10];\n    uint32_t authScheme;\n    rfbClientProtocolExtension* e;\n\n    if (!ReadFromRFBServer(client, (char *)&count, 1)) return FALSE;\n\n    if (count==0)\n    {\n        rfbClientLog(\"List of security types is ZERO, expecting an error to follow\\n\");\n        ReadReason(client);\n        return FALSE;\n    }\n\n    rfbClientLog(\"We have %d security types to read\\n\", count);\n    authScheme=0;\n    /* now, we have a list of available security types to read ( uint8_t[] ) */\n    for (loop=0;loop<count;loop++)\n    {\n        if (!ReadFromRFBServer(client, (char *)&tAuth[loop], 1)) return FALSE;\n        rfbClientLog(\"%d) Received security type %d\\n\", loop, tAuth[loop]);\n        if (flag) continue;\n        extAuthHandler=FALSE;\n        for (e = rfbClientExtensions; e; e = e->next) {\n            if (!e->handleAuthentication) continue;\n            uint32_t const* secType;\n            for (secType = e->securityTypes; secType && *secType; secType++) {\n                if (tAuth[loop]==*secType) {\n                    extAuthHandler=TRUE;\n                }\n            }\n        }\n        if (tAuth[loop]==rfbVncAuth || tAuth[loop]==rfbNoAuth ||\n\t\t\textAuthHandler ||\n#if defined(LIBVNCSERVER_HAVE_GNUTLS) || defined(LIBVNCSERVER_HAVE_LIBSSL)\n            tAuth[loop]==rfbVeNCrypt ||\n#endif\n#ifdef LIBVNCSERVER_HAVE_SASL\n            tAuth[loop]==rfbSASL ||\n#endif /* LIBVNCSERVER_HAVE_SASL */\n            (tAuth[loop]==rfbARD && client->GetCredential) ||\n            (!subAuth && (tAuth[loop]==rfbTLS || (tAuth[loop]==rfbVeNCrypt && client->GetCredential))))\n        {\n            if (!subAuth && client->clientAuthSchemes)\n            {\n                int i;\n                for (i=0;client->clientAuthSchemes[i];i++)\n                {\n                    if (client->clientAuthSchemes[i]==(uint32_t)tAuth[loop])\n                    {\n                        flag++;\n                        authScheme=tAuth[loop];\n                        break;\n                    }\n                }\n            }\n            else\n            {\n                flag++;\n                authScheme=tAuth[loop];\n            }\n            if (flag)\n            {\n                rfbClientLog(\"Selecting security type %d (%d/%d in the list)\\n\", authScheme, loop, count);\n                /* send back a single byte indicating which security type to use */\n                if (!WriteToRFBServer(client, (char *)&tAuth[loop], 1)) return FALSE;\n            }\n        }\n    }\n    if (authScheme==0)\n    {\n        memset(buf1, 0, sizeof(buf1));\n        for (loop=0;loop<count;loop++)\n        {\n            if (strlen(buf1)>=sizeof(buf1)-1) break;\n            snprintf(buf2, sizeof(buf2), (loop>0 ? \", %d\" : \"%d\"), (int)tAuth[loop]);\n            strncat(buf1, buf2, sizeof(buf1)-strlen(buf1)-1);\n        }\n        rfbClientLog(\"Unknown authentication scheme from VNC server: %s\\n\",\n               buf1);\n        return FALSE;\n    }\n    *result = authScheme;\n    return TRUE;\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 0
      },
      {
        "idx": 281671,
        "reasoning": "This code snippet is not vulnerable because it simply initializes a structure and sets supported message flags within a VNC client\u2014it doesn't handle external input or perform any potentially dangerous operations like memory allocation or string manipulation that could lead to exploits. The removal of a cast in the associated commit further suggests a cleanup of existing code rather than an attempt to address a security issue.\n\n\n\n",
        "func": "DefaultSupportedMessages(rfbClient* client)\n{\n    memset((char *)&client->supportedMessages,0,sizeof(client->supportedMessages));\n\n    /* Default client supported messages (universal RFB 3.3 protocol) */\n    SetClient2Server(client, rfbSetPixelFormat);\n    /* SetClient2Server(client, rfbFixColourMapEntries); Not currently supported */\n    SetClient2Server(client, rfbSetEncodings);\n    SetClient2Server(client, rfbFramebufferUpdateRequest);\n    SetClient2Server(client, rfbKeyEvent);\n    SetClient2Server(client, rfbPointerEvent);\n    SetClient2Server(client, rfbClientCutText);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbFramebufferUpdate);\n    SetServer2Client(client, rfbSetColourMapEntries);\n    SetServer2Client(client, rfbBell);\n    SetServer2Client(client, rfbServerCutText);\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 0
      },
      {
        "idx": 281672,
        "reasoning": "This code snippet is safe and doesn't present any immediately obvious vulnerabilities. The function simply retrieves client data based on a provided tag, iterating through a linked list \u2013 there's no input validation issue, memory corruption potential, or other common vulnerability patterns present in this small excerpt.",
        "func": "void* rfbClientGetClientData(rfbClient* client, void* tag)\n{\n\trfbClientData* clientData = client->clientData;\n\n\twhile(clientData) {\n\t\tif(clientData->tag == tag)\n\t\t\treturn clientData->data;\n\t\tclientData = clientData->next;\n\t}\n\n\treturn NULL;\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 0
      },
      {
        "idx": 281673,
        "reasoning": "This code is not vulnerable based on the provided snippet and commit message. The commit simply removes a cast that was deemed unnecessary, indicating a code cleanup rather than a security fix, and the surrounding code handles network communication and protocol parsing without apparent flaws that would introduce vulnerabilities.",
        "func": "InitialiseRFBConnection(rfbClient* client)\n{\n  rfbProtocolVersionMsg pv;\n  int major,minor;\n  uint32_t authScheme;\n  uint32_t subAuthScheme;\n  rfbClientInitMsg ci;\n\n  /* if the connection is immediately closed, don't report anything, so\n       that pmw's monitor can make test connections */\n\n  if (client->listenSpecified)\n    errorMessageOnReadFailure = FALSE;\n\n  if (!ReadFromRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n  pv[sz_rfbProtocolVersionMsg]=0;\n\n  errorMessageOnReadFailure = TRUE;\n\n  pv[sz_rfbProtocolVersionMsg] = 0;\n\n  if (sscanf(pv,rfbProtocolVersionFormat,&major,&minor) != 2) {\n    rfbClientLog(\"Not a valid VNC server (%s)\\n\",pv);\n    return FALSE;\n  }\n\n\n  DefaultSupportedMessages(client);\n  client->major = major;\n  client->minor = minor;\n\n  /* fall back to viewer supported version */\n  if ((major==rfbProtocolMajorVersion) && (minor>rfbProtocolMinorVersion))\n    client->minor = rfbProtocolMinorVersion;\n\n  /* UltraVNC uses minor codes 4 and 6 for the server */\n  if (major==3 && (minor==4 || minor==6)) {\n      rfbClientLog(\"UltraVNC server detected, enabling UltraVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* UltraVNC Single Click uses minor codes 14 and 16 for the server */\n  if (major==3 && (minor==14 || minor==16)) {\n     minor = minor - 10;\n     client->minor = minor;\n     rfbClientLog(\"UltraVNC Single Click server detected, enabling UltraVNC specific messages\\n\",pv);\n     DefaultSupportedMessagesUltraVNC(client);\n  }\n\n  /* TightVNC uses minor codes 5 for the server */\n  if (major==3 && minor==5) {\n      rfbClientLog(\"TightVNC server detected, enabling TightVNC specific messages\\n\",pv);\n      DefaultSupportedMessagesTightVNC(client);\n  }\n\n  /* we do not support > RFB3.8 */\n  if ((major==3 && minor>8) || major>3)\n  {\n    client->major=3;\n    client->minor=8;\n  }\n\n  rfbClientLog(\"VNC server supports protocol version %d.%d (viewer %d.%d)\\n\",\n\t  major, minor, rfbProtocolMajorVersion, rfbProtocolMinorVersion);\n\n  sprintf(pv,rfbProtocolVersionFormat,client->major,client->minor);\n\n  if (!WriteToRFBServer(client, pv, sz_rfbProtocolVersionMsg)) return FALSE;\n\n\n  /* 3.7 and onwards sends a # of security types first */\n  if (client->major==3 && client->minor > 6)\n  {\n    if (!ReadSupportedSecurityType(client, &authScheme, FALSE)) return FALSE;\n  }\n  else\n  {\n    if (!ReadFromRFBServer(client, (char *)&authScheme, 4)) return FALSE;\n    authScheme = rfbClientSwap32IfLE(authScheme);\n  }\n  \n  rfbClientLog(\"Selected Security Scheme %d\\n\", authScheme);\n  client->authScheme = authScheme;\n  \n  switch (authScheme) {\n\n  case rfbConnFailed:\n    ReadReason(client);\n    return FALSE;\n\n  case rfbNoAuth:\n    rfbClientLog(\"No authentication needed\\n\");\n\n    /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n    if ((client->major==3 && client->minor > 7) || client->major>3)\n        if (!rfbHandleAuthResult(client)) return FALSE;        \n\n    break;\n\n  case rfbVncAuth:\n    if (!HandleVncAuth(client)) return FALSE;\n    break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n  case rfbSASL:\n    if (!HandleSASLAuth(client)) return FALSE;\n    break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n  case rfbMSLogon:\n    if (!HandleMSLogonAuth(client)) return FALSE;\n    break;\n\n  case rfbARD:\n#ifndef LIBVNCSERVER_WITH_CLIENT_GCRYPT\n    rfbClientLog(\"GCrypt support was not compiled in\\n\");\n    return FALSE;\n#else\n    if (!HandleARDAuth(client)) return FALSE;\n#endif\n    break;\n\n  case rfbTLS:\n    if (!HandleAnonTLSAuth(client)) return FALSE;\n    /* After the TLS session is established, sub auth types are expected.\n     * Note that all following reading/writing are through the TLS session from here.\n     */\n    if (!ReadSupportedSecurityType(client, &subAuthScheme, TRUE)) return FALSE;\n    client->subAuthScheme = subAuthScheme;\n\n    switch (subAuthScheme) {\n\n      case rfbConnFailed:\n        ReadReason(client);\n        return FALSE;\n\n      case rfbNoAuth:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        /* 3.8 and upwards sends a Security Result for rfbNoAuth */\n        if ((client->major==3 && client->minor > 7) || client->major>3)\n            if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVncAuth:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            (int)subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  case rfbVeNCrypt:\n    if (!HandleVeNCryptAuth(client)) return FALSE;\n\n    switch (client->subAuthScheme) {\n\n      case rfbVeNCryptTLSNone:\n      case rfbVeNCryptX509None:\n        rfbClientLog(\"No sub authentication needed\\n\");\n        if (!rfbHandleAuthResult(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSVNC:\n      case rfbVeNCryptX509VNC:\n        if (!HandleVncAuth(client)) return FALSE;\n        break;\n\n      case rfbVeNCryptTLSPlain:\n      case rfbVeNCryptX509Plain:\n        if (!HandlePlainAuth(client)) return FALSE;\n        break;\n\n#ifdef LIBVNCSERVER_HAVE_SASL\n      case rfbVeNCryptX509SASL:\n      case rfbVeNCryptTLSSASL:\n        if (!HandleSASLAuth(client)) return FALSE;\n        break;\n#endif /* LIBVNCSERVER_HAVE_SASL */\n\n      default:\n        rfbClientLog(\"Unknown sub authentication scheme from VNC server: %d\\n\",\n            client->subAuthScheme);\n        return FALSE;\n    }\n\n    break;\n\n  default:\n    {\n      rfbBool authHandled=FALSE;\n      rfbClientProtocolExtension* e;\n      for (e = rfbClientExtensions; e; e = e->next) {\n        uint32_t const* secType;\n        if (!e->handleAuthentication) continue;\n        for (secType = e->securityTypes; secType && *secType; secType++) {\n          if (authScheme==*secType) {\n            if (!e->handleAuthentication(client, authScheme)) return FALSE;\n            if (!rfbHandleAuthResult(client)) return FALSE;\n            authHandled=TRUE;\n          }\n        }\n      }\n      if (authHandled) break;\n    }\n    rfbClientLog(\"Unknown authentication scheme from VNC server: %d\\n\",\n\t    (int)authScheme);\n    return FALSE;\n  }\n\n  ci.shared = (client->appData.shareDesktop ? 1 : 0);\n\n  if (!WriteToRFBServer(client,  (char *)&ci, sz_rfbClientInitMsg)) return FALSE;\n\n  if (!ReadFromRFBServer(client, (char *)&client->si, sz_rfbServerInitMsg)) return FALSE;\n\n  client->si.framebufferWidth = rfbClientSwap16IfLE(client->si.framebufferWidth);\n  client->si.framebufferHeight = rfbClientSwap16IfLE(client->si.framebufferHeight);\n  client->si.format.redMax = rfbClientSwap16IfLE(client->si.format.redMax);\n  client->si.format.greenMax = rfbClientSwap16IfLE(client->si.format.greenMax);\n  client->si.format.blueMax = rfbClientSwap16IfLE(client->si.format.blueMax);\n  client->si.nameLength = rfbClientSwap32IfLE(client->si.nameLength);\n\n  if (client->si.nameLength > 1<<20) {\n      rfbClientErr(\"Too big desktop name length sent by server: %u B > 1 MB\\n\", (unsigned int)client->si.nameLength);\n      return FALSE;\n  }\n\n  client->desktopName = malloc(client->si.nameLength + 1);\n  if (!client->desktopName) {\n    rfbClientLog(\"Error allocating memory for desktop name, %lu bytes\\n\",\n            (unsigned long)client->si.nameLength);\n    return FALSE;\n  }\n\n  if (!ReadFromRFBServer(client, client->desktopName, client->si.nameLength)) return FALSE;\n\n  client->desktopName[client->si.nameLength] = 0;\n\n  rfbClientLog(\"Desktop name \\\"%s\\\"\\n\",client->desktopName);\n\n  rfbClientLog(\"Connected to VNC server, using protocol version %d.%d\\n\",\n\t  client->major, client->minor);\n\n  rfbClientLog(\"VNC server default format:\\n\");\n  PrintPixelFormat(&client->si.format);\n\n  return TRUE;\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 0
      },
      {
        "idx": 281674,
        "reasoning": "This code snippet is safe and doesn't introduce any vulnerabilities. It simply manipulates a linked list of client protocol extensions, adding a new extension to the beginning\u2014there's no input handling, memory management issues, or potential for control flow manipulation present in this small function.",
        "func": "void rfbClientRegisterExtension(rfbClientProtocolExtension* e)\n{\n\te->next = rfbClientExtensions;\n\trfbClientExtensions = e;\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 198705,
        "reasoning": "The code is vulnerable to heap out-of-bounds writes due to insufficient bounds checking when reading data from the VNC server, specifically within functions like `ReadFromRFBServer` and handling message lengths (e.g., `msg.sct.length`). This allows a malicious server to send crafted messages exceeding expected sizes, overwriting adjacent memory on the heap, as indicated by the incomplete fix for CVE-2018-20019.",
        "func": "HandleRFBServerMessage(rfbClient* client)\n{\n  rfbServerToClientMsg msg;\n\n  if (client->serverPort==-1)\n    client->vncRec->readTimestamp = TRUE;\n  if (!ReadFromRFBServer(client, (char *)&msg, 1))\n    return FALSE;\n\n  switch (msg.type) {\n\n  case rfbSetColourMapEntries:\n  {\n    /* TODO:\n    int i;\n    uint16_t rgb[3];\n    XColor xc;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbSetColourMapEntriesMsg - 1))\n      return FALSE;\n\n    msg.scme.firstColour = rfbClientSwap16IfLE(msg.scme.firstColour);\n    msg.scme.nColours = rfbClientSwap16IfLE(msg.scme.nColours);\n\n    for (i = 0; i < msg.scme.nColours; i++) {\n      if (!ReadFromRFBServer(client, (char *)rgb, 6))\n\treturn FALSE;\n      xc.pixel = msg.scme.firstColour + i;\n      xc.red = rfbClientSwap16IfLE(rgb[0]);\n      xc.green = rfbClientSwap16IfLE(rgb[1]);\n      xc.blue = rfbClientSwap16IfLE(rgb[2]);\n      xc.flags = DoRed|DoGreen|DoBlue;\n      XStoreColor(dpy, cmap, &xc);\n    }\n    */\n\n    break;\n  }\n\n  case rfbFramebufferUpdate:\n  {\n    rfbFramebufferUpdateRectHeader rect;\n    int linesToRead;\n    int bytesPerLine;\n    int i;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg.fu) + 1,\n\t\t\t   sz_rfbFramebufferUpdateMsg - 1))\n      return FALSE;\n\n    msg.fu.nRects = rfbClientSwap16IfLE(msg.fu.nRects);\n\n    for (i = 0; i < msg.fu.nRects; i++) {\n      if (!ReadFromRFBServer(client, (char *)&rect, sz_rfbFramebufferUpdateRectHeader))\n\treturn FALSE;\n\n      rect.encoding = rfbClientSwap32IfLE(rect.encoding);\n      if (rect.encoding == rfbEncodingLastRect)\n\tbreak;\n\n      rect.r.x = rfbClientSwap16IfLE(rect.r.x);\n      rect.r.y = rfbClientSwap16IfLE(rect.r.y);\n      rect.r.w = rfbClientSwap16IfLE(rect.r.w);\n      rect.r.h = rfbClientSwap16IfLE(rect.r.h);\n\n\n      if (rect.encoding == rfbEncodingXCursor ||\n\t  rect.encoding == rfbEncodingRichCursor) {\n\n\tif (!HandleCursorShape(client,\n\t\t\t       rect.r.x, rect.r.y, rect.r.w, rect.r.h,\n\t\t\t       rect.encoding)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n\n      if (rect.encoding == rfbEncodingPointerPos) {\n\tif (!client->HandleCursorPos(client,rect.r.x, rect.r.y)) {\n\t  return FALSE;\n\t}\n\tcontinue;\n      }\n      \n      if (rect.encoding == rfbEncodingKeyboardLedState) {\n          /* OK! We have received a keyboard state message!!! */\n          client->KeyboardLedStateEnabled = 1;\n          if (client->HandleKeyboardLedState!=NULL)\n              client->HandleKeyboardLedState(client, rect.r.x, 0);\n          /* stash it for the future */\n          client->CurrentKeyboardLedState = rect.r.x;\n          continue;\n      }\n\n      if (rect.encoding == rfbEncodingNewFBSize) {\n\tclient->width = rect.r.w;\n\tclient->height = rect.r.h;\n\tclient->updateRect.x = client->updateRect.y = 0;\n\tclient->updateRect.w = client->width;\n\tclient->updateRect.h = client->height;\n\tif (!client->MallocFrameBuffer(client))\n\t  return FALSE;\n\tSendFramebufferUpdateRequest(client, 0, 0, rect.r.w, rect.r.h, FALSE);\n\trfbClientLog(\"Got new framebuffer size: %dx%d\\n\", rect.r.w, rect.r.h);\n\tcontinue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingSupportedMessages) {\n          int loop;\n          if (!ReadFromRFBServer(client, (char *)&client->supportedMessages, sz_rfbSupportedMessages))\n              return FALSE;\n\n          /* msgs is two sets of bit flags of supported messages client2server[] and server2client[] */\n          /* currently ignored by this library */\n\n          rfbClientLog(\"client2server supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.client2server[loop],   client->supportedMessages.client2server[loop+1],\n                client->supportedMessages.client2server[loop+2], client->supportedMessages.client2server[loop+3],\n                client->supportedMessages.client2server[loop+4], client->supportedMessages.client2server[loop+5],\n                client->supportedMessages.client2server[loop+6], client->supportedMessages.client2server[loop+7]);\n\n          rfbClientLog(\"server2client supported messages (bit flags)\\n\");\n          for (loop=0;loop<32;loop+=8)\n            rfbClientLog(\"%02X: %04x %04x %04x %04x - %04x %04x %04x %04x\\n\", loop,\n                client->supportedMessages.server2client[loop],   client->supportedMessages.server2client[loop+1],\n                client->supportedMessages.server2client[loop+2], client->supportedMessages.server2client[loop+3],\n                client->supportedMessages.server2client[loop+4], client->supportedMessages.server2client[loop+5],\n                client->supportedMessages.server2client[loop+6], client->supportedMessages.server2client[loop+7]);\n          continue;\n      }\n\n      /* rect.r.w=byte count, rect.r.h=# of encodings */\n      if (rect.encoding == rfbEncodingSupportedEncodings) {\n          char *buffer;\n          buffer = malloc(rect.r.w);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n\n          /* buffer now contains rect.r.h # of uint32_t encodings that the server supports */\n          /* currently ignored by this library */\n          free(buffer);\n          continue;\n      }\n\n      /* rect.r.w=byte count */\n      if (rect.encoding == rfbEncodingServerIdentity) {\n          char *buffer;\n          buffer = malloc(rect.r.w+1);\n          if (!ReadFromRFBServer(client, buffer, rect.r.w))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          buffer[rect.r.w]=0; /* null terminate, just in case */\n          rfbClientLog(\"Connected to Server \\\"%s\\\"\\n\", buffer);\n          free(buffer);\n          continue;\n      }\n\n      /* rfbEncodingUltraZip is a collection of subrects.   x = # of subrects, and h is always 0 */\n      if (rect.encoding != rfbEncodingUltraZip)\n      {\n        if ((rect.r.x + rect.r.w > client->width) ||\n\t    (rect.r.y + rect.r.h > client->height))\n\t    {\n\t      rfbClientLog(\"Rect too large: %dx%d at (%d, %d)\\n\",\n\t  \t  rect.r.w, rect.r.h, rect.r.x, rect.r.y);\n\t      return FALSE;\n            }\n\n        /* UltraVNC with scaling, will send rectangles with a zero W or H\n         *\n        if ((rect.encoding != rfbEncodingTight) && \n            (rect.r.h * rect.r.w == 0))\n        {\n\t  rfbClientLog(\"Zero size rect - ignoring (encoding=%d (0x%08x) %dx, %dy, %dw, %dh)\\n\", rect.encoding, rect.encoding, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n\t  continue;\n        }\n        */\n        \n        /* If RichCursor encoding is used, we should prevent collisions\n\t   between framebuffer updates and cursor drawing operations. */\n        client->SoftCursorLockArea(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n      }\n\n      switch (rect.encoding) {\n\n      case rfbEncodingRaw: {\n\tint y=rect.r.y, h=rect.r.h;\n\n\tbytesPerLine = rect.r.w * client->format.bitsPerPixel / 8;\n\t/* RealVNC 4.x-5.x on OSX can induce bytesPerLine==0, \n\t   usually during GPU accel. */\n\t/* Regardless of cause, do not divide by zero. */\n\tlinesToRead = bytesPerLine ? (RFB_BUFFER_SIZE / bytesPerLine) : 0;\n\n\twhile (linesToRead && h > 0) {\n\t  if (linesToRead > h)\n\t    linesToRead = h;\n\n\t  if (!ReadFromRFBServer(client, client->buffer,bytesPerLine * linesToRead))\n\t    return FALSE;\n\n\t  client->GotBitmap(client, (uint8_t *)client->buffer,\n\t\t\t   rect.r.x, y, rect.r.w,linesToRead);\n\n\t  h -= linesToRead;\n\t  y += linesToRead;\n\n\t}\n\tbreak;\n      } \n\n      case rfbEncodingCopyRect:\n      {\n\trfbCopyRect cr;\n\n\tif (!ReadFromRFBServer(client, (char *)&cr, sz_rfbCopyRect))\n\t  return FALSE;\n\n\tcr.srcX = rfbClientSwap16IfLE(cr.srcX);\n\tcr.srcY = rfbClientSwap16IfLE(cr.srcY);\n\n\t/* If RichCursor encoding is used, we should extend our\n\t   \"cursor lock area\" (previously set to destination\n\t   rectangle) to the source rectangle as well. */\n\tclient->SoftCursorLockArea(client,\n\t\t\t\t   cr.srcX, cr.srcY, rect.r.w, rect.r.h);\n\n        client->GotCopyRect(client, cr.srcX, cr.srcY, rect.r.w, rect.r.h,\n                            rect.r.x, rect.r.y);\n\n\tbreak;\n      }\n\n      case rfbEncodingRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingCoRRE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleCoRRE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleCoRRE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleCoRRE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingHextile:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleHextile8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleHextile16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleHextile32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n\n      case rfbEncodingUltra:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltra8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltra16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltra32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n      case rfbEncodingUltraZip:\n      {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleUltraZip8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (!HandleUltraZip16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        case 32:\n          if (!HandleUltraZip32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n            return FALSE;\n          break;\n        }\n        break;\n      }\n\n      case rfbEncodingTRLE:\n\t  {\n        switch (client->format.bitsPerPixel) {\n        case 8:\n          if (!HandleTRLE8(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n            return FALSE;\n          break;\n        case 16:\n          if (client->si.format.greenMax > 0x1F) {\n            if (!HandleTRLE16(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else {\n            if (!HandleTRLE15(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          }\n          break;\n        case 32: {\n          uint32_t maxColor =\n              (client->format.redMax << client->format.redShift) |\n              (client->format.greenMax << client->format.greenShift) |\n              (client->format.blueMax << client->format.blueShift);\n          if ((client->format.bigEndian && (maxColor & 0xff) == 0) ||\n              (!client->format.bigEndian && (maxColor & 0xff000000) == 0)) {\n            if (!HandleTRLE24(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (!client->format.bigEndian && (maxColor & 0xff) == 0) {\n            if (!HandleTRLE24Up(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h))\n              return FALSE;\n          } else if (client->format.bigEndian && (maxColor & 0xff000000) == 0) {\n            if (!HandleTRLE24Down(client, rect.r.x, rect.r.y, rect.r.w,\n                                  rect.r.h))\n              return FALSE;\n          } else if (!HandleTRLE32(client, rect.r.x, rect.r.y, rect.r.w,\n                                   rect.r.h))\n            return FALSE;\n          break;\n        }\n        }\n        break;\n      }\n\n#ifdef LIBVNCSERVER_HAVE_LIBZ\n      case rfbEncodingZlib:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZlib8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleZlib16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleZlib32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n     }\n\n#ifdef LIBVNCSERVER_HAVE_LIBJPEG\n      case rfbEncodingTight:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleTight8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (!HandleTight16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 32:\n\t  if (!HandleTight32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\tbreak;\n      }\n#endif\n      case rfbEncodingZRLE:\n\t/* Fail safe for ZYWRLE unsupport VNC server. */\n\tclient->appData.qualityLevel = 9;\n\t/* fall through */\n      case rfbEncodingZYWRLE:\n      {\n\tswitch (client->format.bitsPerPixel) {\n\tcase 8:\n\t  if (!HandleZRLE8(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\tcase 16:\n\t  if (client->si.format.greenMax > 0x1F) {\n\t    if (!HandleZRLE16(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else {\n\t    if (!HandleZRLE15(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  }\n\t  break;\n\tcase 32:\n\t{\n\t  uint32_t maxColor=(client->format.redMax<<client->format.redShift)|\n\t\t(client->format.greenMax<<client->format.greenShift)|\n\t\t(client->format.blueMax<<client->format.blueShift);\n\t  if ((client->format.bigEndian && (maxColor&0xff)==0) ||\n\t      (!client->format.bigEndian && (maxColor&0xff000000)==0)) {\n\t    if (!HandleZRLE24(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!client->format.bigEndian && (maxColor&0xff)==0) {\n\t    if (!HandleZRLE24Up(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (client->format.bigEndian && (maxColor&0xff000000)==0) {\n\t    if (!HandleZRLE24Down(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t      return FALSE;\n\t  } else if (!HandleZRLE32(client, rect.r.x,rect.r.y,rect.r.w,rect.r.h))\n\t    return FALSE;\n\t  break;\n\t}\n\t}\n\tbreak;\n     }\n\n#endif\n\n      default:\n\t {\n\t   rfbBool handled = FALSE;\n\t   rfbClientProtocolExtension* e;\n\n\t   for(e = rfbClientExtensions; !handled && e; e = e->next)\n\t     if(e->handleEncoding && e->handleEncoding(client, &rect))\n\t       handled = TRUE;\n\n\t   if(!handled) {\n\t     rfbClientLog(\"Unknown rect encoding %d\\n\",\n\t\t (int)rect.encoding);\n\t     return FALSE;\n\t   }\n\t }\n      }\n\n      /* Now we may discard \"soft cursor locks\". */\n      client->SoftCursorUnlockScreen(client);\n\n      client->GotFrameBufferUpdate(client, rect.r.x, rect.r.y, rect.r.w, rect.r.h);\n    }\n\n    if (!SendIncrementalFramebufferUpdateRequest(client))\n      return FALSE;\n\n    if (client->FinishedFrameBufferUpdate)\n      client->FinishedFrameBufferUpdate(client);\n\n    break;\n  }\n\n  case rfbBell:\n  {\n    client->Bell(client);\n\n    break;\n  }\n\n  case rfbServerCutText:\n  {\n    char *buffer;\n\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n\t\t\t   sz_rfbServerCutTextMsg - 1))\n      return FALSE;\n\n    msg.sct.length = rfbClientSwap32IfLE(msg.sct.length);\n\n    if (msg.sct.length > 1<<20) {\n\t    rfbClientErr(\"Ignoring too big cut text length sent by server: %u B > 1 MB\\n\", (unsigned int)msg.sct.length);\n\t    return FALSE;\n    }  \n\n    buffer = malloc((uint64_t)msg.sct.length+1);\n\n    if (!ReadFromRFBServer(client, buffer, msg.sct.length)) {\n      free(buffer);\n      return FALSE;\n    }\n\n    buffer[msg.sct.length] = 0;\n\n    if (client->GotXCutText)\n      client->GotXCutText(client, buffer, msg.sct.length);\n\n    free(buffer);\n\n    break;\n  }\n\n  case rfbTextChat:\n  {\n      char *buffer=NULL;\n      if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                             sz_rfbTextChatMsg- 1))\n        return FALSE;\n      msg.tc.length = rfbClientSwap32IfLE(msg.sct.length);\n      switch(msg.tc.length) {\n      case rfbTextChatOpen:\n          rfbClientLog(\"Received TextChat Open\\n\");\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatOpen, NULL);\n          break;\n      case rfbTextChatClose:\n          rfbClientLog(\"Received TextChat Close\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatClose, NULL);\n          break;\n      case rfbTextChatFinished:\n          rfbClientLog(\"Received TextChat Finished\\n\");\n         if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)rfbTextChatFinished, NULL);\n          break;\n      default:\n          buffer=malloc(msg.tc.length+1);\n          if (!ReadFromRFBServer(client, buffer, msg.tc.length))\n          {\n              free(buffer);\n              return FALSE;\n          }\n          /* Null Terminate <just in case> */\n          buffer[msg.tc.length]=0;\n          rfbClientLog(\"Received TextChat \\\"%s\\\"\\n\", buffer);\n          if (client->HandleTextChat!=NULL)\n              client->HandleTextChat(client, (int)msg.tc.length, buffer);\n          free(buffer);\n          break;\n      }\n      break;\n  }\n\n  case rfbXvp:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbXvpMsg -1))\n      return FALSE;\n\n    SetClient2Server(client, rfbXvp);\n    /* technically, we only care what we can *send* to the server\n     * but, we set Server2Client Just in case it ever becomes useful\n     */\n    SetServer2Client(client, rfbXvp);\n\n    if(client->HandleXvpMsg)\n      client->HandleXvpMsg(client, msg.xvp.version, msg.xvp.code);\n\n    break;\n  }\n\n  case rfbResizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbResizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.rsfb.framebufferWidth);\n    client->height = rfbClientSwap16IfLE(msg.rsfb.framebufferHeigth);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  case rfbPalmVNCReSizeFrameBuffer:\n  {\n    if (!ReadFromRFBServer(client, ((char *)&msg) + 1,\n                           sz_rfbPalmVNCReSizeFrameBufferMsg -1))\n      return FALSE;\n    client->width = rfbClientSwap16IfLE(msg.prsfb.buffer_w);\n    client->height = rfbClientSwap16IfLE(msg.prsfb.buffer_h);\n    client->updateRect.x = client->updateRect.y = 0;\n    client->updateRect.w = client->width;\n    client->updateRect.h = client->height;\n    if (!client->MallocFrameBuffer(client))\n      return FALSE;\n    SendFramebufferUpdateRequest(client, 0, 0, client->width, client->height, FALSE);\n    rfbClientLog(\"Got new framebuffer size: %dx%d\\n\", client->width, client->height);\n    break;\n  }\n\n  default:\n    {\n      rfbBool handled = FALSE;\n      rfbClientProtocolExtension* e;\n\n      for(e = rfbClientExtensions; !handled && e; e = e->next)\n\tif(e->handleMessage && e->handleMessage(client, &msg))\n\t  handled = TRUE;\n\n      if(!handled) {\n\tchar buffer[256];\n\trfbClientLog(\"Unknown message type %d from VNC server\\n\",msg.type);\n\tReadFromRFBServer(client, buffer, 256);\n\treturn FALSE;\n      }\n    }\n  }\n\n  return TRUE;\n}",
        "commit_message": "LibVNCClient: remove now-useless cast\n\nre #273",
        "cve_desc": "LibVNC before 0.9.12 contains multiple heap out-of-bounds write vulnerabilities in libvncclient/rfbproto.c. The fix for CVE-2018-20019 was incomplete.",
        "target": 1
      }
    ]
  },
  "libxml2": {
    "0": [
      {
        "idx": 292697,
        "reasoning": "This code snippet, `xmlParseName`, is not directly vulnerable to the heap-based buffer overread described in the commit message regarding `xmlNextChar` and internal subsets. The commit message focuses on incorrect handling of the internal subset *before* reaching the name parsing stage, while this code handles parsing names *after* the subset should have been processed, and includes a check for `XML_MAX_NAME_LENGTH` to prevent excessively long names.\n\n\n\n",
        "func": "xmlParseName(xmlParserCtxtPtr ctxt) {\n    const xmlChar *in;\n    const xmlChar *ret;\n    int count = 0;\n\n    GROW;\n\n#ifdef DEBUG\n    nbParseName++;\n#endif\n\n    /*\n     * Accelerator for simple ASCII names\n     */\n    in = ctxt->input->cur;\n    if (((*in >= 0x61) && (*in <= 0x7A)) ||\n\t((*in >= 0x41) && (*in <= 0x5A)) ||\n\t(*in == '_') || (*in == ':')) {\n\tin++;\n\twhile (((*in >= 0x61) && (*in <= 0x7A)) ||\n\t       ((*in >= 0x41) && (*in <= 0x5A)) ||\n\t       ((*in >= 0x30) && (*in <= 0x39)) ||\n\t       (*in == '_') || (*in == '-') ||\n\t       (*in == ':') || (*in == '.'))\n\t    in++;\n\tif ((*in > 0) && (*in < 0x80)) {\n\t    count = in - ctxt->input->cur;\n            if ((count > XML_MAX_NAME_LENGTH) &&\n                ((ctxt->options & XML_PARSE_HUGE) == 0)) {\n                xmlFatalErr(ctxt, XML_ERR_NAME_TOO_LONG, \"Name\");\n                return(NULL);\n            }\n\t    ret = xmlDictLookup(ctxt->dict, ctxt->input->cur, count);\n\t    ctxt->input->cur = in;\n\t    ctxt->nbChars += count;\n\t    ctxt->input->col += count;\n\t    if (ret == NULL)\n\t        xmlErrMemory(ctxt, NULL);\n\t    return(ret);\n\t}\n    }\n    /* accelerator for special cases */\n    return(xmlParseNameComplex(ctxt));\n}",
        "commit_message": "Heap-based buffer overread in xmlNextChar\n\nFor https://bugzilla.gnome.org/show_bug.cgi?id=759671\n\nwhen the end of the internal subset isn't properly detected\nxmlParseInternalSubset should just return instead of trying\nto process input further.",
        "cve_desc": "The xmlNextChar function in libxml2 before 2.9.4 allows remote attackers to cause a denial of service (heap-based buffer over-read) via a crafted XML document.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 201330,
        "reasoning": "This code is vulnerable to a double-free due to the conditional freeing of `contextNode` within the loop, specifically when `contextNode->type == XML_NAMESPACE_DECL`. The `xmlXPathNodeSetFreeNs((xmlNsPtr) contextNode)` call can free a node that is also freed later by `xmlXPathReleaseObject`, leading to a double free when the same node is encountered again during iteration, as described in the CVE.",
        "func": "\nstatic int\nxmlXPathCompOpEvalPositionalPredicate(xmlXPathParserContextPtr ctxt,\n\t\t\t\t      xmlXPathStepOpPtr op,\n\t\t\t\t      xmlNodeSetPtr set,\n\t\t\t\t      int contextSize,\n\t\t\t\t      int minPos,\n\t\t\t\t      int maxPos,\n\t\t\t\t      int hasNsNodes)\n{\n    if (op->ch1 != -1) {\n\txmlXPathCompExprPtr comp = ctxt->comp;\n\tif (comp->steps[op->ch1].op != XPATH_OP_PREDICATE) {\n\t    /*\n\t    * TODO: raise an internal error.\n\t    */\n\t}\n\tcontextSize = xmlXPathCompOpEvalPredicate(ctxt,\n\t    &comp->steps[op->ch1], set, contextSize, hasNsNodes);\n\tCHECK_ERROR0;\n\tif (contextSize <= 0)\n\t    return(0);\n    }\n    /*\n    * Check if the node set contains a sufficient number of nodes for\n    * the requested range.\n    */\n    if (contextSize < minPos) {\n\txmlXPathNodeSetClear(set, hasNsNodes);\n\treturn(0);\n    }\n    if (op->ch2 == -1) {\n\t/*\n\t* TODO: Can this ever happen?\n\t*/\n\treturn (contextSize);\n    } else {\n\txmlDocPtr oldContextDoc;\n\tint i, pos = 0, newContextSize = 0, contextPos = 0, res;\n\txmlXPathStepOpPtr exprOp;\n\txmlXPathObjectPtr contextObj = NULL, exprRes = NULL;\n\txmlNodePtr oldContextNode, contextNode = NULL;\n\txmlXPathContextPtr xpctxt = ctxt->context;\n\n#ifdef LIBXML_XPTR_ENABLED\n\t    /*\n\t    * URGENT TODO: Check the following:\n\t    *  We don't expect location sets if evaluating prediates, right?\n\t    *  Only filters should expect location sets, right?\n\t*/\n#endif /* LIBXML_XPTR_ENABLED */\n\n\t/*\n\t* Save old context.\n\t*/\n\toldContextNode = xpctxt->node;\n\toldContextDoc = xpctxt->doc;\n\t/*\n\t* Get the expression of this predicate.\n\t*/\n\texprOp = &ctxt->comp->steps[op->ch2];\n\tfor (i = 0; i < set->nodeNr; i++) {\n\t    if (set->nodeTab[i] == NULL)\n\t\tcontinue;\n\n\t    contextNode = set->nodeTab[i];\n\t    xpctxt->node = contextNode;\n\t    xpctxt->contextSize = contextSize;\n\t    xpctxt->proximityPosition = ++contextPos;\n\n\t    /*\n\t    * Initialize the new set.\n\t    * Also set the xpath document in case things like\n\t    * key() evaluation are attempted on the predicate\n\t    */\n\t    if ((contextNode->type != XML_NAMESPACE_DECL) &&\n\t\t(contextNode->doc != NULL))\n\t\txpctxt->doc = contextNode->doc;\n\t    /*\n\t    * Evaluate the predicate expression with 1 context node\n\t    * at a time; this node is packaged into a node set; this\n\t    * node set is handed over to the evaluation mechanism.\n\t    */\n\t    if (contextObj == NULL)\n\t\tcontextObj = xmlXPathCacheNewNodeSet(xpctxt, contextNode);\n\t    else\n\t\txmlXPathNodeSetAddUnique(contextObj->nodesetval,\n\t\t    contextNode);\n\n\t    valuePush(ctxt, contextObj);\n\t    res = xmlXPathCompOpEvalToBoolean(ctxt, exprOp, 1);\n\n\t    if ((ctxt->error != XPATH_EXPRESSION_OK) || (res == -1)) {\n\t        xmlXPathObjectPtr tmp;\n\t\t/* pop the result */\n\t\ttmp = valuePop(ctxt);\n\t\txmlXPathReleaseObject(xpctxt, tmp);\n\t\t/* then pop off contextObj, which will be freed later */\n\t\tvaluePop(ctxt);\n\t\tgoto evaluation_error;\n\t    }\n\n\t    if (res)\n\t\tpos++;\n\n\t    if (res && (pos >= minPos) && (pos <= maxPos)) {\n\t\t/*\n\t\t* Fits in the requested range.\n\t\t*/\n\t\tnewContextSize++;\n\t\tif (minPos == maxPos) {\n\t\t    /*\n\t\t    * Only 1 node was requested.\n\t\t    */\n\t\t    if (contextNode->type == XML_NAMESPACE_DECL) {\n\t\t\t/*\n\t\t\t* As always: take care of those nasty\n\t\t\t* namespace nodes.\n\t\t\t*/\n\t\t\tset->nodeTab[i] = NULL;\n\t\t    }\n\t\t    xmlXPathNodeSetClear(set, hasNsNodes);\n\t\t    set->nodeNr = 1;\n\t\t    set->nodeTab[0] = contextNode;\n\t\t    goto evaluation_exit;\n\t\t}\n\t\tif (pos == maxPos) {\n\t\t    /*\n\t\t    * We are done.\n\t\t    */\n\t\t    xmlXPathNodeSetClearFromPos(set, i +1, hasNsNodes);\n\t\t    goto evaluation_exit;\n\t\t}\n\t    } else {\n\t\t/*\n\t\t* Remove the entry from the initial node set.\n\t\t*/\n\t\tset->nodeTab[i] = NULL;\n\t\tif (contextNode->type == XML_NAMESPACE_DECL)\n\t\t    xmlXPathNodeSetFreeNs((xmlNsPtr) contextNode);\n\t    }\n\t    if (exprRes != NULL) {\n\t\txmlXPathReleaseObject(ctxt->context, exprRes);\n\t\texprRes = NULL;\n\t    }\n\t    if (ctxt->value == contextObj) {\n\t\t/*\n\t\t* Don't free the temporary XPath object holding the\n\t\t* context node, in order to avoid massive recreation\n\t\t* inside this loop.\n\t\t*/\n\t\tvaluePop(ctxt);\n\t\txmlXPathNodeSetClear(contextObj->nodesetval, hasNsNodes);\n\t    } else {\n\t\t/*\n\t\t* The object was lost in the evaluation machinery.\n\t\t* Can this happen? Maybe in case of internal-errors.\n\t\t*/\n\t\tcontextObj = NULL;\n\t    }\n\t}\n\tgoto evaluation_exit;\n\nevaluation_error:\n\txmlXPathNodeSetClear(set, hasNsNodes);\n\tnewContextSize = 0;\n\nevaluation_exit:\n\tif (contextObj != NULL) {\n\t    if (ctxt->value == contextObj)\n\t\tvaluePop(ctxt);\n\t    xmlXPathReleaseObject(xpctxt, contextObj);\n\t}\n\tif (exprRes != NULL)\n\t    xmlXPathReleaseObject(ctxt->context, exprRes);\n\t/*\n\t* Reset/invalidate the context.\n\t*/\n\txpctxt->node = oldContextNode;\n\txpctxt->doc = oldContextDoc;\n\txpctxt->contextSize = -1;\n\txpctxt->proximityPosition = -1;\n\treturn(newContextSize);\n    }",
        "commit_message": "Fix a potential freeing error in XPath",
        "cve_desc": "Double free vulnerability in libxml2 2.7.8 and other versions, as used in Google Chrome before 8.0.552.215 and other products, allows remote attackers to cause a denial of service or possibly have unspecified other impact via vectors related to XPath handling.",
        "target": 1
      },
      {
        "idx": 201377,
        "reasoning": "This code is vulnerable to a denial-of-service (DoS) attack due to excessive stack consumption because the `xmlStringDecodeEntities` function is called recursively within `xmlParseAttValueComplex` without properly incrementing the parser context's recursion depth counter. This allows a malicious XML document with deeply nested entity references to exhaust the stack, leading to an application crash.",
        "func": "xmlParseAttValueComplex(xmlParserCtxtPtr ctxt, int *attlen, int normalize) {\n    xmlChar limit = 0;\n    xmlChar *buf = NULL;\n    xmlChar *rep = NULL;\n    size_t len = 0;\n    size_t buf_size = 0;\n    int c, l, in_space = 0;\n    xmlChar *current = NULL;\n    xmlEntityPtr ent;\n\n    if (NXT(0) == '\"') {\n\tctxt->instate = XML_PARSER_ATTRIBUTE_VALUE;\n\tlimit = '\"';\n        NEXT;\n    } else if (NXT(0) == '\\'') {\n\tlimit = '\\'';\n\tctxt->instate = XML_PARSER_ATTRIBUTE_VALUE;\n        NEXT;\n    } else {\n\txmlFatalErr(ctxt, XML_ERR_ATTRIBUTE_NOT_STARTED, NULL);\n\treturn(NULL);\n    }\n\n    /*\n     * allocate a translation buffer.\n     */\n    buf_size = XML_PARSER_BUFFER_SIZE;\n    buf = (xmlChar *) xmlMallocAtomic(buf_size);\n    if (buf == NULL) goto mem_error;\n\n    /*\n     * OK loop until we reach one of the ending char or a size limit.\n     */\n    c = CUR_CHAR(l);\n    while (((NXT(0) != limit) && /* checked */\n            (IS_CHAR(c)) && (c != '<')) &&\n            (ctxt->instate != XML_PARSER_EOF)) {\n        /*\n         * Impose a reasonable limit on attribute size, unless XML_PARSE_HUGE\n         * special option is given\n         */\n        if ((len > XML_MAX_TEXT_LENGTH) &&\n            ((ctxt->options & XML_PARSE_HUGE) == 0)) {\n            xmlFatalErrMsg(ctxt, XML_ERR_ATTRIBUTE_NOT_FINISHED,\n                           \"AttValue length too long\\n\");\n            goto mem_error;\n        }\n\tif (c == 0) break;\n\tif (c == '&') {\n\t    in_space = 0;\n\t    if (NXT(1) == '#') {\n\t\tint val = xmlParseCharRef(ctxt);\n\n\t\tif (val == '&') {\n\t\t    if (ctxt->replaceEntities) {\n\t\t\tif (len + 10 > buf_size) {\n\t\t\t    growBuffer(buf, 10);\n\t\t\t}\n\t\t\tbuf[len++] = '&';\n\t\t    } else {\n\t\t\t/*\n\t\t\t * The reparsing will be done in xmlStringGetNodeList()\n\t\t\t * called by the attribute() function in SAX.c\n\t\t\t */\n\t\t\tif (len + 10 > buf_size) {\n\t\t\t    growBuffer(buf, 10);\n\t\t\t}\n\t\t\tbuf[len++] = '&';\n\t\t\tbuf[len++] = '#';\n\t\t\tbuf[len++] = '3';\n\t\t\tbuf[len++] = '8';\n\t\t\tbuf[len++] = ';';\n\t\t    }\n\t\t} else if (val != 0) {\n\t\t    if (len + 10 > buf_size) {\n\t\t\tgrowBuffer(buf, 10);\n\t\t    }\n\t\t    len += xmlCopyChar(0, &buf[len], val);\n\t\t}\n\t    } else {\n\t\tent = xmlParseEntityRef(ctxt);\n\t\tctxt->nbentities++;\n\t\tif (ent != NULL)\n\t\t    ctxt->nbentities += ent->owner;\n\t\tif ((ent != NULL) &&\n\t\t    (ent->etype == XML_INTERNAL_PREDEFINED_ENTITY)) {\n\t\t    if (len + 10 > buf_size) {\n\t\t\tgrowBuffer(buf, 10);\n\t\t    }\n\t\t    if ((ctxt->replaceEntities == 0) &&\n\t\t        (ent->content[0] == '&')) {\n\t\t\tbuf[len++] = '&';\n\t\t\tbuf[len++] = '#';\n\t\t\tbuf[len++] = '3';\n\t\t\tbuf[len++] = '8';\n\t\t\tbuf[len++] = ';';\n\t\t    } else {\n\t\t\tbuf[len++] = ent->content[0];\n\t\t    }\n\t\t} else if ((ent != NULL) &&\n\t\t           (ctxt->replaceEntities != 0)) {\n\t\t    if (ent->etype != XML_INTERNAL_PREDEFINED_ENTITY) {\n\t\t\trep = xmlStringDecodeEntities(ctxt, ent->content,\n\t\t\t\t\t\t      XML_SUBSTITUTE_REF,\n\t\t\t\t\t\t      0, 0, 0);\n\t\t\tif (rep != NULL) {\n\t\t\t    current = rep;\n\t\t\t    while (*current != 0) { /* non input consuming */\n                                if ((*current == 0xD) || (*current == 0xA) ||\n                                    (*current == 0x9)) {\n                                    buf[len++] = 0x20;\n                                    current++;\n                                } else\n                                    buf[len++] = *current++;\n\t\t\t\tif (len + 10 > buf_size) {\n\t\t\t\t    growBuffer(buf, 10);\n\t\t\t\t}\n\t\t\t    }\n\t\t\t    xmlFree(rep);\n\t\t\t    rep = NULL;\n\t\t\t}\n\t\t    } else {\n\t\t\tif (len + 10 > buf_size) {\n\t\t\t    growBuffer(buf, 10);\n\t\t\t}\n\t\t\tif (ent->content != NULL)\n\t\t\t    buf[len++] = ent->content[0];\n\t\t    }\n\t\t} else if (ent != NULL) {\n\t\t    int i = xmlStrlen(ent->name);\n\t\t    const xmlChar *cur = ent->name;\n\n\t\t    /*\n\t\t     * This may look absurd but is needed to detect\n\t\t     * entities problems\n\t\t     */\n\t\t    if ((ent->etype != XML_INTERNAL_PREDEFINED_ENTITY) &&\n\t\t\t(ent->content != NULL) && (ent->checked == 0)) {\n\t\t\tunsigned long oldnbent = ctxt->nbentities;\n\n\t\t\trep = xmlStringDecodeEntities(ctxt, ent->content,\n\t\t\t\t\t\t  XML_SUBSTITUTE_REF, 0, 0, 0);\n\n\t\t\tent->checked = (ctxt->nbentities - oldnbent + 1) * 2;\n\t\t\tif (rep != NULL) {\n\t\t\t    if (xmlStrchr(rep, '<'))\n\t\t\t        ent->checked |= 1;\n\t\t\t    xmlFree(rep);\n\t\t\t    rep = NULL;\n\t\t\t}\n\t\t    }\n\n\t\t    /*\n\t\t     * Just output the reference\n\t\t     */\n\t\t    buf[len++] = '&';\n\t\t    while (len + i + 10 > buf_size) {\n\t\t\tgrowBuffer(buf, i + 10);\n\t\t    }\n\t\t    for (;i > 0;i--)\n\t\t\tbuf[len++] = *cur++;\n\t\t    buf[len++] = ';';\n\t\t}\n\t    }\n\t} else {\n\t    if ((c == 0x20) || (c == 0xD) || (c == 0xA) || (c == 0x9)) {\n\t        if ((len != 0) || (!normalize)) {\n\t\t    if ((!normalize) || (!in_space)) {\n\t\t\tCOPY_BUF(l,buf,len,0x20);\n\t\t\twhile (len + 10 > buf_size) {\n\t\t\t    growBuffer(buf, 10);\n\t\t\t}\n\t\t    }\n\t\t    in_space = 1;\n\t\t}\n\t    } else {\n\t        in_space = 0;\n\t\tCOPY_BUF(l,buf,len,c);\n\t\tif (len + 10 > buf_size) {\n\t\t    growBuffer(buf, 10);\n\t\t}\n\t    }\n\t    NEXTL(l);\n\t}\n\tGROW;\n\tc = CUR_CHAR(l);\n    }\n    if (ctxt->instate == XML_PARSER_EOF)\n        goto error;\n\n    if ((in_space) && (normalize)) {\n        while ((len > 0) && (buf[len - 1] == 0x20)) len--;\n    }\n    buf[len] = 0;\n    if (RAW == '<') {\n\txmlFatalErr(ctxt, XML_ERR_LT_IN_ATTRIBUTE, NULL);\n    } else if (RAW != limit) {\n\tif ((c != 0) && (!IS_CHAR(c))) {\n\t    xmlFatalErrMsg(ctxt, XML_ERR_INVALID_CHAR,\n\t\t\t   \"invalid character in attribute value\\n\");\n\t} else {\n\t    xmlFatalErrMsg(ctxt, XML_ERR_ATTRIBUTE_NOT_FINISHED,\n\t\t\t   \"AttValue: ' expected\\n\");\n        }\n    } else\n\tNEXT;\n\n    /*\n     * There we potentially risk an overflow, don't allow attribute value of\n     * length more than INT_MAX it is a very reasonnable assumption !\n     */\n    if (len >= INT_MAX) {\n        xmlFatalErrMsg(ctxt, XML_ERR_ATTRIBUTE_NOT_FINISHED,\n                       \"AttValue length too long\\n\");\n        goto mem_error;\n    }\n\n    if (attlen != NULL) *attlen = (int) len;\n    return(buf);\n\nmem_error:\n    xmlErrMemory(ctxt, NULL);\nerror:\n    if (buf != NULL)\n        xmlFree(buf);\n    if (rep != NULL)\n        xmlFree(rep);\n    return(NULL);\n}",
        "commit_message": "Add missing increments of recursion depth counter to XML parser.\n\nFor https://bugzilla.gnome.org/show_bug.cgi?id=765207\nCVE-2016-3705\nThe functions xmlParserEntityCheck() and xmlParseAttValueComplex() used to call\nxmlStringDecodeEntities() in a recursive context without incrementing the\n'depth' counter in the parser context. Because of that omission, the parser\nfailed to detect attribute recursions in certain documents before running out\nof stack space.",
        "cve_desc": "The (1) xmlParserEntityCheck and (2) xmlParseAttValueComplex functions in parser.c in libxml2 2.9.3 do not properly keep track of the recursion depth, which allows context-dependent attackers to cause a denial of service (stack consumption and application crash) via a crafted XML document containing a large number of nested entity references.",
        "target": 1
      },
      {
        "idx": 201378,
        "reasoning": "This code is vulnerable because the `xmlParserEntityCheck` function recursively calls `xmlStringDecodeEntities` without incrementing a recursion depth counter within the parser context. This omission allows a malicious XML document with deeply nested entity references to exhaust the stack space, leading to a denial-of-service condition and application crash.",
        "func": "xmlParserEntityCheck(xmlParserCtxtPtr ctxt, size_t size,\n                     xmlEntityPtr ent, size_t replacement)\n{\n    size_t consumed = 0;\n\n    if ((ctxt == NULL) || (ctxt->options & XML_PARSE_HUGE))\n        return (0);\n    if (ctxt->lastError.code == XML_ERR_ENTITY_LOOP)\n        return (1);\n\n    /*\n     * This may look absurd but is needed to detect\n     * entities problems\n     */\n    if ((ent != NULL) && (ent->etype != XML_INTERNAL_PREDEFINED_ENTITY) &&\n\t(ent->content != NULL) && (ent->checked == 0)) {\n\tunsigned long oldnbent = ctxt->nbentities;\n\txmlChar *rep;\n\n\tent->checked = 1;\n\n\trep = xmlStringDecodeEntities(ctxt, ent->content,\n\t\t\t\t  XML_SUBSTITUTE_REF, 0, 0, 0);\n\n\tent->checked = (ctxt->nbentities - oldnbent + 1) * 2;\n\tif (rep != NULL) {\n\t    if (xmlStrchr(rep, '<'))\n\t\tent->checked |= 1;\n\t    xmlFree(rep);\n\t    rep = NULL;\n\t}\n    }\n    if (replacement != 0) {\n\tif (replacement < XML_MAX_TEXT_LENGTH)\n\t    return(0);\n\n        /*\n\t * If the volume of entity copy reaches 10 times the\n\t * amount of parsed data and over the large text threshold\n\t * then that's very likely to be an abuse.\n\t */\n        if (ctxt->input != NULL) {\n\t    consumed = ctxt->input->consumed +\n\t               (ctxt->input->cur - ctxt->input->base);\n\t}\n        consumed += ctxt->sizeentities;\n\n        if (replacement < XML_PARSER_NON_LINEAR * consumed)\n\t    return(0);\n    } else if (size != 0) {\n        /*\n         * Do the check based on the replacement size of the entity\n         */\n        if (size < XML_PARSER_BIG_ENTITY)\n\t    return(0);\n\n        /*\n         * A limit on the amount of text data reasonably used\n         */\n        if (ctxt->input != NULL) {\n            consumed = ctxt->input->consumed +\n                (ctxt->input->cur - ctxt->input->base);\n        }\n        consumed += ctxt->sizeentities;\n\n        if ((size < XML_PARSER_NON_LINEAR * consumed) &&\n\t    (ctxt->nbentities * 3 < XML_PARSER_NON_LINEAR * consumed))\n            return (0);\n    } else if (ent != NULL) {\n        /*\n         * use the number of parsed entities in the replacement\n         */\n        size = ent->checked / 2;\n\n        /*\n         * The amount of data parsed counting entities size only once\n         */\n        if (ctxt->input != NULL) {\n            consumed = ctxt->input->consumed +\n                (ctxt->input->cur - ctxt->input->base);\n        }\n        consumed += ctxt->sizeentities;\n\n        /*\n         * Check the density of entities for the amount of data\n\t * knowing an entity reference will take at least 3 bytes\n         */\n        if (size * 3 < consumed * XML_PARSER_NON_LINEAR)\n            return (0);\n    } else {\n        /*\n         * strange we got no data for checking\n         */\n\tif (((ctxt->lastError.code != XML_ERR_UNDECLARED_ENTITY) &&\n\t     (ctxt->lastError.code != XML_WAR_UNDECLARED_ENTITY)) ||\n\t    (ctxt->nbentities <= 10000))\n\t    return (0);\n    }\n    xmlFatalErr(ctxt, XML_ERR_ENTITY_LOOP, NULL);\n    return (1);\n}",
        "commit_message": "Add missing increments of recursion depth counter to XML parser.\n\nFor https://bugzilla.gnome.org/show_bug.cgi?id=765207\nCVE-2016-3705\nThe functions xmlParserEntityCheck() and xmlParseAttValueComplex() used to call\nxmlStringDecodeEntities() in a recursive context without incrementing the\n'depth' counter in the parser context. Because of that omission, the parser\nfailed to detect attribute recursions in certain documents before running out\nof stack space.",
        "cve_desc": "The (1) xmlParserEntityCheck and (2) xmlParseAttValueComplex functions in parser.c in libxml2 2.9.3 do not properly keep track of the recursion depth, which allows context-dependent attackers to cause a denial of service (stack consumption and application crash) via a crafted XML document containing a large number of nested entity references.",
        "target": 1
      },
      {
        "idx": 202087,
        "reasoning": "This code is vulnerable to an infinite loop during LZMA decompression when handling crafted input files that trigger `LZMA_MEMLIMIT_ERROR` or other error conditions not thoroughly checked before continuing the decompression loop. The original code didn't adequately handle certain LZMA error codes, leading to a re-attempt of decompression even when the data was corrupt or invalid, resulting in the infinite loop.",
        "func": "xz_decomp(xz_statep state)\n{\n    int ret;\n    unsigned had;\n    unsigned long crc, len;\n    lzma_stream *strm = &(state->strm);\n\n    lzma_action action = LZMA_RUN;\n\n    /* fill output buffer up to end of deflate stream */\n    had = strm->avail_out;\n    do {\n        /* get more input for inflate() */\n        if (strm->avail_in == 0 && xz_avail(state) == -1)\n            return -1;\n        if (strm->avail_in == 0) {\n            xz_error(state, LZMA_DATA_ERROR, \"unexpected end of file\");\n            return -1;\n        }\n        if (state->eof)\n            action = LZMA_FINISH;\n\n        /* decompress and handle errors */\n#ifdef LIBXML_ZLIB_ENABLED\n        if (state->how == GZIP) {\n            state->zstrm.avail_in = (uInt) state->strm.avail_in;\n            state->zstrm.next_in = (Bytef *) state->strm.next_in;\n            state->zstrm.avail_out = (uInt) state->strm.avail_out;\n            state->zstrm.next_out = (Bytef *) state->strm.next_out;\n            ret = inflate(&state->zstrm, Z_NO_FLUSH);\n            if (ret == Z_STREAM_ERROR || ret == Z_NEED_DICT) {\n                xz_error(state, Z_STREAM_ERROR,\n                         \"internal error: inflate stream corrupt\");\n                return -1;\n            }\n            if (ret == Z_MEM_ERROR)\n                ret = LZMA_MEM_ERROR;\n            if (ret == Z_DATA_ERROR)\n                ret = LZMA_DATA_ERROR;\n            if (ret == Z_STREAM_END)\n                ret = LZMA_STREAM_END;\n            state->strm.avail_in = state->zstrm.avail_in;\n            state->strm.next_in = state->zstrm.next_in;\n            state->strm.avail_out = state->zstrm.avail_out;\n            state->strm.next_out = state->zstrm.next_out;\n        } else                  /* state->how == LZMA */\n#endif\n            ret = lzma_code(strm, action);\n        if (ret == LZMA_MEM_ERROR) {\n            xz_error(state, LZMA_MEM_ERROR, \"out of memory\");\n            return -1;\n        }\n        if (ret == LZMA_DATA_ERROR) {\n            xz_error(state, LZMA_DATA_ERROR, \"compressed data error\");\n            return -1;\n        }\n        if (ret == LZMA_PROG_ERROR) {\n            xz_error(state, LZMA_PROG_ERROR, \"compression error\");\n            return -1;\n        }\n    } while (strm->avail_out && ret != LZMA_STREAM_END);\n\n    /* update available output and crc check value */\n    state->have = had - strm->avail_out;\n    state->next = strm->next_out - state->have;\n#ifdef LIBXML_ZLIB_ENABLED\n    state->zstrm.adler =\n        crc32(state->zstrm.adler, state->next, state->have);\n#endif\n\n    if (ret == LZMA_STREAM_END) {\n#ifdef LIBXML_ZLIB_ENABLED\n        if (state->how == GZIP) {\n            if (gz_next4(state, &crc) == -1 || gz_next4(state, &len) == -1) {\n                xz_error(state, LZMA_DATA_ERROR, \"unexpected end of file\");\n                return -1;\n            }\n            if (crc != state->zstrm.adler) {\n                xz_error(state, LZMA_DATA_ERROR, \"incorrect data check\");\n                return -1;\n            }\n            if (len != (state->zstrm.total_out & 0xffffffffL)) {\n                xz_error(state, LZMA_DATA_ERROR, \"incorrect length check\");\n                return -1;\n            }\n            state->strm.avail_in = 0;\n            state->strm.next_in = NULL;\n            state->strm.avail_out = 0;\n            state->strm.next_out = NULL;\n        } else\n#endif\n        if (strm->avail_in != 0 || !state->eof) {\n            xz_error(state, LZMA_DATA_ERROR, \"trailing garbage\");\n            return -1;\n        }\n        state->how = LOOK;      /* ready for next stream, once have is 0 (leave\n                                 * state->direct unchanged to remember how) */\n    }\n\n    /* good decompression */\n    return 0;\n}",
        "commit_message": "Fix infinite loop in LZMA decompression\n\nCheck the liblzma error code more thoroughly to avoid infinite loops.\n\nCloses: https://gitlab.gnome.org/GNOME/libxml2/issues/13\nCloses: https://bugzilla.gnome.org/show_bug.cgi?id=794914\n\nThis is CVE-2018-9251 and CVE-2018-14567.\n\nThanks to Dongliang Mu and Simon W\u00f6rner for the reports.",
        "cve_desc": "The xz_decomp function in xzlib.c in libxml2 2.9.8, if --with-lzma is used, allows remote attackers to cause a denial of service (infinite loop) via a crafted XML file that triggers LZMA_MEMLIMIT_ERROR, as demonstrated by xmllint, a different vulnerability than CVE-2015-8035.",
        "target": 1
      },
      {
        "idx": 204068,
        "reasoning": "The `xmlNextChar` function fails to adequately check the boundaries of the input buffer when handling non-UTF-8 character sets, potentially leading to reads beyond the allocated memory. Specifically, the code continues reading even after reaching the end of the input buffer in these cases, causing a heap-based buffer over-read as described in the CVE.",
        "func": "xmlNextChar(xmlParserCtxtPtr ctxt)\n{\n    if ((ctxt == NULL) || (ctxt->instate == XML_PARSER_EOF) ||\n        (ctxt->input == NULL))\n        return;\n\n    if (ctxt->charset == XML_CHAR_ENCODING_UTF8) {\n        if ((*ctxt->input->cur == 0) &&\n            (xmlParserInputGrow(ctxt->input, INPUT_CHUNK) <= 0) &&\n            (ctxt->instate != XML_PARSER_COMMENT)) {\n            /*\n             * If we are at the end of the current entity and\n             * the context allows it, we pop consumed entities\n             * automatically.\n             * the auto closing should be blocked in other cases\n             */\n            xmlPopInput(ctxt);\n        } else {\n            const unsigned char *cur;\n            unsigned char c;\n\n            /*\n             *   2.11 End-of-Line Handling\n             *   the literal two-character sequence \"#xD#xA\" or a standalone\n             *   literal #xD, an XML processor must pass to the application\n             *   the single character #xA.\n             */\n            if (*(ctxt->input->cur) == '\\n') {\n                ctxt->input->line++; ctxt->input->col = 1;\n            } else\n                ctxt->input->col++;\n\n            /*\n             * We are supposed to handle UTF8, check it's valid\n             * From rfc2044: encoding of the Unicode values on UTF-8:\n             *\n             * UCS-4 range (hex.)           UTF-8 octet sequence (binary)\n             * 0000 0000-0000 007F   0xxxxxxx\n             * 0000 0080-0000 07FF   110xxxxx 10xxxxxx\n             * 0000 0800-0000 FFFF   1110xxxx 10xxxxxx 10xxxxxx\n             *\n             * Check for the 0x110000 limit too\n             */\n            cur = ctxt->input->cur;\n\n            c = *cur;\n            if (c & 0x80) {\n\t        if (c == 0xC0)\n\t\t    goto encoding_error;\n                if (cur[1] == 0) {\n                    xmlParserInputGrow(ctxt->input, INPUT_CHUNK);\n                    cur = ctxt->input->cur;\n                }\n                if ((cur[1] & 0xc0) != 0x80)\n                    goto encoding_error;\n                if ((c & 0xe0) == 0xe0) {\n                    unsigned int val;\n\n                    if (cur[2] == 0) {\n                        xmlParserInputGrow(ctxt->input, INPUT_CHUNK);\n                        cur = ctxt->input->cur;\n                    }\n                    if ((cur[2] & 0xc0) != 0x80)\n                        goto encoding_error;\n                    if ((c & 0xf0) == 0xf0) {\n                        if (cur[3] == 0) {\n                            xmlParserInputGrow(ctxt->input, INPUT_CHUNK);\n                            cur = ctxt->input->cur;\n                        }\n                        if (((c & 0xf8) != 0xf0) ||\n                            ((cur[3] & 0xc0) != 0x80))\n                            goto encoding_error;\n                        /* 4-byte code */\n                        ctxt->input->cur += 4;\n                        val = (cur[0] & 0x7) << 18;\n                        val |= (cur[1] & 0x3f) << 12;\n                        val |= (cur[2] & 0x3f) << 6;\n                        val |= cur[3] & 0x3f;\n                    } else {\n                        /* 3-byte code */\n                        ctxt->input->cur += 3;\n                        val = (cur[0] & 0xf) << 12;\n                        val |= (cur[1] & 0x3f) << 6;\n                        val |= cur[2] & 0x3f;\n                    }\n                    if (((val > 0xd7ff) && (val < 0xe000)) ||\n                        ((val > 0xfffd) && (val < 0x10000)) ||\n                        (val >= 0x110000)) {\n\t\t\txmlErrEncodingInt(ctxt, XML_ERR_INVALID_CHAR,\n\t\t\t\t\t  \"Char 0x%X out of allowed range\\n\",\n\t\t\t\t\t  val);\n                    }\n                } else\n                    /* 2-byte code */\n                    ctxt->input->cur += 2;\n            } else\n                /* 1-byte code */\n                ctxt->input->cur++;\n\n            ctxt->nbChars++;\n            if (*ctxt->input->cur == 0)\n                xmlParserInputGrow(ctxt->input, INPUT_CHUNK);\n        }\n    } else {\n        /*\n         * Assume it's a fixed length encoding (1) with\n         * a compatible encoding for the ASCII set, since\n         * XML constructs only use < 128 chars\n         */\n\n        if (*(ctxt->input->cur) == '\\n') {\n            ctxt->input->line++; ctxt->input->col = 1;\n        } else\n            ctxt->input->col++;\n        ctxt->input->cur++;\n        ctxt->nbChars++;\n        if (*ctxt->input->cur == 0)\n            xmlParserInputGrow(ctxt->input, INPUT_CHUNK);\n    }\n    if ((*ctxt->input->cur == '%') && (!ctxt->html))\n        xmlParserHandlePEReference(ctxt);\n    if ((*ctxt->input->cur == 0) &&\n        (xmlParserInputGrow(ctxt->input, INPUT_CHUNK) <= 0))\n        xmlPopInput(ctxt);\n    return;\nencoding_error:\n    /*\n     * If we detect an UTF8 error that probably mean that the\n     * input encoding didn't get properly advertised in the\n     * declaration header. Report the error and switch the encoding\n     * to ISO-Latin-1 (if you don't like this policy, just declare the\n     * encoding !)\n     */\n    if ((ctxt == NULL) || (ctxt->input == NULL) ||\n        (ctxt->input->end - ctxt->input->cur < 4)) {\n\t__xmlErrEncoding(ctxt, XML_ERR_INVALID_CHAR,\n\t\t     \"Input is not proper UTF-8, indicate encoding !\\n\",\n\t\t     NULL, NULL);\n    } else {\n        char buffer[150];\n\n\tsnprintf(buffer, 149, \"Bytes: 0x%02X 0x%02X 0x%02X 0x%02X\\n\",\n\t\t\tctxt->input->cur[0], ctxt->input->cur[1],\n\t\t\tctxt->input->cur[2], ctxt->input->cur[3]);\n\t__xmlErrEncoding(ctxt, XML_ERR_INVALID_CHAR,\n\t\t     \"Input is not proper UTF-8, indicate encoding !\\n%s\",\n\t\t     BAD_CAST buffer, NULL);\n    }\n    ctxt->charset = XML_CHAR_ENCODING_8859_1;\n    ctxt->input->cur++;\n    return;\n}",
        "commit_message": "Heap-based buffer overread in htmlCurrentChar\n\nFor https://bugzilla.gnome.org/show_bug.cgi?id=758606\n\n* parserInternals.c:\n(xmlNextChar): Add an test to catch other issues on ctxt->input\ncorruption proactively.\nFor non-UTF-8 charsets, xmlNextChar() failed to check for the end\nof the input buffer and would continuing reading.  Fix this by\npulling out the check for the end of the input buffer into common\ncode, and return if we reach the end of the input buffer\nprematurely.\n* result/HTML/758606.html: Added.\n* result/HTML/758606.html.err: Added.\n* result/HTML/758606.html.sax: Added.\n* result/HTML/758606_2.html: Added.\n* result/HTML/758606_2.html.err: Added.\n* result/HTML/758606_2.html.sax: Added.\n* test/HTML/758606.html: Added test case.\n* test/HTML/758606_2.html: Added test case.",
        "cve_desc": "The htmlCurrentChar function in libxml2 before 2.9.4, as used in Apple iOS before 9.3.2, OS X before 10.11.5, tvOS before 9.2.1, and watchOS before 2.2.1, allows remote attackers to cause a denial of service (heap-based buffer over-read) via a crafted XML document.",
        "target": 1
      }
    ]
  },
  "libxslt": {
    "0": [
      {
        "idx": 308102,
        "reasoning": "This code addresses the type confusion vulnerability described in CVE-2015-7995 by explicitly checking if the parent node is an element before attempting to dereference its namespace. The fix ensures that namespace access is only performed on element nodes, preventing a potential crash or exploit scenario when encountering other node types.\n",
        "func": "xsltStylePreCompute(xsltStylesheetPtr style, xmlNodePtr node) {\n    /*\n    * The xsltXSLTElemMarker marker was set beforehand by\n    *  the parsing mechanism for all elements in the XSLT namespace.\n    */\n    if (style == NULL) {\n\tif ((node != NULL) && (node->type == XML_ELEMENT_NODE))\n\t    node->psvi = NULL;\n\treturn;\n    }\n    if (node == NULL)\n\treturn;\n    if (! IS_XSLT_ELEM_FAST(node))\n\treturn;\n\n    node->psvi = NULL;\n    if (XSLT_CCTXT(style)->inode->type != 0) {\n\tswitch (XSLT_CCTXT(style)->inode->type) {\n\t    case XSLT_FUNC_APPLYTEMPLATES:\n\t\txsltApplyTemplatesComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_WITHPARAM:\n\t\txsltWithParamComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_VALUEOF:\n\t\txsltValueOfComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_COPY:\n\t\txsltCopyComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_COPYOF:\n\t\txsltCopyOfComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_IF:\n\t\txsltIfComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_CHOOSE:\n\t\txsltChooseComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_WHEN:\n\t\txsltWhenComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_OTHERWISE:\n\t\t/* NOP yet */\n\t\treturn;\n\t    case XSLT_FUNC_FOREACH:\n\t\txsltForEachComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_APPLYIMPORTS:\n\t\txsltApplyImportsComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_ATTRIBUTE:\n\t\txsltAttributeComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_ELEMENT:\n\t\txsltElementComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_SORT:\n\t\txsltSortComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_COMMENT:\n\t\txsltCommentComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_NUMBER:\n\t\txsltNumberComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_PI:\n\t\txsltProcessingInstructionComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_CALLTEMPLATE:\n\t\txsltCallTemplateComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_PARAM:\n\t\txsltParamComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_VARIABLE:\n\t\txsltVariableComp(style, node);\n\t\tbreak;\n\t    case XSLT_FUNC_FALLBACK:\n\t\t/* NOP yet */\n\t\treturn;\n\t    case XSLT_FUNC_DOCUMENT:\n\t\t/* The extra one */\n\t\tnode->psvi = (void *) xsltDocumentComp(style, node,\n\t\t    (xsltTransformFunction) xsltDocumentElem);\n\t\tbreak;\n\t    case XSLT_FUNC_MESSAGE:\n\t\t/* NOP yet */\n\t\treturn;\n\t    default:\n\t\t/*\n\t\t* NOTE that xsl:text, xsl:template, xsl:stylesheet,\n\t\t*  xsl:transform, xsl:import, xsl:include are not expected\n\t\t*  to be handed over to this function.\n\t\t*/\n\t\txsltTransformError(NULL, style, node,\n\t\t    \"Internal error: (xsltStylePreCompute) cannot handle \"\n\t\t    \"the XSLT element '%s'.\\n\", node->name);\n\t\tstyle->errors++;\n\t\treturn;\n\t}\n    } else {\n\t/*\n\t* Fallback to string comparison.\n\t*/\n\tif (IS_XSLT_NAME(node, \"apply-templates\")) {\n\t    xsltApplyTemplatesComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"with-param\")) {\n\t    xsltWithParamComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"value-of\")) {\n\t    xsltValueOfComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"copy\")) {\n\t    xsltCopyComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"copy-of\")) {\n\t    xsltCopyOfComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"if\")) {\n\t    xsltIfComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"choose\")) {\n\t    xsltChooseComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"when\")) {\n\t    xsltWhenComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"otherwise\")) {\n\t    /* NOP yet */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"for-each\")) {\n\t    xsltForEachComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"apply-imports\")) {\n\t    xsltApplyImportsComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"attribute\")) {\n\t    xsltAttributeComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"element\")) {\n\t    xsltElementComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"sort\")) {\n\t    xsltSortComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"comment\")) {\n\t    xsltCommentComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"number\")) {\n\t    xsltNumberComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"processing-instruction\")) {\n\t    xsltProcessingInstructionComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"call-template\")) {\n\t    xsltCallTemplateComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"param\")) {\n\t    xsltParamComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"variable\")) {\n\t    xsltVariableComp(style, node);\n\t} else if (IS_XSLT_NAME(node, \"fallback\")) {\n\t    /* NOP yet */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"document\")) {\n\t    /* The extra one */\n\t    node->psvi = (void *) xsltDocumentComp(style, node,\n\t\t(xsltTransformFunction) xsltDocumentElem);\n\t} else if (IS_XSLT_NAME(node, \"output\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"preserve-space\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"strip-space\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"key\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"message\")) {\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"attribute-set\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"namespace-alias\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"decimal-format\")) {\n\t    /* Top-level */\n\t    return;\n\t} else if (IS_XSLT_NAME(node, \"include\")) {\n\t    /* Top-level */\n\t} else {\n\t    /*\n\t    * NOTE that xsl:text, xsl:template, xsl:stylesheet,\n\t    *  xsl:transform, xsl:import, xsl:include are not expected\n\t    *  to be handed over to this function.\n\t    */\n\t    xsltTransformError(NULL, style, node,\n\t\t\"Internal error: (xsltStylePreCompute) cannot handle \"\n\t\t\"the XSLT element '%s'.\\n\", node->name);\n\t\tstyle->errors++;\n\t    return;\n\t}\n    }\n    /*\n    * Assign the current list of in-scope namespaces to the\n    * item. This is needed for XPath expressions.\n    */\n    if (node->psvi != NULL) {\n\t((xsltStylePreCompPtr) node->psvi)->inScopeNs =\n\t    XSLT_CCTXT(style)->inode->inScopeNs;\n    }\n}",
        "commit_message": "Fix for type confusion in preprocessing attributes\n\nCVE-2015-7995 http://www.openwall.com/lists/oss-security/2015/10/27/10\nWe need to check that the parent node is an element before dereferencing\nits namespace",
        "cve_desc": "The xsltStylePreCompute function in preproc.c in libxslt 1.1.28 does not check if the parent node is an element, which allows attackers to cause a denial of service via a crafted XML file, related to a \"type confusion\" issue.",
        "target": 0
      },
      {
        "idx": 308103,
        "reasoning": "This code snippet addresses the vulnerability described in CVE-2015-7995 by explicitly checking `inst->type != XML_ELEMENT_NODE` before attempting to dereference the parent node's namespace. This check prevents the type confusion that could occur when processing attributes of non-element nodes, thus mitigating the risk of a crash or potential exploitation.\n\n\n\n",
        "func": "xsltCommentComp(xsltStylesheetPtr style, xmlNodePtr inst) {\n#ifdef XSLT_REFACTORED\n    xsltStyleItemCommentPtr comp;\n#else\n    xsltStylePreCompPtr comp;\n#endif\n\n    if ((style == NULL) || (inst == NULL) || (inst->type != XML_ELEMENT_NODE))\n\treturn;\n\n#ifdef XSLT_REFACTORED\n    comp = (xsltStyleItemCommentPtr) xsltNewStylePreComp(style, XSLT_FUNC_COMMENT);\n#else\n    comp = xsltNewStylePreComp(style, XSLT_FUNC_COMMENT);\n#endif\n\n    if (comp == NULL)\n\treturn;\n    inst->psvi = comp;\n    comp->inst = inst;\n}",
        "commit_message": "Fix for type confusion in preprocessing attributes\n\nCVE-2015-7995 http://www.openwall.com/lists/oss-security/2015/10/27/10\nWe need to check that the parent node is an element before dereferencing\nits namespace",
        "cve_desc": "The xsltStylePreCompute function in preproc.c in libxslt 1.1.28 does not check if the parent node is an element, which allows attackers to cause a denial of service via a crafted XML file, related to a \"type confusion\" issue.",
        "target": 0
      },
      {
        "idx": 308104,
        "reasoning": "This code snippet addresses the vulnerability described in CVE-2015-7995 by explicitly checking `inst->type != XML_ELEMENT_NODE` before attempting to dereference the parent node's namespace. This check prevents the type confusion that could occur when processing attributes of non-element nodes, thus mitigating the risk of a crash or potential exploitation.\n\n\n\n",
        "func": "xsltCopyComp(xsltStylesheetPtr style, xmlNodePtr inst) {\n#ifdef XSLT_REFACTORED\n    xsltStyleItemCopyPtr comp;\n#else\n    xsltStylePreCompPtr comp;\n#endif\n\n    if ((style == NULL) || (inst == NULL) || (inst->type != XML_ELEMENT_NODE))\n\treturn;\n#ifdef XSLT_REFACTORED\n    comp = (xsltStyleItemCopyPtr) xsltNewStylePreComp(style, XSLT_FUNC_COPY);\n#else\n    comp = xsltNewStylePreComp(style, XSLT_FUNC_COPY);\n#endif\n\n    if (comp == NULL)\n\treturn;\n    inst->psvi = comp;\n    comp->inst = inst;\n\n\n    comp->use = xsltGetCNsProp(style, inst, (const xmlChar *)\"use-attribute-sets\",\n\t\t\t\t    XSLT_NAMESPACE);\n    if (comp->use == NULL)\n\tcomp->has_use = 0;\n    else\n\tcomp->has_use = 1;\n}",
        "commit_message": "Fix for type confusion in preprocessing attributes\n\nCVE-2015-7995 http://www.openwall.com/lists/oss-security/2015/10/27/10\nWe need to check that the parent node is an element before dereferencing\nits namespace",
        "cve_desc": "The xsltStylePreCompute function in preproc.c in libxslt 1.1.28 does not check if the parent node is an element, which allows attackers to cause a denial of service via a crafted XML file, related to a \"type confusion\" issue.",
        "target": 0
      },
      {
        "idx": 308105,
        "reasoning": "This code snippet addresses the type confusion vulnerability described in CVE-2015-7995 by explicitly checking `inst->type != XML_ELEMENT_NODE` before attempting to access the node's namespace. This ensures that the code only dereferences the namespace of element nodes, preventing the vulnerability where a non-element node could lead to a crash or potentially exploitable behavior.\n\n\n\n",
        "func": "xsltWithParamComp(xsltStylesheetPtr style, xmlNodePtr inst) {\n#ifdef XSLT_REFACTORED\n    xsltStyleItemWithParamPtr comp;\n#else\n    xsltStylePreCompPtr comp;\n#endif\n\n    if ((style == NULL) || (inst == NULL) || (inst->type != XML_ELEMENT_NODE))\n\treturn;\n\n#ifdef XSLT_REFACTORED\n    comp = (xsltStyleItemWithParamPtr) xsltNewStylePreComp(style, XSLT_FUNC_WITHPARAM);\n#else\n    comp = xsltNewStylePreComp(style, XSLT_FUNC_WITHPARAM);\n#endif\n\n    if (comp == NULL)\n\treturn;\n    inst->psvi = comp;\n    comp->inst = inst;\n\n    /*\n    * Attribute \"name\".\n    */\n    xsltGetQNameProperty(style, inst, BAD_CAST \"name\",\n\t1, &(comp->has_name), &(comp->ns), &(comp->name));\n    if (comp->ns)\n\tcomp->has_ns = 1;\n    /*\n    * Attribute \"select\".\n    */\n    comp->select = xsltGetCNsProp(style, inst, (const xmlChar *)\"select\",\n\t                        XSLT_NAMESPACE);\n    if (comp->select != NULL) {\n\tcomp->comp = xsltXPathCompile(style, comp->select);\n\tif (comp->comp == NULL) {\n\t    xsltTransformError(NULL, style, inst,\n\t\t \"XSLT-with-param: Failed to compile select \"\n\t\t \"expression '%s'\\n\", comp->select);\n\t    style->errors++;\n\t}\n\tif (inst->children != NULL) {\n\t    xsltTransformError(NULL, style, inst,\n\t\t\"XSLT-with-param: The content should be empty since \"\n\t\t\"the attribute select is present.\\n\");\n\t    style->warnings++;\n\t}\n    }\n}",
        "commit_message": "Fix for type confusion in preprocessing attributes\n\nCVE-2015-7995 http://www.openwall.com/lists/oss-security/2015/10/27/10\nWe need to check that the parent node is an element before dereferencing\nits namespace",
        "cve_desc": "The xsltStylePreCompute function in preproc.c in libxslt 1.1.28 does not check if the parent node is an element, which allows attackers to cause a denial of service via a crafted XML file, related to a \"type confusion\" issue.",
        "target": 0
      },
      {
        "idx": 308106,
        "reasoning": "This code snippet addresses the vulnerability described in CVE-2015-7995 by explicitly checking `inst->type != XML_ELEMENT_NODE` before attempting to access the node's namespace, preventing the type confusion. The fix ensures that namespace dereferencing only occurs on element nodes, thus mitigating the risk of accessing invalid memory locations.\n\n\n\n",
        "func": "xsltIfComp(xsltStylesheetPtr style, xmlNodePtr inst) {\n#ifdef XSLT_REFACTORED\n    xsltStyleItemIfPtr comp;\n#else\n    xsltStylePreCompPtr comp;\n#endif\n\n    if ((style == NULL) || (inst == NULL) || (inst->type != XML_ELEMENT_NODE))\n\treturn;\n\n#ifdef XSLT_REFACTORED\n    comp = (xsltStyleItemIfPtr)\n\txsltNewStylePreComp(style, XSLT_FUNC_IF);\n#else\n    comp = xsltNewStylePreComp(style, XSLT_FUNC_IF);\n#endif\n\n    if (comp == NULL)\n\treturn;\n    inst->psvi = comp;\n    comp->inst = inst;\n\n    comp->test = xsltGetCNsProp(style, inst, (const xmlChar *)\"test\", XSLT_NAMESPACE);\n    if (comp->test == NULL) {\n\txsltTransformError(NULL, style, inst,\n\t     \"xsl:if : test is not defined\\n\");\n\tif (style != NULL) style->errors++;\n\treturn;\n    }\n    comp->comp = xsltXPathCompile(style, comp->test);\n    if (comp->comp == NULL) {\n\txsltTransformError(NULL, style, inst,\n\t     \"xsl:if : could not compile test expression '%s'\\n\",\n\t                 comp->test);\n\tif (style != NULL) style->errors++;\n    }\n}",
        "commit_message": "Fix for type confusion in preprocessing attributes\n\nCVE-2015-7995 http://www.openwall.com/lists/oss-security/2015/10/27/10\nWe need to check that the parent node is an element before dereferencing\nits namespace",
        "cve_desc": "The xsltStylePreCompute function in preproc.c in libxslt 1.1.28 does not check if the parent node is an element, which allows attackers to cause a denial of service via a crafted XML file, related to a \"type confusion\" issue.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200696,
        "reasoning": "The vulnerability lies in passing potentially invalid nodes (specifically namespace nodes) to the `xmlGetLineNo` function, which leads to an out-of-bounds heap read. This occurs because the code doesn't validate the node type before calling `xmlGetLineNo`, and certain node types can cause `xmlGetLineNo` to access memory outside the allocated buffer, resulting in a crash or potentially exploitable memory corruption as described in the CVE.",
        "func": "exsltSaxonLineNumberFunction(xmlXPathParserContextPtr ctxt, int nargs) {\n    xmlNodePtr cur = NULL;\n\n    if (nargs == 0) {\n\tcur = ctxt->context->node;\n    } else if (nargs == 1) {\n\txmlXPathObjectPtr obj;\n\txmlNodeSetPtr nodelist;\n\tint i;\n\n\tif ((ctxt->value == NULL) || (ctxt->value->type != XPATH_NODESET)) {\n\t    xsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"saxon:line-number() : invalid arg expecting a node-set\\n\");\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    return;\n\t}\n\n\tobj = valuePop(ctxt);\n\tnodelist = obj->nodesetval;\n\tif ((nodelist == NULL) || (nodelist->nodeNr <= 0)) {\n\t    xmlXPathFreeObject(obj);\n\t    valuePush(ctxt, xmlXPathNewFloat(-1));\n\t    return;\n\t}\n\tcur = nodelist->nodeTab[0];\n\tfor (i = 1;i < nodelist->nodeNr;i++) {\n\t    int ret = xmlXPathCmpNodes(cur, nodelist->nodeTab[i]);\n\t    if (ret == -1)\n\t\tcur = nodelist->nodeTab[i];\n\t}\n\txmlXPathFreeObject(obj);\n    } else {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"saxon:line-number() : invalid number of args %d\\n\",\n\t\tnargs);\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n\n    valuePush(ctxt, xmlXPathNewFloat(xmlGetLineNo(cur)));\n    return;\n}",
        "commit_message": "Fix saxon:line-number with namespace nodes\n\nexsltSaxonLineNumberFunction must make sure not to pass namespace\n\"nodes\" to xmlGetLineNo. Otherwise, an OOB heap read results which\ntypically leads to a segfault.\n\nFound with afl-fuzz and ASan.",
        "cve_desc": "libxslt in Apple iOS before 9.3.3, OS X before 10.11.6, iTunes before 12.4.2 on Windows, iCloud before 5.2.1 on Windows, tvOS before 9.2.2, and watchOS before 2.2.2 allows remote attackers to cause a denial of service (memory corruption) or possibly have unspecified other impact via unknown vectors, a different vulnerability than CVE-2016-4607, CVE-2016-4608, CVE-2016-4610, and CVE-2016-4612.",
        "target": 1
      },
      {
        "idx": 201917,
        "reasoning": "This code is vulnerable because it directly exposes memory addresses by calculating the difference between a node's address and the null pointer address, potentially revealing heap layout information to an attacker. An attacker could leverage this information to craft exploits, such as heap spraying or information disclosure attacks, by understanding the memory space of the application.",
        "func": "xsltGenerateIdFunction(xmlXPathParserContextPtr ctxt, int nargs){\n    xmlNodePtr cur = NULL;\n    unsigned long val;\n    xmlChar str[20];\n\n    if (nargs == 0) {\n\tcur = ctxt->context->node;\n    } else if (nargs == 1) {\n\txmlXPathObjectPtr obj;\n\txmlNodeSetPtr nodelist;\n\tint i, ret;\n\n\tif ((ctxt->value == NULL) || (ctxt->value->type != XPATH_NODESET)) {\n\t    ctxt->error = XPATH_INVALID_TYPE;\n\t    xsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid arg expecting a node-set\\n\");\n\t    return;\n\t}\n\tobj = valuePop(ctxt);\n\tnodelist = obj->nodesetval;\n\tif ((nodelist == NULL) || (nodelist->nodeNr <= 0)) {\n\t    xmlXPathFreeObject(obj);\n\t    valuePush(ctxt, xmlXPathNewCString(\"\"));\n\t    return;\n\t}\n\tcur = nodelist->nodeTab[0];\n\tfor (i = 1;i < nodelist->nodeNr;i++) {\n\t    ret = xmlXPathCmpNodes(cur, nodelist->nodeTab[i]);\n\t    if (ret == -1)\n\t        cur = nodelist->nodeTab[i];\n\t}\n\txmlXPathFreeObject(obj);\n    } else {\n\txsltTransformError(xsltXPathGetTransformContext(ctxt), NULL, NULL,\n\t\t\"generate-id() : invalid number of args %d\\n\", nargs);\n\tctxt->error = XPATH_INVALID_ARITY;\n\treturn;\n    }\n    /*\n     * Okay this is ugly but should work, use the NodePtr address\n     * to forge the ID\n     */\n    val = (unsigned long)((char *)cur - (char *)0);\n    val /= sizeof(xmlNode);\n    sprintf((char *)str, \"id%ld\", val);\n    valuePush(ctxt, xmlXPathNewString(str));\n}",
        "commit_message": "Fix generate-id() to not expose object addresses\n\nAs pointed out by Chris Evans <scarybeasts@gmail.com> it's better\nsecurity wise to not expose object addresses directly, use a diff\nw.r.t. the document root own address to avoid this\n* libxslt/functions.c: fix IDs generation code",
        "cve_desc": "The xsltGenerateIdFunction function in functions.c in libxslt 1.1.26 and earlier, as used in Google Chrome before 10.0.648.127 and other products, allows remote attackers to obtain potentially sensitive information about heap memory addresses via an XML document containing a call to the XSLT generate-id XPath function.",
        "target": 1
      }
    ]
  },
  "libyang": {
    "0": [],
    "1": []
  },
  "lighttpd1.4": {
    "0": [],
    "1": [
      {
        "idx": 9619,
        "reasoning": "The code is vulnerable to a signed integer overflow due to the `i+=2` increment within the loop when encountering `%2F`. If a crafted URL contains repeated instances of `%2F`, `i` can increment beyond the `used` length, leading to an out-of-bounds read and ultimately a crash as described in the CVE, specifically when `url-path-2f-decode` is enabled.",
        "func": "static int burl_normalize_2F_to_slash_fix (buffer *b, int qs, int i)\n{\n    char * const s = b->ptr;\n    const int blen = (int)buffer_string_length(b);\n    const int used = qs < 0 ? blen : qs;\n    int j = i;\n    for (; i < used; ++i, ++j) {\n        s[j] = s[i];\n        if (s[i] == '%' && s[i+1] == '2' && s[i+2] == 'F') {\n            s[j] = '/';\n            i+=2;\n         }\n     }\n     if (qs >= 0) {\n        memmove(s+j, s+qs, blen - qs);\n        j += blen - qs;\n     }\n     buffer_string_set_length(b, j);\n     return qs;\n}\n",
        "commit_message": "[core] fix abort in http-parseopts (fixes #2945)\n\nfix abort in server.http-parseopts with url-path-2f-decode enabled\n\n(thx stze)\n\nx-ref:\n  \"Security - SIGABRT during GET request handling with url-path-2f-decode enabled\"\n  https://redmine.lighttpd.net/issues/2945",
        "cve_desc": "lighttpd before 1.4.54 has a signed integer overflow, which might allow remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via a malicious HTTP GET request, as demonstrated by mishandling of /%2F? in burl_normalize_2F_to_slash_fix in burl.c. NOTE: The developer states \"The feature which can be abused to cause the crash is a new feature in lighttpd 1.4.50, and is not enabled by default. It must be explicitly configured in the config file (e.g. lighttpd.conf). Certain input will trigger an abort() in lighttpd when that feature is enabled. lighttpd detects the underflow or realloc() will fail (in both 32-bit and 64-bit executables), also detected in lighttpd. Either triggers an explicit abort() by lighttpd. This is not exploitable beyond triggering the explicit abort() with subsequent application exit.",
        "target": 1
      }
    ]
  },
  "linux": {
    "0": [
      {
        "idx": 21544,
        "reasoning": "This code is not vulnerable. The commit addresses a bug in how new memory zones are added to the system's zone lists, ensuring all nodes can utilize the new memory, but the provided code snippet (`__add_pages`) itself doesn't contain the flawed logic; it's a lower-level function involved in adding sections within a zone, and isn't directly responsible for the zone list building process that was corrected by the commit.\n\n\n\n",
        "func": "int __ref __add_pages(int nid, struct zone *zone, unsigned long phys_start_pfn,\n\t\t\tunsigned long nr_pages)\n{\n\tunsigned long i;\n\tint err = 0;\n\tint start_sec, end_sec;\n\t/* during initialize mem_map, align hot-added range to section */\n\tstart_sec = pfn_to_section_nr(phys_start_pfn);\n\tend_sec = pfn_to_section_nr(phys_start_pfn + nr_pages - 1);\n\n\tfor (i = start_sec; i <= end_sec; i++) {\n\t\terr = __add_section(nid, zone, i << PFN_SECTION_SHIFT);\n\n\t\t/*\n\t\t * EEXIST is finally dealt with by ioresource collision\n\t\t * check. see add_memory() => register_memory_resource()\n\t\t * Warning will be printed if there is collision.\n\t\t */\n\t\tif (err && (err != -EEXIST))\n\t\t\tbreak;\n\t\terr = 0;\n\t}\n\n\treturn err;\n}\n",
        "commit_message": "mm/hotplug: correctly add new zone to all other nodes' zone lists\n\nWhen online_pages() is called to add new memory to an empty zone, it\nrebuilds all zone lists by calling build_all_zonelists().  But there's a\nbug which prevents the new zone to be added to other nodes' zone lists.\n\nonline_pages() {\n\tbuild_all_zonelists()\n\t.....\n\tnode_set_state(zone_to_nid(zone), N_HIGH_MEMORY)\n}\n\nHere the node of the zone is put into N_HIGH_MEMORY state after calling\nbuild_all_zonelists(), but build_all_zonelists() only adds zones from\nnodes in N_HIGH_MEMORY state to the fallback zone lists.\nbuild_all_zonelists()\n\n    ->__build_all_zonelists()\n\t->build_zonelists()\n\t    ->find_next_best_node()\n\t\t->for_each_node_state(n, N_HIGH_MEMORY)\n\nSo memory in the new zone will never be used by other nodes, and it may\ncause strange behavor when system is under memory pressure.  So put node\ninto N_HIGH_MEMORY state before calling build_all_zonelists().\n\nSigned-off-by: Jianguo Wu <wujianguo@huawei.com>\nSigned-off-by: Jiang Liu <liuj97@gmail.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@suse.cz>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Rusty Russell <rusty@rustcorp.com.au>\nCc: Yinghai Lu <yinghai@kernel.org>\nCc: Tony Luck <tony.luck@intel.com>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Keping Chen <chenkeping@huawei.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The online_pages function in mm/memory_hotplug.c in the Linux kernel before 3.6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact in opportunistic circumstances by using memory that was hot-added by an administrator.",
        "target": 0
      },
      {
        "idx": 21545,
        "reasoning": "This code is not vulnerable because the commit addresses a logic error in how new memory zones are added to the system's zone lists, ensuring all nodes can utilize the new memory\u2014it doesn't introduce a security flaw or exploitable condition. The fix ensures proper memory management under pressure, preventing potential system instability, but doesn't relate to typical vulnerability categories like buffer overflows or privilege escalation.\n\n\n\n",
        "func": "static int __meminit __add_section(int nid, struct zone *zone,\n\t\t\t\t\tunsigned long phys_start_pfn)\n{\n\tint nr_pages = PAGES_PER_SECTION;\n\tint ret;\n\n\tif (pfn_valid(phys_start_pfn))\n\t\treturn -EEXIST;\n\n\tret = sparse_add_one_section(zone, phys_start_pfn, nr_pages);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\tret = __add_zone(zone, phys_start_pfn);\n\n\tif (ret < 0)\n\t\treturn ret;\n\n\treturn register_new_memory(nid, __pfn_to_section(phys_start_pfn));\n}\n",
        "commit_message": "mm/hotplug: correctly add new zone to all other nodes' zone lists\n\nWhen online_pages() is called to add new memory to an empty zone, it\nrebuilds all zone lists by calling build_all_zonelists().  But there's a\nbug which prevents the new zone to be added to other nodes' zone lists.\n\nonline_pages() {\n\tbuild_all_zonelists()\n\t.....\n\tnode_set_state(zone_to_nid(zone), N_HIGH_MEMORY)\n}\n\nHere the node of the zone is put into N_HIGH_MEMORY state after calling\nbuild_all_zonelists(), but build_all_zonelists() only adds zones from\nnodes in N_HIGH_MEMORY state to the fallback zone lists.\nbuild_all_zonelists()\n\n    ->__build_all_zonelists()\n\t->build_zonelists()\n\t    ->find_next_best_node()\n\t\t->for_each_node_state(n, N_HIGH_MEMORY)\n\nSo memory in the new zone will never be used by other nodes, and it may\ncause strange behavor when system is under memory pressure.  So put node\ninto N_HIGH_MEMORY state before calling build_all_zonelists().\n\nSigned-off-by: Jianguo Wu <wujianguo@huawei.com>\nSigned-off-by: Jiang Liu <liuj97@gmail.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@suse.cz>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Rusty Russell <rusty@rustcorp.com.au>\nCc: Yinghai Lu <yinghai@kernel.org>\nCc: Tony Luck <tony.luck@intel.com>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Keping Chen <chenkeping@huawei.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The online_pages function in mm/memory_hotplug.c in the Linux kernel before 3.6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact in opportunistic circumstances by using memory that was hot-added by an administrator.",
        "target": 0
      },
      {
        "idx": 21546,
        "reasoning": "This code is not vulnerable. The commit message details a logic error in how new memory zones were added to system-wide zone lists, specifically regarding the `N_HIGH_MEMORY` node state, and the patch corrects this by ensuring the node is in the correct state *before* zone list building \u2013 it doesn\u2019t introduce any new security weaknesses, but rather fixes a potential availability issue.\n\n\n\n",
        "func": "static int __meminit __add_zone(struct zone *zone, unsigned long phys_start_pfn)\n{\n\tstruct pglist_data *pgdat = zone->zone_pgdat;\n\tint nr_pages = PAGES_PER_SECTION;\n\tint nid = pgdat->node_id;\n\tint zone_type;\n\tunsigned long flags;\n\n\tzone_type = zone - pgdat->node_zones;\n\tif (!zone->wait_table) {\n\t\tint ret;\n\n\t\tret = init_currently_empty_zone(zone, phys_start_pfn,\n\t\t\t\t\t\tnr_pages, MEMMAP_HOTPLUG);\n\t\tif (ret)\n\t\t\treturn ret;\n\t}\n\tpgdat_resize_lock(zone->zone_pgdat, &flags);\n\tgrow_zone_span(zone, phys_start_pfn, phys_start_pfn + nr_pages);\n\tgrow_pgdat_span(zone->zone_pgdat, phys_start_pfn,\n\t\t\tphys_start_pfn + nr_pages);\n\tpgdat_resize_unlock(zone->zone_pgdat, &flags);\n\tmemmap_init_zone(nr_pages, nid, zone_type,\n\t\t\t phys_start_pfn, MEMMAP_HOTPLUG);\n\treturn 0;\n}\n",
        "commit_message": "mm/hotplug: correctly add new zone to all other nodes' zone lists\n\nWhen online_pages() is called to add new memory to an empty zone, it\nrebuilds all zone lists by calling build_all_zonelists().  But there's a\nbug which prevents the new zone to be added to other nodes' zone lists.\n\nonline_pages() {\n\tbuild_all_zonelists()\n\t.....\n\tnode_set_state(zone_to_nid(zone), N_HIGH_MEMORY)\n}\n\nHere the node of the zone is put into N_HIGH_MEMORY state after calling\nbuild_all_zonelists(), but build_all_zonelists() only adds zones from\nnodes in N_HIGH_MEMORY state to the fallback zone lists.\nbuild_all_zonelists()\n\n    ->__build_all_zonelists()\n\t->build_zonelists()\n\t    ->find_next_best_node()\n\t\t->for_each_node_state(n, N_HIGH_MEMORY)\n\nSo memory in the new zone will never be used by other nodes, and it may\ncause strange behavor when system is under memory pressure.  So put node\ninto N_HIGH_MEMORY state before calling build_all_zonelists().\n\nSigned-off-by: Jianguo Wu <wujianguo@huawei.com>\nSigned-off-by: Jiang Liu <liuj97@gmail.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@suse.cz>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Rusty Russell <rusty@rustcorp.com.au>\nCc: Yinghai Lu <yinghai@kernel.org>\nCc: Tony Luck <tony.luck@intel.com>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Keping Chen <chenkeping@huawei.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The online_pages function in mm/memory_hotplug.c in the Linux kernel before 3.6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact in opportunistic circumstances by using memory that was hot-added by an administrator.",
        "target": 0
      },
      {
        "idx": 21547,
        "reasoning": "This code is not vulnerable. The commit addresses a potential memory management issue where newly added memory zones weren't being properly included in the fallback lists for other nodes, potentially leading to memory pressure issues \u2013 it doesn\u2019t introduce any security flaws like buffer overflows, injection vulnerabilities, or privilege escalation paths. \n\n\n\n",
        "func": "void __online_page_free(struct page *page)\n{\n\tClearPageReserved(page);\n\tinit_page_count(page);\n\t__free_page(page);\n}\n",
        "commit_message": "mm/hotplug: correctly add new zone to all other nodes' zone lists\n\nWhen online_pages() is called to add new memory to an empty zone, it\nrebuilds all zone lists by calling build_all_zonelists().  But there's a\nbug which prevents the new zone to be added to other nodes' zone lists.\n\nonline_pages() {\n\tbuild_all_zonelists()\n\t.....\n\tnode_set_state(zone_to_nid(zone), N_HIGH_MEMORY)\n}\n\nHere the node of the zone is put into N_HIGH_MEMORY state after calling\nbuild_all_zonelists(), but build_all_zonelists() only adds zones from\nnodes in N_HIGH_MEMORY state to the fallback zone lists.\nbuild_all_zonelists()\n\n    ->__build_all_zonelists()\n\t->build_zonelists()\n\t    ->find_next_best_node()\n\t\t->for_each_node_state(n, N_HIGH_MEMORY)\n\nSo memory in the new zone will never be used by other nodes, and it may\ncause strange behavor when system is under memory pressure.  So put node\ninto N_HIGH_MEMORY state before calling build_all_zonelists().\n\nSigned-off-by: Jianguo Wu <wujianguo@huawei.com>\nSigned-off-by: Jiang Liu <liuj97@gmail.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@suse.cz>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Rusty Russell <rusty@rustcorp.com.au>\nCc: Yinghai Lu <yinghai@kernel.org>\nCc: Tony Luck <tony.luck@intel.com>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Keping Chen <chenkeping@huawei.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The online_pages function in mm/memory_hotplug.c in the Linux kernel before 3.6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact in opportunistic circumstances by using memory that was hot-added by an administrator.",
        "target": 0
      },
      {
        "idx": 21548,
        "reasoning": "This code is not vulnerable. The commit addresses a bug in how new memory zones are added to the system's zone lists, ensuring all nodes can utilize the new memory, but the provided code snippet `__online_page_increment_counters` simply increments page counters and doesn't introduce any security flaws itself. \n\n\n\n",
        "func": "void __online_page_increment_counters(struct page *page)\n{\n\ttotalram_pages++;\n\n#ifdef CONFIG_HIGHMEM\n\tif (PageHighMem(page))\n\t\ttotalhigh_pages++;\n#endif\n}\n",
        "commit_message": "mm/hotplug: correctly add new zone to all other nodes' zone lists\n\nWhen online_pages() is called to add new memory to an empty zone, it\nrebuilds all zone lists by calling build_all_zonelists().  But there's a\nbug which prevents the new zone to be added to other nodes' zone lists.\n\nonline_pages() {\n\tbuild_all_zonelists()\n\t.....\n\tnode_set_state(zone_to_nid(zone), N_HIGH_MEMORY)\n}\n\nHere the node of the zone is put into N_HIGH_MEMORY state after calling\nbuild_all_zonelists(), but build_all_zonelists() only adds zones from\nnodes in N_HIGH_MEMORY state to the fallback zone lists.\nbuild_all_zonelists()\n\n    ->__build_all_zonelists()\n\t->build_zonelists()\n\t    ->find_next_best_node()\n\t\t->for_each_node_state(n, N_HIGH_MEMORY)\n\nSo memory in the new zone will never be used by other nodes, and it may\ncause strange behavor when system is under memory pressure.  So put node\ninto N_HIGH_MEMORY state before calling build_all_zonelists().\n\nSigned-off-by: Jianguo Wu <wujianguo@huawei.com>\nSigned-off-by: Jiang Liu <liuj97@gmail.com>\nCc: Mel Gorman <mgorman@suse.de>\nCc: Michal Hocko <mhocko@suse.cz>\nCc: Minchan Kim <minchan@kernel.org>\nCc: Rusty Russell <rusty@rustcorp.com.au>\nCc: Yinghai Lu <yinghai@kernel.org>\nCc: Tony Luck <tony.luck@intel.com>\nCc: KAMEZAWA Hiroyuki <kamezawa.hiroyu@jp.fujitsu.com>\nCc: KOSAKI Motohiro <kosaki.motohiro@jp.fujitsu.com>\nCc: David Rientjes <rientjes@google.com>\nCc: Keping Chen <chenkeping@huawei.com>\nSigned-off-by: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The online_pages function in mm/memory_hotplug.c in the Linux kernel before 3.6 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact in opportunistic circumstances by using memory that was hot-added by an administrator.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 573,
        "reasoning": "This code is vulnerable to a divide-by-zero error because the `do_div(t, ca->cnt_rtt)` operation occurs without checking if `ca->cnt_rtt` is zero, which can happen when `rtt_reset` is called. This allows a local user, by triggering the reading of TCP stats with the Illinois congestion control algorithm enabled, to cause a kernel OOPS and a denial of service.",
        "func": "static void tcp_illinois_info(struct sock *sk, u32 ext,\n\t\t\t      struct sk_buff *skb)\n{\n\tconst struct illinois *ca = inet_csk_ca(sk);\n\n\tif (ext & (1 << (INET_DIAG_VEGASINFO - 1))) {\n\t\tstruct tcpvegas_info info = {\n\t\t\t.tcpv_enabled = 1,\n \t\t\t.tcpv_rttcnt = ca->cnt_rtt,\n \t\t\t.tcpv_minrtt = ca->base_rtt,\n \t\t};\n\t\tu64 t = ca->sum_rtt;\n \n\t\tdo_div(t, ca->cnt_rtt);\n\t\tinfo.tcpv_rtt = t;\n \n \t\tnla_put(skb, INET_DIAG_VEGASINFO, sizeof(info), &info);\n \t}\n }\n",
        "commit_message": "net: fix divide by zero in tcp algorithm illinois\n\nReading TCP stats when using TCP Illinois congestion control algorithm\ncan cause a divide by zero kernel oops.\n\nThe division by zero occur in tcp_illinois_info() at:\n do_div(t, ca->cnt_rtt);\nwhere ca->cnt_rtt can become zero (when rtt_reset is called)\n\nSteps to Reproduce:\n 1. Register tcp_illinois:\n     # sysctl -w net.ipv4.tcp_congestion_control=illinois\n 2. Monitor internal TCP information via command \"ss -i\"\n     # watch -d ss -i\n 3. Establish new TCP conn to machine\n\nEither it fails at the initial conn, or else it needs to wait\nfor a loss or a reset.\n\nThis is only related to reading stats.  The function avg_delay() also\nperforms the same divide, but is guarded with a (ca->cnt_rtt > 0) at its\ncalling point in update_params().  Thus, simply fix tcp_illinois_info().\n\nFunction tcp_illinois_info() / get_info() is called without\nsocket lock.  Thus, eliminate any race condition on ca->cnt_rtt\nby using a local stack variable.  Simply reuse info.tcpv_rttcnt,\nas its already set to ca->cnt_rtt.\nFunction avg_delay() is not affected by this race condition, as\nits called with the socket lock.\n\nCc: Petr Matousek <pmatouse@redhat.com>\nSigned-off-by: Jesper Dangaard Brouer <brouer@redhat.com>\nAcked-by: Eric Dumazet <edumazet@google.com>\nAcked-by: Stephen Hemminger <shemminger@vyatta.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The tcp_illinois_info function in net/ipv4/tcp_illinois.c in the Linux kernel before 3.4.19, when the net.ipv4.tcp_congestion_control illinois setting is enabled, allows local users to cause a denial of service (divide-by-zero error and OOPS) by reading TCP stats.",
        "target": 1
      },
      {
        "idx": 579,
        "reasoning": "This code is vulnerable because a recent commit introduced an incorrect argument order in the `compat_put_timeval` function call, potentially passing kernel addresses as user pointers\u2014and vice versa. This flaw can lead to an `EFAULT` error, denial of service, or, on certain architectures like HP-PA, allow reading of sensitive kernel memory due to bypassed user address range checks as described in the CVE.",
        "func": "static int do_siocgstamp(struct net *net, struct socket *sock,\n\t\t\t unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timeval ktv;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n \terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&ktv);\n \tset_fs(old_fs);\n \tif (!err)\n\t\terr = compat_put_timeval(up, &ktv);\n \n \treturn err;\n }\n",
        "commit_message": "Fix order of arguments to compat_put_time[spec|val]\n\nCommit 644595f89620 (\"compat: Handle COMPAT_USE_64BIT_TIME in\nnet/socket.c\") introduced a bug where the helper functions to take\neither a 64-bit or compat time[spec|val] got the arguments in the wrong\norder, passing the kernel stack pointer off as a user pointer (and vice\nversa).\n\nBecause of the user address range check, that in turn then causes an\nEFAULT due to the user pointer range checking failing for the kernel\naddress.  Incorrectly resuling in a failed system call for 32-bit\nprocesses with a 64-bit kernel.\n\nOn odder architectures like HP-PA (with separate user/kernel address\nspaces), it can be used read kernel memory.\n\nSigned-off-by: Mikulas Patocka <mpatocka@redhat.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The (1) do_siocgstamp and (2) do_siocgstampns functions in net/socket.c in the Linux kernel before 3.5.4 use an incorrect argument order, which allows local users to obtain sensitive information from kernel memory or cause a denial of service (system crash) via a crafted ioctl call.",
        "target": 1
      },
      {
        "idx": 580,
        "reasoning": "This code is vulnerable because a recent commit introduced an incorrect argument order to the `compat_put_timespec` function, potentially passing kernel addresses as user pointers\u2014and vice versa. This flaw can lead to an `EFAULT` error, denial of service, or, on architectures with distinct user/kernel spaces like HP-PA, allow reading of sensitive kernel memory.",
        "func": "static int do_siocgstampns(struct net *net, struct socket *sock,\n\t\t\t   unsigned int cmd, void __user *up)\n{\n\tmm_segment_t old_fs = get_fs();\n\tstruct timespec kts;\n\tint err;\n\n\tset_fs(KERNEL_DS);\n \terr = sock_do_ioctl(net, sock, cmd, (unsigned long)&kts);\n \tset_fs(old_fs);\n \tif (!err)\n\t\terr = compat_put_timespec(up, &kts);\n \n \treturn err;\n }\n",
        "commit_message": "Fix order of arguments to compat_put_time[spec|val]\n\nCommit 644595f89620 (\"compat: Handle COMPAT_USE_64BIT_TIME in\nnet/socket.c\") introduced a bug where the helper functions to take\neither a 64-bit or compat time[spec|val] got the arguments in the wrong\norder, passing the kernel stack pointer off as a user pointer (and vice\nversa).\n\nBecause of the user address range check, that in turn then causes an\nEFAULT due to the user pointer range checking failing for the kernel\naddress.  Incorrectly resuling in a failed system call for 32-bit\nprocesses with a 64-bit kernel.\n\nOn odder architectures like HP-PA (with separate user/kernel address\nspaces), it can be used read kernel memory.\n\nSigned-off-by: Mikulas Patocka <mpatocka@redhat.com>\nCc: stable@vger.kernel.org\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The (1) do_siocgstamp and (2) do_siocgstampns functions in net/socket.c in the Linux kernel before 3.5.4 use an incorrect argument order, which allows local users to obtain sensitive information from kernel memory or cause a denial of service (system crash) via a crafted ioctl call.",
        "target": 1
      },
      {
        "idx": 620,
        "reasoning": "This code is vulnerable to a use-after-free because the `p->mm` pointer could become null between the `if (p->mm)` check and the subsequent access of `p->mm->hiwater_rss` and `p->mm->hiwater_vm`.  Specifically, another part of the kernel could free the memory pointed to by `p->mm` in that brief window, leading to a crash or information leak when the code attempts to dereference the now-invalid pointer.",
        "func": " void xacct_add_tsk(struct taskstats *stats, struct task_struct *p)\n {\n \t/* convert pages-jiffies to Mbyte-usec */\n \tstats->coremem = jiffies_to_usecs(p->acct_rss_mem1) * PAGE_SIZE / MB;\n \tstats->virtmem = jiffies_to_usecs(p->acct_vm_mem1) * PAGE_SIZE / MB;\n\tif (p->mm) {\n \t\t/* adjust to KB unit */\n\t\tstats->hiwater_rss   = p->mm->hiwater_rss * PAGE_SIZE / KB;\n\t\tstats->hiwater_vm    = p->mm->hiwater_vm * PAGE_SIZE / KB;\n \t}\n \tstats->read_char\t= p->rchar;\n \tstats->write_char\t= p->wchar;\n\tstats->read_syscalls\t= p->syscr;\n\tstats->write_syscalls\t= p->syscw;\n}\n",
        "commit_message": "[PATCH] xacct_add_tsk: fix pure theoretical ->mm use-after-free\n\nParanoid fix. The task can free its ->mm after the 'if (p->mm)' check.\n\nSigned-off-by: Oleg Nesterov <oleg@tv-sign.ru>\nCc: Shailabh Nagar <nagar@watson.ibm.com>\nCc: Balbir Singh <balbir@in.ibm.com>\nCc: Jay Lan <jlan@sgi.com>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "Use-after-free vulnerability in the xacct_add_tsk function in kernel/tsacct.c in the Linux kernel before 2.6.19 allows local users to obtain potentially sensitive information from kernel memory or cause a denial of service (system crash) via a taskstats TASKSTATS_CMD_ATTR_PID command.",
        "target": 1
      },
      {
        "idx": 621,
        "reasoning": "The `rds_recvmsg` function is vulnerable because it doesn't always populate the `msg_name` field of the `msghdr` structure with the correct address information, potentially leading to the kernel copying up to 128 bytes of kernel memory into userspace when `recvfrom` or `recvmsg` are called with an oversized address length. Specifically, code paths bypassing the `sin = (struct sockaddr_in *)msg->msg_name;` section can return a non-negative value without proper address initialization, exposing kernel data to user applications.",
        "func": "int rds_recvmsg(struct kiocb *iocb, struct socket *sock, struct msghdr *msg,\n\t\tsize_t size, int msg_flags)\n{\n\tstruct sock *sk = sock->sk;\n\tstruct rds_sock *rs = rds_sk_to_rs(sk);\n\tlong timeo;\n\tint ret = 0, nonblock = msg_flags & MSG_DONTWAIT;\n\tstruct sockaddr_in *sin;\n\tstruct rds_incoming *inc = NULL;\n\n\t/* udp_recvmsg()->sock_recvtimeo() gets away without locking too.. */\n\ttimeo = sock_rcvtimeo(sk, nonblock);\n \n \trdsdebug(\"size %zu flags 0x%x timeo %ld\\n\", size, msg_flags, timeo);\n \n \tif (msg_flags & MSG_OOB)\n \t\tgoto out;\n \n\twhile (1) {\n\t\t/* If there are pending notifications, do those - and nothing else */\n\t\tif (!list_empty(&rs->rs_notify_queue)) {\n\t\t\tret = rds_notify_queue_get(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (rs->rs_cong_notify) {\n\t\t\tret = rds_notify_cong(rs, msg);\n\t\t\tbreak;\n\t\t}\n\n\t\tif (!rds_next_incoming(rs, &inc)) {\n\t\t\tif (nonblock) {\n\t\t\t\tret = -EAGAIN;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\ttimeo = wait_event_interruptible_timeout(*sk_sleep(sk),\n\t\t\t\t\t(!list_empty(&rs->rs_notify_queue) ||\n\t\t\t\t\t rs->rs_cong_notify ||\n\t\t\t\t\t rds_next_incoming(rs, &inc)), timeo);\n\t\t\trdsdebug(\"recvmsg woke inc %p timeo %ld\\n\", inc,\n\t\t\t\t timeo);\n\t\t\tif (timeo > 0 || timeo == MAX_SCHEDULE_TIMEOUT)\n\t\t\t\tcontinue;\n\n\t\t\tret = timeo;\n\t\t\tif (ret == 0)\n\t\t\t\tret = -ETIMEDOUT;\n\t\t\tbreak;\n\t\t}\n\n\t\trdsdebug(\"copying inc %p from %pI4:%u to user\\n\", inc,\n\t\t\t &inc->i_conn->c_faddr,\n\t\t\t ntohs(inc->i_hdr.h_sport));\n\t\tret = inc->i_conn->c_trans->inc_copy_to_user(inc, msg->msg_iov,\n\t\t\t\t\t\t\t     size);\n\t\tif (ret < 0)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * if the message we just copied isn't at the head of the\n\t\t * recv queue then someone else raced us to return it, try\n\t\t * to get the next message.\n\t\t */\n\t\tif (!rds_still_queued(rs, inc, !(msg_flags & MSG_PEEK))) {\n\t\t\trds_inc_put(inc);\n\t\t\tinc = NULL;\n\t\t\trds_stats_inc(s_recv_deliver_raced);\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (ret < be32_to_cpu(inc->i_hdr.h_len)) {\n\t\t\tif (msg_flags & MSG_TRUNC)\n\t\t\t\tret = be32_to_cpu(inc->i_hdr.h_len);\n\t\t\tmsg->msg_flags |= MSG_TRUNC;\n\t\t}\n\n\t\tif (rds_cmsg_recv(inc, msg)) {\n\t\t\tret = -EFAULT;\n\t\t\tgoto out;\n\t\t}\n\n\t\trds_stats_inc(s_recv_delivered);\n\n\t\tsin = (struct sockaddr_in *)msg->msg_name;\n\t\tif (sin) {\n\t\t\tsin->sin_family = AF_INET;\n \t\t\tsin->sin_port = inc->i_hdr.h_sport;\n \t\t\tsin->sin_addr.s_addr = inc->i_saddr;\n \t\t\tmemset(sin->sin_zero, 0, sizeof(sin->sin_zero));\n \t\t}\n \t\tbreak;\n \t}\n\n\tif (inc)\n\t\trds_inc_put(inc);\n\nout:\n\treturn ret;\n}\n",
        "commit_message": "rds: set correct msg_namelen\n\nJay Fenlason (fenlason@redhat.com) found a bug,\nthat recvfrom() on an RDS socket can return the contents of random kernel\nmemory to userspace if it was called with a address length larger than\nsizeof(struct sockaddr_in).\nrds_recvmsg() also fails to set the addr_len paramater properly before\nreturning, but that's just a bug.\nThere are also a number of cases wher recvfrom() can return an entirely bogus\naddress. Anything in rds_recvmsg() that returns a non-negative value but does\nnot go through the \"sin = (struct sockaddr_in *)msg->msg_name;\" code path\nat the end of the while(1) loop will return up to 128 bytes of kernel memory\nto userspace.\n\nAnd I write two test programs to reproduce this bug, you will see that in\nrds_server, fromAddr will be overwritten and the following sock_fd will be\ndestroyed.\nYes, it is the programmer's fault to set msg_namelen incorrectly, but it is\nbetter to make the kernel copy the real length of address to user space in\nsuch case.\n\nHow to run the test programs ?\nI test them on 32bit x86 system, 3.5.0-rc7.\n\n1 compile\ngcc -o rds_client rds_client.c\ngcc -o rds_server rds_server.c\n\n2 run ./rds_server on one console\n\n3 run ./rds_client on another console\n\n4 you will see something like:\nserver is waiting to receive data...\nold socket fd=3\nserver received data from client:data from client\nmsg.msg_namelen=32\nnew socket fd=-1067277685\nsendmsg()\n: Bad file descriptor\n\n/***************** rds_client.c ********************/\n\nint main(void)\n{\n\tint sock_fd;\n\tstruct sockaddr_in serverAddr;\n\tstruct sockaddr_in toAddr;\n\tchar recvBuffer[128] = \"data from client\";\n\tstruct msghdr msg;\n\tstruct iovec iov;\n\n\tsock_fd = socket(AF_RDS, SOCK_SEQPACKET, 0);\n\tif (sock_fd < 0) {\n\t\tperror(\"create socket error\\n\");\n\t\texit(1);\n\t}\n\n\tmemset(&serverAddr, 0, sizeof(serverAddr));\n\tserverAddr.sin_family = AF_INET;\n\tserverAddr.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\tserverAddr.sin_port = htons(4001);\n\n\tif (bind(sock_fd, (struct sockaddr*)&serverAddr, sizeof(serverAddr)) < 0) {\n\t\tperror(\"bind() error\\n\");\n\t\tclose(sock_fd);\n\t\texit(1);\n\t}\n\n\tmemset(&toAddr, 0, sizeof(toAddr));\n\ttoAddr.sin_family = AF_INET;\n\ttoAddr.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\ttoAddr.sin_port = htons(4000);\n\tmsg.msg_name = &toAddr;\n\tmsg.msg_namelen = sizeof(toAddr);\n\tmsg.msg_iov = &iov;\n\tmsg.msg_iovlen = 1;\n\tmsg.msg_iov->iov_base = recvBuffer;\n\tmsg.msg_iov->iov_len = strlen(recvBuffer) + 1;\n\tmsg.msg_control = 0;\n\tmsg.msg_controllen = 0;\n\tmsg.msg_flags = 0;\n\n\tif (sendmsg(sock_fd, &msg, 0) == -1) {\n\t\tperror(\"sendto() error\\n\");\n\t\tclose(sock_fd);\n\t\texit(1);\n\t}\n\n\tprintf(\"client send data:%s\\n\", recvBuffer);\n\n\tmemset(recvBuffer, '\\0', 128);\n\n\tmsg.msg_name = &toAddr;\n\tmsg.msg_namelen = sizeof(toAddr);\n\tmsg.msg_iov = &iov;\n\tmsg.msg_iovlen = 1;\n\tmsg.msg_iov->iov_base = recvBuffer;\n\tmsg.msg_iov->iov_len = 128;\n\tmsg.msg_control = 0;\n\tmsg.msg_controllen = 0;\n\tmsg.msg_flags = 0;\n\tif (recvmsg(sock_fd, &msg, 0) == -1) {\n\t\tperror(\"recvmsg() error\\n\");\n\t\tclose(sock_fd);\n\t\texit(1);\n\t}\n\n\tprintf(\"receive data from server:%s\\n\", recvBuffer);\n\n\tclose(sock_fd);\n\n\treturn 0;\n}\n\n/***************** rds_server.c ********************/\n\nint main(void)\n{\n\tstruct sockaddr_in fromAddr;\n\tint sock_fd;\n\tstruct sockaddr_in serverAddr;\n\tunsigned int addrLen;\n\tchar recvBuffer[128];\n\tstruct msghdr msg;\n\tstruct iovec iov;\n\n\tsock_fd = socket(AF_RDS, SOCK_SEQPACKET, 0);\n\tif(sock_fd < 0) {\n\t\tperror(\"create socket error\\n\");\n\t\texit(0);\n\t}\n\n\tmemset(&serverAddr, 0, sizeof(serverAddr));\n\tserverAddr.sin_family = AF_INET;\n\tserverAddr.sin_addr.s_addr = inet_addr(\"127.0.0.1\");\n\tserverAddr.sin_port = htons(4000);\n\tif (bind(sock_fd, (struct sockaddr*)&serverAddr, sizeof(serverAddr)) < 0) {\n\t\tperror(\"bind error\\n\");\n\t\tclose(sock_fd);\n\t\texit(1);\n\t}\n\n\tprintf(\"server is waiting to receive data...\\n\");\n\tmsg.msg_name = &fromAddr;\n\n\t/*\n\t * I add 16 to sizeof(fromAddr), ie 32,\n\t * and pay attention to the definition of fromAddr,\n\t * recvmsg() will overwrite sock_fd,\n\t * since kernel will copy 32 bytes to userspace.\n\t *\n\t * If you just use sizeof(fromAddr), it works fine.\n\t * */\n\tmsg.msg_namelen = sizeof(fromAddr) + 16;\n\t/* msg.msg_namelen = sizeof(fromAddr); */\n\tmsg.msg_iov = &iov;\n\tmsg.msg_iovlen = 1;\n\tmsg.msg_iov->iov_base = recvBuffer;\n\tmsg.msg_iov->iov_len = 128;\n\tmsg.msg_control = 0;\n\tmsg.msg_controllen = 0;\n\tmsg.msg_flags = 0;\n\n\twhile (1) {\n\t\tprintf(\"old socket fd=%d\\n\", sock_fd);\n\t\tif (recvmsg(sock_fd, &msg, 0) == -1) {\n\t\t\tperror(\"recvmsg() error\\n\");\n\t\t\tclose(sock_fd);\n\t\t\texit(1);\n\t\t}\n\t\tprintf(\"server received data from client:%s\\n\", recvBuffer);\n\t\tprintf(\"msg.msg_namelen=%d\\n\", msg.msg_namelen);\n\t\tprintf(\"new socket fd=%d\\n\", sock_fd);\n\t\tstrcat(recvBuffer, \"--data from server\");\n\t\tif (sendmsg(sock_fd, &msg, 0) == -1) {\n\t\t\tperror(\"sendmsg()\\n\");\n\t\t\tclose(sock_fd);\n\t\t\texit(1);\n\t\t}\n\t}\n\n\tclose(sock_fd);\n\treturn 0;\n}\n\nSigned-off-by: Weiping Pan <wpan@redhat.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_recvmsg function in net/rds/recv.c in the Linux kernel before 3.0.44 does not initialize a certain structure member, which allows local users to obtain potentially sensitive information from kernel stack memory via a (1) recvfrom or (2) recvmsg system call on an RDS socket.",
        "target": 1
      }
    ]
  },
  "linux-2.6": {
    "0": [
      {
        "idx": 486911,
        "reasoning": "This code snippet is for `compat_sys_futimesat` and is **not** directly related to the vulnerability described in the commit message, which concerns `compat_sys_mount`. The commit message details a NULL pointer dereference issue in the mount system call when handling data pages, while this code safely handles potentially NULL timeval pointers by passing NULL to `do_utimes` when `t` is NULL, avoiding any dereference.\n\n\n\n",
        "func": "asmlinkage long compat_sys_futimesat(unsigned int dfd, char __user *filename, struct compat_timeval __user *t)\n{\n\tstruct timeval tv[2];\n\n\tif (t) {\n\t\tif (get_user(tv[0].tv_sec, &t[0].tv_sec) ||\n\t\t    get_user(tv[0].tv_usec, &t[0].tv_usec) ||\n\t\t    get_user(tv[1].tv_sec, &t[1].tv_sec) ||\n\t\t    get_user(tv[1].tv_usec, &t[1].tv_usec))\n\t\t\treturn -EFAULT;\n\t}\n\treturn do_utimes(dfd, filename, t ? tv : NULL);\n}",
        "commit_message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "The compat_sys_mount function in fs/compat.c in Linux kernel 2.6.20 and earlier allows local users to cause a denial of service (NULL pointer dereference and oops) by mounting a smbfs file system in compatibility mode (\"mount -t smbfs\").",
        "target": 0
      },
      {
        "idx": 486912,
        "reasoning": "This code snippet, `compat_get_fd_set`, is not directly related to the reported vulnerability in `compat_sys_mount`. The commit message specifically addresses a NULL pointer dereference when `data_page` is NULL *within* `compat_sys_mount`, while this code handles file descriptor sets and doesn't appear to interact with that specific condition or data structure.\n\n\n\n",
        "func": "int compat_get_fd_set(unsigned long nr, compat_ulong_t __user *ufdset,\n\t\t\tunsigned long *fdset)\n{\n\tnr = ROUND_UP(nr, __COMPAT_NFDBITS);\n\tif (ufdset) {\n\t\tunsigned long odd;\n\n\t\tif (!access_ok(VERIFY_WRITE, ufdset, nr*sizeof(compat_ulong_t)))\n\t\t\treturn -EFAULT;\n\n\t\todd = nr & 1UL;\n\t\tnr &= ~1UL;\n\t\twhile (nr) {\n\t\t\tunsigned long h, l;\n\t\t\t__get_user(l, ufdset);\n\t\t\t__get_user(h, ufdset+1);\n\t\t\tufdset += 2;\n\t\t\t*fdset++ = h << 32 | l;\n\t\t\tnr -= 2;\n\t\t}\n\t\tif (odd)\n\t\t\t__get_user(*fdset, ufdset);\n\t} else {\n\t\t/* Tricky, must clear full unsigned long in the\n\t\t * kernel fdset at the end, this makes sure that\n\t\t * actually happens.\n\t\t */\n\t\tmemset(fdset, 0, ((nr + 1) & ~1)*sizeof(compat_ulong_t));\n\t}\n\treturn 0;\n}",
        "commit_message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "The compat_sys_mount function in fs/compat.c in Linux kernel 2.6.20 and earlier allows local users to cause a denial of service (NULL pointer dereference and oops) by mounting a smbfs file system in compatibility mode (\"mount -t smbfs\").",
        "target": 0
      },
      {
        "idx": 486913,
        "reasoning": "This code snippet for `compat_sys_fstatfs` is not directly related to the reported vulnerability in `compat_sys_mount`. The commit message details a NULL pointer dereference issue specifically within the mounting process when `data_page` is NULL, while this code handles file status information retrieval and doesn't appear to involve the problematic `data_page` pointer.\n\n\n\n",
        "func": "asmlinkage long compat_sys_fstatfs(unsigned int fd, struct compat_statfs __user *buf)\n{\n\tstruct file * file;\n\tstruct kstatfs tmp;\n\tint error;\n\n\terror = -EBADF;\n\tfile = fget(fd);\n\tif (!file)\n\t\tgoto out;\n\terror = vfs_statfs(file->f_dentry, &tmp);\n\tif (!error)\n\t\terror = put_compat_statfs(buf, &tmp);\n\tfput(file);\nout:\n\treturn error;\n}",
        "commit_message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "The compat_sys_mount function in fs/compat.c in Linux kernel 2.6.20 and earlier allows local users to cause a denial of service (NULL pointer dereference and oops) by mounting a smbfs file system in compatibility mode (\"mount -t smbfs\").",
        "target": 0
      },
      {
        "idx": 486914,
        "reasoning": "This code snippet is for the `compat_sys_select` system call and is not related to the reported vulnerability in `compat_sys_mount`. The commit message and description clearly indicate the issue lies within the mounting process and specifically addresses a NULL pointer dereference when handling data pages during mounting, which isn't present in the provided `select` code.\n\n\n\n",
        "func": "asmlinkage long compat_sys_select(int n, compat_ulong_t __user *inp,\n\tcompat_ulong_t __user *outp, compat_ulong_t __user *exp,\n\tstruct compat_timeval __user *tvp)\n{\n\ts64 timeout = -1;\n\tstruct compat_timeval tv;\n\tint ret;\n\n\tif (tvp) {\n\t\tif (copy_from_user(&tv, tvp, sizeof(tv)))\n\t\t\treturn -EFAULT;\n\n\t\tif (tv.tv_sec < 0 || tv.tv_usec < 0)\n\t\t\treturn -EINVAL;\n\n\t\t/* Cast to u64 to make GCC stop complaining */\n\t\tif ((u64)tv.tv_sec >= (u64)MAX_INT64_SECONDS)\n\t\t\ttimeout = -1;\t/* infinite */\n\t\telse {\n\t\t\ttimeout = ROUND_UP(tv.tv_usec, 1000000/HZ);\n\t\t\ttimeout += tv.tv_sec * HZ;\n\t\t}\n\t}\n\n\tret = compat_core_sys_select(n, inp, outp, exp, &timeout);\n\n\tif (tvp) {\n\t\tstruct compat_timeval rtv;\n\n\t\tif (current->personality & STICKY_TIMEOUTS)\n\t\t\tgoto sticky;\n\t\trtv.tv_usec = jiffies_to_usecs(do_div((*(u64*)&timeout), HZ));\n\t\trtv.tv_sec = timeout;\n\t\tif (compat_timeval_compare(&rtv, &tv) >= 0)\n\t\t\trtv = tv;\n\t\tif (copy_to_user(tvp, &rtv, sizeof(rtv))) {\nsticky:\n\t\t\t/*\n\t\t\t * If an application puts its timeval in read-only\n\t\t\t * memory, we don't want the Linux-specific update to\n\t\t\t * the timeval to cause a fault after the select has\n\t\t\t * completed successfully. However, because we're not\n\t\t\t * updating the timeval, we can't restart the system\n\t\t\t * call.\n\t\t\t */\n\t\t\tif (ret == -ERESTARTNOHAND)\n\t\t\t\tret = -EINTR;\n\t\t}\n\t}\n\n\treturn ret;\n}",
        "commit_message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "The compat_sys_mount function in fs/compat.c in Linux kernel 2.6.20 and earlier allows local users to cause a denial of service (NULL pointer dereference and oops) by mounting a smbfs file system in compatibility mode (\"mount -t smbfs\").",
        "target": 0
      },
      {
        "idx": 486915,
        "reasoning": "This code snippet for `compat_sys_getdents64` is not directly related to the reported vulnerability in `compat_sys_mount`. The commit message specifically addresses a NULL pointer dereference issue during mounting with OpenVZ in 32-bit mode, while this code handles directory entry retrieval and doesn't appear to have similar issues regarding NULL pointer handling or data conversion with a potentially NULL `data_page`.\n\n\n\n",
        "func": "asmlinkage long compat_sys_getdents64(unsigned int fd,\n\t\tstruct linux_dirent64 __user * dirent, unsigned int count)\n{\n\tstruct file * file;\n\tstruct linux_dirent64 __user * lastdirent;\n\tstruct compat_getdents_callback64 buf;\n\tint error;\n\n\terror = -EFAULT;\n\tif (!access_ok(VERIFY_WRITE, dirent, count))\n\t\tgoto out;\n\n\terror = -EBADF;\n\tfile = fget(fd);\n\tif (!file)\n\t\tgoto out;\n\n\tbuf.current_dir = dirent;\n\tbuf.previous = NULL;\n\tbuf.count = count;\n\tbuf.error = 0;\n\n\terror = vfs_readdir(file, compat_filldir64, &buf);\n\tif (error < 0)\n\t\tgoto out_putf;\n\terror = buf.error;\n\tlastdirent = buf.previous;\n\tif (lastdirent) {\n\t\ttypeof(lastdirent->d_off) d_off = file->f_pos;\n\t\t__put_user_unaligned(d_off, &lastdirent->d_off);\n\t\terror = count - buf.count;\n\t}\n\nout_putf:\n\tfput(file);\nout:\n\treturn error;\n}",
        "commit_message": "[PATCH] skip data conversion in compat_sys_mount when data_page is NULL\n\nOpenVZ Linux kernel team has found a problem with mounting in compat mode.\n\nSimple command \"mount -t smbfs ...\" on Fedora Core 5 distro in 32-bit mode\nleads to oops:\n\n  Unable to handle kernel NULL pointer dereference at 0000000000000000 RIP: compat_sys_mount+0xd6/0x290\n  Process mount (pid: 14656, veid=300, threadinfo ffff810034d30000, task ffff810034c86bc0)\n  Call Trace: ia32_sysret+0x0/0xa\n\nThe problem is that data_page pointer can be NULL, so we should skip data\nconversion in this case.\n\nSigned-off-by: Andrey Mirkin <amirkin@openvz.org>\nCc: <stable@kernel.org>\nSigned-off-by: Andrew Morton <akpm@osdl.org>\nSigned-off-by: Linus Torvalds <torvalds@osdl.org>",
        "cve_desc": "The compat_sys_mount function in fs/compat.c in Linux kernel 2.6.20 and earlier allows local users to cause a denial of service (NULL pointer dereference and oops) by mounting a smbfs file system in compatibility mode (\"mount -t smbfs\").",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 215290,
        "reasoning": "This code is vulnerable because it fails to properly zero-extend the `eax` register after a 32-bit entry path to `ptrace` on x86_64 systems, as highlighted by CVE-2007-4573. This lack of zero-extension can lead to an out-of-bounds access to the system call table via the `%RAX` register, potentially allowing a local user to gain elevated privileges.",
        "func": "static int putreg(struct task_struct *child,\n\tunsigned long regno, unsigned long value)\n{\n\tunsigned long tmp; \n\t\n\t/* Some code in the 64bit emulation may not be 64bit clean.\n\t   Don't take any chances. */\n\tif (test_tsk_thread_flag(child, TIF_IA32))\n\t\tvalue &= 0xffffffff;\n\tswitch (regno) {\n\t\tcase offsetof(struct user_regs_struct,fs):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.fsindex = value & 0xffff; \n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,gs):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.gsindex = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,ds):\n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.ds = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,es): \n\t\t\tif (value && (value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.es = value & 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,ss):\n\t\t\tif ((value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tvalue &= 0xffff;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,fs_base):\n\t\t\tif (value >= TASK_SIZE_OF(child))\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.fs = value;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct,gs_base):\n\t\t\tif (value >= TASK_SIZE_OF(child))\n\t\t\t\treturn -EIO;\n\t\t\tchild->thread.gs = value;\n\t\t\treturn 0;\n\t\tcase offsetof(struct user_regs_struct, eflags):\n\t\t\tvalue &= FLAG_MASK;\n\t\t\ttmp = get_stack_long(child, EFL_OFFSET); \n\t\t\ttmp &= ~FLAG_MASK; \n\t\t\tvalue |= tmp;\n\t\t\tbreak;\n\t\tcase offsetof(struct user_regs_struct,cs): \n\t\t\tif ((value & 3) != 3)\n\t\t\t\treturn -EIO;\n\t\t\tvalue &= 0xffff;\n\t\t\tbreak;\n\t}\n\tput_stack_long(child, regno - sizeof(struct pt_regs), value);\n\treturn 0;\n}",
        "commit_message": "x86_64: Zero extend all registers after ptrace in 32bit entry path.\n\nStrictly it's only needed for eax.\n\nIt actually does a little more than strictly needed -- the other registers\nare already zero extended.\n\nAlso remove the now unnecessary and non functional compat task check\nin ptrace.\n\nThis is CVE-2007-4573\n\nFound by Wojciech Purczynski\n\nSigned-off-by: Andi Kleen <ak@suse.de>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The IA32 system call emulation functionality in Linux kernel 2.4.x and 2.6.x before 2.6.22.7, when running on the x86_64 architecture, does not zero extend the eax register after the 32bit entry path to ptrace is used, which might allow local users to gain privileges by triggering an out-of-bounds access to the system call table using the %RAX register.",
        "target": 1
      },
      {
        "idx": 215311,
        "reasoning": "This code is vulnerable because it copies `struct iovec` data from user space but doesn't verify the user-provided pointers (`iov_base`) within those structures before attempting to access the memory they point to, potentially leading to a kernel crash or information disclosure. This lack of validation allows a malicious user to supply a pointer to an arbitrary kernel address, potentially gaining root privileges as described in the related CVE, by triggering a fault when the kernel attempts to read from or write to that address.",
        "func": "static int get_iovec_page_array(const struct iovec __user *iov,\n\t\t\t\tunsigned int nr_vecs, struct page **pages,\n\t\t\t\tstruct partial_page *partial, int aligned)\n{\n\tint buffers = 0, error = 0;\n\n\tdown_read(&current->mm->mmap_sem);\n\n\twhile (nr_vecs) {\n\t\tunsigned long off, npages;\n\t\tstruct iovec entry;\n\t\tvoid __user *base;\n\t\tsize_t len;\n\t\tint i;\n\n\t\terror = -EFAULT;\n\t\tif (copy_from_user_mmap_sem(&entry, iov, sizeof(entry)))\n\t\t\tbreak;\n\n\t\tbase = entry.iov_base;\n\t\tlen = entry.iov_len;\n\n\t\t/*\n\t\t * Sanity check this iovec. 0 read succeeds.\n\t\t */\n\t\terror = 0;\n\t\tif (unlikely(!len))\n\t\t\tbreak;\n\t\terror = -EFAULT;\n\t\tif (unlikely(!base))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Get this base offset and number of pages, then map\n\t\t * in the user pages.\n\t\t */\n\t\toff = (unsigned long) base & ~PAGE_MASK;\n\n\t\t/*\n\t\t * If asked for alignment, the offset must be zero and the\n\t\t * length a multiple of the PAGE_SIZE.\n\t\t */\n\t\terror = -EINVAL;\n\t\tif (aligned && (off || len & ~PAGE_MASK))\n\t\t\tbreak;\n\n\t\tnpages = (off + len + PAGE_SIZE - 1) >> PAGE_SHIFT;\n\t\tif (npages > PIPE_BUFFERS - buffers)\n\t\t\tnpages = PIPE_BUFFERS - buffers;\n\n\t\terror = get_user_pages(current, current->mm,\n\t\t\t\t       (unsigned long) base, npages, 0, 0,\n\t\t\t\t       &pages[buffers], NULL);\n\n\t\tif (unlikely(error <= 0))\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Fill this contiguous range into the partial page map.\n\t\t */\n\t\tfor (i = 0; i < error; i++) {\n\t\t\tconst int plen = min_t(size_t, len, PAGE_SIZE - off);\n\n\t\t\tpartial[buffers].offset = off;\n\t\t\tpartial[buffers].len = plen;\n\n\t\t\toff = 0;\n\t\t\tlen -= plen;\n\t\t\tbuffers++;\n\t\t}\n\n\t\t/*\n\t\t * We didn't complete this iov, stop here since it probably\n\t\t * means we have to move some of this into a pipe to\n\t\t * be able to continue.\n\t\t */\n\t\tif (len)\n\t\t\tbreak;\n\n\t\t/*\n\t\t * Don't continue if we mapped fewer pages than we asked for,\n\t\t * or if we mapped the max number of pages that we have\n\t\t * room for.\n\t\t */\n\t\tif (error < npages || buffers == PIPE_BUFFERS)\n\t\t\tbreak;\n\n\t\tnr_vecs--;\n\t\tiov++;\n\t}\n\n\tup_read(&current->mm->mmap_sem);\n\n\tif (buffers)\n\t\treturn buffers;\n\n\treturn error;\n}",
        "commit_message": "splice: fix user pointer access in get_iovec_page_array()\n\nCommit 8811930dc74a503415b35c4a79d14fb0b408a361 (\"splice: missing user\npointer access verification\") added the proper access_ok() calls to\ncopy_from_user_mmap_sem() which ensures we can copy the struct iovecs\nfrom userspace to the kernel.\n\nBut we also must check whether we can access the actual memory region\npointed to by the struct iovec to fix the access checks properly.\n\nSigned-off-by: Bastian Blank <waldi@debian.org>\nAcked-by: Oliver Pinter <oliver.pntr@gmail.com>\nCc: Jens Axboe <jens.axboe@oracle.com>\nCc: Andrew Morton <akpm@linux-foundation.org>\nSigned-off-by: Pekka Enberg <penberg@cs.helsinki.fi>\nSigned-off-by: Linus Torvalds <torvalds@linux-foundation.org>",
        "cve_desc": "The vmsplice_to_pipe function in Linux kernel 2.6.17 through 2.6.24.1 does not validate a certain userspace pointer before dereference, which allows local users to gain root privileges via crafted arguments in a vmsplice system call, a different vulnerability than CVE-2008-0009 and CVE-2008-0010.",
        "target": 1
      }
    ]
  },
  "linux-pam": {
    "0": [
      {
        "idx": 325941,
        "reasoning": "This code snippet, `str_to_uid`, is not directly related to the vulnerability described in the commit message. The vulnerability lies within the `pam_setquota` module's handling of mount points and how it interacts with `fusermount`, while this code only focuses on converting a string to a user ID and includes basic validation \u2013 it doesn\u2019t handle filesystem mounting or quota application.\n\n\n\n",
        "func": "str_to_uid(pam_handle_t *pamh, const char *value, uid_t default_value, const char *param) {\n    unsigned long ul;\n    char *ep;\n    uid_t uid;\n\n    errno = 0;\n    ul = strtoul(value, &ep, 10);\n    if (!(ul >= MAX_UID_VALUE\n        || (uid_t)ul >= MAX_UID_VALUE\n        || (errno != 0 && ul == 0)\n        || value == ep\n        || *ep != '\\0')) {\n        uid = (uid_t)ul;\n    } else {\n        pam_syslog(pamh, LOG_ERR, \"Parameter \\\"%s=%s\\\" invalid, \"\n                   \"setting to %u\", param, value, default_value);\n        uid = default_value;\n    }\n\n    return uid;\n}",
        "commit_message": "pam_setquota: skip mountpoints equal to the user's $HOME\n\nMatthias Gerstner found the following issue:\n\n<quote>\nSo this pam_setquota module iterates over all mounted file systems using\n`setmntent()` and `getmntent()`.  It tries to find the longest match of\na file system mounted on /home/$USER or above (except when the\nfs=/some/path parameter is passed to the pam module).\n\nThe thing is that /home/$USER is owned by the unprivileged user.  And\nthere exist tools like fusermount from libfuse which is by default\ninstalled setuid-root for everybody.  fusermount allows to mount a FUSE\nfile system using an arbitrary \"source device name\" as the unprivileged\nuser.\n\nThus considering the following use case:\n\n1) there is only the root file system (/) or a file system is mounted on\n   /home, but not on /home/$USER.\n2) the attacker mounts a fake FUSE file system over its own home directory:\n\n  ```\n  user $ export _FUSE_COMMFD=0\n  user $ fusermount $HOME -ononempty,fsname=/dev/sda1\n  ```\n\n  This will result in a mount entry in /proc/mounts looking like this:\n\n  ```\n  /dev/sda1 on /home/$USER type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=100)\n  ```\n3) when the attacker now logs in with pam_setquota configured then\n   pam_setquota will identify /dev/sda1 and the file system where\n   to apply the user's quota on.\n\nAs a result an unprivileged user has full control over onto which block\ndevice the quota is applied.\n</quote>\n\nIf the user's $HOME is on a separate partition, setting a quota on the\nuser's $HOME does not really make sense, so this patch skips mountpoints\nequal to the user's $HOME, preventing the above mentioned bug as\na side-effect (or vice-versa).\n\nReported-by: Matthias Gerstner <mgerstner@suse.de>\nCo-authored-by: Tom\u00e1\u0161 Mr\u00e1z <tmraz@redhat.com>\nCo-authored-by: Dmitry V. Levin <ldv@altlinux.org>\nResolves: https://github.com/linux-pam/linux-pam/pull/230",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 325942,
        "reasoning": "The provided code snippet `pam_sm_close_session` is a stub function that always returns `PAM_SUCCESS` and doesn't interact with mount points or quota settings. Therefore, it is not related to the vulnerability described in the commit message and is not vulnerable itself. \n\n\n\n",
        "func": "pam_sm_close_session(pam_handle_t *pamh UNUSED, int flags UNUSED,\n\t\t     int argc UNUSED, const char **argv UNUSED)\n{\n  return PAM_SUCCESS;\n}",
        "commit_message": "pam_setquota: skip mountpoints equal to the user's $HOME\n\nMatthias Gerstner found the following issue:\n\n<quote>\nSo this pam_setquota module iterates over all mounted file systems using\n`setmntent()` and `getmntent()`.  It tries to find the longest match of\na file system mounted on /home/$USER or above (except when the\nfs=/some/path parameter is passed to the pam module).\n\nThe thing is that /home/$USER is owned by the unprivileged user.  And\nthere exist tools like fusermount from libfuse which is by default\ninstalled setuid-root for everybody.  fusermount allows to mount a FUSE\nfile system using an arbitrary \"source device name\" as the unprivileged\nuser.\n\nThus considering the following use case:\n\n1) there is only the root file system (/) or a file system is mounted on\n   /home, but not on /home/$USER.\n2) the attacker mounts a fake FUSE file system over its own home directory:\n\n  ```\n  user $ export _FUSE_COMMFD=0\n  user $ fusermount $HOME -ononempty,fsname=/dev/sda1\n  ```\n\n  This will result in a mount entry in /proc/mounts looking like this:\n\n  ```\n  /dev/sda1 on /home/$USER type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=100)\n  ```\n3) when the attacker now logs in with pam_setquota configured then\n   pam_setquota will identify /dev/sda1 and the file system where\n   to apply the user's quota on.\n\nAs a result an unprivileged user has full control over onto which block\ndevice the quota is applied.\n</quote>\n\nIf the user's $HOME is on a separate partition, setting a quota on the\nuser's $HOME does not really make sense, so this patch skips mountpoints\nequal to the user's $HOME, preventing the above mentioned bug as\na side-effect (or vice-versa).\n\nReported-by: Matthias Gerstner <mgerstner@suse.de>\nCo-authored-by: Tom\u00e1\u0161 Mr\u00e1z <tmraz@redhat.com>\nCo-authored-by: Dmitry V. Levin <ldv@altlinux.org>\nResolves: https://github.com/linux-pam/linux-pam/pull/230",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 325943,
        "reasoning": "This code snippet is not directly vulnerable; it's a debug function simply logging quota information. The vulnerability lies in how `pam_setquota` iterates through mount points and potentially applies quotas to attacker-controlled block devices via FUSE, which this commit aims to fix by skipping mountpoints equal to the user's `$HOME`.\n\n\n\n",
        "func": "debug(pam_handle_t *pamh, const struct if_dqblk *p,\n      const char *device, const char *dbgprefix) {\n  pam_syslog(pamh, LOG_DEBUG, \"%s device=%s bsoftlimit=%llu bhardlimit=%llu \"\n                              \"isoftlimit=%llu ihardlimit=%llu btime=%llu itime=%llu\",\n\t     dbgprefix, device,\n\t     (unsigned long long) p->dqb_bsoftlimit,\n\t     (unsigned long long) p->dqb_bhardlimit,\n\t     (unsigned long long) p->dqb_isoftlimit,\n\t     (unsigned long long) p->dqb_ihardlimit,\n\t     (unsigned long long) p->dqb_btime,\n\t     (unsigned long long) p->dqb_itime);\n}",
        "commit_message": "pam_setquota: skip mountpoints equal to the user's $HOME\n\nMatthias Gerstner found the following issue:\n\n<quote>\nSo this pam_setquota module iterates over all mounted file systems using\n`setmntent()` and `getmntent()`.  It tries to find the longest match of\na file system mounted on /home/$USER or above (except when the\nfs=/some/path parameter is passed to the pam module).\n\nThe thing is that /home/$USER is owned by the unprivileged user.  And\nthere exist tools like fusermount from libfuse which is by default\ninstalled setuid-root for everybody.  fusermount allows to mount a FUSE\nfile system using an arbitrary \"source device name\" as the unprivileged\nuser.\n\nThus considering the following use case:\n\n1) there is only the root file system (/) or a file system is mounted on\n   /home, but not on /home/$USER.\n2) the attacker mounts a fake FUSE file system over its own home directory:\n\n  ```\n  user $ export _FUSE_COMMFD=0\n  user $ fusermount $HOME -ononempty,fsname=/dev/sda1\n  ```\n\n  This will result in a mount entry in /proc/mounts looking like this:\n\n  ```\n  /dev/sda1 on /home/$USER type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=100)\n  ```\n3) when the attacker now logs in with pam_setquota configured then\n   pam_setquota will identify /dev/sda1 and the file system where\n   to apply the user's quota on.\n\nAs a result an unprivileged user has full control over onto which block\ndevice the quota is applied.\n</quote>\n\nIf the user's $HOME is on a separate partition, setting a quota on the\nuser's $HOME does not really make sense, so this patch skips mountpoints\nequal to the user's $HOME, preventing the above mentioned bug as\na side-effect (or vice-versa).\n\nReported-by: Matthias Gerstner <mgerstner@suse.de>\nCo-authored-by: Tom\u00e1\u0161 Mr\u00e1z <tmraz@redhat.com>\nCo-authored-by: Dmitry V. Levin <ldv@altlinux.org>\nResolves: https://github.com/linux-pam/linux-pam/pull/230",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 325944,
        "reasoning": "This code is now safe because the patch skips mountpoints that are equal to the user's `$HOME`, preventing an attacker from mounting a FUSE filesystem over their home directory and controlling the quota device. This effectively mitigates the vulnerability described, where an unprivileged user could gain control over which block device the quota is applied to.",
        "func": "pam_sm_open_session(pam_handle_t *pamh, int flags UNUSED,\n\t\t    int argc, const char **argv)\n{\n  int retval;\n  char *val, *mntdevice = NULL;\n  const void *user;\n  const struct passwd *pwd;\n  struct pam_params param = {\n          .start_uid = PAM_USERTYPE_UIDMIN,\n          .end_uid = 0,\n          .fs = NULL };\n  struct if_dqblk ndqblk;\n  FILE *fp;\n  size_t mnt_len = 0, match_size = 0;\n#ifdef HAVE_GETMNTENT_R\n  char buf[BUFSIZ];\n  struct mntent ent;\n#endif\n  const struct mntent *mnt;\n  const char *service;\n\n  if (pam_get_item(pamh, PAM_SERVICE, (const void **)&service) != PAM_SUCCESS)\n    service = \"\";\n\n  /* Get UID_MIN for default start_uid from login.defs */\n  val = pam_modutil_search_key(pamh, PATH_LOGIN_DEFS, \"UID_MIN\");\n\n  /* Should UID_MIN be undefined, use current value of param.start_uid\n   * pre-defined as PAM_USERTYPE_UIDMIN set by configure as safe\n   * starting UID to avoid setting a quota for root and system\n   * users if startuid= parameter is absent.\n   */\n  if (val) {\n    param.start_uid = str_to_uid(pamh, val, param.start_uid, PATH_LOGIN_DEFS\":UID_MIN\");\n  }\n\n  /* Parse parameter values\n   * Must come after pam_modutil_search_key so that the current system\n   * default for UID_MIN is already in p.start_uid to serve as default\n   * for str_to_uid in case of a parse error.\n   * */\n  parse_params(pamh, argc, argv, &param);\n\n  if (param.debug >= 1)\n    pam_syslog(pamh, LOG_DEBUG, \"Config: startuid=%u enduid=%u fs=%s \"\n                    \"debug=%d overwrite=%d\",\n                    param.start_uid, param.end_uid,\n                    param.fs ? param.fs : \"(none)\",\n                    param.debug, param.overwrite);\n\n  /* Determine the user name so we can get the home directory */\n  retval = pam_get_item(pamh, PAM_USER, &user);\n  if (retval != PAM_SUCCESS || user == NULL || *(const char *)user == '\\0') {\n    pam_syslog(pamh, LOG_NOTICE, \"user unknown\");\n    return PAM_USER_UNKNOWN;\n  }\n\n  /* Get the password entry */\n  pwd = pam_modutil_getpwnam(pamh, user);\n  if (pwd == NULL) {\n    pam_syslog(pamh, LOG_NOTICE, \"user unknown\");\n    return PAM_USER_UNKNOWN;\n  }\n\n  /* Check if we should not set quotas for user */\n  if ((pwd->pw_uid < param.start_uid) ||\n      ((param.end_uid >= param.start_uid) && (param.start_uid != 0) &&\n       (pwd->pw_uid > param.end_uid)))\n    return PAM_SUCCESS;\n\n  /* Find out what device the filesystem is hosted on */\n  if ((fp = setmntent(\"/proc/mounts\", \"r\")) == NULL) {\n    pam_syslog(pamh, LOG_ERR, \"Unable to open /proc/mounts\");\n    return PAM_PERM_DENIED;\n  }\n\n  while (\n#ifdef HAVE_GETMNTENT_R\n           (mnt = getmntent_r(fp, &ent, buf, sizeof(buf))) != NULL\n#else\n           (mnt = getmntent(fp)) != NULL\n#endif\n        ) {\n    /* If param.fs is not specified use filesystem with users homedir\n     * as default.\n     */\n    if (param.fs == NULL) {\n      /* Mask trailing / from mnt->mnt_dir, to get a leading / on the\n       * remaining suffix returned by pam_str_skip_prefix_len()\n       */\n      for (mnt_len = strlen(mnt->mnt_dir); mnt_len > 0; --mnt_len)\n        if (mnt->mnt_dir[mnt_len - 1] != '/')\n          break;\n      const char *s;\n      if (param.debug >= 2)\n        pam_syslog(pamh, LOG_DEBUG, \"Trying to match pw_dir=\\\"%s\\\" \"\n                        \"with mnt_dir=\\\"%s\\\"\", pwd->pw_dir, mnt->mnt_dir);\n      /*\n       * (mnt_len > match_size) Only try matching the mnt_dir if its length\n       * is longer than the last matched length, trying to find the longest\n       * mnt_dir for a given pwd_dir.\n       *\n       * (mnt_len == 0 && mnt->mnt_dir[0] == '/') special-cases the\n       * root-dir /, which is the only mnt_dir with a trailing '/', which\n       * got masked earlier.\n       */\n      if ((mnt_len > match_size || (mnt_len == 0 && mnt->mnt_dir[0] == '/')) &&\n         (s = pam_str_skip_prefix_len(pwd->pw_dir, mnt->mnt_dir, mnt_len)) != NULL &&\n         s[0] == '/') {\n        free(mntdevice);\n        if ((mntdevice = strdup(mnt->mnt_fsname)) == NULL) {\n          pam_syslog(pamh, LOG_CRIT, \"Memory allocation error\");\n          endmntent(fp);\n          return PAM_PERM_DENIED;\n        }\n        match_size = mnt_len;\n        if (param.debug >= 2)\n          pam_syslog(pamh, LOG_DEBUG, \"Found pw_dir=\\\"%s\\\" in mnt_dir=\\\"%s\\\" \"\n                     \"with suffix=\\\"%s\\\" on device=\\\"%s\\\"\", pwd->pw_dir,\n                     mnt->mnt_dir, s, mntdevice);\n      }\n    /* param.fs has been specified, find exactly matching fileystem */\n    } else if ((strncmp(param.fs, mnt->mnt_dir, param.fs_len) == 0\n                && mnt->mnt_dir[param.fs_len] == '\\0') ||\n               (strncmp(param.fs, mnt->mnt_fsname, param.fs_len) == 0\n                && mnt->mnt_fsname[param.fs_len] == '\\0' )) {\n        free(mntdevice);\n        if ((mntdevice = strdup(mnt->mnt_fsname)) == NULL) {\n          pam_syslog(pamh, LOG_CRIT, \"Memory allocation error\");\n          endmntent(fp);\n          return PAM_PERM_DENIED;\n        }\n        if (param.debug >= 2)\n          pam_syslog(pamh, LOG_DEBUG, \"Found fs=\\\"%s\\\" in mnt_dir=\\\"%s\\\" \"\n                     \"on device=\\\"%s\\\"\", param.fs, mnt->mnt_dir, mntdevice);\n    }\n  }\n\n  endmntent(fp);\n\n  if (mntdevice == NULL) {\n    pam_syslog(pamh, LOG_ERR, \"Filesystem or device not found: %s\", param.fs ? param.fs : pwd->pw_dir);\n    return PAM_PERM_DENIED;\n  }\n\n  /* Get limits */\n  if (quotactl(QCMD(Q_GETQUOTA, USRQUOTA), mntdevice, pwd->pw_uid,\n               (void *)&ndqblk) == -1) {\n    pam_syslog(pamh, LOG_ERR, \"fail to get limits for user %s : %m\",\n               pwd->pw_name);\n    free(mntdevice);\n    return PAM_PERM_DENIED;\n  }\n\n  if (param.debug >= 1)\n    debug(pamh, &ndqblk, mntdevice, \"Quota read:\");\n\n  /* Only overwrite if quotas aren't already set or if overwrite is set */\n  if ((ndqblk.dqb_bsoftlimit == 0 && ndqblk.dqb_bhardlimit == 0 &&\n       ndqblk.dqb_isoftlimit == 0 && ndqblk.dqb_ihardlimit == 0) ||\n      param.overwrite == 1) {\n\n    /* Parse new limits\n     * Exit with an error should only the hard- or softlimit be\n     * configured but not both.\n     * This avoids errors, inconsistencies and possible race conditons\n     * during setquota.\n     */\n    ndqblk.dqb_valid = 0;\n    if (!parse_dqblk(pamh, argc, argv, &ndqblk)) {\n      pam_syslog(pamh, LOG_ERR,\n                 \"Both soft- and hardlimits for %s need to be configured \"\n                 \"at the same time!\", mntdevice);\n      free(mntdevice);\n      return PAM_PERM_DENIED;\n    }\n\n    /* Nothing changed? Are no limits defined at all in configuration? */\n    if (ndqblk.dqb_valid == 0) {\n      pam_syslog(pamh, LOG_AUTH | LOG_WARNING, \"no limits defined in \"\n                 \"configuration for user %s on %s\", pwd->pw_name, mntdevice);\n      free(mntdevice);\n      return PAM_IGNORE;\n    }\n\n    /* Set limits */\n    if (quotactl(QCMD(Q_SETQUOTA, USRQUOTA), mntdevice, pwd->pw_uid,\n                 (void *)&ndqblk) == -1) {\n      pam_syslog(pamh, LOG_ERR, \"failed to set limits for user %s on %s: %m\",\n                 pwd->pw_name, mntdevice);\n      free(mntdevice);\n      return PAM_PERM_DENIED;\n    }\n    if (param.debug >= 1)\n      debug(pamh, &ndqblk, mntdevice, \"Quota set:\");\n\n    /* End module */\n    free(mntdevice);\n    return PAM_SUCCESS;\n\n  } else {\n    /* Quota exists and overwrite!=1 */\n    if (param.debug >= 1) {\n      pam_syslog(pamh, LOG_DEBUG, \"Quota already exists for user %s \"\n                 \"on %s, not overwriting it without \\\"overwrite=1\\\"\",\n                 pwd->pw_name, mntdevice);\n    }\n    /* End module */\n    free(mntdevice);\n    return PAM_IGNORE;\n  }\n\n}",
        "commit_message": "pam_setquota: skip mountpoints equal to the user's $HOME\n\nMatthias Gerstner found the following issue:\n\n<quote>\nSo this pam_setquota module iterates over all mounted file systems using\n`setmntent()` and `getmntent()`.  It tries to find the longest match of\na file system mounted on /home/$USER or above (except when the\nfs=/some/path parameter is passed to the pam module).\n\nThe thing is that /home/$USER is owned by the unprivileged user.  And\nthere exist tools like fusermount from libfuse which is by default\ninstalled setuid-root for everybody.  fusermount allows to mount a FUSE\nfile system using an arbitrary \"source device name\" as the unprivileged\nuser.\n\nThus considering the following use case:\n\n1) there is only the root file system (/) or a file system is mounted on\n   /home, but not on /home/$USER.\n2) the attacker mounts a fake FUSE file system over its own home directory:\n\n  ```\n  user $ export _FUSE_COMMFD=0\n  user $ fusermount $HOME -ononempty,fsname=/dev/sda1\n  ```\n\n  This will result in a mount entry in /proc/mounts looking like this:\n\n  ```\n  /dev/sda1 on /home/$USER type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=100)\n  ```\n3) when the attacker now logs in with pam_setquota configured then\n   pam_setquota will identify /dev/sda1 and the file system where\n   to apply the user's quota on.\n\nAs a result an unprivileged user has full control over onto which block\ndevice the quota is applied.\n</quote>\n\nIf the user's $HOME is on a separate partition, setting a quota on the\nuser's $HOME does not really make sense, so this patch skips mountpoints\nequal to the user's $HOME, preventing the above mentioned bug as\na side-effect (or vice-versa).\n\nReported-by: Matthias Gerstner <mgerstner@suse.de>\nCo-authored-by: Tom\u00e1\u0161 Mr\u00e1z <tmraz@redhat.com>\nCo-authored-by: Dmitry V. Levin <ldv@altlinux.org>\nResolves: https://github.com/linux-pam/linux-pam/pull/230",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 325945,
        "reasoning": "This code snippet, `parse_dqblk`, is not directly vulnerable to the described issue. The vulnerability lies in how `pam_setquota` iterates through mounted filesystems and determines where to apply quotas, not within this function which merely parses arguments *after* a filesystem has already been selected. \n\n\n\n",
        "func": "parse_dqblk(pam_handle_t *pamh, int argc, const char **argv, struct if_dqblk *p) {\n  bool bhard = false, bsoft = false, ihard = false, isoft = false;\n\n  /* step through arguments */\n  for (; argc-- > 0; ++argv) {\n    const char *str;\n    if ((str = pam_str_skip_prefix(*argv, \"bhardlimit=\")) != NULL) {\n      p->dqb_bhardlimit = str_to_dqb_num(pamh, str, \"bhardlimit\");\n      p->dqb_valid |= QIF_BLIMITS;\n      bhard = true;\n    } else if ((str = pam_str_skip_prefix(*argv, \"bsoftlimit=\")) != NULL) {\n      p->dqb_bsoftlimit = str_to_dqb_num(pamh, str, \"bsoftlimit\");\n      p->dqb_valid |= QIF_BLIMITS;\n      bsoft = true;\n    } else if ((str = pam_str_skip_prefix(*argv, \"ihardlimit=\")) != NULL) {\n      p->dqb_ihardlimit = str_to_dqb_num(pamh, str, \"ihardlimit\");\n      p->dqb_valid |= QIF_ILIMITS;\n      ihard = true;\n    } else if ((str = pam_str_skip_prefix(*argv, \"isoftlimit=\")) != NULL) {\n      p->dqb_isoftlimit = str_to_dqb_num(pamh, str, \"isoftlimit\");\n      p->dqb_valid |= QIF_ILIMITS;\n      isoft = true;\n    } else if ((str = pam_str_skip_prefix(*argv, \"btime=\")) != NULL) {\n      p->dqb_btime = str_to_dqb_num(pamh, str, \"btime\");\n      p->dqb_valid |= QIF_BTIME;\n    } else if ((str = pam_str_skip_prefix(*argv, \"itime=\")) != NULL) {\n      p->dqb_itime = str_to_dqb_num(pamh, str, \"itime\");\n      p->dqb_valid |= QIF_ITIME;\n    }\n  }\n\n  /* return FALSE if a softlimit or hardlimit has been set\n   * independently of its counterpart.\n   */\n  return !(bhard ^ bsoft) && !(ihard ^ isoft);\n}",
        "commit_message": "pam_setquota: skip mountpoints equal to the user's $HOME\n\nMatthias Gerstner found the following issue:\n\n<quote>\nSo this pam_setquota module iterates over all mounted file systems using\n`setmntent()` and `getmntent()`.  It tries to find the longest match of\na file system mounted on /home/$USER or above (except when the\nfs=/some/path parameter is passed to the pam module).\n\nThe thing is that /home/$USER is owned by the unprivileged user.  And\nthere exist tools like fusermount from libfuse which is by default\ninstalled setuid-root for everybody.  fusermount allows to mount a FUSE\nfile system using an arbitrary \"source device name\" as the unprivileged\nuser.\n\nThus considering the following use case:\n\n1) there is only the root file system (/) or a file system is mounted on\n   /home, but not on /home/$USER.\n2) the attacker mounts a fake FUSE file system over its own home directory:\n\n  ```\n  user $ export _FUSE_COMMFD=0\n  user $ fusermount $HOME -ononempty,fsname=/dev/sda1\n  ```\n\n  This will result in a mount entry in /proc/mounts looking like this:\n\n  ```\n  /dev/sda1 on /home/$USER type fuse (rw,nosuid,nodev,relatime,user_id=1000,group_id=100)\n  ```\n3) when the attacker now logs in with pam_setquota configured then\n   pam_setquota will identify /dev/sda1 and the file system where\n   to apply the user's quota on.\n\nAs a result an unprivileged user has full control over onto which block\ndevice the quota is applied.\n</quote>\n\nIf the user's $HOME is on a separate partition, setting a quota on the\nuser's $HOME does not really make sense, so this patch skips mountpoints\nequal to the user's $HOME, preventing the above mentioned bug as\na side-effect (or vice-versa).\n\nReported-by: Matthias Gerstner <mgerstner@suse.de>\nCo-authored-by: Tom\u00e1\u0161 Mr\u00e1z <tmraz@redhat.com>\nCo-authored-by: Dmitry V. Levin <ldv@altlinux.org>\nResolves: https://github.com/linux-pam/linux-pam/pull/230",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 212156,
        "reasoning": "This code is vulnerable to a buffer overflow because the `tmp` buffer, intended to hold the expanded string, has a fixed size (`MAX_ENV`) and can be overflowed by excessively long environment variables or PAM items returned by `pam_getenv` or `_pam_get_item_byname`. Although the code attempts to detect overflows with `strlen` checks, these checks are insufficient to prevent a malicious user from crafting input that leads to excessive CPU consumption due to repeated logging and potential crashes, as described in CVE-2011-3149.",
        "func": "static int _expand_arg(pam_handle_t *pamh, char **value)\n{\n  const char *orig=*value, *tmpptr=NULL;\n  char *ptr;       /*\n\t\t    * Sure would be nice to use tmpptr but it needs to be\n\t\t    * a constant so that the compiler will shut up when I\n\t\t    * call pam_getenv and _pam_get_item_byname -- sigh\n\t\t    */\n\n  /* No unexpanded variable can be bigger than BUF_SIZE */\n  char type, tmpval[BUF_SIZE];\n\n  /* I know this shouldn't be hard-coded but it's so much easier this way */\n  char tmp[MAX_ENV];\n\n  D((\"Remember to initialize tmp!\"));\n  memset(tmp, 0, MAX_ENV);\n\n  /*\n   * (possibly non-existent) environment variables can be used as values\n   * by prepending a \"$\" and wrapping in {} (ie: ${HOST}), can escape with \"\\\"\n   * (possibly non-existent) PAM items can be used as values\n   * by prepending a \"@\" and wrapping in {} (ie: @{PAM_RHOST}, can escape\n   *\n   */\n  D((\"Expanding <%s>\",orig));\n  while (*orig) {     /* while there is some input to deal with */\n    if ('\\\\' == *orig) {\n      ++orig;\n      if ('$' != *orig && '@' != *orig) {\n\tD((\"Unrecognized escaped character: <%c> - ignoring\", *orig));\n\tpam_syslog(pamh, LOG_ERR,\n\t\t   \"Unrecognized escaped character: <%c> - ignoring\",\n\t\t   *orig);\n      } else if ((strlen(tmp) + 1) < MAX_ENV) {\n\ttmp[strlen(tmp)] = *orig++;        /* Note the increment */\n      } else {\n\t/* is it really a good idea to try to log this? */\n\tD((\"Variable buffer overflow: <%s> + <%s>\", tmp, tmpptr));\n\tpam_syslog (pamh, LOG_ERR, \"Variable buffer overflow: <%s> + <%s>\",\n\t\t tmp, tmpptr);\n      }\n      continue;\n    }\n    if ('$' == *orig || '@' == *orig) {\n      if ('{' != *(orig+1)) {\n\tD((\"Expandable variables must be wrapped in {}\"\n\t   \" <%s> - ignoring\", orig));\n\tpam_syslog(pamh, LOG_ERR, \"Expandable variables must be wrapped in {}\"\n\t\t \" <%s> - ignoring\", orig);\n\tif ((strlen(tmp) + 1) < MAX_ENV) {\n\t  tmp[strlen(tmp)] = *orig++;        /* Note the increment */\n\t}\n\tcontinue;\n      } else {\n\tD((\"Expandable argument: <%s>\", orig));\n\ttype = *orig;\n\torig+=2;     /* skip the ${ or @{ characters */\n\tptr = strchr(orig, '}');\n\tif (ptr) {\n\t  *ptr++ = '\\0';\n\t} else {\n\t  D((\"Unterminated expandable variable: <%s>\", orig-2));\n\t  pam_syslog(pamh, LOG_ERR,\n\t\t     \"Unterminated expandable variable: <%s>\", orig-2);\n\t  return PAM_ABORT;\n\t}\n\tstrncpy(tmpval, orig, sizeof(tmpval));\n\ttmpval[sizeof(tmpval)-1] = '\\0';\n\torig=ptr;\n\t/*\n\t * so, we know we need to expand tmpval, it is either\n\t * an environment variable or a PAM_ITEM. type will tell us which\n\t */\n\tswitch (type) {\n\n\tcase '$':\n\t  D((\"Expanding env var: <%s>\",tmpval));\n\t  tmpptr = pam_getenv(pamh, tmpval);\n\t  D((\"Expanded to <%s>\", tmpptr));\n\t  break;\n\n\tcase '@':\n\t  D((\"Expanding pam item: <%s>\",tmpval));\n\t  tmpptr = _pam_get_item_byname(pamh, tmpval);\n\t  D((\"Expanded to <%s>\", tmpptr));\n\t  break;\n\n\tdefault:\n\t  D((\"Impossible error, type == <%c>\", type));\n\t  pam_syslog(pamh, LOG_CRIT, \"Impossible error, type == <%c>\", type);\n\t  return PAM_ABORT;\n\t}         /* switch */\n\n\tif (tmpptr) {\n\t  if ((strlen(tmp) + strlen(tmpptr)) < MAX_ENV) {\n\t    strcat(tmp, tmpptr);\n\t  } else {\n\t    /* is it really a good idea to try to log this? */\n\t    D((\"Variable buffer overflow: <%s> + <%s>\", tmp, tmpptr));\n\t    pam_syslog (pamh, LOG_ERR,\n\t\t\t\"Variable buffer overflow: <%s> + <%s>\", tmp, tmpptr);\n\t  }\n\t}\n      }           /* if ('{' != *orig++) */\n    } else {      /* if ( '$' == *orig || '@' == *orig) */\n      if ((strlen(tmp) + 1) < MAX_ENV) {\n\ttmp[strlen(tmp)] = *orig++;        /* Note the increment */\n      } else {\n\t/* is it really a good idea to try to log this? */\n\tD((\"Variable buffer overflow: <%s> + <%s>\", tmp, tmpptr));\n\tpam_syslog(pamh, LOG_ERR,\n\t\t   \"Variable buffer overflow: <%s> + <%s>\", tmp, tmpptr);\n      }\n    }\n  }              /* for (;*orig;) */\n\n  if (strlen(tmp) > strlen(*value)) {\n    free(*value);\n    if ((*value = malloc(strlen(tmp) +1)) == NULL) {\n      D((\"Couldn't malloc %d bytes for expanded var\", strlen(tmp)+1));\n      pam_syslog (pamh, LOG_ERR, \"Couldn't malloc %lu bytes for expanded var\",\n\t       (unsigned long)strlen(tmp)+1);\n      return PAM_BUF_ERR;\n    }\n  }\n  strcpy(*value, tmp);\n  memset(tmp,'\\0',sizeof(tmp));\n  D((\"Exit.\"));\n\n  return PAM_SUCCESS;\n}",
        "commit_message": "pam_env: abort when encountering an overflowed environment variable expansion\n\n* modules/pam_env/pam_env.c (_expand_arg): Abort when encountering an\noverflowed environment variable expansion.\nFixes CVE-2011-3149.\nBug-Ubuntu: https://bugs.launchpad.net/ubuntu/+source/pam/+bug/874565",
        "cve_desc": "The _expand_arg function in the pam_env module (modules/pam_env/pam_env.c) in Linux-PAM (aka pam) before 1.1.5 does not properly handle when environment variable expansion can overflow, which allows local users to cause a denial of service (CPU consumption).",
        "target": 1
      }
    ]
  },
  "lua": {
    "0": [
      {
        "idx": 321509,
        "reasoning": "This code snippet is not directly related to the bug fix described in the commit message, which concerns the positioning of finalized objects within the garbage collection lists ('finobj' and 'allgc'). The `findlast` function simply finds the last element in a linked list, a common and safe operation that doesn't introduce vulnerabilities related to object finalization or garbage collection logic.\n\n\n\n",
        "func": "static GCObject **findlast (GCObject **p) {\n  while (*p != NULL)\n    p = &(*p)->next;\n  return p;\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 0
      },
      {
        "idx": 321510,
        "reasoning": "This code snippet focuses on garbage collection cycle management and doesn't directly handle user input or external data processing, thus lacking a clear attack surface for common vulnerabilities like injection or buffer overflows. The commit message describes a fix related to object finalization within the garbage collector itself, addressing internal state management rather than introducing exploitable behavior.\n\n\n\n",
        "func": "static void stepgenfull (lua_State *L, global_State *g) {\n  lu_mem newatomic;  /* count of traversed objects */\n  lu_mem lastatomic = g->lastatomic;  /* count from last collection */\n  if (g->gckind == KGC_GEN)  /* still in generational mode? */\n    enterinc(g);  /* enter incremental mode */\n  luaC_runtilstate(L, bitmask(GCSpropagate));  /* start new cycle */\n  newatomic = atomic(L);  /* mark everybody */\n  if (newatomic < lastatomic + (lastatomic >> 3)) {  /* good collection? */\n    atomic2gen(L, g);  /* return to generational mode */\n    setminordebt(g);\n  }\n  else {  /* another bad collection; stay in incremental mode */\n    g->GCestimate = gettotalbytes(g);  /* first estimate */;\n    entersweep(L);\n    luaC_runtilstate(L, bitmask(GCSpause));  /* finish collection */\n    setpause(g);\n    g->lastatomic = newatomic;\n  }\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 0
      },
      {
        "idx": 321511,
        "reasoning": "This code snippet focuses on clearing entries within tables during garbage collection and doesn't directly handle object finalization or memory management in a way that introduces vulnerabilities like use-after-free or double-free. The commit message describes a fix related to the order of objects in GC lists, which is separate from the table clearing logic implemented in this function; therefore, this code is not flagged as vulnerable based on the provided context.\n\n\n\n",
        "func": "static void clearbykeys (global_State *g, GCObject *l) {\n  for (; l; l = gco2t(l)->gclist) {\n    Table *h = gco2t(l);\n    Node *limit = gnodelast(h);\n    Node *n;\n    for (n = gnode(h, 0); n < limit; n++) {\n      if (iscleared(g, gckeyN(n)))  /* unmarked key? */\n        setempty(gval(n));  /* remove entry */\n      if (isempty(gval(n)))  /* is entry empty? */\n        clearkey(n);  /* clear its key */\n    }\n  }\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 0
      },
      {
        "idx": 321512,
        "reasoning": "This code snippet is not flagged as vulnerable because it focuses on managing graylists\u2014lists of objects potentially involved in garbage collection\u2014and doesn't directly handle object creation, destruction, or external input that could lead to memory corruption or control flow hijacking. The commit message addresses a garbage collection issue related to finalized objects, but the provided code only concerns itself with re-linking lists of already existing objects, not introducing new vulnerabilities.\n\n\n\n",
        "func": "static void correctgraylists (global_State *g) {\n  GCObject **list = correctgraylist(&g->grayagain);\n  *list = g->weak; g->weak = NULL;\n  list = correctgraylist(list);\n  *list = g->allweak; g->allweak = NULL;\n  list = correctgraylist(list);\n  *list = g->ephemeron; g->ephemeron = NULL;\n  correctgraylist(list);\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 0
      },
      {
        "idx": 321513,
        "reasoning": "This code snippet focuses on resetting garbage collection states and initiating marking of root objects\u2014it doesn't directly handle object finalization or manipulation of the 'finobj'/'allgc' lists mentioned in the commit message. Therefore, based solely on this code, there's no apparent vulnerability related to the described bug fix; the snippet appears to be preparatory work *before* finalization would occur, not part of the problematic logic itself.\n\n\n\n",
        "func": "static void restartcollection (global_State *g) {\n  g->gray = g->grayagain = NULL;\n  g->weak = g->allweak = g->ephemeron = NULL;\n  markobject(g, g->mainthread);\n  markvalue(g, &g->l_registry);\n  markmt(g);\n  markbeingfnz(g);  /* mark any finalizing object left from previous cycle */\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 201787,
        "reasoning": "The vulnerability lies in how `markold` is called on the `finobj` list; the commit message itself acknowledges that finalized objects are moved to the *beginning* of `allgc`, but `markold` isn't iterating through the entire `allgc` list, leading to potentially unvisited and unmarked objects. This insufficient marking during garbage collection, as described in the CVE, can result in a heap-based buffer over-read when attempting to access object names via `getobjname` on these unmarked objects.",
        "func": "static void youngcollection (lua_State *L, global_State *g) {\n  GCObject **psurvival;  /* to point to first non-dead survival object */\n  lua_assert(g->gcstate == GCSpropagate);\n  markold(g, g->survival, g->reallyold);\n  markold(g, g->finobj, g->finobjrold);\n  atomic(L);\n\n  /* sweep nursery and get a pointer to its last live element */\n  psurvival = sweepgen(L, g, &g->allgc, g->survival);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->reallyold);\n  g->reallyold = g->old;\n  g->old = *psurvival;  /* 'survival' survivals are old now */\n  g->survival = g->allgc;  /* all news are survivals */\n\n  /* repeat for 'finobj' lists */\n  psurvival = sweepgen(L, g, &g->finobj, g->finobjsur);\n  /* sweep 'survival' and 'old' */\n  sweepgen(L, g, psurvival, g->finobjrold);\n  g->finobjrold = g->finobjold;\n  g->finobjold = *psurvival;  /* 'survival' survivals are old now */\n  g->finobjsur = g->finobj;  /* all news are survivals */\n\n  sweepgen(L, g, &g->tobefnz, NULL);\n\n  finishgencycle(L, g);\n}",
        "commit_message": "Fixed bug of old finalized objects in the GC\n\nWhen an object aged OLD1 is finalized, it is moved from the list\n'finobj' to the *beginning* of the list 'allgc'. So, this part of the\nlist (and not only the survival list) must be visited by 'markold'.",
        "cve_desc": "Lua 5.4.0 has a getobjname heap-based buffer over-read because youngcollection in lgc.c uses markold for an insufficient number of list members.",
        "target": 1
      },
      {
        "idx": 210106,
        "reasoning": "The vulnerability lies in the calculation of `goodsize` and its comparison to `L->stacksize` \u2013 if `inuse` is small, `goodsize` can be significantly smaller than the current `stacksize`, potentially leading to a re-allocation to a much smaller stack. This smaller stack, combined with subsequent stack operations, can then cause a heap-based buffer overflow, over-read, or use-after-free as described in the CVE, because the code doesn't fully account for all stack usage when determining the new stack size.",
        "func": "void luaD_shrinkstack (lua_State *L) {\n  int inuse = stackinuse(L);\n  int goodsize = inuse + (inuse / 8) + 2*EXTRA_STACK;\n  if (goodsize > LUAI_MAXSTACK)\n    goodsize = LUAI_MAXSTACK;  /* respect stack limit */\n  /* if thread is currently not handling a stack overflow and its\n     good size is smaller than current size, shrink its stack */\n  if (inuse <= (LUAI_MAXSTACK - EXTRA_STACK) &&\n      goodsize < L->stacksize)\n    luaD_reallocstack(L, goodsize, 0);  /* ok if that fails */\n  else  /* don't change stack */\n    condmovestack(L,{},{});  /* (change only for debugging) */\n  luaE_shrinkCI(L);  /* shrink CI list */\n}",
        "commit_message": "Keep minimum size when shrinking a stack\n\nWhen shrinking a stack (during GC), do not make it smaller than the\ninitial stack size.",
        "cve_desc": "Lua through 5.4.0 mishandles the interaction between stack resizes and garbage collection, leading to a heap-based buffer overflow, heap-based buffer over-read, or use-after-free.",
        "target": 1
      }
    ]
  },
  "mariadb-connector-c": {
    "0": [],
    "1": []
  },
  "mbed-coap": {
    "0": [],
    "1": []
  },
  "minetest": {
    "0": [
      {
        "idx": 296227,
        "reasoning": "This code snippet focuses on handling initial client connections and validating data like player names and protocol versions, and it does not appear to contain any immediately obvious vulnerabilities related to accessing other players' inventories as the commit message suggests it addresses. The code implements several checks and sanitizations, such as validating player name length and allowed characters, and verifying protocol versions, which mitigate common attack vectors.",
        "func": "void Server::handleCommand_Init(NetworkPacket* pkt)\n{\n\n\tif(pkt->getSize() < 1)\n\t\treturn;\n\n\tsession_t peer_id = pkt->getPeerId();\n\tRemoteClient *client = getClient(peer_id, CS_Created);\n\n\tstd::string addr_s;\n\ttry {\n\t\tAddress address = getPeerAddress(peer_id);\n\t\taddr_s = address.serializeString();\n\t}\n\tcatch (con::PeerNotFoundException &e) {\n\t\t/*\n\t\t * no peer for this packet found\n\t\t * most common reason is peer timeout, e.g. peer didn't\n\t\t * respond for some time, your server was overloaded or\n\t\t * things like that.\n\t\t */\n\t\tinfostream << \"Server::ProcessData(): Canceling: peer \" << peer_id <<\n\t\t\t\" not found\" << std::endl;\n\t\treturn;\n\t}\n\n\t// If net_proto_version is set, this client has already been handled\n\tif (client->getState() > CS_Created) {\n\t\tverbosestream << \"Server: Ignoring multiple TOSERVER_INITs from \" <<\n\t\t\taddr_s << \" (peer_id=\" << peer_id << \")\" << std::endl;\n\t\treturn;\n\t}\n\n\tverbosestream << \"Server: Got TOSERVER_INIT from \" << addr_s <<\n\t\t\" (peer_id=\" << peer_id << \")\" << std::endl;\n\n\t// Do not allow multiple players in simple singleplayer mode.\n\t// This isn't a perfect way to do it, but will suffice for now\n\tif (m_simple_singleplayer_mode && m_clients.getClientIDs().size() > 1) {\n\t\tinfostream << \"Server: Not allowing another client (\" << addr_s <<\n\t\t\t\") to connect in simple singleplayer mode\" << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_SINGLEPLAYER);\n\t\treturn;\n\t}\n\n\t// First byte after command is maximum supported\n\t// serialization version\n\tu8 client_max;\n\tu16 supp_compr_modes;\n\tu16 min_net_proto_version = 0;\n\tu16 max_net_proto_version;\n\tstd::string playerName;\n\n\t*pkt >> client_max >> supp_compr_modes >> min_net_proto_version\n\t\t\t>> max_net_proto_version >> playerName;\n\n\tu8 our_max = SER_FMT_VER_HIGHEST_READ;\n\t// Use the highest version supported by both\n\tu8 depl_serial_v = std::min(client_max, our_max);\n\t// If it's lower than the lowest supported, give up.\n\tif (depl_serial_v < SER_FMT_VER_LOWEST_READ)\n\t\tdepl_serial_v = SER_FMT_VER_INVALID;\n\n\tif (depl_serial_v == SER_FMT_VER_INVALID) {\n\t\tactionstream << \"Server: A mismatched client tried to connect from \" <<\n\t\t\taddr_s << \" ser_fmt_max=\" << (int)client_max << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_WRONG_VERSION);\n\t\treturn;\n\t}\n\n\tclient->setPendingSerializationVersion(depl_serial_v);\n\n\t/*\n\t\tRead and check network protocol version\n\t*/\n\n\tu16 net_proto_version = 0;\n\n\t// Figure out a working version if it is possible at all\n\tif (max_net_proto_version >= SERVER_PROTOCOL_VERSION_MIN ||\n\t\t\tmin_net_proto_version <= SERVER_PROTOCOL_VERSION_MAX) {\n\t\t// If maximum is larger than our maximum, go with our maximum\n\t\tif (max_net_proto_version > SERVER_PROTOCOL_VERSION_MAX)\n\t\t\tnet_proto_version = SERVER_PROTOCOL_VERSION_MAX;\n\t\t// Else go with client's maximum\n\t\telse\n\t\t\tnet_proto_version = max_net_proto_version;\n\t}\n\n\tverbosestream << \"Server: \" << addr_s << \": Protocol version: min: \"\n\t\t\t<< min_net_proto_version << \", max: \" << max_net_proto_version\n\t\t\t<< \", chosen: \" << net_proto_version << std::endl;\n\n\tclient->net_proto_version = net_proto_version;\n\n\tif ((g_settings->getBool(\"strict_protocol_version_checking\") &&\n\t\t\tnet_proto_version != LATEST_PROTOCOL_VERSION) ||\n\t\t\tnet_proto_version < SERVER_PROTOCOL_VERSION_MIN ||\n\t\t\tnet_proto_version > SERVER_PROTOCOL_VERSION_MAX) {\n\t\tactionstream << \"Server: A mismatched client tried to connect from \" <<\n\t\t\taddr_s << \" proto_max=\" << (int)max_net_proto_version << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_WRONG_VERSION);\n\t\treturn;\n\t}\n\n\t/*\n\t\tValidate player name\n\t*/\n\tconst char* playername = playerName.c_str();\n\n\tsize_t pns = playerName.size();\n\tif (pns == 0 || pns > PLAYERNAME_SIZE) {\n\t\tactionstream << \"Server: Player with \" <<\n\t\t\t((pns > PLAYERNAME_SIZE) ? \"a too long\" : \"an empty\") <<\n\t\t\t\" name tried to connect from \" << addr_s << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_WRONG_NAME);\n\t\treturn;\n\t}\n\n\tif (!string_allowed(playerName, PLAYERNAME_ALLOWED_CHARS)) {\n\t\tactionstream << \"Server: Player with an invalid name tried to connect \"\n\t\t\t\"from \" << addr_s << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_WRONG_CHARS_IN_NAME);\n\t\treturn;\n\t}\n\n\tm_clients.setPlayerName(peer_id, playername);\n\t//TODO (later) case insensitivity\n\n\tstd::string legacyPlayerNameCasing = playerName;\n\n\tif (!isSingleplayer() && strcasecmp(playername, \"singleplayer\") == 0) {\n\t\tactionstream << \"Server: Player with the name \\\"singleplayer\\\" tried \"\n\t\t\t\"to connect from \" << addr_s << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_WRONG_NAME);\n\t\treturn;\n\t}\n\n\t{\n\t\tstd::string reason;\n\t\tif (m_script->on_prejoinplayer(playername, addr_s, &reason)) {\n\t\t\tactionstream << \"Server: Player with the name \\\"\" << playerName <<\n\t\t\t\t\"\\\" tried to connect from \" << addr_s <<\n\t\t\t\t\" but it was disallowed for the following reason: \" << reason <<\n\t\t\t\tstd::endl;\n\t\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_CUSTOM_STRING, reason);\n\t\t\treturn;\n\t\t}\n\t}\n\n\tinfostream << \"Server: New connection: \\\"\" << playerName << \"\\\" from \" <<\n\t\taddr_s << \" (peer_id=\" << peer_id << \")\" << std::endl;\n\n\t// Enforce user limit.\n\t// Don't enforce for users that have some admin right or mod permits it.\n\tif (m_clients.isUserLimitReached() &&\n\t\t\tplayername != g_settings->get(\"name\") &&\n\t\t\t!m_script->can_bypass_userlimit(playername, addr_s)) {\n\t\tactionstream << \"Server: \" << playername << \" tried to join from \" <<\n\t\t\taddr_s << \", but there are already max_users=\" <<\n\t\t\tg_settings->getU16(\"max_users\") << \" players.\" << std::endl;\n\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_TOO_MANY_USERS);\n\t\treturn;\n\t}\n\n\t/*\n\t\tCompose auth methods for answer\n\t*/\n\tstd::string encpwd; // encrypted Password field for the user\n\tbool has_auth = m_script->getAuth(playername, &encpwd, NULL);\n\tu32 auth_mechs = 0;\n\n\tclient->chosen_mech = AUTH_MECHANISM_NONE;\n\n\tif (has_auth) {\n\t\tstd::vector<std::string> pwd_components = str_split(encpwd, '#');\n\t\tif (pwd_components.size() == 4) {\n\t\t\tif (pwd_components[1] == \"1\") { // 1 means srp\n\t\t\t\tauth_mechs |= AUTH_MECHANISM_SRP;\n\t\t\t\tclient->enc_pwd = encpwd;\n\t\t\t} else {\n\t\t\t\tactionstream << \"User \" << playername << \" tried to log in, \"\n\t\t\t\t\t\"but password field was invalid (unknown mechcode).\" <<\n\t\t\t\t\tstd::endl;\n\t\t\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_SERVER_FAIL);\n\t\t\t\treturn;\n\t\t\t}\n\t\t} else if (base64_is_valid(encpwd)) {\n\t\t\tauth_mechs |= AUTH_MECHANISM_LEGACY_PASSWORD;\n\t\t\tclient->enc_pwd = encpwd;\n\t\t} else {\n\t\t\tactionstream << \"User \" << playername << \" tried to log in, but \"\n\t\t\t\t\"password field was invalid (invalid base64).\" << std::endl;\n\t\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_SERVER_FAIL);\n\t\t\treturn;\n\t\t}\n\t} else {\n\t\tstd::string default_password = g_settings->get(\"default_password\");\n\t\tif (default_password.length() == 0) {\n\t\t\tauth_mechs |= AUTH_MECHANISM_FIRST_SRP;\n\t\t} else {\n\t\t\t// Take care of default passwords.\n\t\t\tclient->enc_pwd = get_encoded_srp_verifier(playerName, default_password);\n\t\t\tauth_mechs |= AUTH_MECHANISM_SRP;\n\t\t\t// Allocate player in db, but only on successful login.\n\t\t\tclient->create_player_on_auth_success = true;\n\t\t}\n\t}\n\n\t/*\n\t\tAnswer with a TOCLIENT_HELLO\n\t*/\n\n\tverbosestream << \"Sending TOCLIENT_HELLO with auth method field: \"\n\t\t<< auth_mechs << std::endl;\n\n\tNetworkPacket resp_pkt(TOCLIENT_HELLO,\n\t\t1 + 4 + legacyPlayerNameCasing.size(), peer_id);\n\n\tu16 depl_compress_mode = NETPROTO_COMPRESSION_NONE;\n\tresp_pkt << depl_serial_v << depl_compress_mode << net_proto_version\n\t\t<< auth_mechs << legacyPlayerNameCasing;\n\n\tSend(&resp_pkt);\n\n\tclient->allowed_auth_mechs = auth_mechs;\n\tclient->setDeployedCompressionMode(depl_compress_mode);\n\n\tm_clients.event(peer_id, CSE_Hello);\n}",
        "commit_message": "Prevent players accessing inventories of other players (#10341)",
        "cve_desc": "In Minetest before 5.4.0, players can add or subtract items from a different player's inventory.",
        "target": 0
      },
      {
        "idx": 296228,
        "reasoning": "This code snippet appears safe as it handles a player leaving a mod channel and doesn't directly deal with inventory access or player data manipulation. The function focuses on managing channel membership based on player ID and a channel name, with no apparent logic that could lead to unauthorized data access\u2014addressing the stated goal of preventing access to other players' inventories.\n\n\n\n",
        "func": "void Server::handleCommand_ModChannelLeave(NetworkPacket *pkt)\n{\n\tstd::string channel_name;\n\t*pkt >> channel_name;\n\n\tsession_t peer_id = pkt->getPeerId();\n\tNetworkPacket resp_pkt(TOCLIENT_MODCHANNEL_SIGNAL,\n\t\t1 + 2 + channel_name.size(), peer_id);\n\n\t// Send signal to client to notify join succeed or not\n\tif (g_settings->getBool(\"enable_mod_channels\") &&\n\t\t\tm_modchannel_mgr->leaveChannel(channel_name, peer_id)) {\n\t\tresp_pkt << (u8)MODCHANNEL_SIGNAL_LEAVE_OK;\n\t\tinfostream << \"Peer \" << peer_id << \" left channel \" << channel_name <<\n\t\t\tstd::endl;\n\t} else {\n\t\tresp_pkt << (u8) MODCHANNEL_SIGNAL_LEAVE_FAILURE;\n\t\tinfostream << \"Peer \" << peer_id << \" left channel \" << channel_name <<\n\t\t\t\", but was not registered.\" << std::endl;\n\t}\n\tresp_pkt << channel_name;\n\tSend(&resp_pkt);\n}",
        "commit_message": "Prevent players accessing inventories of other players (#10341)",
        "cve_desc": "In Minetest before 5.4.0, players can add or subtract items from a different player's inventory.",
        "target": 0
      },
      {
        "idx": 296229,
        "reasoning": "This code snippet handles damage received by players and doesn't appear to directly relate to inventory access, the issue the commit message aims to resolve. Therefore, based solely on the provided code, there's no immediately obvious vulnerability regarding unauthorized inventory access, and it's not flagged as vulnerable in this context.\n\n\n\n",
        "func": "void Server::handleCommand_Damage(NetworkPacket* pkt)\n{\n\tu16 damage;\n\n\t*pkt >> damage;\n\n\tsession_t peer_id = pkt->getPeerId();\n\tRemotePlayer *player = m_env->getPlayer(peer_id);\n\n\tif (player == NULL) {\n\t\terrorstream <<\n\t\t\t\"Server::ProcessData(): Canceling: No player for peer_id=\" <<\n\t\t\tpeer_id << \" disconnecting peer!\" << std::endl;\n\t\tDisconnectPeer(peer_id);\n\t\treturn;\n\t}\n\n\tPlayerSAO *playersao = player->getPlayerSAO();\n\tif (playersao == NULL) {\n\t\terrorstream <<\n\t\t\t\"Server::ProcessData(): Canceling: No player object for peer_id=\" <<\n\t\t\tpeer_id << \" disconnecting peer!\" << std::endl;\n\t\tDisconnectPeer(peer_id);\n\t\treturn;\n\t}\n\n\tif (!playersao->isImmortal()) {\n\t\tif (playersao->isDead()) {\n\t\t\tverbosestream << \"Server::ProcessData(): Info: \"\n\t\t\t\t\"Ignoring damage as player \" << player->getName()\n\t\t\t\t<< \" is already dead.\" << std::endl;\n\t\t\treturn;\n\t\t}\n\n\t\tactionstream << player->getName() << \" damaged by \"\n\t\t\t\t<< (int)damage << \" hp at \" << PP(playersao->getBasePosition() / BS)\n\t\t\t\t<< std::endl;\n\n\t\tPlayerHPChangeReason reason(PlayerHPChangeReason::FALL);\n\t\tplayersao->setHP((s32)playersao->getHP() - (s32)damage, reason);\n\t\tSendPlayerHPOrDie(playersao, reason);\n\t}\n}",
        "commit_message": "Prevent players accessing inventories of other players (#10341)",
        "cve_desc": "In Minetest before 5.4.0, players can add or subtract items from a different player's inventory.",
        "target": 0
      },
      {
        "idx": 296230,
        "reasoning": "This code appears safe as it focuses on securely handling the first stage of the SRP (Secure Remote Password) authentication protocol, specifically managing password setting and verification. The checks for allowed mechanisms, empty passwords, and client state prevent unauthorized access and ensure proper authentication flow, mitigating common vulnerabilities like brute-force attacks or unauthorized state transitions.\n\n\n\n",
        "func": "void Server::handleCommand_FirstSrp(NetworkPacket* pkt)\n{\n\tsession_t peer_id = pkt->getPeerId();\n\tRemoteClient *client = getClient(peer_id, CS_Invalid);\n\tClientState cstate = client->getState();\n\n\tstd::string playername = client->getName();\n\n\tstd::string salt;\n\tstd::string verification_key;\n\n\tstd::string addr_s = getPeerAddress(peer_id).serializeString();\n\tu8 is_empty;\n\n\t*pkt >> salt >> verification_key >> is_empty;\n\n\tverbosestream << \"Server: Got TOSERVER_FIRST_SRP from \" << addr_s\n\t\t<< \", with is_empty=\" << (is_empty == 1) << std::endl;\n\n\t// Either this packet is sent because the user is new or to change the password\n\tif (cstate == CS_HelloSent) {\n\t\tif (!client->isMechAllowed(AUTH_MECHANISM_FIRST_SRP)) {\n\t\t\tactionstream << \"Server: Client from \" << addr_s\n\t\t\t\t\t<< \" tried to set password without being \"\n\t\t\t\t\t<< \"authenticated, or the username being new.\" << std::endl;\n\t\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_UNEXPECTED_DATA);\n\t\t\treturn;\n\t\t}\n\n\t\tif (!isSingleplayer() &&\n\t\t\t\tg_settings->getBool(\"disallow_empty_password\") &&\n\t\t\t\tis_empty == 1) {\n\t\t\tactionstream << \"Server: \" << playername\n\t\t\t\t\t<< \" supplied empty password from \" << addr_s << std::endl;\n\t\t\tDenyAccess(peer_id, SERVER_ACCESSDENIED_EMPTY_PASSWORD);\n\t\t\treturn;\n\t\t}\n\n\t\tstd::string initial_ver_key;\n\n\t\tinitial_ver_key = encode_srp_verifier(verification_key, salt);\n\t\tm_script->createAuth(playername, initial_ver_key);\n\t\tm_script->on_authplayer(playername, addr_s, true);\n\n\t\tacceptAuth(peer_id, false);\n\t} else {\n\t\tif (cstate < CS_SudoMode) {\n\t\t\tinfostream << \"Server::ProcessData(): Ignoring TOSERVER_FIRST_SRP from \"\n\t\t\t\t\t<< addr_s << \": \" << \"Client has wrong state \" << cstate << \".\"\n\t\t\t\t\t<< std::endl;\n\t\t\treturn;\n\t\t}\n\t\tm_clients.event(peer_id, CSE_SudoLeave);\n\t\tstd::string pw_db_field = encode_srp_verifier(verification_key, salt);\n\t\tbool success = m_script->setPassword(playername, pw_db_field);\n\t\tif (success) {\n\t\t\tactionstream << playername << \" changes password\" << std::endl;\n\t\t\tSendChatMessage(peer_id, ChatMessage(CHATMESSAGE_TYPE_SYSTEM,\n\t\t\t\tL\"Password change successful.\"));\n\t\t} else {\n\t\t\tactionstream << playername <<\n\t\t\t\t\" tries to change password but it fails\" << std::endl;\n\t\t\tSendChatMessage(peer_id, ChatMessage(CHATMESSAGE_TYPE_SYSTEM,\n\t\t\t\tL\"Password change failed or unavailable.\"));\n\t\t}\n\t}\n}",
        "commit_message": "Prevent players accessing inventories of other players (#10341)",
        "cve_desc": "In Minetest before 5.4.0, players can add or subtract items from a different player's inventory.",
        "target": 0
      }
    ],
    "1": []
  },
  "mod_auth_openidc": {
    "0": [
      {
        "idx": 410158,
        "reasoning": "This code appears safe as it implements multiple layers of validation for the `target_link_uri` parameter, including checking against configured settings (`oidc_target_link_uri_matches_configuration`) and validating the URL itself (`oidc_validate_redirect_url`) to prevent open redirect vulnerabilities. The commit message also indicates a fix related to allowing the `OIDCRedirectURLsAllowed` setting to apply to `target_link_uri`, suggesting proactive security measures were taken.\n\n\n\n",
        "func": "static int oidc_handle_discovery_response(request_rec *r, oidc_cfg *c) {\n\n\t/* variables to hold the values returned in the response */\n\tchar *issuer = NULL, *target_link_uri = NULL, *login_hint = NULL,\n\t\t\t*auth_request_params = NULL, *csrf_cookie, *csrf_query = NULL,\n\t\t\t*user = NULL, *path_scopes;\n\toidc_provider_t *provider = NULL;\n\tchar *error_str = NULL;\n\tchar *error_description = NULL;\n\n\toidc_util_get_request_parameter(r, OIDC_DISC_OP_PARAM, &issuer);\n\toidc_util_get_request_parameter(r, OIDC_DISC_USER_PARAM, &user);\n\toidc_util_get_request_parameter(r, OIDC_DISC_RT_PARAM, &target_link_uri);\n\toidc_util_get_request_parameter(r, OIDC_DISC_LH_PARAM, &login_hint);\n\toidc_util_get_request_parameter(r, OIDC_DISC_SC_PARAM, &path_scopes);\n\toidc_util_get_request_parameter(r, OIDC_DISC_AR_PARAM,\n\t\t\t&auth_request_params);\n\toidc_util_get_request_parameter(r, OIDC_CSRF_NAME, &csrf_query);\n\tcsrf_cookie = oidc_util_get_cookie(r, OIDC_CSRF_NAME);\n\n\t/* do CSRF protection if not 3rd party initiated SSO */\n\tif (csrf_cookie) {\n\n\t\t/* clean CSRF cookie */\n\t\toidc_util_set_cookie(r, OIDC_CSRF_NAME, \"\", 0,\n\t\t\t\tOIDC_COOKIE_EXT_SAME_SITE_NONE(r));\n\n\t\t/* compare CSRF cookie value with query parameter value */\n\t\tif ((csrf_query == NULL)\n\t\t\t\t|| apr_strnatcmp(csrf_query, csrf_cookie) != 0) {\n\t\t\toidc_warn(r,\n\t\t\t\t\t\"CSRF protection failed, no Discovery and dynamic client registration will be allowed\");\n\t\t\tcsrf_cookie = NULL;\n\t\t}\n\t}\n\n\t// TODO: trim issuer/accountname/domain input and do more input validation\n\n\toidc_debug(r,\n\t\t\t\"issuer=\\\"%s\\\", target_link_uri=\\\"%s\\\", login_hint=\\\"%s\\\", user=\\\"%s\\\"\",\n\t\t\tissuer, target_link_uri, login_hint, user);\n\n\tif (target_link_uri == NULL) {\n\t\tif (c->default_sso_url == NULL) {\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"SSO to this module without specifying a \\\"target_link_uri\\\" parameter is not possible because \" OIDCDefaultURL \" is not set.\",\n\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t}\n\t\ttarget_link_uri = c->default_sso_url;\n\t}\n\n\t/* do open redirect prevention, step 1 */\n\tif (oidc_target_link_uri_matches_configuration(r, c, target_link_uri)\n\t\t\t== FALSE) {\n\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\"Invalid Request\",\n\t\t\t\t\"\\\"target_link_uri\\\" parameter does not match configuration settings, aborting to prevent an open redirect.\",\n\t\t\t\tHTTP_UNAUTHORIZED);\n\t}\n\n\t/* do input validation on the target_link_uri parameter value, step 2 */\n\tif (oidc_validate_redirect_url(r, c, target_link_uri, TRUE, &error_str,\n\t\t\t&error_description) == FALSE) {\n\t\treturn oidc_util_html_send_error(r, c->error_template, error_str,\n\t\t\t\terror_description,\n\t\t\t\tHTTP_UNAUTHORIZED);\n\t}\n\n\t/* see if this is a static setup */\n\tif (c->metadata_dir == NULL) {\n\t\tif ((oidc_provider_static_config(r, c, &provider) == TRUE)\n\t\t\t\t&& (issuer != NULL)) {\n\t\t\tif (apr_strnatcmp(provider->issuer, issuer) != 0) {\n\t\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\tapr_psprintf(r->pool,\n\t\t\t\t\t\t\t\t\"The \\\"iss\\\" value must match the configured providers' one (%s != %s).\",\n\t\t\t\t\t\t\t\tissuer, c->provider.issuer),\n\t\t\t\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t\t}\n\t\t}\n\t\treturn oidc_authenticate_user(r, c, NULL, target_link_uri, login_hint,\n\t\t\t\tNULL, NULL, auth_request_params, path_scopes);\n\t}\n\n\t/* find out if the user entered an account name or selected an OP manually */\n\tif (user != NULL) {\n\n\t\tif (login_hint == NULL)\n\t\t\tlogin_hint = apr_pstrdup(r->pool, user);\n\n\t\t/* normalize the user identifier */\n\t\tif (strstr(user, \"https://\") != user)\n\t\t\tuser = apr_psprintf(r->pool, \"https://%s\", user);\n\n\t\t/* got an user identifier as input, perform OP discovery with that */\n\t\tif (oidc_proto_url_based_discovery(r, c, user, &issuer) == FALSE) {\n\n\t\t\t/* something did not work out, show a user facing error */\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"Could not resolve the provided user identifier to an OpenID Connect provider; check your syntax.\",\n\t\t\t\t\tHTTP_NOT_FOUND);\n\t\t}\n\n\t\t/* issuer is set now, so let's continue as planned */\n\n\t} else if (strstr(issuer, OIDC_STR_AT) != NULL) {\n\n\t\tif (login_hint == NULL) {\n\t\t\tlogin_hint = apr_pstrdup(r->pool, issuer);\n\t\t\t//char *p = strstr(issuer, OIDC_STR_AT);\n\t\t\t//*p = '\\0';\n\t\t}\n\n\t\t/* got an account name as input, perform OP discovery with that */\n\t\tif (oidc_proto_account_based_discovery(r, c, issuer, &issuer)\n\t\t\t\t== FALSE) {\n\n\t\t\t/* something did not work out, show a user facing error */\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"Could not resolve the provided account name to an OpenID Connect provider; check your syntax.\",\n\t\t\t\t\tHTTP_NOT_FOUND);\n\t\t}\n\n\t\t/* issuer is set now, so let's continue as planned */\n\n\t}\n\n\t/* strip trailing '/' */\n\tint n = strlen(issuer);\n\tif (issuer[n - 1] == OIDC_CHAR_FORWARD_SLASH)\n\t\tissuer[n - 1] = '\\0';\n\n\t/* try and get metadata from the metadata directories for the selected OP */\n\tif ((oidc_metadata_get(r, c, issuer, &provider, csrf_cookie != NULL) == TRUE)\n\t\t\t&& (provider != NULL)) {\n\n\t\t/* now we've got a selected OP, send the user there to authenticate */\n\t\treturn oidc_authenticate_user(r, c, provider, target_link_uri,\n\t\t\t\tlogin_hint, NULL, NULL, auth_request_params, path_scopes);\n\t}\n\n\t/* something went wrong */\n\treturn oidc_util_html_send_error(r, c->error_template, \"Invalid Request\",\n\t\t\t\"Could not find valid provider metadata for the selected OpenID Connect provider; contact the administrator\",\n\t\t\tHTTP_NOT_FOUND);\n}",
        "commit_message": "apply OIDCRedirectURLsAllowed setting to target_link_uri\n\ncloses #672; thanks @Meheni\nrelease 2.4.9.4\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "mod_auth_openidc is an authentication/authorization module for the Apache 2.x HTTP server that functions as an OpenID Connect Relying Party, authenticating users against an OpenID Connect Provider. In versions prior to 2.4.9.4, the 3rd-party init SSO functionality of mod_auth_openidc was reported to be vulnerable to an open redirect attack by supplying a crafted URL in the `target_link_uri` parameter. A patch in version 2.4.9.4 made it so that the `OIDCRedirectURLsAllowed` setting must be applied to the `target_link_uri` parameter. There are no known workarounds aside from upgrading to a patched version.",
        "target": 0
      },
      {
        "idx": 410159,
        "reasoning": "This code is not directly vulnerable based on the snippet provided. The commit message indicates the application of a configuration setting (`OIDCRedirectURLsAllowed`) to `target_link_uri`, and the code focuses on validating redirect URIs and cookie settings to prevent potential security issues like session fixation or cross-site scripting \u2013 it doesn\u2019t introduce new vulnerabilities itself.",
        "func": "static int oidc_authenticate_user(request_rec *r, oidc_cfg *c,\n\t\toidc_provider_t *provider, const char *original_url,\n\t\tconst char *login_hint, const char *id_token_hint, const char *prompt,\n\t\tconst char *auth_request_params, const char *path_scope) {\n\n\toidc_debug(r, \"enter\");\n\n\tif (provider == NULL) {\n\n\t\t// TODO: should we use an explicit redirect to the discovery endpoint (maybe a \"discovery\" param to the redirect_uri)?\n\t\tif (c->metadata_dir != NULL) {\n\t\t\t/*\n\t\t\t * Will be handled in the content handler; avoid:\n\t\t\t * No authentication done but request not allowed without authentication\n\t\t\t * by setting r->user\n\t\t\t */\n\t\t\toidc_debug(r, \"defer discovery to the content handler\");\n\t\t\toidc_request_state_set(r, OIDC_REQUEST_STATE_KEY_DISCOVERY, \"\");\n\t\t\tr->user = \"\";\n\t\t\treturn OK;\n\t\t}\n\n\t\t/* we're not using multiple OP's configured in a metadata directory, pick the statically configured OP */\n\t\tif (oidc_provider_static_config(r, c, &provider) == FALSE)\n\t\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\t}\n\n\t/* generate the random nonce value that correlates requests and responses */\n\tchar *nonce = NULL;\n\tif (oidc_proto_generate_nonce(r, &nonce, OIDC_PROTO_NONCE_LENGTH) == FALSE)\n\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\n\tchar *pkce_state = NULL;\n\tchar *code_challenge = NULL;\n\n\tif ((oidc_util_spaced_string_contains(r->pool, provider->response_type,\n\t\t\tOIDC_PROTO_CODE) == TRUE) && (provider->pkce != NULL)) {\n\n\t\t/* generate the code verifier value that correlates authorization requests and code exchange requests */\n\t\tif (provider->pkce->state(r, &pkce_state) == FALSE)\n\t\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\n\t\t/* generate the PKCE code challenge */\n\t\tif (provider->pkce->challenge(r, pkce_state, &code_challenge) == FALSE)\n\t\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\t}\n\n\t/* create the state between request/response */\n\toidc_proto_state_t *proto_state = oidc_proto_state_new();\n\toidc_proto_state_set_original_url(proto_state, original_url);\n\toidc_proto_state_set_original_method(proto_state,\n\t\t\toidc_original_request_method(r, c, TRUE));\n\toidc_proto_state_set_issuer(proto_state, provider->issuer);\n\toidc_proto_state_set_response_type(proto_state, provider->response_type);\n\toidc_proto_state_set_nonce(proto_state, nonce);\n\toidc_proto_state_set_timestamp_now(proto_state);\n\tif (provider->response_mode)\n\t\toidc_proto_state_set_response_mode(proto_state,\n\t\t\t\tprovider->response_mode);\n\tif (prompt)\n\t\toidc_proto_state_set_prompt(proto_state, prompt);\n\tif (pkce_state)\n\t\toidc_proto_state_set_pkce_state(proto_state, pkce_state);\n\n\t/* get a hash value that fingerprints the browser concatenated with the random input */\n\tchar *state = oidc_get_browser_state_hash(r, c, nonce);\n\n\t/*\n\t * create state that restores the context when the authorization response comes in\n\t * and cryptographically bind it to the browser\n\t */\n\tint rc = oidc_authorization_request_set_cookie(r, c, state, proto_state);\n\tif (rc != OK) {\n\t\toidc_proto_state_destroy(proto_state);\n\t\treturn rc;\n\t}\n\n\t/*\n\t * printout errors if Cookie settings are not going to work\n\t * TODO: separate this code out into its own function\n\t */\n\tapr_uri_t o_uri;\n\tmemset(&o_uri, 0, sizeof(apr_uri_t));\n\tapr_uri_t r_uri;\n\tmemset(&r_uri, 0, sizeof(apr_uri_t));\n\tapr_uri_parse(r->pool, original_url, &o_uri);\n\tapr_uri_parse(r->pool, oidc_get_redirect_uri(r, c), &r_uri);\n\tif ((apr_strnatcmp(o_uri.scheme, r_uri.scheme) != 0)\n\t\t\t&& (apr_strnatcmp(r_uri.scheme, \"https\") == 0)) {\n\t\toidc_error(r,\n\t\t\t\t\"the URL scheme (%s) of the configured \" OIDCRedirectURI \" does not match the URL scheme of the URL being accessed (%s): the \\\"state\\\" and \\\"session\\\" cookies will not be shared between the two!\",\n\t\t\t\tr_uri.scheme, o_uri.scheme);\n\t\toidc_proto_state_destroy(proto_state);\n\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\t}\n\n\tif (c->cookie_domain == NULL) {\n\t\tif (apr_strnatcmp(o_uri.hostname, r_uri.hostname) != 0) {\n\t\t\tchar *p = strstr(o_uri.hostname, r_uri.hostname);\n\t\t\tif ((p == NULL) || (apr_strnatcmp(r_uri.hostname, p) != 0)) {\n\t\t\t\toidc_error(r,\n\t\t\t\t\t\t\"the URL hostname (%s) of the configured \" OIDCRedirectURI \" does not match the URL hostname of the URL being accessed (%s): the \\\"state\\\" and \\\"session\\\" cookies will not be shared between the two!\",\n\t\t\t\t\t\tr_uri.hostname, o_uri.hostname);\n\t\t\t\toidc_proto_state_destroy(proto_state);\n\t\t\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tif (!oidc_util_cookie_domain_valid(r_uri.hostname, c->cookie_domain)) {\n\t\t\toidc_error(r,\n\t\t\t\t\t\"the domain (%s) configured in \" OIDCCookieDomain \" does not match the URL hostname (%s) of the URL being accessed (%s): setting \\\"state\\\" and \\\"session\\\" cookies will not work!!\",\n\t\t\t\t\tc->cookie_domain, o_uri.hostname, original_url);\n\t\t\toidc_proto_state_destroy(proto_state);\n\t\t\treturn HTTP_INTERNAL_SERVER_ERROR;\n\t\t}\n\t}\n\n\t/* send off to the OpenID Connect Provider */\n\t// TODO: maybe show intermediate/progress screen \"redirecting to\"\n\treturn oidc_proto_authorization_request(r, provider, login_hint,\n\t\t\toidc_get_redirect_uri_iss(r, c, provider), state, proto_state,\n\t\t\tid_token_hint, code_challenge, auth_request_params, path_scope);\n}",
        "commit_message": "apply OIDCRedirectURLsAllowed setting to target_link_uri\n\ncloses #672; thanks @Meheni\nrelease 2.4.9.4\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "mod_auth_openidc is an authentication/authorization module for the Apache 2.x HTTP server that functions as an OpenID Connect Relying Party, authenticating users against an OpenID Connect Provider. In versions prior to 2.4.9.4, the 3rd-party init SSO functionality of mod_auth_openidc was reported to be vulnerable to an open redirect attack by supplying a crafted URL in the `target_link_uri` parameter. A patch in version 2.4.9.4 made it so that the `OIDCRedirectURLsAllowed` setting must be applied to the `target_link_uri` parameter. There are no known workarounds aside from upgrading to a patched version.",
        "target": 0
      },
      {
        "idx": 410160,
        "reasoning": "This code snippet is not directly vulnerable based on the provided context. The function focuses on refreshing access tokens and handling ID tokens within an OpenID Connect flow, and there are no immediately apparent issues like input validation flaws or insecure data handling that would introduce a security risk\u2014the commit message also indicates a configuration update related to allowed redirect URLs, which isn't reflected in this code.\n\n\n\n",
        "func": "static apr_byte_t oidc_refresh_access_token(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session, oidc_provider_t *provider,\n\t\tchar **new_access_token) {\n\n\toidc_debug(r, \"enter\");\n\n\t/* get the refresh token that was stored in the session */\n\tconst char *refresh_token = oidc_session_get_refresh_token(r, session);\n\tif (refresh_token == NULL) {\n\t\toidc_warn(r,\n\t\t\t\t\"refresh token routine called but no refresh_token found in the session\");\n\t\treturn FALSE;\n\t}\n\n\t/* elements returned in the refresh response */\n\tchar *s_id_token = NULL;\n\tint expires_in = -1;\n\tchar *s_token_type = NULL;\n\tchar *s_access_token = NULL;\n\tchar *s_refresh_token = NULL;\n\n\t/* refresh the tokens by calling the token endpoint */\n\tif (oidc_proto_refresh_request(r, c, provider, refresh_token, &s_id_token,\n\t\t\t&s_access_token, &s_token_type, &expires_in, &s_refresh_token)\n\t\t\t== FALSE) {\n\t\toidc_error(r, \"access_token could not be refreshed\");\n\t\treturn FALSE;\n\t}\n\n\t/* store the new access_token in the session and discard the old one */\n\toidc_session_set_access_token(r, session, s_access_token);\n\toidc_session_set_access_token_expires(r, session, expires_in);\n\n\t/* reset the access token refresh timestamp */\n\toidc_session_reset_access_token_last_refresh(r, session);\n\n\t/* see if we need to return it as a parameter */\n\tif (new_access_token != NULL)\n\t\t*new_access_token = s_access_token;\n\n\t/* if we have a new refresh token (rolling refresh), store it in the session and overwrite the old one */\n\tif (s_refresh_token != NULL)\n\t\toidc_session_set_refresh_token(r, session, s_refresh_token);\n\n\t/* if we have a new id_token, store it in the session and update the session max lifetime if required */\n\tif (s_id_token != NULL) {\n\t\t/* only store the serialized representation when client cookie based session tracking is not in use */\n\t\tif (c->session_type != OIDC_SESSION_TYPE_CLIENT_COOKIE) \n\t\t\toidc_session_set_idtoken(r, session, s_id_token);\n\t\t\n\t\toidc_jwt_t *id_token_jwt = NULL;\n\t\toidc_jose_error_t err;\n\t\tif (oidc_jwt_parse(r->pool, s_id_token, &id_token_jwt, NULL, &err) == TRUE) {\n\n\t\t\t/* store the claims payload in the id_token for later reference */\n\t\t\toidc_session_set_idtoken_claims(r, session,\n\t\t\t\tid_token_jwt->payload.value.str);\n\n\t\t\tif (provider->session_max_duration == 0) {\n\t\t\t\t/* update the session expiry to match the expiry of the id_token */\n\t\t\t\tapr_time_t session_expires = apr_time_from_sec(id_token_jwt->payload.exp);\n\t\t\t\toidc_session_set_session_expires(r, session, session_expires);\n\n\t\t\t\t/* log message about the updated max session duration */\n\t\t\t\toidc_log_session_expires(r, \"session max lifetime\", session_expires);\n\t\t\t}\t\t\n\t\t} else { \n\t\t\toidc_warn(r, \"parsing of id_token failed\");\n\t\t}\n\t}\n\n\treturn TRUE;\n}",
        "commit_message": "apply OIDCRedirectURLsAllowed setting to target_link_uri\n\ncloses #672; thanks @Meheni\nrelease 2.4.9.4\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "mod_auth_openidc is an authentication/authorization module for the Apache 2.x HTTP server that functions as an OpenID Connect Relying Party, authenticating users against an OpenID Connect Provider. In versions prior to 2.4.9.4, the 3rd-party init SSO functionality of mod_auth_openidc was reported to be vulnerable to an open redirect attack by supplying a crafted URL in the `target_link_uri` parameter. A patch in version 2.4.9.4 made it so that the `OIDCRedirectURLsAllowed` setting must be applied to the `target_link_uri` parameter. There are no known workarounds aside from upgrading to a patched version.",
        "target": 0
      },
      {
        "idx": 410161,
        "reasoning": "This code snippet is not directly vulnerable based on the provided context. The commit message indicates the application of a setting (`OIDCRedirectURLsAllowed`) to `target_link_uri`, suggesting a security enhancement related to redirect URL validation rather than introducing a flaw within the `oidc_content_handler` function itself. \n\n\n\n",
        "func": "int oidc_content_handler(request_rec *r) {\n\toidc_cfg *c = ap_get_module_config(r->server->module_config,\n\t\t\t&auth_openidc_module);\n\tint rc = DECLINED;\n\t/* track if the session needs to be updated/saved into the cache */\n\tapr_byte_t needs_save = FALSE;\n\toidc_session_t *session = NULL;\n\n\tif (oidc_enabled(r) == TRUE) {\n\n\t\tif (oidc_util_request_matches_url(r, oidc_get_redirect_uri(r, c)) == TRUE) {\n\n\t\t\tif (oidc_util_request_has_parameter(r,\n\t\t\t\t\tOIDC_REDIRECT_URI_REQUEST_INFO)) {\n\n\t\t\t\toidc_session_load(r, &session);\n\n\t\t\t\trc = oidc_handle_existing_session(r, c, session, &needs_save);\n\t\t\t\tif (rc == OK)\n\t\t\t\t\t/* handle request for session info */\n\t\t\t\t\trc = oidc_handle_info_request(r, c, session, needs_save);\n\n\t\t\t\t/* free resources allocated for the session */\n\t\t\t\toidc_session_free(r, session);\n\n\t\t\t} else if (oidc_util_request_has_parameter(r,\n\t\t\t\t\tOIDC_REDIRECT_URI_REQUEST_JWKS)) {\n\n\t\t\t\t/* handle JWKs request */\n\t\t\t\trc = oidc_handle_jwks(r, c);\n\n\t\t\t} else {\n\n\t\t\t\trc = OK;\n\n\t\t\t}\n\n\t\t} else if (oidc_request_state_get(r, OIDC_REQUEST_STATE_KEY_DISCOVERY) != NULL) {\n\n\t\t\trc = oidc_discovery(r, c);\n\n\t\t} else if (oidc_request_state_get(r, OIDC_REQUEST_STATE_KEY_AUTHN) != NULL) {\n\n\t\t\trc = OK;\n\n\t\t}\n\n\t}\n\n\treturn rc;\n}",
        "commit_message": "apply OIDCRedirectURLsAllowed setting to target_link_uri\n\ncloses #672; thanks @Meheni\nrelease 2.4.9.4\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "mod_auth_openidc is an authentication/authorization module for the Apache 2.x HTTP server that functions as an OpenID Connect Relying Party, authenticating users against an OpenID Connect Provider. In versions prior to 2.4.9.4, the 3rd-party init SSO functionality of mod_auth_openidc was reported to be vulnerable to an open redirect attack by supplying a crafted URL in the `target_link_uri` parameter. A patch in version 2.4.9.4 made it so that the `OIDCRedirectURLsAllowed` setting must be applied to the `target_link_uri` parameter. There are no known workarounds aside from upgrading to a patched version.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 208434,
        "reasoning": "This code is vulnerable to an open redirect attack because it doesn't adequately validate the `target_link_uri` parameter before redirecting the user, potentially allowing an attacker to redirect users to malicious websites. While the code attempts to mitigate this with `oidc_target_link_uri_matches_configuration`, the CVE description states this check was insufficient prior to version 2.4.9.4 and required the `OIDCRedirectURLsAllowed` setting to be properly applied \u2013 which the provided snippet doesn\u2019t explicitly demonstrate being enforced.",
        "func": "static int oidc_handle_discovery_response(request_rec *r, oidc_cfg *c) {\n\n\t/* variables to hold the values returned in the response */\n\tchar *issuer = NULL, *target_link_uri = NULL, *login_hint = NULL,\n\t\t\t*auth_request_params = NULL, *csrf_cookie, *csrf_query = NULL,\n\t\t\t*user = NULL, *path_scopes;\n\toidc_provider_t *provider = NULL;\n\n\toidc_util_get_request_parameter(r, OIDC_DISC_OP_PARAM, &issuer);\n\toidc_util_get_request_parameter(r, OIDC_DISC_USER_PARAM, &user);\n\toidc_util_get_request_parameter(r, OIDC_DISC_RT_PARAM, &target_link_uri);\n\toidc_util_get_request_parameter(r, OIDC_DISC_LH_PARAM, &login_hint);\n\toidc_util_get_request_parameter(r, OIDC_DISC_SC_PARAM, &path_scopes);\n\toidc_util_get_request_parameter(r, OIDC_DISC_AR_PARAM,\n\t\t\t&auth_request_params);\n\toidc_util_get_request_parameter(r, OIDC_CSRF_NAME, &csrf_query);\n\tcsrf_cookie = oidc_util_get_cookie(r, OIDC_CSRF_NAME);\n\n\t/* do CSRF protection if not 3rd party initiated SSO */\n\tif (csrf_cookie) {\n\n\t\t/* clean CSRF cookie */\n\t\toidc_util_set_cookie(r, OIDC_CSRF_NAME, \"\", 0,\n\t\t\t\tOIDC_COOKIE_EXT_SAME_SITE_NONE(r));\n\n\t\t/* compare CSRF cookie value with query parameter value */\n\t\tif ((csrf_query == NULL)\n\t\t\t\t|| apr_strnatcmp(csrf_query, csrf_cookie) != 0) {\n\t\t\toidc_warn(r,\n\t\t\t\t\t\"CSRF protection failed, no Discovery and dynamic client registration will be allowed\");\n\t\t\tcsrf_cookie = NULL;\n\t\t}\n\t}\n\n\t// TODO: trim issuer/accountname/domain input and do more input validation\n\n\toidc_debug(r,\n\t\t\t\"issuer=\\\"%s\\\", target_link_uri=\\\"%s\\\", login_hint=\\\"%s\\\", user=\\\"%s\\\"\",\n\t\t\tissuer, target_link_uri, login_hint, user);\n\n\tif (target_link_uri == NULL) {\n\t\tif (c->default_sso_url == NULL) {\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"SSO to this module without specifying a \\\"target_link_uri\\\" parameter is not possible because \" OIDCDefaultURL \" is not set.\",\n\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t}\n\t\ttarget_link_uri = c->default_sso_url;\n\t}\n\n\t/* do open redirect prevention */\n\tif (oidc_target_link_uri_matches_configuration(r, c, target_link_uri)\n\t\t\t== FALSE) {\n\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\"Invalid Request\",\n\t\t\t\t\"\\\"target_link_uri\\\" parameter does not match configuration settings, aborting to prevent an open redirect.\",\n\t\t\t\tHTTP_UNAUTHORIZED);\n\t}\n\n\t/* see if this is a static setup */\n\tif (c->metadata_dir == NULL) {\n\t\tif ((oidc_provider_static_config(r, c, &provider) == TRUE)\n\t\t\t\t&& (issuer != NULL)) {\n\t\t\tif (apr_strnatcmp(provider->issuer, issuer) != 0) {\n\t\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\tapr_psprintf(r->pool,\n\t\t\t\t\t\t\t\t\"The \\\"iss\\\" value must match the configured providers' one (%s != %s).\",\n\t\t\t\t\t\t\t\tissuer, c->provider.issuer),\n\t\t\t\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t\t}\n\t\t}\n\t\treturn oidc_authenticate_user(r, c, NULL, target_link_uri, login_hint,\n\t\t\t\tNULL, NULL, auth_request_params, path_scopes);\n\t}\n\n\t/* find out if the user entered an account name or selected an OP manually */\n\tif (user != NULL) {\n\n\t\tif (login_hint == NULL)\n\t\t\tlogin_hint = apr_pstrdup(r->pool, user);\n\n\t\t/* normalize the user identifier */\n\t\tif (strstr(user, \"https://\") != user)\n\t\t\tuser = apr_psprintf(r->pool, \"https://%s\", user);\n\n\t\t/* got an user identifier as input, perform OP discovery with that */\n\t\tif (oidc_proto_url_based_discovery(r, c, user, &issuer) == FALSE) {\n\n\t\t\t/* something did not work out, show a user facing error */\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"Could not resolve the provided user identifier to an OpenID Connect provider; check your syntax.\",\n\t\t\t\t\tHTTP_NOT_FOUND);\n\t\t}\n\n\t\t/* issuer is set now, so let's continue as planned */\n\n\t} else if (strstr(issuer, OIDC_STR_AT) != NULL) {\n\n\t\tif (login_hint == NULL) {\n\t\t\tlogin_hint = apr_pstrdup(r->pool, issuer);\n\t\t\t//char *p = strstr(issuer, OIDC_STR_AT);\n\t\t\t//*p = '\\0';\n\t\t}\n\n\t\t/* got an account name as input, perform OP discovery with that */\n\t\tif (oidc_proto_account_based_discovery(r, c, issuer, &issuer)\n\t\t\t\t== FALSE) {\n\n\t\t\t/* something did not work out, show a user facing error */\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\",\n\t\t\t\t\t\"Could not resolve the provided account name to an OpenID Connect provider; check your syntax.\",\n\t\t\t\t\tHTTP_NOT_FOUND);\n\t\t}\n\n\t\t/* issuer is set now, so let's continue as planned */\n\n\t}\n\n\t/* strip trailing '/' */\n\tint n = strlen(issuer);\n\tif (issuer[n - 1] == OIDC_CHAR_FORWARD_SLASH)\n\t\tissuer[n - 1] = '\\0';\n\n\t/* try and get metadata from the metadata directories for the selected OP */\n\tif ((oidc_metadata_get(r, c, issuer, &provider, csrf_cookie != NULL) == TRUE)\n\t\t\t&& (provider != NULL)) {\n\n\t\t/* now we've got a selected OP, send the user there to authenticate */\n\t\treturn oidc_authenticate_user(r, c, provider, target_link_uri,\n\t\t\t\tlogin_hint, NULL, NULL, auth_request_params, path_scopes);\n\t}\n\n\t/* something went wrong */\n\treturn oidc_util_html_send_error(r, c->error_template, \"Invalid Request\",\n\t\t\t\"Could not find valid provider metadata for the selected OpenID Connect provider; contact the administrator\",\n\t\t\tHTTP_NOT_FOUND);\n}",
        "commit_message": "apply OIDCRedirectURLsAllowed setting to target_link_uri\n\ncloses #672; thanks @Meheni\nrelease 2.4.9.4\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "mod_auth_openidc is an authentication/authorization module for the Apache 2.x HTTP server that functions as an OpenID Connect Relying Party, authenticating users against an OpenID Connect Provider. In versions prior to 2.4.9.4, the 3rd-party init SSO functionality of mod_auth_openidc was reported to be vulnerable to an open redirect attack by supplying a crafted URL in the `target_link_uri` parameter. A patch in version 2.4.9.4 made it so that the `OIDCRedirectURLsAllowed` setting must be applied to the `target_link_uri` parameter. There are no known workarounds aside from upgrading to a patched version.",
        "target": 1
      },
      {
        "idx": 214410,
        "reasoning": "This code is vulnerable to an open redirect because it doesn't fully sanitize the `post_logout_redirect_uri` parameter before including it in the logout request URL. Specifically, the validation only checks for malformed URLs, illegal characters (\\n, \\r), and hostname matching, failing to prevent crafted URLs with trailing slashes that bypass the hostname check and redirect to an arbitrary external site, as highlighted by the CVE description.",
        "func": "static int oidc_handle_logout(request_rec *r, oidc_cfg *c,\n\t\toidc_session_t *session) {\n\n\toidc_provider_t *provider = NULL;\n\t/* pickup the command or URL where the user wants to go after logout */\n\tchar *url = NULL;\n\toidc_util_get_request_parameter(r, OIDC_REDIRECT_URI_REQUEST_LOGOUT, &url);\n\n\toidc_debug(r, \"enter (url=%s)\", url);\n\n\tif (oidc_is_front_channel_logout(url)) {\n\t\treturn oidc_handle_logout_request(r, c, session, url);\n\t} else if (oidc_is_back_channel_logout(url)) {\n\t\treturn oidc_handle_logout_backchannel(r, c);\n\t}\n\n\tif ((url == NULL) || (apr_strnatcmp(url, \"\") == 0)) {\n\n\t\turl = c->default_slo_url;\n\n\t} else {\n\n\t\t/* do input validation on the logout parameter value */\n\n\t\tconst char *error_description = NULL;\n\t\tapr_uri_t uri;\n\n\t\tif (apr_uri_parse(r->pool, url, &uri) != APR_SUCCESS) {\n\t\t\tconst char *error_description = apr_psprintf(r->pool,\n\t\t\t\t\t\"Logout URL malformed: %s\", url);\n\t\t\toidc_error(r, \"%s\", error_description);\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Malformed URL\", error_description,\n\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\n\t\t}\n\n\t\tconst char *c_host = oidc_get_current_url_host(r);\n\t\tif ((uri.hostname != NULL)\n\t\t\t\t&& ((strstr(c_host, uri.hostname) == NULL)\n\t\t\t\t\t\t|| (strstr(uri.hostname, c_host) == NULL))) {\n\t\t\terror_description =\n\t\t\t\t\tapr_psprintf(r->pool,\n\t\t\t\t\t\t\t\"logout value \\\"%s\\\" does not match the hostname of the current request \\\"%s\\\"\",\n\t\t\t\t\t\t\tapr_uri_unparse(r->pool, &uri, 0), c_host);\n\t\t\toidc_error(r, \"%s\", error_description);\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\", error_description,\n\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t}\n\n\t\t/* validate the URL to prevent HTTP header splitting */\n\t\tif (((strstr(url, \"\\n\") != NULL) || strstr(url, \"\\r\") != NULL)) {\n\t\t\terror_description =\n\t\t\t\t\tapr_psprintf(r->pool,\n\t\t\t\t\t\t\t\"logout value \\\"%s\\\" contains illegal \\\"\\n\\\" or \\\"\\r\\\" character(s)\",\n\t\t\t\t\t\t\turl);\n\t\t\toidc_error(r, \"%s\", error_description);\n\t\t\treturn oidc_util_html_send_error(r, c->error_template,\n\t\t\t\t\t\"Invalid Request\", error_description,\n\t\t\t\t\tHTTP_INTERNAL_SERVER_ERROR);\n\t\t}\n\t}\n\n\toidc_get_provider_from_session(r, c, session, &provider);\n\n\tif ((provider != NULL) && (provider->end_session_endpoint != NULL)) {\n\n\t\tconst char *id_token_hint = oidc_session_get_idtoken(r, session);\n\n\t\tchar *logout_request = apr_pstrdup(r->pool,\n\t\t\t\tprovider->end_session_endpoint);\n\t\tif (id_token_hint != NULL) {\n\t\t\tlogout_request = apr_psprintf(r->pool, \"%s%sid_token_hint=%s\",\n\t\t\t\t\tlogout_request, strchr(logout_request ? logout_request : \"\",\n\t\t\t\t\t\t\tOIDC_CHAR_QUERY) != NULL ?\n\t\t\t\t\t\t\t\t\tOIDC_STR_AMP :\n\t\t\t\t\t\t\t\t\tOIDC_STR_QUERY,\n\t\t\t\t\t\t\t\t\toidc_util_escape_string(r, id_token_hint));\n\t\t}\n\n\t\tif (url != NULL) {\n\t\t\tlogout_request = apr_psprintf(r->pool,\n\t\t\t\t\t\"%s%spost_logout_redirect_uri=%s\", logout_request,\n\t\t\t\t\tstrchr(logout_request ? logout_request : \"\",\n\t\t\t\t\t\t\tOIDC_CHAR_QUERY) != NULL ?\n\t\t\t\t\t\t\t\t\tOIDC_STR_AMP :\n\t\t\t\t\t\t\t\t\tOIDC_STR_QUERY,\n\t\t\t\t\t\t\t\t\toidc_util_escape_string(r, url));\n\t\t}\n\t\turl = logout_request;\n\t}\n\n\treturn oidc_handle_logout_request(r, c, session, url);\n}",
        "commit_message": "improve validation of the post-logout URL; closes #449\n\n- to avoid an open redirect; thanks AIMOTO Norihito\n- release 2.4.0.1\n\nSigned-off-by: Hans Zandbelt <hans.zandbelt@zmartzone.eu>",
        "cve_desc": "A flaw was found in mod_auth_openidc before version 2.4.0.1. An open redirect issue exists in URLs with trailing slashes similar to CVE-2019-3877 in mod_auth_mellon.",
        "target": 1
      }
    ]
  },
  "mongo": {
    "0": [
      {
        "idx": 269623,
        "reasoning": "This code is not flagged as vulnerable because it appears to safely construct a BSON document from accumulated values, handling missing values by explicitly setting them to BSONNULL. There are no immediately obvious issues like buffer overflows, injection vulnerabilities, or improper input validation within the provided snippet; it focuses on controlled document creation and size tracking.\n\n\n\n",
        "func": "Document DocumentSourceGroup::makeDocument(const Value& id,\n                                           const Accumulators& accums,\n                                           bool mergeableOutput) {\n    const size_t n = _accumulatedFields.size();\n    MutableDocument out(1 + n);\n\n    /* add the _id field */\n    out.addField(\"_id\", expandId(id));\n\n    /* add the rest of the fields */\n    for (size_t i = 0; i < n; ++i) {\n        Value val = accums[i]->getValue(mergeableOutput);\n        if (val.missing()) {\n            // we return null in this case so return objects are predictable\n            out.addField(_accumulatedFields[i].fieldName, Value(BSONNULL));\n        } else {\n            out.addField(_accumulatedFields[i].fieldName, std::move(val));\n        }\n    }\n\n    _stats.totalOutputDataSizeBytes += out.getApproximateSize();\n    return out.freeze();\n}",
        "commit_message": "SERVER-60218 add initialize helper function for document_source_group\n(cherry picked from commit 867f52afbb79bc00e35c70f8e0681b7d602f97b2)",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 269624,
        "reasoning": "This code snippet is safe and doesn't introduce any vulnerabilities. It simply returns a value from a member variable (`_maxAllowedMemoryUsageBytes`) within the `DocumentSourceGroup` class, posing no immediate risk of memory corruption, injection, or other common exploits. \n\n\n\n",
        "func": "size_t DocumentSourceGroup::getMaxMemoryUsageBytes() const {\n    return _memoryTracker._maxAllowedMemoryUsageBytes;\n}",
        "commit_message": "SERVER-60218 add initialize helper function for document_source_group\n(cherry picked from commit 867f52afbb79bc00e35c70f8e0681b7d602f97b2)",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 269625,
        "reasoning": "This code snippet appears safe as it primarily focuses on serializing data structures into a BSON format for output, with checks and invariants to ensure data consistency. There are no immediately obvious vulnerabilities like buffer overflows, injection flaws, or improper input validation that would raise security concerns within the provided context.\n\n\n\n",
        "func": "Value DocumentSourceGroup::serialize(boost::optional<ExplainOptions::Verbosity> explain) const {\n    MutableDocument insides;\n\n    // Add the _id.\n    if (_idFieldNames.empty()) {\n        invariant(_idExpressions.size() == 1);\n        insides[\"_id\"] = _idExpressions[0]->serialize(static_cast<bool>(explain));\n    } else {\n        // Decomposed document case.\n        invariant(_idExpressions.size() == _idFieldNames.size());\n        MutableDocument md;\n        for (size_t i = 0; i < _idExpressions.size(); i++) {\n            md[_idFieldNames[i]] = _idExpressions[i]->serialize(static_cast<bool>(explain));\n        }\n        insides[\"_id\"] = md.freezeToValue();\n    }\n\n    // Add the remaining fields.\n    for (auto&& accumulatedField : _accumulatedFields) {\n        intrusive_ptr<AccumulatorState> accum = accumulatedField.makeAccumulator();\n        insides[accumulatedField.fieldName] =\n            Value(accum->serialize(accumulatedField.expr.initializer,\n                                   accumulatedField.expr.argument,\n                                   static_cast<bool>(explain)));\n    }\n\n    if (_doingMerge) {\n        // This makes the output unparsable (with error) on pre 2.6 shards, but it will never\n        // be sent to old shards when this flag is true since they can't do a merge anyway.\n        insides[\"$doingMerge\"] = Value(true);\n    }\n\n    MutableDocument out;\n    out[getSourceName()] = Value(insides.freeze());\n\n    if (explain && *explain >= ExplainOptions::Verbosity::kExecStats) {\n        MutableDocument md;\n\n        for (size_t i = 0; i < _accumulatedFields.size(); i++) {\n            md[_accumulatedFields[i].fieldName] = Value(static_cast<long long>(\n                _memoryTracker[_accumulatedFields[i].fieldName].maxMemoryBytes()));\n        }\n\n        out[\"maxAccumulatorMemoryUsageBytes\"] = Value(md.freezeToValue());\n        out[\"totalOutputDataSizeBytes\"] =\n            Value(static_cast<long long>(_stats.totalOutputDataSizeBytes));\n        out[\"usedDisk\"] = Value(_stats.usedDisk);\n    }\n\n    return Value(out.freezeToValue());\n}",
        "commit_message": "SERVER-60218 add initialize helper function for document_source_group\n(cherry picked from commit 867f52afbb79bc00e35c70f8e0681b7d602f97b2)",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 269626,
        "reasoning": "This code is not vulnerable because it carefully validates input and restricts functionality to specific, safe scenarios. It explicitly checks for conditions like a single grouping field, non-variable references, and only allows `$first` accumulators, preventing potential injection or manipulation issues that could arise from more complex or unrestricted operations.\n\n\n\n",
        "func": "DocumentSourceGroup::rewriteGroupAsTransformOnFirstDocument() const {\n    if (_idExpressions.size() != 1) {\n        // This transformation is only intended for $group stages that group on a single field.\n        return nullptr;\n    }\n\n    auto fieldPathExpr = dynamic_cast<ExpressionFieldPath*>(_idExpressions.front().get());\n    if (!fieldPathExpr || fieldPathExpr->isVariableReference()) {\n        return nullptr;\n    }\n\n    const auto fieldPath = fieldPathExpr->getFieldPath();\n    if (fieldPath.getPathLength() == 1) {\n        // The path is $$CURRENT or $$ROOT. This isn't really a sensible value to group by (since\n        // each document has a unique _id, it will just return the entire collection). We only\n        // apply the rewrite when grouping by a single field, so we cannot apply it in this case,\n        // where we are grouping by the entire document.\n        invariant(fieldPath.getFieldName(0) == \"CURRENT\" || fieldPath.getFieldName(0) == \"ROOT\");\n        return nullptr;\n    }\n\n    const auto groupId = fieldPath.tail().fullPath();\n\n    // We can't do this transformation if there are any non-$first accumulators.\n    for (auto&& accumulator : _accumulatedFields) {\n        if (AccumulatorDocumentsNeeded::kFirstDocument !=\n            accumulator.makeAccumulator()->documentsNeeded()) {\n            return nullptr;\n        }\n    }\n\n    std::vector<std::pair<std::string, boost::intrusive_ptr<Expression>>> fields;\n\n    boost::intrusive_ptr<Expression> idField;\n    // The _id field can be specified either as a fieldpath (ex. _id: \"$a\") or as a singleton\n    // object (ex. _id: {v: \"$a\"}).\n    if (_idFieldNames.empty()) {\n        idField = ExpressionFieldPath::deprecatedCreate(pExpCtx.get(), groupId);\n    } else {\n        invariant(_idFieldNames.size() == 1);\n        idField = ExpressionObject::create(pExpCtx.get(),\n                                           {{_idFieldNames.front(), _idExpressions.front()}});\n    }\n    fields.push_back(std::make_pair(\"_id\", idField));\n\n    for (auto&& accumulator : _accumulatedFields) {\n        fields.push_back(std::make_pair(accumulator.fieldName, accumulator.expr.argument));\n\n        // Since we don't attempt this transformation for non-$first accumulators,\n        // the initializer should always be trivial.\n    }\n\n    return GroupFromFirstDocumentTransformation::create(pExpCtx, groupId, std::move(fields));\n}",
        "commit_message": "SERVER-60218 add initialize helper function for document_source_group\n(cherry picked from commit 867f52afbb79bc00e35c70f8e0681b7d602f97b2)",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 269627,
        "reasoning": "This code snippet appears safe as it simply iterates through a pre-existing `_groups` data structure and constructs a `Document` from its elements. There's no external input processing or resource management that introduces common vulnerabilities like injection, buffer overflows, or use-after-free issues within the presented `getNextStandard` function itself.\n\n\n\n",
        "func": "DocumentSource::GetNextResult DocumentSourceGroup::getNextStandard() {\n    // Not spilled, and not streaming.\n    if (_groups->empty())\n        return GetNextResult::makeEOF();\n\n    Document out = makeDocument(groupsIterator->first, groupsIterator->second, pExpCtx->needsMerge);\n\n    if (++groupsIterator == _groups->end())\n        dispose();\n\n    return out;\n}",
        "commit_message": "SERVER-60218 add initialize helper function for document_source_group\n(cherry picked from commit 867f52afbb79bc00e35c70f8e0681b7d602f97b2)",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 198167,
        "reasoning": "This code is vulnerable because it creates the `.dbshell` history file with default file permissions, likely allowing any local user to read sensitive commands stored within. The `fopen(filename, \"wt\")` call doesn't specify any permission restrictions, leading to the world-readable permissions described in the CVE, potentially exposing a user's MongoDB interactions.",
        "func": "int linenoiseHistorySave(const char* filename) {\n    FILE* fp = fopen(filename, \"wt\");\n    if (fp == NULL) {\n        return -1;\n    }\n\n    for (int j = 0; j < historyLen; ++j) {\n        if (history[j][0] != '\\0') {\n            fprintf(fp, \"%s\\n\", history[j]);\n        }\n    }\n    fclose(fp);\n    return 0;\n}",
        "commit_message": "SERVER-25335 avoid group and other permissions when creating .dbshell history file",
        "cve_desc": "The client in MongoDB uses world-readable permissions on .dbshell history files, which might allow local users to obtain sensitive information by reading these files.",
        "target": 1
      },
      {
        "idx": 198179,
        "reasoning": "This code is vulnerable to a denial of service because it doesn't properly handle invalid X.509 client certificates, potentially leading to a crash as described in the CVE. Specifically, the code attempts to extract cluster IDs from the subject name and performs string operations without sufficient validation, which could cause an out-of-bounds read or other errors when presented with a malformed certificate.",
        "func": "    Status CmdAuthenticate::_authenticateX509(const UserName& user, const BSONObj& cmdObj) {\n        if (!getSSLManager()) {\n            return Status(ErrorCodes::ProtocolError,\n                          \"SSL support is required for the MONGODB-X509 mechanism.\");\n        }\n        if(user.getDB() != \"$external\") {\n            return Status(ErrorCodes::ProtocolError,\n                          \"X.509 authentication must always use the $external database.\");\n        }\n\n        ClientBasic *client = ClientBasic::getCurrent();\n        AuthorizationSession* authorizationSession = client->getAuthorizationSession();\n        std::string subjectName = client->port()->getX509SubjectName();\n\n        if (user.getUser() != subjectName) {\n            return Status(ErrorCodes::AuthenticationFailed,\n                          \"There is no x.509 client certificate matching the user.\");\n        }\n        else {\n            std::string srvSubjectName = getSSLManager()->getServerSubjectName();\n            std::string srvClusterId = srvSubjectName.substr(srvSubjectName.find(\",OU=\"));\n            std::string peerClusterId = subjectName.substr(subjectName.find(\",OU=\"));\n\n            fassert(17002, !srvClusterId.empty() && srvClusterId != srvSubjectName);\n\n            // Handle internal cluster member auth, only applies to server-server connections\n            int clusterAuthMode = serverGlobalParams.clusterAuthMode.load(); \n            if (srvClusterId == peerClusterId) {\n                if (clusterAuthMode == ServerGlobalParams::ClusterAuthMode_undefined ||\n                    clusterAuthMode == ServerGlobalParams::ClusterAuthMode_keyFile) {\n                    return Status(ErrorCodes::AuthenticationFailed, \"The provided certificate \" \n                                  \"can only be used for cluster authentication, not client \" \n                                  \"authentication. The current configuration does not allow \" \n                                  \"x.509 cluster authentication, check the --clusterAuthMode flag\");\n                }\n                authorizationSession->grantInternalAuthorization();\n            }\n            // Handle normal client authentication, only applies to client-server connections\n            else {\n                if (_isX509AuthDisabled) {\n                    return Status(ErrorCodes::BadValue,\n                                  _x509AuthenticationDisabledMessage);\n                }\n                Status status = authorizationSession->addAndAuthorizeUser(user);\n                if (!status.isOK()) {\n                    return status;\n                }\n            }\n            return Status::OK();\n        }\n    }",
        "commit_message": "SERVER-13573 Fix x.509 auth exception",
        "cve_desc": "The CmdAuthenticate::_authenticateX509 function in db/commands/authentication_commands.cpp in mongod in MongoDB 2.6.x before 2.6.2 allows remote attackers to cause a denial of service (daemon crash) by attempting authentication with an invalid X.509 client certificate.",
        "target": 1
      },
      {
        "idx": 200506,
        "reasoning": "This code is vulnerable to a denial-of-service attack because the `compressionHeader.uncompressedSize` value, provided by the client, is used directly to allocate memory for `outputMessageBuffer` without sufficient validation beyond checking if it exceeds `MaxMessageSizeBytes`. A malicious client could provide a large `uncompressedSize` value (close to `MaxMessageSizeBytes`) leading to significant memory allocation, potentially exhausting server resources and causing a DoS, as described in the CVE.",
        "func": "StatusWith<Message> MessageCompressorManager::decompressMessage(const Message& msg,\n                                                                MessageCompressorId* compressorId) {\n    auto inputHeader = msg.header();\n    ConstDataRangeCursor input(inputHeader.data(), inputHeader.data() + inputHeader.dataLen());\n    if (input.length() < CompressionHeader::size()) {\n        return {ErrorCodes::BadValue, \"Invalid compressed message header\"};\n    }\n    CompressionHeader compressionHeader(&input);\n\n    auto compressor = _registry->getCompressor(compressionHeader.compressorId);\n    if (!compressor) {\n        return {ErrorCodes::InternalError,\n                \"Compression algorithm specified in message is not available\"};\n    }\n\n    if (compressorId) {\n        *compressorId = compressor->getId();\n    }\n\n    LOG(3) << \"Decompressing message with \" << compressor->getName();\n\n    size_t bufferSize = compressionHeader.uncompressedSize + MsgData::MsgDataHeaderSize;\n    if (bufferSize > MaxMessageSizeBytes) {\n        return {ErrorCodes::BadValue,\n                \"Decompressed message would be larger than maximum message size\"};\n    }\n\n    auto outputMessageBuffer = SharedBuffer::allocate(bufferSize);\n    MsgData::View outMessage(outputMessageBuffer.get());\n    outMessage.setId(inputHeader.getId());\n    outMessage.setResponseToMsgId(inputHeader.getResponseToMsgId());\n    outMessage.setOperation(compressionHeader.originalOpCode);\n    outMessage.setLen(bufferSize);\n\n    DataRangeCursor output(outMessage.data(), outMessage.data() + outMessage.dataLen());\n\n    auto sws = compressor->decompressData(input, output);\n\n    if (!sws.isOK())\n        return sws.getStatus();\n\n    if (sws.getValue() != static_cast<std::size_t>(compressionHeader.uncompressedSize)) {\n        return {ErrorCodes::BadValue, \"Decompressing message returned less data than expected\"};\n    }\n\n    outMessage.setLen(sws.getValue() + MsgData::MsgDataHeaderSize);\n\n    return {Message(outputMessageBuffer)};\n}",
        "commit_message": "SERVER-43751 Recompute compressor manager message parameters",
        "cve_desc": "An unauthenticated client can trigger denial of service by issuing specially crafted wire protocol messages, which cause the message decompressor to incorrectly allocate memory. This issue affects: MongoDB Inc. MongoDB Server v4.2 versions prior to 4.2.1; v4.0 versions prior to 4.0.13; v3.6 versions prior to 3.6.15; v3.4 versions prior to 3.4.24.",
        "target": 1
      },
      {
        "idx": 200542,
        "reasoning": "This code is vulnerable to a denial-of-service (DoS) attack because it doesn't adequately validate the `sourceNss` before attempting to access the source collection, potentially leading to a crash or resource exhaustion if the namespace is maliciously crafted. Specifically, the code allows a rename operation to proceed even if `sourceColl` is null, and then attempts to derive a `dropTargetNss` from potentially invalid data, ultimately calling `dropCollection` which could exacerbate the DoS.",
        "func": "Status renameCollectionForApplyOps(OperationContext* opCtx,\n                                   const std::string& dbName,\n                                   const BSONElement& ui,\n                                   const BSONObj& cmd,\n                                   const repl::OpTime& renameOpTime) {\n\n    const auto sourceNsElt = cmd.firstElement();\n    const auto targetNsElt = cmd[\"to\"];\n    uassert(ErrorCodes::TypeMismatch,\n            \"'renameCollection' must be of type String\",\n            sourceNsElt.type() == BSONType::String);\n    uassert(ErrorCodes::TypeMismatch,\n            \"'to' must be of type String\",\n            targetNsElt.type() == BSONType::String);\n\n    NamespaceString sourceNss(sourceNsElt.valueStringData());\n    NamespaceString targetNss(targetNsElt.valueStringData());\n    NamespaceString uiNss(getNamespaceFromUUIDElement(opCtx, ui));\n\n    if ((repl::ReplicationCoordinator::get(opCtx)->getReplicationMode() ==\n         repl::ReplicationCoordinator::modeNone) &&\n        targetNss.isOplog()) {\n        return Status(ErrorCodes::IllegalOperation,\n                      str::stream() << \"Cannot rename collection to the oplog\");\n    }\n\n    // If the UUID we're targeting already exists, rename from there no matter what.\n    if (!uiNss.isEmpty()) {\n        sourceNss = uiNss;\n    }\n\n    OptionalCollectionUUID targetUUID;\n    if (!ui.eoo())\n        targetUUID = uassertStatusOK(UUID::parse(ui));\n\n    RenameCollectionOptions options;\n    options.dropTarget = cmd[\"dropTarget\"].trueValue();\n    if (cmd[\"dropTarget\"].type() == BinData) {\n        auto uuid = uassertStatusOK(UUID::parse(cmd[\"dropTarget\"]));\n        options.dropTargetUUID = uuid;\n    }\n\n    const Collection* const sourceColl =\n        AutoGetCollectionForRead(opCtx, sourceNss, AutoGetCollection::ViewMode::kViewsPermitted)\n            .getCollection();\n\n    if (sourceNss.isDropPendingNamespace() || sourceColl == nullptr) {\n        NamespaceString dropTargetNss;\n\n        if (options.dropTarget)\n            dropTargetNss = targetNss;\n\n        if (options.dropTargetUUID) {\n            dropTargetNss = getNamespaceFromUUID(opCtx, options.dropTargetUUID.get());\n        }\n\n        // Downgrade renameCollection to dropCollection.\n        if (!dropTargetNss.isEmpty()) {\n            BSONObjBuilder unusedResult;\n            return dropCollection(opCtx,\n                                  dropTargetNss,\n                                  unusedResult,\n                                  renameOpTime,\n                                  DropCollectionSystemCollectionMode::kAllowSystemCollectionDrops);\n        }\n\n        return Status(ErrorCodes::NamespaceNotFound,\n                      str::stream()\n                          << \"renameCollection() cannot accept a source \"\n                             \"collection that does not exist or is in a drop-pending state: \"\n                          << sourceNss.toString());\n    }\n\n    const std::string dropTargetMsg =\n        options.dropTargetUUID ? \" and drop \" + options.dropTargetUUID->toString() + \".\" : \".\";\n    const std::string uuidString = targetUUID ? targetUUID->toString() : \"UUID unknown\";\n    log() << \"renameCollectionForApplyOps: rename \" << sourceNss << \" (\" << uuidString << \") to \"\n          << targetNss << dropTargetMsg;\n\n    options.stayTemp = cmd[\"stayTemp\"].trueValue();\n    return renameCollectionCommon(opCtx, sourceNss, targetNss, targetUUID, renameOpTime, options);\n}",
        "commit_message": "SERVER-35636 renameCollectionForApplyOps checks for complete namespace",
        "cve_desc": "A user authorized to perform database queries may trigger denial of service by issuing specially crafted applyOps invocations. This issue affects: MongoDB Inc. MongoDB Server v4.0 versions prior to 4.0.10; v3.6 versions prior to 3.6.13.",
        "target": 1
      },
      {
        "idx": 205822,
        "reasoning": "The code is vulnerable to a denial of service due to the potential for an infinite loop within the repeated multiplication used to calculate the power of integer bases and exponents. Specifically, if `baseLong` is 1 or -1 and `expLong` is a very large positive number, the loop will iterate excessively, consuming resources and potentially locking the database, as described in the CVE.",
        "func": "Value ExpressionPow::evaluate(const Document& root) const {\n    Value baseVal = vpOperand[0]->evaluate(root);\n    Value expVal = vpOperand[1]->evaluate(root);\n    if (baseVal.nullish() || expVal.nullish())\n        return Value(BSONNULL);\n\n    BSONType baseType = baseVal.getType();\n    BSONType expType = expVal.getType();\n\n    uassert(28762,\n            str::stream() << \"$pow's base must be numeric, not \" << typeName(baseType),\n            baseVal.numeric());\n    uassert(28763,\n            str::stream() << \"$pow's exponent must be numeric, not \" << typeName(expType),\n            expVal.numeric());\n\n    auto checkNonZeroAndNeg = [](bool isZeroAndNeg) {\n        uassert(28764, \"$pow cannot take a base of 0 and a negative exponent\", !isZeroAndNeg);\n    };\n\n    // If either argument is decimal, return a decimal.\n    if (baseType == NumberDecimal || expType == NumberDecimal) {\n        Decimal128 baseDecimal = baseVal.coerceToDecimal();\n        Decimal128 expDecimal = expVal.coerceToDecimal();\n        checkNonZeroAndNeg(baseDecimal.isZero() && expDecimal.isNegative());\n        return Value(baseDecimal.power(expDecimal));\n    }\n\n    // pow() will cast args to doubles.\n    double baseDouble = baseVal.coerceToDouble();\n    double expDouble = expVal.coerceToDouble();\n    checkNonZeroAndNeg(baseDouble == 0 && expDouble < 0);\n\n    // If either argument is a double, return a double.\n    if (baseType == NumberDouble || expType == NumberDouble) {\n        return Value(std::pow(baseDouble, expDouble));\n    }\n\n    // base and exp are both integers.\n\n    auto representableAsLong = [](long long base, long long exp) {\n        // If exp is greater than 63 and base is not -1, 0, or 1, the result will overflow.\n        // If exp is negative and the base is not -1 or 1, the result will be fractional.\n        if (exp < 0 || exp > 63) {\n            return std::abs(base) == 1 || base == 0;\n        }\n\n        struct MinMax {\n            long long min;\n            long long max;\n        };\n\n        // Array indices correspond to exponents 0 through 63. The values in each index are the min\n        // and max bases, respectively, that can be raised to that exponent without overflowing a\n        // 64-bit int. For max bases, this was computed by solving for b in\n        // b = (2^63-1)^(1/exp) for exp = [0, 63] and truncating b. To calculate min bases, for even\n        // exps the equation  used was b = (2^63-1)^(1/exp), and for odd exps the equation used was\n        // b = (-2^63)^(1/exp). Since the magnitude of long min is greater than long max, the\n        // magnitude of some of the min bases raised to odd exps is greater than the corresponding\n        // max bases raised to the same exponents.\n\n        static const MinMax kBaseLimits[] = {\n            {std::numeric_limits<long long>::min(), std::numeric_limits<long long>::max()},  // 0\n            {std::numeric_limits<long long>::min(), std::numeric_limits<long long>::max()},\n            {-3037000499LL, 3037000499LL},\n            {-2097152, 2097151},\n            {-55108, 55108},\n            {-6208, 6208},\n            {-1448, 1448},\n            {-512, 511},\n            {-234, 234},\n            {-128, 127},\n            {-78, 78},  // 10\n            {-52, 52},\n            {-38, 38},\n            {-28, 28},\n            {-22, 22},\n            {-18, 18},\n            {-15, 15},\n            {-13, 13},\n            {-11, 11},\n            {-9, 9},\n            {-8, 8},  // 20\n            {-8, 7},\n            {-7, 7},\n            {-6, 6},\n            {-6, 6},\n            {-5, 5},\n            {-5, 5},\n            {-5, 5},\n            {-4, 4},\n            {-4, 4},\n            {-4, 4},  // 30\n            {-4, 4},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-3, 3},\n            {-2, 2},  // 40\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},  // 50\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},\n            {-2, 2},  // 60\n            {-2, 2},\n            {-2, 2},\n            {-2, 1}};\n\n        return base >= kBaseLimits[exp].min && base <= kBaseLimits[exp].max;\n    };\n\n    long long baseLong = baseVal.getLong();\n    long long expLong = expVal.getLong();\n\n    // If the result cannot be represented as a long, return a double. Otherwise if either number\n    // is a long, return a long. If both numbers are ints, then return an int if the result fits or\n    // a long if it is too big.\n    if (!representableAsLong(baseLong, expLong)) {\n        return Value(std::pow(baseLong, expLong));\n    }\n\n    long long result = 1;\n    // Use repeated multiplication, since pow() casts args to doubles which could result in loss of\n    // precision if arguments are very large.\n    for (int i = 0; i < expLong; i++) {\n        result *= baseLong;\n    }\n\n    if (baseType == NumberLong || expType == NumberLong) {\n        return Value(result);\n    }\n    return Value::createIntOrLong(result);\n}",
        "commit_message": "SERVER-38070 fix infinite loop in agg expression",
        "cve_desc": "A user authorized to perform database queries may trigger denial of service by issuing specially crafted queries, which loop indefinitely in mathematics processing while retaining locks. This issue affects: MongoDB Inc. MongoDB Server v4.0 versions prior to 4.0.5; v3.6 versions prior to 3.6.10; v3.4 versions prior to 3.4.19.",
        "target": 1
      }
    ]
  },
  "mono": {
    "0": [
      {
        "idx": 285704,
        "reasoning": "This code snippet appears safe as it focuses on retrieving method handles and includes checks for various method types, including generic methods and those built during type building. The commit message explicitly states it *handles* invalid instantiation of generic methods, suggesting a defensive approach rather than introducing a vulnerability\u2014it's fixing a potential issue related to incorrect method resolution, not creating a new one.\n\n\n\n",
        "func": "static MonoMethod*\nmono_reflection_method_get_handle (MonoObject *method)\n{\n\tMonoClass *class = mono_object_class (method);\n\tif (is_sr_mono_method (class) || is_sr_mono_generic_method (class)) {\n\t\tMonoReflectionMethod *sr_method = (MonoReflectionMethod*)method;\n\t\treturn sr_method->method;\n\t}\n\tif (is_sre_method_builder (class)) {\n\t\tMonoReflectionMethodBuilder *mb = (MonoReflectionMethodBuilder*)method;\n\t\treturn mb->mhandle;\n\t}\n\tif (is_sre_method_on_tb_inst (class)) {\n\t\tMonoReflectionMethodOnTypeBuilderInst *m = (MonoReflectionMethodOnTypeBuilderInst*)method;\n\t\tMonoMethod *result;\n\t\t/*FIXME move this to a proper method and unify with resolve_object*/\n\t\tif (m->method_args) {\n\t\t\tresult = mono_reflection_method_on_tb_inst_get_handle (m);\n\t\t} else {\n\t\t\tMonoType *type = mono_reflection_type_get_handle ((MonoReflectionType*)m->inst);\n\t\t\tMonoClass *inflated_klass = mono_class_from_mono_type (type);\n\t\t\tMonoMethod *mono_method;\n\n\t\t\tif (is_sre_method_builder (mono_object_class (m->mb)))\n\t\t\t\tmono_method = ((MonoReflectionMethodBuilder *)m->mb)->mhandle;\n \t\t\telse if (is_sr_mono_method (mono_object_class (m->mb)))\n\t\t\t\tmono_method = ((MonoReflectionMethod *)m->mb)->method;\n\t\t\telse\n\t\t\t\tg_error (\"resolve_object:: can't handle a MTBI with base_method of type %s\", mono_type_get_full_name (mono_object_class (m->mb)));\n\n\t\t\tresult = inflate_mono_method (inflated_klass, mono_method, (MonoObject*)m->mb);\n\t\t}\n\t\treturn result;\n\t}\n\n\tg_error (\"Can't handle methods of type %s:%s\", class->name_space, class->name);\n\treturn NULL;",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 0
      },
      {
        "idx": 285705,
        "reasoning": "This code snippet focuses on adding type information to an assembly's exported type table and doesn't directly handle method instantiation or parameter binding, which is where the commit message indicates a fix was applied in `reflection.c` and `verify.c`. Therefore, this code is not flagged as vulnerable because it operates on class metadata and doesn't appear to be involved in the generic method instantiation process addressed by the commit.\n\n\n\n",
        "func": "add_exported_type (MonoReflectionAssemblyBuilder *assemblyb, MonoDynamicImage *assembly, MonoClass *klass, guint32 parent_index)\n{\n\tMonoDynamicTable *table;\n\tguint32 *values;\n\tguint32 scope, scope_idx, impl, current_idx;\n\tgboolean forwarder = TRUE;\n\tgpointer iter = NULL;\n\tMonoClass *nested;\n\n\tif (klass->nested_in) {\n\t\timpl = (parent_index << MONO_IMPLEMENTATION_BITS) + MONO_IMPLEMENTATION_EXP_TYPE;\n\t\tforwarder = FALSE;\n\t} else {\n\t\tscope = resolution_scope_from_image (assembly, klass->image);\n\t\tg_assert ((scope & MONO_RESOLTION_SCOPE_MASK) == MONO_RESOLTION_SCOPE_ASSEMBLYREF);\n\t\tscope_idx = scope >> MONO_RESOLTION_SCOPE_BITS;\n\t\timpl = (scope_idx << MONO_IMPLEMENTATION_BITS) + MONO_IMPLEMENTATION_ASSEMBLYREF;\n\t}\n\n\ttable = &assembly->tables [MONO_TABLE_EXPORTEDTYPE];\n\n\ttable->rows++;\n\talloc_table (table, table->rows);\n\tcurrent_idx = table->next_idx;\n\tvalues = table->values + current_idx * MONO_EXP_TYPE_SIZE;\n\n\tvalues [MONO_EXP_TYPE_FLAGS] = forwarder ? TYPE_ATTRIBUTE_FORWARDER : 0;\n\tvalues [MONO_EXP_TYPE_TYPEDEF] = 0;\n\tvalues [MONO_EXP_TYPE_IMPLEMENTATION] = impl;\n\tvalues [MONO_EXP_TYPE_NAME] = string_heap_insert (&assembly->sheap, klass->name);\n\tvalues [MONO_EXP_TYPE_NAMESPACE] = string_heap_insert (&assembly->sheap, klass->name_space);\n\n\ttable->next_idx++;\n\n\twhile ((nested = mono_class_get_nested_types (klass, &iter)))\n\t\tadd_exported_type (assemblyb, assembly, nested, current_idx);\n}",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 0
      },
      {
        "idx": 285706,
        "reasoning": "This code snippet appears safe as it primarily focuses on constructing a new `MonoType` with custom modifiers from provided arrays. While it involves memory allocation and copying, the sizes are calculated based on array lengths and a fixed `MonoType` size, and there's no immediately obvious path for buffer overflows or other memory corruption vulnerabilities given the context of the commit message addressing generic method instantiation checks elsewhere.\n\n\n\n",
        "func": "add_custom_modifiers (MonoDynamicImage *assembly, MonoType *type, MonoArray *modreq, MonoArray *modopt)\n{\n\tint i, count, len, pos;\n\tMonoType *t;\n\n\tcount = 0;\n\tif (modreq)\n\t\tcount += mono_array_length (modreq);\n\tif (modopt)\n\t\tcount += mono_array_length (modopt);\n\n\tif (count == 0)\n\t\treturn mono_metadata_type_dup (NULL, type);\n\n\tlen = MONO_SIZEOF_TYPE + ((gint32)count) * sizeof (MonoCustomMod);\n\tt = g_malloc (len);\n\tmemcpy (t, type, MONO_SIZEOF_TYPE);\n\n\tt->num_mods = count;\n\tpos = 0;\n\tif (modreq) {\n\t\tfor (i = 0; i < mono_array_length (modreq); ++i) {\n\t\t\tMonoType *mod = mono_type_array_get_and_resolve (modreq, i);\n\t\t\tt->modifiers [pos].required = 1;\n\t\t\tt->modifiers [pos].token = mono_image_typedef_or_ref (assembly, mod);\n\t\t\tpos ++;\n\t\t}\n\t}\n\tif (modopt) {\n\t\tfor (i = 0; i < mono_array_length (modopt); ++i) {\n\t\t\tMonoType *mod = mono_type_array_get_and_resolve (modopt, i);\n\t\t\tt->modifiers [pos].required = 0;\n\t\t\tt->modifiers [pos].token = mono_image_typedef_or_ref (assembly, mod);\n\t\t\tpos ++;\n\t\t}\n\t}\n\n\treturn t;\n}",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 0
      },
      {
        "idx": 285707,
        "reasoning": "This code snippet is not directly related to the commit message's focus on handling invalid generic method instantiations; it simply checks if a class represents a pointer type within the reflection system. Therefore, there's no apparent vulnerability introduced or addressed by this specific code in relation to the described fix for generic method instantiation issues.\n\n\n\n",
        "func": "static gboolean\nis_sre_pointer (MonoClass *class)\n{\n\tcheck_corlib_type_cached (class, \"System.Reflection.Emit\", \"PointerType\");",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 0
      },
      {
        "idx": 285708,
        "reasoning": "This code snippet appears safe as it only *checks* a condition related to dynamic generic classes and fields, rather than modifying data or directly handling external input. The commit message focuses on validating method instantiations elsewhere, and this function simply provides a read-only check on field properties\u2014it doesn't introduce any obvious avenues for exploitation like buffer overflows or injection attacks.\n\n\n\n",
        "func": "is_field_on_inst (MonoClassField *field)\n{\n\treturn (field->parent->generic_class && field->parent->generic_class->is_dynamic && ((MonoDynamicGenericClass*)field->parent->generic_class)->fields);\n}",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 198947,
        "reasoning": "This code is vulnerable because it lacks sufficient validation of the provided `types` array used to instantiate generic methods, potentially allowing attackers to bypass generic constraints defined on the method. By supplying crafted type arguments, an attacker could instantiate a generic method with types that violate its intended restrictions, potentially leading to arbitrary code execution as described in CVE-2023-42893.",
        "func": "MonoReflectionMethod*\nmono_reflection_bind_generic_method_parameters (MonoReflectionMethod *rmethod, MonoArray *types)\n{\n\tMonoClass *klass;\n\tMonoMethod *method, *inflated;\n\tMonoMethodInflated *imethod;\n\tMonoGenericContext tmp_context;\n\tMonoGenericInst *ginst;\n\tMonoType **type_argv;\n\tint count, i;\n\n\tMONO_ARCH_SAVE_REGS;\n\n\t/*FIXME but this no longer should happen*/\n\tif (!strcmp (rmethod->object.vtable->klass->name, \"MethodBuilder\")) {\n#ifndef DISABLE_REFLECTION_EMIT\n\t\tMonoReflectionMethodBuilder *mb = NULL;\n\t\tMonoReflectionTypeBuilder *tb;\n\t\tMonoClass *klass;\n\n\t\tmb = (MonoReflectionMethodBuilder *) rmethod;\n\t\ttb = (MonoReflectionTypeBuilder *) mb->type;\n\t\tklass = mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)tb));\n\n\t\tmethod = methodbuilder_to_mono_method (klass, mb);\n#else\n\t\tg_assert_not_reached ();\n\t\tmethod = NULL;\n#endif\n\t} else {\n\t\tmethod = rmethod->method;\n\t}\n\n\tklass = method->klass;\n\n\tif (method->is_inflated)\n\t\tmethod = ((MonoMethodInflated *) method)->declaring;\n\n\tcount = mono_method_signature (method)->generic_param_count;\n\tif (count != mono_array_length (types))\n\t\treturn NULL;\n\n\ttype_argv = g_new0 (MonoType *, count);\n\tfor (i = 0; i < count; i++) {\n\t\tMonoReflectionType *garg = mono_array_get (types, gpointer, i);\n\t\ttype_argv [i] = mono_reflection_type_get_handle (garg);\n\t}\n\tginst = mono_metadata_get_generic_inst (count, type_argv);\n\tg_free (type_argv);\n\n\ttmp_context.class_inst = klass->generic_class ? klass->generic_class->context.class_inst : NULL;\n\ttmp_context.method_inst = ginst;\n\n\tinflated = mono_class_inflate_generic_method (method, &tmp_context);\n\timethod = (MonoMethodInflated *) inflated;\n\n\t/*FIXME but I think this is no longer necessary*/\n\tif (method->klass->image->dynamic) {\n\t\tMonoDynamicImage *image = (MonoDynamicImage*)method->klass->image;\n\t\t/*\n\t\t * This table maps metadata structures representing inflated methods/fields\n\t\t * to the reflection objects representing their generic definitions.\n\t\t */\n\t\tmono_loader_lock ();\n\t\tmono_g_hash_table_insert (image->generic_def_objects, imethod, rmethod);\n\t\tmono_loader_unlock ();\n\t}\n\t\n\treturn mono_method_get_object (mono_object_domain (rmethod), inflated, NULL);",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 1
      },
      {
        "idx": 209836,
        "reasoning": "This code is vulnerable to race conditions due to concurrent access to memory, as indicated by the commit message disabling \"fast paths\" because they are \"racy.\" Specifically, the multiple `memcpy` and `mono_value_copy` operations, especially within loops, lack proper synchronization mechanisms, allowing multiple threads to potentially corrupt data during the array copy process, potentially leading to a denial of service or data corruption as seen in the related CVE.",
        "func": "ves_icall_System_Array_FastCopy (MonoArray *source, int source_idx, MonoArray* dest, int dest_idx, int length)\n{\n\tint element_size;\n\tvoid * dest_addr;\n\tvoid * source_addr;\n\tMonoClass *src_class;\n\tMonoClass *dest_class;\n\tint i;\n\n\tMONO_ARCH_SAVE_REGS;\n\n\tif (source->obj.vtable->klass->rank != dest->obj.vtable->klass->rank)\n\t\treturn FALSE;\n\n\tif (source->bounds || dest->bounds)\n\t\treturn FALSE;\n\n\t/* there's no integer overflow since mono_array_length returns an unsigned integer */\n\tif ((dest_idx + length > mono_array_length (dest)) ||\n\t\t(source_idx + length > mono_array_length (source)))\n\t\treturn FALSE;\n\n\tsrc_class = source->obj.vtable->klass->element_class;\n\tdest_class = dest->obj.vtable->klass->element_class;\n\n\t/*\n\t * Handle common cases.\n\t */\n\n\t/* Case1: object[] -> valuetype[] (ArrayList::ToArray) */\n\tif (src_class == mono_defaults.object_class && dest_class->valuetype) {\n\t\tint has_refs = dest_class->has_references;\n\t\tfor (i = source_idx; i < source_idx + length; ++i) {\n\t\t\tMonoObject *elem = mono_array_get (source, MonoObject*, i);\n\t\t\tif (elem && !mono_object_isinst (elem, dest_class))\n\t\t\t\treturn FALSE;\n\t\t}\n\n\t\telement_size = mono_array_element_size (dest->obj.vtable->klass);\n\t\tmemset (mono_array_addr_with_size (dest, element_size, dest_idx), 0, element_size * length);\n\t\tfor (i = 0; i < length; ++i) {\n\t\t\tMonoObject *elem = mono_array_get (source, MonoObject*, source_idx + i);\n\t\t\tvoid *addr = mono_array_addr_with_size (dest, element_size, dest_idx + i);\n\t\t\tif (!elem)\n\t\t\t\tcontinue;\n\t\t\tif (has_refs)\n\t\t\t\tmono_value_copy (addr, (char *)elem + sizeof (MonoObject), dest_class);\n\t\t\telse\n\t\t\t\tmemcpy (addr, (char *)elem + sizeof (MonoObject), element_size);\n\t\t}\n\t\treturn TRUE;\n\t}\n\n\t/* Check if we're copying a char[] <==> (u)short[] */\n\tif (src_class != dest_class) {\n\t\tif (dest_class->valuetype || dest_class->enumtype || src_class->valuetype || src_class->enumtype)\n\t\t\treturn FALSE;\n\n\t\tif (mono_class_is_subclass_of (src_class, dest_class, FALSE))\n\t\t\t;\n\t\t/* Case2: object[] -> reftype[] (ArrayList::ToArray) */\n\t\telse if (mono_class_is_subclass_of (dest_class, src_class, FALSE))\n\t\t\tfor (i = source_idx; i < source_idx + length; ++i) {\n\t\t\t\tMonoObject *elem = mono_array_get (source, MonoObject*, i);\n\t\t\t\tif (elem && !mono_object_isinst (elem, dest_class))\n\t\t\t\t\treturn FALSE;\n\t\t\t}\n\t\telse\n\t\t\treturn FALSE;\n\t}\n\n\tif (dest_class->valuetype) {\n\t\telement_size = mono_array_element_size (source->obj.vtable->klass);\n\t\tsource_addr = mono_array_addr_with_size (source, element_size, source_idx);\n\t\tif (dest_class->has_references) {\n\t\t\tmono_value_copy_array (dest, dest_idx, source_addr, length);\n\t\t} else {\n\t\t\tdest_addr = mono_array_addr_with_size (dest, element_size, dest_idx);\n\t\t\tmemmove (dest_addr, source_addr, element_size * length);\n\t\t}\n\t} else {\n\t\tmono_array_memcpy_refs (dest, dest_idx, source, source_idx, length);\n\t}\n\n\treturn TRUE;\n}",
        "commit_message": "Disable some of the FastCopy fast paths since they are racy.",
        "cve_desc": "The RuntimeHelpers.InitializeArray method in metadata/icall.c in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, does not properly restrict data types, which allows remote attackers to modify internal read-only data structures, and cause a denial of service (plugin crash) or corrupt the internal state of the security manager, via a crafted media file, as demonstrated by modifying a C# struct.",
        "target": 1
      },
      {
        "idx": 212789,
        "reasoning": "This code is vulnerable because it frees resources (`synch_cs` and `name`) associated with a thread *after* the thread itself has been closed via `CloseHandle(thread)`. Accessing these freed members in other parts of the system after the thread is considered \"dead\" can lead to crashes or, as the CVE describes, corruption of internal data structures if other code attempts to interact with the now-invalid thread object.",
        "func": "void ves_icall_System_Threading_InternalThread_Thread_free_internal (MonoInternalThread *this, HANDLE thread)\n{\n\tMONO_ARCH_SAVE_REGS;\n\n\tTHREAD_DEBUG (g_message (\"%s: Closing thread %p, handle %p\", __func__, this, thread));\n\n\tif (thread)\n\t\tCloseHandle (thread);\n\n\tif (this->synch_cs) {\n\t\tDeleteCriticalSection (this->synch_cs);\n\t\tg_free (this->synch_cs);\n\t\tthis->synch_cs = NULL;\n\t}\n\n\tg_free (this->name);\n}",
        "commit_message": "Fix access to freed members of a dead thread\n\n* threads.c: Fix access to freed members of a dead thread. Found\nand fixed by Rodrigo Kumpera <rkumpera@novell.com>\nRef: CVE-2011-0992",
        "cve_desc": "The RuntimeHelpers.InitializeArray method in metadata/icall.c in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, does not properly restrict data types, which allows remote attackers to modify internal read-only data structures, and cause a denial of service (plugin crash) or corrupt the internal state of the security manager, via a crafted media file, as demonstrated by modifying a C# struct.",
        "target": 1
      },
      {
        "idx": 214165,
        "reasoning": "This code is vulnerable because it lacks sufficient validation of the provided `types` array used to instantiate generic methods, potentially allowing attackers to bypass generic constraints. By supplying crafted type arguments, an attacker could instantiate a generic method with types that violate its intended restrictions, leading to potential arbitrary code execution as described in CVE-2023-42893.",
        "func": "MonoReflectionMethod*\nmono_reflection_bind_generic_method_parameters (MonoReflectionMethod *rmethod, MonoArray *types)\n{\n\tMonoClass *klass;\n\tMonoMethod *method, *inflated;\n\tMonoMethodInflated *imethod;\n\tMonoGenericContext tmp_context;\n\tMonoGenericInst *ginst;\n\tMonoType **type_argv;\n\tint count, i;\n\n\tMONO_ARCH_SAVE_REGS;\n\n\tif (!strcmp (rmethod->object.vtable->klass->name, \"MethodBuilder\")) {\n#ifndef DISABLE_REFLECTION_EMIT\n\t\tMonoReflectionMethodBuilder *mb = NULL;\n\t\tMonoReflectionTypeBuilder *tb;\n\t\tMonoClass *klass;\n\n\t\tmb = (MonoReflectionMethodBuilder *) rmethod;\n\t\ttb = (MonoReflectionTypeBuilder *) mb->type;\n\t\tklass = mono_class_from_mono_type (mono_reflection_type_get_handle ((MonoReflectionType*)tb));\n\n\t\tmethod = methodbuilder_to_mono_method (klass, mb);\n#else\n\t\tg_assert_not_reached ();\n\t\tmethod = NULL;\n#endif\n\t} else {\n\t\tmethod = rmethod->method;\n\t}\n\n\tklass = method->klass;\n\n\tif (method->is_inflated)\n\t\tmethod = ((MonoMethodInflated *) method)->declaring;\n\n\tcount = mono_method_signature (method)->generic_param_count;\n\tif (count != mono_array_length (types))\n\t\treturn NULL;\n\n\ttype_argv = g_new0 (MonoType *, count);\n\tfor (i = 0; i < count; i++) {\n\t\tMonoReflectionType *garg = mono_array_get (types, gpointer, i);\n\t\ttype_argv [i] = mono_reflection_type_get_handle (garg);\n\t}\n\tginst = mono_metadata_get_generic_inst (count, type_argv);\n\tg_free (type_argv);\n\n\ttmp_context.class_inst = klass->generic_class ? klass->generic_class->context.class_inst : NULL;\n\ttmp_context.method_inst = ginst;\n\n\tinflated = mono_class_inflate_generic_method (method, &tmp_context);\n\timethod = (MonoMethodInflated *) inflated;\n\n\tif (method->klass->image->dynamic) {\n\t\tMonoDynamicImage *image = (MonoDynamicImage*)method->klass->image;\n\t\t/*\n\t\t * This table maps metadata structures representing inflated methods/fields\n\t\t * to the reflection objects representing their generic definitions.\n\t\t */\n\t\tmono_loader_lock ();\n\t\tmono_g_hash_table_insert (image->generic_def_objects, imethod, rmethod);\n\t\tmono_loader_unlock ();\n\t}\n\t\n\treturn mono_method_get_object (mono_object_domain (rmethod), inflated, NULL);",
        "commit_message": "Handle invalid instantiation of generic methods.\n\n\t* verify.c: Add new function to internal verifier API to check\n\tmethod instantiations.\n\n\t* reflection.c (mono_reflection_bind_generic_method_parameters):\n\tCheck the instantiation before returning it.\n\n\tFixes #655847",
        "cve_desc": "Mono, when Moonlight before 2.3.0.1 or 2.99.x before 2.99.0.10 is used, does not properly validate arguments to generic methods, which allows remote attackers to bypass generic constraints, and possibly execute arbitrary code, via a crafted method call.",
        "target": 1
      },
      {
        "idx": 214584,
        "reasoning": "This code is vulnerable because it allows initialization of arrays with reference types or value types containing references, which can lead to modification of internal data structures. Specifically, the initial check to prevent reference types is bypassed in certain scenarios, allowing a crafted media file to corrupt the security manager's internal state as described in the CVE.",
        "func": "ves_icall_System_Runtime_CompilerServices_RuntimeHelpers_InitializeArray (MonoArray *array, MonoClassField *field_handle)\n{\n\tMonoClass *klass = array->obj.vtable->klass;\n\tguint32 size = mono_array_element_size (klass);\n\tMonoType *type = mono_type_get_underlying_type (&klass->element_class->byval_arg);\n\tint align;\n\tconst char *field_data;\n\n\tif (MONO_TYPE_IS_REFERENCE (type) ||\n\t\t\t(type->type == MONO_TYPE_VALUETYPE &&\n\t\t\t\t(!mono_type_get_class (type) ||\n\t\t\t\tmono_type_get_class (type)->has_references))) {\n\t\tMonoException *exc = mono_get_exception_argument(\"array\",\n\t\t\t\"Cannot initialize array containing references\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tif (!(field_handle->type->attrs & FIELD_ATTRIBUTE_HAS_FIELD_RVA)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field doesn't have an RVA\");\n\t\tmono_raise_exception (exc);\n\t}\n\n\tsize *= array->max_length;\n\tfield_data = mono_field_get_data (field_handle);\n\n\tif (size > mono_type_size (field_handle->type, &align)) {\n\t\tMonoException *exc = mono_get_exception_argument(\"field_handle\",\n\t\t\t\"Field not large enough to fill array\");\n\t\tmono_raise_exception (exc);\n\t}\n\n#if G_BYTE_ORDER != G_LITTLE_ENDIAN\n#define SWAP(n) {\\\n\tguint ## n *data = (guint ## n *) mono_array_addr (array, char, 0); \\\n\tguint ## n *src = (guint ## n *) field_data; \\\n\tguint ## n *end = (guint ## n *)((char*)src + size); \\\n\\\n\tfor (; src < end; data++, src++) { \\\n\t\t*data = read ## n (src); \\\n\t} \\\n}\n\n\t/* printf (\"Initialize array with elements of %s type\\n\", klass->element_class->name); */\n\n\tswitch (type->type) {\n\tcase MONO_TYPE_CHAR:\n\tcase MONO_TYPE_I2:\n\tcase MONO_TYPE_U2:\n\t\tSWAP (16);\n\t\tbreak;\n\tcase MONO_TYPE_I4:\n\tcase MONO_TYPE_U4:\n\tcase MONO_TYPE_R4:\n\t\tSWAP (32);\n\t\tbreak;\n\tcase MONO_TYPE_I8:\n\tcase MONO_TYPE_U8:\n\tcase MONO_TYPE_R8:\n\t\tSWAP (64);\n\t\tbreak;\n\tdefault:\n\t\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n\t\tbreak;\n\t}\n#else\n\tmemcpy (mono_array_addr (array, char, 0), field_data, size);\n#ifdef ARM_FPU_FPA\n\tif (klass->element_class->byval_arg.type == MONO_TYPE_R8) {\n\t\tgint i;\n\t\tdouble tmp;\n\t\tdouble *data = (double*)mono_array_addr (array, double, 0);\n\n\t\tfor (i = 0; i < size; i++, data++) {\n\t\t\treadr8 (data, &tmp);\n\t\t\t*data = tmp;\n\t\t}\n\t}\n#endif\n#endif\n}",
        "commit_message": "Allow only primitive types/enums in RuntimeHelpers.InitializeArray ().",
        "cve_desc": "The RuntimeHelpers.InitializeArray method in metadata/icall.c in Mono, when Moonlight 2.x before 2.4.1 or 3.x before 3.99.3 is used, does not properly restrict data types, which allows remote attackers to modify internal read-only data structures, and cause a denial of service (plugin crash) or corrupt the internal state of the security manager, via a crafted media file, as demonstrated by modifying a C# struct.",
        "target": 1
      }
    ]
  },
  "mpv": {
    "0": [],
    "1": []
  },
  "mruby": {
    "0": [
      {
        "idx": 60626,
        "reasoning": "This code snippet appears safe as it focuses on managing the gray list during garbage collection, specifically adding objects to be revisited. The commit message indicates a fix related to freeing objects and potential stack references, but the code itself doesn't demonstrate any direct vulnerabilities like memory corruption or control flow issues; it's a defensive measure *against* potential issues arising from object freeing elsewhere.\n\n\n\n",
        "func": "add_gray_list(mrb_state *mrb, mrb_gc *gc, struct RBasic *obj)\n{\n#ifdef MRB_GC_STRESS\n  if (obj->tt > MRB_TT_MAXDEFINE) {\n    abort();\n  }\n#endif\n  paint_gray(obj);\n  obj->gcnext = gc->gray_list;\n  gc->gray_list = obj;\n}\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 0
      },
      {
        "idx": 60627,
        "reasoning": "This code is safe and doesn't introduce any immediately obvious vulnerabilities. The commit message and code snippet indicate a fix to clear a stack region potentially holding references to freed objects, which is a good practice for memory safety and preventing use-after-free issues \u2013 it's *resolving* a potential problem, not *creating* one. \n\n\n\n",
        "func": "add_heap(mrb_state *mrb, mrb_gc *gc)\n{\n  mrb_heap_page *page = (mrb_heap_page *)mrb_calloc(mrb, 1, sizeof(mrb_heap_page) + MRB_HEAP_PAGE_SIZE * sizeof(RVALUE));\n  RVALUE *p, *e;\n  struct RBasic *prev = NULL;\n\n  for (p = objects(page), e=p+MRB_HEAP_PAGE_SIZE; p<e; p++) {\n    p->as.free.tt = MRB_TT_FREE;\n    p->as.free.next = prev;\n    prev = &p->as.basic;\n  }\n  page->freelist = prev;\n\n  link_heap_page(gc, page);\n  link_free_heap_page(gc, page);\n}\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 0
      },
      {
        "idx": 60628,
        "reasoning": "This code appears safe as it focuses on garbage collection state management and clearing potentially dangling references in specific GC modes. The commit message explicitly addresses freeing objects and clearing related stack regions, indicating a proactive effort to *prevent* vulnerabilities related to use-after-free, rather than introducing one.",
        "func": "change_gen_gc_mode(mrb_state *mrb, mrb_gc *gc, mrb_bool enable)\n{\n  if (is_generational(gc) && !enable) {\n    clear_all_old(mrb, gc);\n    mrb_assert(gc->state == MRB_GC_STATE_ROOT);\n    gc->full = FALSE;\n  }\n  else if (!is_generational(gc) && enable) {\n    incremental_gc_until(mrb, gc, MRB_GC_STATE_ROOT);\n    gc->majorgc_old_threshold = gc->live_after_mark/100 * DEFAULT_MAJOR_GC_INC_RATIO;\n    gc->full = FALSE;\n  }\n  gc->generational = enable;\n}\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 0
      },
      {
        "idx": 60629,
        "reasoning": "This code snippet addresses a garbage collection issue by clearing unused stack regions that might hold references to freed objects, preventing potential use-after-free scenarios. The fix focuses on ensuring proper GC state transitions and sweeping dead objects, which is a defensive programming practice and doesn't introduce new vulnerabilities based on the provided context.\n\n\n\n",
        "func": "clear_all_old(mrb_state *mrb, mrb_gc *gc)\n{\n  mrb_bool origin_mode = gc->generational;\n\n  mrb_assert(is_generational(gc));\n  if (is_major_gc(gc)) {\n    /* finish the half baked GC */\n    incremental_gc_until(mrb, gc, MRB_GC_STATE_ROOT);\n  }\n\n  /* Sweep the dead objects, then reset all the live objects\n   * (including all the old objects, of course) to white. */\n  gc->generational = FALSE;\n  prepare_incremental_sweep(mrb, gc);\n  incremental_gc_until(mrb, gc, MRB_GC_STATE_ROOT);\n  gc->generational = origin_mode;\n\n  /* The gray objects have already been painted as white */\n  gc->atomic_gray_list = gc->gray_list = NULL;\n}\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 0
      },
      {
        "idx": 60630,
        "reasoning": "This code is intended to safely free heap memory in mruby by iterating through heap pages and explicitly freeing objects that haven't already been marked as free. The commit message explicitly states it addresses issue #3596 by clearing a stack region potentially referencing freed objects, indicating a proactive measure to prevent use-after-free issues rather than a current vulnerability\u2014therefore, it's not flagged as vulnerable based on the provided snippet and context.\n",
        "func": "free_heap(mrb_state *mrb, mrb_gc *gc)\n{\n  mrb_heap_page *page = gc->heaps;\n  mrb_heap_page *tmp;\n  RVALUE *p, *e;\n\n  while (page) {\n    tmp = page;\n    page = page->next;\n    for (p = objects(tmp), e=p+MRB_HEAP_PAGE_SIZE; p<e; p++) {\n      if (p->as.free.tt != MRB_TT_FREE)\n        obj_free(mrb, &p->as.basic, TRUE);\n    }\n    mrb_free(mrb, tmp);\n  }\n}\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 2758,
        "reasoning": "This code is vulnerable because it attempts to clear potentially freed objects from the stack, but doesn't fully prevent use-after-free scenarios; specifically, it only nulls out values *if* they are already marked as free, leaving a window where a dangling pointer could still be dereferenced before garbage collection. The CVE confirms this allows attackers to craft input that triggers a use-after-free by manipulating object lifetimes and stack references, leading to a crash or potentially exploitable behavior.",
        "func": "mark_context_stack(mrb_state *mrb, struct mrb_context *c)\n {\n   size_t i;\n   size_t e;\n \n   if (c->stack == NULL) return;\n   e = c->stack - c->stbase;\n  if (c->ci) e += c->ci->nregs;\n  if (c->stbase + e > c->stend) e = c->stend - c->stbase;\n  for (i=0; i<e; i++) {\n     mrb_value v = c->stbase[i];\n \n     if (!mrb_immediate_p(v)) {\n      if (mrb_basic_ptr(v)->tt == MRB_TT_FREE) {\n        c->stbase[i] = mrb_nil_value();\n      }\n      else {\n        mrb_gc_mark(mrb, mrb_basic_ptr(v));\n      }\n     }\n   }\n }\n",
        "commit_message": "Clear unused stack region that may refer freed objects; fix #3596",
        "cve_desc": "The mark_context_stack function in gc.c in mruby through 1.2.0 allows attackers to cause a denial of service (heap-based use-after-free and application crash) or possibly have unspecified other impact via a crafted .rb file.",
        "target": 1
      },
      {
        "idx": 3688,
        "reasoning": "The `mrb_class_real` function doesn't handle the case where `cl->super` becomes NULL during the loop, leading to a NULL pointer dereference. This occurs specifically when dealing with `BasicObject` due to its class hierarchy, as described in CVE-2023-23978, causing a crash or potentially exploitable behavior.",
        "func": " mrb_class_real(struct RClass* cl)\n {\n  if (cl == 0)\n    return NULL;\n   while ((cl->tt == MRB_TT_SCLASS) || (cl->tt == MRB_TT_ICLASS)) {\n     cl = cl->super;\n   }\n   return cl;\n }\n",
        "commit_message": "`mrb_class_real()` did not work for `BasicObject`; fix #4037",
        "cve_desc": "An issue was discovered in mruby 1.4.1. There is a NULL pointer dereference in mrb_class_real because \"class BasicObject\" is not properly supported in class.c.",
        "target": 1
      },
      {
        "idx": 3689,
        "reasoning": "This code is vulnerable to a heap-based buffer over-read because it fails to adequately extend the fiber's stack when a large number of arguments are passed. Specifically, the check `len >= c->stend - c->stack` prevents writing *past* the stack's current end, but doesn't *resize* the stack to accommodate the arguments, leading to a potential over-read when `fiber_switch_context` or subsequent execution accesses data beyond the allocated stack space.",
        "func": "fiber_switch(mrb_state *mrb, mrb_value self, mrb_int len, const mrb_value *a, mrb_bool resume, mrb_bool vmexec)\n {\n   struct mrb_context *c = fiber_check(mrb, self);\n   struct mrb_context *old_c = mrb->c;\n   mrb_value value;\n \n   fiber_check_cfunc(mrb, c);\n  if (resume && c->status == MRB_FIBER_TRANSFERRED) {\n     mrb_raise(mrb, E_FIBER_ERROR, \"resuming transferred fiber\");\n   }\n  if (c->status == MRB_FIBER_RUNNING || c->status == MRB_FIBER_RESUMED) {\n     mrb_raise(mrb, E_FIBER_ERROR, \"double resume (fib)\");\n   }\n  if (c->status == MRB_FIBER_TERMINATED) {\n     mrb_raise(mrb, E_FIBER_ERROR, \"resuming dead fiber\");\n   }\n  mrb->c->status = resume ? MRB_FIBER_RESUMED : MRB_FIBER_TRANSFERRED;\n   c->prev = resume ? mrb->c : (c->prev ? c->prev : mrb->root_c);\n  if (c->status == MRB_FIBER_CREATED) {\n     mrb_value *b, *e;\n \n    if (len >= c->stend - c->stack) {\n      mrb_raise(mrb, E_FIBER_ERROR, \"too many arguments to fiber\");\n    }\n     b = c->stack+1;\n     e = b + len;\n     while (b<e) {\n      *b++ = *a++;\n    }\n    c->cibase->argc = (int)len;\n    value = c->stack[0] = MRB_PROC_ENV(c->ci->proc)->stack[0];\n  }\n   else {\n     value = fiber_result(mrb, a, len);\n   }\n  fiber_switch_context(mrb, c);\n \n   if (vmexec) {\n     c->vmexec = TRUE;\n    value = mrb_vm_exec(mrb, c->ci[-1].proc, c->ci->pc);\n    mrb->c = old_c;\n  }\n  else {\n    MARK_CONTEXT_MODIFY(c);\n  }\n  return value;\n}\n",
        "commit_message": "Extend stack when pushing arguments that does not fit in; fix #4038",
        "cve_desc": "An issue was discovered in mruby 1.4.1. There is a heap-based buffer over-read associated with OP_ENTER because mrbgems/mruby-fiber/src/fiber.c does not extend the stack in cases of many arguments to fiber.",
        "target": 1
      },
      {
        "idx": 3690,
        "reasoning": "This code is vulnerable because it directly copies the `flags` field from the original object to the clone, including flags like the embedded flag, potentially leading to a NULL pointer dereference if the original object has flags that are invalid for a cloned object. Specifically, copying the embedded flag without proper checks, as described in the CVE, can cause issues when the clone attempts to use these inherited flags, resulting in a crash.",
        "func": "mrb_obj_clone(mrb_state *mrb, mrb_value self)\n{\n  struct RObject *p;\n  mrb_value clone;\n\n  if (mrb_immediate_p(self)) {\n    mrb_raisef(mrb, E_TYPE_ERROR, \"can't clone %S\", self);\n  }\n  if (mrb_type(self) == MRB_TT_SCLASS) {\n    mrb_raise(mrb, E_TYPE_ERROR, \"can't clone singleton class\");\n  }\n  p = (struct RObject*)mrb_obj_alloc(mrb, mrb_type(self), mrb_obj_class(mrb, self));\n  p->c = mrb_singleton_class_clone(mrb, self);\n   mrb_field_write_barrier(mrb, (struct RBasic*)p, (struct RBasic*)p->c);\n   clone = mrb_obj_value(p);\n   init_copy(mrb, clone, self);\n  p->flags = mrb_obj_ptr(self)->flags;\n \n   return clone;\n }\n",
        "commit_message": "Allow `Object#clone` to copy frozen status only; fix #4036\n\nCopying all flags from the original object may overwrite the clone's\nflags e.g. the embedded flag.",
        "cve_desc": "An issue was discovered in mruby 1.4.1. There is a NULL pointer dereference in mrb_class, related to certain .clone usage, because mrb_obj_clone in kernel.c copies flags other than the MRB_FLAG_IS_FROZEN flag (e.g., the embedded flag).",
        "target": 1
      },
      {
        "idx": 3693,
        "reasoning": "This code is vulnerable because it calls `initialize_copy` on `TT_ICLASS` objects, which are internal and should not be exposed to the Ruby world, leading to a crash due to uninitialized pointers like in `mrb_hash_keys`.  Specifically, the `initialize_copy` call attempts to operate on an internal object in a way it wasn't designed for, triggering the denial-of-service condition described in the CVE.",
        "func": " init_copy(mrb_state *mrb, mrb_value dest, mrb_value obj)\n {\n   switch (mrb_type(obj)) {\n     case MRB_TT_CLASS:\n     case MRB_TT_MODULE:\n       copy_class(mrb, dest, obj);\n      mrb_iv_copy(mrb, dest, obj);\n      mrb_iv_remove(mrb, dest, mrb_intern_lit(mrb, \"__classname__\"));\n      break;\n    case MRB_TT_OBJECT:\n    case MRB_TT_SCLASS:\n    case MRB_TT_HASH:\n    case MRB_TT_DATA:\n    case MRB_TT_EXCEPTION:\n      mrb_iv_copy(mrb, dest, obj);\n      break;\n    case MRB_TT_ISTRUCT:\n      mrb_istruct_copy(dest, obj);\n      break;\n\n    default:\n      break;\n  }\n  mrb_funcall(mrb, dest, \"initialize_copy\", 1, obj);\n}\n",
        "commit_message": "Should not call `initialize_copy` for `TT_ICLASS`; fix #4027\n\nSince `TT_ICLASS` is a internal object that should never be revealed\nto Ruby world.",
        "cve_desc": "The init_copy function in kernel.c in mruby 1.4.1 makes initialize_copy calls for TT_ICLASS objects, which allows attackers to cause a denial of service (mrb_hash_keys uninitialized pointer and application crash) or possibly have unspecified other impact.",
        "target": 1
      }
    ]
  },
  "mupdf": {
    "0": [
      {
        "idx": 354845,
        "reasoning": "This code snippet focuses on managing graphics state during PDF processing, specifically handling line join styles and stroke states. There's no immediately apparent vulnerability related to resource management, input validation, or control flow within this small function; it appears to be correctly managing state transitions and doesn't introduce any obvious security risks based on the provided context.\n\n\n\n",
        "func": "static void pdf_run_j(fz_context *ctx, pdf_processor *proc, int linejoin)\n{\n\tpdf_run_processor *pr = (pdf_run_processor *)proc;\n\tpdf_gstate *gstate = pdf_flush_text(ctx, pr);\n\n\tpr->dev->flags &= ~FZ_DEVFLAG_LINEJOIN_UNDEFINED;\n\tgstate->stroke_state = fz_unshare_stroke_state(ctx, gstate->stroke_state);\n\tgstate->stroke_state->linejoin = linejoin;\n}",
        "commit_message": "Bug 698890: Remember to end groups when showing images.",
        "cve_desc": "In MuPDF 1.12.0 and earlier, multiple reachable assertions in the PDF parser allow an attacker to cause a denial of service (assert crash) via a crafted file.",
        "target": 0
      },
      {
        "idx": 354846,
        "reasoning": "This code snippet is not flagged as vulnerable because it simply sets a render flag within a graphics state structure. There's no direct handling of external input, memory management, or operations that typically lead to vulnerabilities like buffer overflows or code injection; it's a straightforward state update related to text rendering.\n\n\n\n",
        "func": "static void pdf_run_Tr(fz_context *ctx, pdf_processor *proc, int render)\n{\n\tpdf_run_processor *pr = (pdf_run_processor *)proc;\n\tpdf_gstate *gstate = pr->gstate + pr->gtop;\n\tgstate->text.render = render;\n}",
        "commit_message": "Bug 698890: Remember to end groups when showing images.",
        "cve_desc": "In MuPDF 1.12.0 and earlier, multiple reachable assertions in the PDF parser allow an attacker to cause a denial of service (assert crash) via a crafted file.",
        "target": 0
      },
      {
        "idx": 354847,
        "reasoning": "This code snippet appears safe as it focuses on managing graphics state related to line caps during image rendering, specifically ensuring proper initialization and unsharing of stroke state. There's no immediately apparent input handling, memory management, or logical flaw that would suggest a vulnerability like buffer overflow, injection, or denial of service within this isolated function.\n\n\n\n",
        "func": "static void pdf_run_J(fz_context *ctx, pdf_processor *proc, int linecap)\n{\n\tpdf_run_processor *pr = (pdf_run_processor *)proc;\n\tpdf_gstate *gstate = pdf_flush_text(ctx, pr);\n\n\tpr->dev->flags &= ~(FZ_DEVFLAG_STARTCAP_UNDEFINED | FZ_DEVFLAG_DASHCAP_UNDEFINED | FZ_DEVFLAG_ENDCAP_UNDEFINED);\n\tgstate->stroke_state = fz_unshare_stroke_state(ctx, gstate->stroke_state);\n\tgstate->stroke_state->start_cap = linecap;\n\tgstate->stroke_state->dash_cap = linecap;\n\tgstate->stroke_state->end_cap = linecap;\n}",
        "commit_message": "Bug 698890: Remember to end groups when showing images.",
        "cve_desc": "In MuPDF 1.12.0 and earlier, multiple reachable assertions in the PDF parser allow an attacker to cause a denial of service (assert crash) via a crafted file.",
        "target": 0
      },
      {
        "idx": 354848,
        "reasoning": "This code addresses a bug where groups weren't being properly ended when displaying images, specifically within the context of soft masks and transparency. The commit implements a `cleanup_state` variable and `fz_always` block to ensure that resources like soft masks and groups are always closed, even if errors occur during processing, preventing resource leaks and potential crashes \u2013 thus, it's a fix, not introducing a vulnerability.\n",
        "func": "pdf_run_xobject(fz_context *ctx, pdf_run_processor *proc, pdf_xobject *xobj, pdf_obj *page_resources, const fz_matrix *transform, int is_smask)\n{\n\tpdf_run_processor *pr = (pdf_run_processor *)proc;\n\tpdf_gstate *gstate = NULL;\n\tint oldtop = 0;\n\tint oldbot = -1;\n\tfz_matrix local_transform = *transform;\n\tsoftmask_save softmask = { NULL };\n\tint gparent_save;\n\tfz_matrix gparent_save_ctm;\n\tint cleanup_state = 0;\n\tchar errmess[256] = \"\";\n\tpdf_obj *resources;\n\tfz_rect xobj_bbox;\n\tfz_matrix xobj_matrix;\n\tint transparency = 0;\n\tpdf_document *doc;\n\tfz_colorspace *cs = NULL;\n\tfz_default_colorspaces *saved_def_cs = NULL;\n\n\t/* Avoid infinite recursion */\n\tif (xobj == NULL || pdf_mark_obj(ctx, xobj->obj))\n\t\treturn;\n\n\tfz_var(cleanup_state);\n\tfz_var(gstate);\n\tfz_var(oldtop);\n\tfz_var(oldbot);\n\tfz_var(cs);\n\tfz_var(saved_def_cs);\n\n\tgparent_save = pr->gparent;\n\tpr->gparent = pr->gtop;\n\toldtop = pr->gtop;\n\n\tfz_try(ctx)\n\t{\n\t\tpdf_gsave(ctx, pr);\n\n\t\tgstate = pr->gstate + pr->gtop;\n\n\t\tpdf_xobject_bbox(ctx, xobj, &xobj_bbox);\n\t\tpdf_xobject_matrix(ctx, xobj, &xobj_matrix);\n\t\ttransparency = pdf_xobject_transparency(ctx, xobj);\n\n\t\t/* apply xobject's transform matrix */\n\t\tfz_concat(&local_transform, &xobj_matrix, &local_transform);\n\t\tfz_concat(&gstate->ctm, &local_transform, &gstate->ctm);\n\n\t\t/* The gparent is updated with the modified ctm */\n\t\tgparent_save_ctm = pr->gstate[pr->gparent].ctm;\n\t\tpr->gstate[pr->gparent].ctm = gstate->ctm;\n\n\t\t/* apply soft mask, create transparency group and reset state */\n\t\tif (transparency)\n\t\t{\n\t\t\tfz_rect bbox;\n\t\t\tint isolated = pdf_xobject_isolated(ctx, xobj);\n\n\t\t\tbbox = xobj_bbox;\n\t\t\tfz_transform_rect(&bbox, &gstate->ctm);\n\n\t\t\t/* Remember that we tried to call begin_softmask. Even\n\t\t\t * if it throws an error, we must call end_softmask. */\n\t\t\tcleanup_state = 1;\n\t\t\tgstate = begin_softmask(ctx, pr, &softmask);\n\n\t\t\t/* Remember that we tried to call fz_begin_group. Even\n\t\t\t * if it throws an error, we must call fz_end_group. */\n\t\t\tcleanup_state = 2;\n\t\t\tif (isolated)\n\t\t\t\tcs = pdf_xobject_colorspace(ctx, xobj);\n\t\t\tfz_begin_group(ctx, pr->dev, &bbox,\n\t\t\t\t\tcs,\n\t\t\t\t\t(is_smask ? 1 : isolated),\n\t\t\t\t\tpdf_xobject_knockout(ctx, xobj),\n\t\t\t\t\tgstate->blendmode, gstate->fill.alpha);\n\n\t\t\tgstate->blendmode = 0;\n\t\t\tgstate->stroke.alpha = 1;\n\t\t\tgstate->fill.alpha = 1;\n\t\t}\n\n\t\t/* Remember that we tried to save for the clippath. Even if it\n\t\t * throws an error, we must pop it. */\n\t\tcleanup_state = 3;\n\t\tpdf_gsave(ctx, pr); /* Save here so the clippath doesn't persist */\n\n\t\t/* clip to the bounds */\n\t\tfz_moveto(ctx, pr->path, xobj_bbox.x0, xobj_bbox.y0);\n\t\tfz_lineto(ctx, pr->path, xobj_bbox.x1, xobj_bbox.y0);\n\t\tfz_lineto(ctx, pr->path, xobj_bbox.x1, xobj_bbox.y1);\n\t\tfz_lineto(ctx, pr->path, xobj_bbox.x0, xobj_bbox.y1);\n\t\tfz_closepath(ctx, pr->path);\n\t\tpr->clip = 1;\n\t\tpdf_show_path(ctx, pr, 0, 0, 0, 0);\n\n\t\t/* run contents */\n\n\t\tresources = pdf_xobject_resources(ctx, xobj);\n\t\tif (!resources)\n\t\t\tresources = page_resources;\n\n\t\tsaved_def_cs = pr->default_cs;\n\t\tpr->default_cs = NULL;\n\t\tpr->default_cs = pdf_update_default_colorspaces(ctx, saved_def_cs, resources);\n\n\t\tif (pr->default_cs != saved_def_cs)\n\t\t\tfz_set_default_colorspaces(ctx, pr->dev, pr->default_cs);\n\n\t\tdoc = pdf_get_bound_document(ctx, xobj->obj);\n\n\t\toldbot = pr->gbot;\n\t\tpr->gbot = pr->gtop;\n\n\t\tpdf_process_contents(ctx, (pdf_processor*)pr, doc, resources, xobj->obj, NULL);\n\t}\n\tfz_always(ctx)\n\t{\n\t\tfz_drop_colorspace(ctx, cs);\n\n\t\tif (saved_def_cs)\n\t\t{\n\t\t\tfz_drop_default_colorspaces(ctx, pr->default_cs);\n\t\t\tpr->default_cs = saved_def_cs;\n\t\t\tfz_try(ctx)\n\t\t\t{\n\t\t\t\tfz_set_default_colorspaces(ctx, pr->dev, pr->default_cs);\n\t\t\t}\n\t\t\tfz_catch(ctx)\n\t\t\t{\n\t\t\t\t/* Postpone the problem */\n\t\t\t\tstrcpy(errmess, fz_caught_message(ctx));\n\t\t\t}\n\t\t}\n\n\t\t/* Undo any gstate mismatches due to the pdf_process_contents call */\n\t\tif (oldbot != -1)\n\t\t{\n\t\t\twhile (pr->gtop > pr->gbot)\n\t\t\t{\n\t\t\t\tpdf_grestore(ctx, pr);\n\t\t\t}\n\t\t\tpr->gbot = oldbot;\n\t\t}\n\n\t\tif (cleanup_state >= 3)\n\t\t\tpdf_grestore(ctx, pr); /* Remove the state we pushed for the clippath */\n\n\t\t/* wrap up transparency stacks */\n\t\tif (transparency)\n\t\t{\n\t\t\tif (cleanup_state >= 2)\n\t\t\t{\n\t\t\t\tfz_try(ctx)\n\t\t\t\t{\n\t\t\t\t\tfz_end_group(ctx, pr->dev);\n\t\t\t\t}\n\t\t\t\tfz_catch(ctx)\n\t\t\t\t{\n\t\t\t\t\t/* Postpone the problem */\n\t\t\t\t\tif (errmess[0])\n\t\t\t\t\t\tfz_warn(ctx, \"%s\", errmess);\n\t\t\t\t\tstrcpy(errmess, fz_caught_message(ctx));\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (cleanup_state >= 1)\n\t\t\t{\n\t\t\t\tfz_try(ctx)\n\t\t\t\t{\n\t\t\t\t\tend_softmask(ctx, pr, &softmask);\n\t\t\t\t}\n\t\t\t\tfz_catch(ctx)\n\t\t\t\t{\n\t\t\t\t\t/* Postpone the problem */\n\t\t\t\t\tif (errmess[0])\n\t\t\t\t\t\tfz_warn(ctx, \"%s\", errmess);\n\t\t\t\t\tstrcpy(errmess, fz_caught_message(ctx));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\tpr->gstate[pr->gparent].ctm = gparent_save_ctm;\n\t\tpr->gparent = gparent_save;\n\n\t\twhile (oldtop < pr->gtop)\n\t\t\tpdf_grestore(ctx, pr);\n\n\t\tpdf_unmark_obj(ctx, xobj->obj);\n\t}\n\tfz_catch(ctx)\n\t{\n\t\tfz_rethrow(ctx);\n\t}\n\n\t/* Rethrow postponed errors */\n\tif (errmess[0])\n\t\tfz_throw(ctx, FZ_ERROR_GENERIC, \"%s\", errmess);\n}",
        "commit_message": "Bug 698890: Remember to end groups when showing images.",
        "cve_desc": "In MuPDF 1.12.0 and earlier, multiple reachable assertions in the PDF parser allow an attacker to cause a denial of service (assert crash) via a crafted file.",
        "target": 0
      },
      {
        "idx": 354849,
        "reasoning": "This code snippet is safe as it primarily focuses on copying and retaining references to existing objects (fonts, xobjects, stroke states) within the PDF document's graphics state, rather than creating or modifying them in a way that could lead to vulnerabilities. The function ensures proper resource management by dropping old references before keeping new ones, preventing potential memory leaks but not introducing exploitable flaws.\n\n\n\n",
        "func": "pdf_copy_pattern_gstate(fz_context *ctx, pdf_gstate *gs, const pdf_gstate *old)\n{\n\tgs->ctm = old->ctm;\n\n\tpdf_drop_font(ctx, gs->text.font);\n\tgs->text.font = pdf_keep_font(ctx, old->text.font);\n\n\tpdf_drop_xobject(ctx, gs->softmask);\n\tgs->softmask = pdf_keep_xobject(ctx, old->softmask);\n\n\tfz_drop_stroke_state(ctx, gs->stroke_state);\n\tgs->stroke_state = fz_keep_stroke_state(ctx, old->stroke_state);\n}",
        "commit_message": "Bug 698890: Remember to end groups when showing images.",
        "cve_desc": "In MuPDF 1.12.0 and earlier, multiple reachable assertions in the PDF parser allow an attacker to cause a denial of service (assert crash) via a crafted file.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 211586,
        "reasoning": "The `xps_parse_color` function is vulnerable to a stack-based buffer overflow because it reads an unbounded number of color samples from the `ContextColor` string without checking if the number of samples exceeds the allocated buffer size (`samples`). This allows a malicious actor to provide a crafted XPS file with a large number of comma-separated values in the `ContextColor` attribute, overwriting adjacent stack memory and potentially executing arbitrary code.",
        "func": "xps_parse_color(xps_document *doc, char *base_uri, char *string,\n\t\tfz_colorspace **csp, float *samples)\n{\n\tchar *p;\n\tint i, n;\n\tchar buf[1024];\n\tchar *profile;\n\n\t*csp = fz_device_rgb(doc->ctx);\n\n\tsamples[0] = 1;\n\tsamples[1] = 0;\n\tsamples[2] = 0;\n\tsamples[3] = 0;\n\n\tif (string[0] == '#')\n\t{\n\t\tif (strlen(string) == 9)\n\t\t{\n\t\t\tsamples[0] = unhex(string[1]) * 16 + unhex(string[2]);\n\t\t\tsamples[1] = unhex(string[3]) * 16 + unhex(string[4]);\n\t\t\tsamples[2] = unhex(string[5]) * 16 + unhex(string[6]);\n\t\t\tsamples[3] = unhex(string[7]) * 16 + unhex(string[8]);\n\t\t}\n\t\telse\n\t\t{\n\t\t\tsamples[0] = 255;\n\t\t\tsamples[1] = unhex(string[1]) * 16 + unhex(string[2]);\n\t\t\tsamples[2] = unhex(string[3]) * 16 + unhex(string[4]);\n\t\t\tsamples[3] = unhex(string[5]) * 16 + unhex(string[6]);\n\t\t}\n\n\t\tsamples[0] /= 255;\n\t\tsamples[1] /= 255;\n\t\tsamples[2] /= 255;\n\t\tsamples[3] /= 255;\n\t}\n\n\telse if (string[0] == 's' && string[1] == 'c' && string[2] == '#')\n\t{\n\t\tif (count_commas(string) == 2)\n\t\t\tsscanf(string, \"sc#%g,%g,%g\", samples + 1, samples + 2, samples + 3);\n\t\tif (count_commas(string) == 3)\n\t\t\tsscanf(string, \"sc#%g,%g,%g,%g\", samples, samples + 1, samples + 2, samples + 3);\n\t}\n\n\telse if (strstr(string, \"ContextColor \") == string)\n\t{\n\t\t/* Crack the string for profile name and sample values */\n\t\tfz_strlcpy(buf, string, sizeof buf);\n\n\t\tprofile = strchr(buf, ' ');\n\t\tif (!profile)\n\t\t{\n\t\t\tfz_warn(doc->ctx, \"cannot find icc profile uri in '%s'\", string);\n\t\t\treturn;\n\t\t}\n\n\t\t*profile++ = 0;\n\t\tp = strchr(profile, ' ');\n\t\tif (!p)\n\t\t{\n\t\t\tfz_warn(doc->ctx, \"cannot find component values in '%s'\", profile);\n\t\t\treturn;\n\t\t}\n\n\t\t*p++ = 0;\n\t\tn = count_commas(p) + 1;\n\t\ti = 0;\n\t\twhile (i < n)\n\t\t{\n\t\t\tsamples[i++] = fz_atof(p);\n\t\t\tp = strchr(p, ',');\n\t\t\tif (!p)\n\t\t\t\tbreak;\n\t\t\tp ++;\n\t\t\tif (*p == ' ')\n\t\t\t\tp ++;\n\t\t}\n\t\twhile (i < n)\n\t\t{\n\t\t\tsamples[i++] = 0;\n\t\t}\n\n\t\t/* TODO: load ICC profile */\n\t\tswitch (n)\n\t\t{\n\t\tcase 2: *csp = fz_device_gray(doc->ctx); break;\n\t\tcase 4: *csp = fz_device_rgb(doc->ctx); break;\n\t\tcase 5: *csp = fz_device_cmyk(doc->ctx); break;\n\t\tdefault: *csp = fz_device_gray(doc->ctx); break;\n\t\t}\n\t}\n}",
        "commit_message": "Bug 694957: fix stack buffer overflow in xps_parse_color\n\nxps_parse_color happily reads more than FZ_MAX_COLORS values out of a\nContextColor array which overflows the passed in samples array.\nLimiting the number of allowed samples to FZ_MAX_COLORS and make sure\nto use that constant for all callers fixes the problem.\n\nThanks to Jean-Jamil Khalif\u00e9 for reporting and investigating the issue\nand providing a sample exploit file.",
        "cve_desc": "Stack-based buffer overflow in the xps_parse_color function in xps/xps-common.c in MuPDF 1.3 and earlier allows remote attackers to execute arbitrary code via a large number of entries in the ContextColor value of the Fill attribute in a Path element.",
        "target": 1
      },
      {
        "idx": 215036,
        "reasoning": "This code is vulnerable to a division by zero error because the calculation of `reps` relies on `min_band_mem`, which can be zero if `w` (page width) is zero. Consequently, when a page has zero width, `min_band_mem` becomes zero, leading to a division by zero when calculating `reps = (max_band_memory / min_band_mem)`.",
        "func": "initialise_banding(fz_context *ctx, render_details *render, int color)\n{\n\tsize_t min_band_mem;\n\tint bpp, h, w, reps;\n\n\trender->colorspace = output_cs;\n\trender->format = output_format;\n#if GREY_FALLBACK != 0\n\tif (color == 0)\n\t{\n\t\tif (render->colorspace == CS_RGB)\n\t\t{\n\t\t\t/* Fallback from PPM to PGM */\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\trender->format = OUT_PGM;\n\t\t}\n\t\telse if (render->colorspace == CS_CMYK)\n\t\t{\n\t\t\trender->colorspace = CS_GRAY;\n\t\t\tif (render->format == OUT_PKM)\n\t\t\t\trender->format = OUT_PBM;\n\t\t\telse\n\t\t\t\trender->format = OUT_PGM;\n\t\t}\n\t}\n#endif\n\n\tswitch (render->colorspace)\n\t{\n\tcase CS_GRAY:\n\t\tbpp = 1;\n\t\tbreak;\n\tcase CS_RGB:\n\t\tbpp = 2;\n\t\tbreak;\n\tdefault:\n\tcase CS_CMYK:\n\t\tbpp = 3;\n\t\tbreak;\n\t}\n\n\tw = render->ibounds.x1 - render->ibounds.x0;\n\tmin_band_mem = (size_t)bpp * w * min_band_height;\n\treps = (int)(max_band_memory / min_band_mem);\n\tif (reps < 1)\n\t\treps = 1;\n\n\t/* Adjust reps to even out the work between threads */\n\tif (render->num_workers > 0)\n\t{\n\t\tint runs, num_bands;\n\t\th = render->ibounds.y1 - render->ibounds.y0;\n\t\tnum_bands = (h + min_band_height - 1) / min_band_height;\n\t\t/* num_bands = number of min_band_height bands */\n\t\truns = (num_bands + reps-1) / reps;\n\t\t/* runs = number of worker runs of reps min_band_height bands */\n\t\truns = ((runs + render->num_workers - 1) / render->num_workers) * render->num_workers;\n\t\t/* runs = number of worker runs rounded up to make use of all our threads */\n\t\treps = (num_bands + runs - 1) / runs;\n\t}\n\n\trender->band_height_multiple = reps;\n\trender->bands_rendered = 0;\n\n\tif (output_format == OUT_PGM || output_format == OUT_PPM)\n\t{\n\t\trender->bander = fz_new_pnm_band_writer(ctx, out);\n\t\trender->n = output_format == OUT_PGM ? 1 : 3;\n\t}\n\telse if (output_format == OUT_PAM)\n\t{\n\t\trender->bander = fz_new_pam_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n\telse if (output_format == OUT_PBM)\n\t{\n\t\trender->bander = fz_new_pbm_band_writer(ctx, out);\n\t\trender->n = 1;\n\t}\n\telse if (output_format == OUT_PKM)\n\t{\n\t\trender->bander = fz_new_pkm_band_writer(ctx, out);\n\t\trender->n = 4;\n\t}\n}",
        "commit_message": "Bug 704834: Fix division by zero for zero width pages in muraster.",
        "cve_desc": "A Floating point exception (division-by-zero) flaw was found in Mupdf for zero width pages in muraster.c. It is fixed in Mupdf-1.20.0-rc1 upstream.",
        "target": 1
      }
    ]
  },
  "mutt": {
    "0": [
      {
        "idx": 296385,
        "reasoning": "This code addresses the vulnerability by explicitly checking for an unencrypted `PREAUTH` response and prompting the user to abort the connection if TLS isn't established, preventing a potential MITM attack. The fix reuses the `$ssl_starttls` quadoption to confirm with the user whether to proceed with an unencrypted connection after receiving a `PREAUTH` response, effectively mitigating the risk described in CVE-2014-2567 and CVE-2020-12398.",
        "func": "int imap_open_connection (IMAP_DATA* idata)\n{\n  if (mutt_socket_open (idata->conn) < 0)\n    return -1;\n\n  idata->state = IMAP_CONNECTED;\n\n  if (imap_cmd_step (idata) != IMAP_CMD_OK)\n  {\n    imap_close_connection (idata);\n    return -1;\n  }\n\n  if (ascii_strncasecmp (\"* OK\", idata->buf, 4) == 0)\n  {\n    if (ascii_strncasecmp (\"* OK [CAPABILITY\", idata->buf, 16)\n        && imap_check_capabilities (idata))\n      goto bail;\n#if defined(USE_SSL)\n    /* Attempt STARTTLS if available and desired. */\n    if (!idata->conn->ssf && (option(OPTSSLFORCETLS) ||\n                              mutt_bit_isset (idata->capabilities, STARTTLS)))\n    {\n      int rc;\n\n      if (option(OPTSSLFORCETLS))\n        rc = MUTT_YES;\n      else if ((rc = query_quadoption (OPT_SSLSTARTTLS,\n                                       _(\"Secure connection with TLS?\"))) == -1)\n\tgoto err_close_conn;\n      if (rc == MUTT_YES)\n      {\n\tif ((rc = imap_exec (idata, \"STARTTLS\", IMAP_CMD_FAIL_OK)) == -1)\n\t  goto bail;\n\tif (rc != -2)\n\t{\n\t  if (mutt_ssl_starttls (idata->conn))\n\t  {\n\t    mutt_error (_(\"Could not negotiate TLS connection\"));\n\t    mutt_sleep (1);\n\t    goto err_close_conn;\n\t  }\n\t  else\n\t  {\n\t    /* RFC 2595 demands we recheck CAPABILITY after TLS completes. */\n\t    if (imap_exec (idata, \"CAPABILITY\", 0))\n\t      goto bail;\n\t  }\n\t}\n      }\n    }\n\n    if (option(OPTSSLFORCETLS) && ! idata->conn->ssf)\n    {\n      mutt_error _(\"Encrypted connection unavailable\");\n      mutt_sleep (1);\n      goto err_close_conn;\n    }\n#endif\n  }\n  else if (ascii_strncasecmp (\"* PREAUTH\", idata->buf, 9) == 0)\n  {\n#if defined(USE_SSL)\n    /* An unencrypted PREAUTH response is most likely a MITM attack.\n     * Require a confirmation. */\n    if (!idata->conn->ssf)\n    {\n      if (option(OPTSSLFORCETLS) ||\n          (query_quadoption (OPT_SSLSTARTTLS,\n                             _(\"Abort unencrypted PREAUTH connection?\")) != MUTT_NO))\n      {\n        mutt_error _(\"Encrypted connection unavailable\");\n        mutt_sleep (1);\n        goto err_close_conn;\n      }\n    }\n#endif\n\n    idata->state = IMAP_AUTHENTICATED;\n    if (imap_check_capabilities (idata) != 0)\n      goto bail;\n    FREE (&idata->capstr);\n  }\n  else\n  {\n    imap_error (\"imap_open_connection()\", idata->buf);\n    goto bail;\n  }\n\n  return 0;\n\n#if defined(USE_SSL)\nerr_close_conn:\n  imap_close_connection (idata);\n#endif\nbail:\n  FREE (&idata->capstr);\n  return -1;\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 0
      },
      {
        "idx": 296386,
        "reasoning": "This code snippet is **not vulnerable** because it relates to managing IMAP flags and access rights, and doesn't handle connection establishment or encryption negotiation\u2014the areas addressed by the commit message regarding MITM prevention. The commit message specifically details a fix related to STARTTLS handling during authentication, which is entirely separate from the function's purpose of setting flags on existing, established connections.\n\n\n\n",
        "func": "static void imap_set_flag (IMAP_DATA* idata, int aclbit, int flag,\n                           const char *str, char *flags, size_t flsize)\n{\n  if (mutt_bit_isset (idata->ctx->rights, aclbit))\n    if (flag && imap_has_flag (idata->flags, str))\n      safe_strcat (flags, flsize, str);\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 0
      },
      {
        "idx": 296387,
        "reasoning": "This code is safe with respect to the vulnerability described in the commit message. The commit message states the fix reuses the `$ssl_starttls` quadoption to prompt to abort the connection if unencrypted, preventing the MITM attack by ensuring encryption is properly checked and enforced before proceeding with operations like sending messages via postpone or forwarding. \n\n\n\n",
        "func": "int imap_sync_mailbox (CONTEXT* ctx, int expunge, int* index_hint)\n{\n  IMAP_DATA* idata;\n  CONTEXT* appendctx = NULL;\n  HEADER* h;\n  HEADER** hdrs = NULL;\n  int oldsort;\n  int n;\n  int rc, quickdel_rc = 0;\n\n  idata = (IMAP_DATA*) ctx->data;\n\n  if (idata->state < IMAP_SELECTED)\n  {\n    dprint (2, (debugfile, \"imap_sync_mailbox: no mailbox selected\\n\"));\n    return -1;\n  }\n\n  /* This function is only called when the calling code expects the context\n   * to be changed. */\n  imap_allow_reopen (ctx);\n\n  if ((rc = imap_check_mailbox (ctx, index_hint, 0)) != 0)\n    goto out;\n\n  /* if we are expunging anyway, we can do deleted messages very quickly... */\n  if (expunge && mutt_bit_isset (ctx->rights, MUTT_ACL_DELETE))\n  {\n    if ((quickdel_rc = imap_exec_msgset (idata,\n                                         \"UID STORE\", \"+FLAGS.SILENT (\\\\Deleted)\",\n                                         MUTT_DELETED, 1, 0)) < 0)\n    {\n      rc = quickdel_rc;\n      mutt_error (_(\"Expunge failed\"));\n      mutt_sleep (1);\n      goto out;\n    }\n\n    if (quickdel_rc > 0)\n    {\n      /* mark these messages as unchanged so second pass ignores them. Done\n       * here so BOGUS UW-IMAP 4.7 SILENT FLAGS updates are ignored. */\n      for (n = 0; n < ctx->msgcount; n++)\n        if (ctx->hdrs[n]->deleted && ctx->hdrs[n]->changed)\n          ctx->hdrs[n]->active = 0;\n      if (!ctx->quiet)\n        mutt_message (_(\"Marking %d messages deleted...\"), quickdel_rc);\n    }\n  }\n\n#if USE_HCACHE\n  idata->hcache = imap_hcache_open (idata, NULL);\n#endif\n\n  /* save messages with real (non-flag) changes */\n  for (n = 0; n < ctx->msgcount; n++)\n  {\n    h = ctx->hdrs[n];\n\n    if (h->deleted)\n    {\n      imap_cache_del (idata, h);\n#if USE_HCACHE\n      imap_hcache_del (idata, HEADER_DATA(h)->uid);\n#endif\n    }\n\n    if (h->active && h->changed)\n    {\n#if USE_HCACHE\n      imap_hcache_put (idata, h);\n#endif\n      /* if the message has been rethreaded or attachments have been deleted\n       * we delete the message and reupload it.\n       * This works better if we're expunging, of course. */\n      /* TODO: why the h->env check? */\n      if ((h->env && h->env->changed) || h->attach_del)\n      {\n        /* NOTE and TODO:\n         *\n         * The mx_open_mailbox() in append mode below merely hijacks an existing\n         * idata; it doesn't reset idata->ctx.  imap_append_message() ends up\n         * using (borrowing) the same idata we are using.\n         *\n         * Right after the APPEND operation finishes, the server can send an\n         * EXISTS notifying of the new message.  Then, while still inside\n         * imap_append_message(), imap_cmd_step() -> imap_cmd_finish() will\n         * call imap_read_headers() to download those (because the idata's\n         * reopen_allow is set).\n         *\n         * The imap_read_headers() will open (and clobber) the idata->hcache we\n         * just opened above, then close it.\n         *\n         * The easy and less dangerous fix done here (for a stable branch bug\n         * fix) is to close and reopen the header cache around the operation.\n         *\n         * A better fix would be allowing idata->hcache reuse.  When that is\n         * done, the close/reopen in read_headers_condstore_qresync_updates()\n         * can also be removed. */\n#if USE_HCACHE\n        imap_hcache_close (idata);\n#endif\n        if (!ctx->quiet)\n          mutt_message (_(\"Saving changed messages... [%d/%d]\"), n+1,\n                        ctx->msgcount);\n\tif (!appendctx)\n\t  appendctx = mx_open_mailbox (ctx->path, MUTT_APPEND | MUTT_QUIET, NULL);\n\tif (!appendctx)\n\t  dprint (1, (debugfile, \"imap_sync_mailbox: Error opening mailbox in append mode\\n\"));\n\telse\n\t  _mutt_save_message (h, appendctx, 1, 0, 0);\n        /* TODO: why the check for h->env?  Is this possible? */\n        if (h->env)\n          h->env->changed = 0;\n#if USE_HCACHE\n        idata->hcache = imap_hcache_open (idata, NULL);\n#endif\n      }\n    }\n  }\n\n#if USE_HCACHE\n  imap_hcache_close (idata);\n#endif\n\n  /* presort here to avoid doing 10 resorts in imap_exec_msgset.\n   *\n   * Note: sync_helper() may trigger an imap_exec() if the queue fills\n   * up.  Because IMAP_REOPEN_ALLOW is set, this may result in new\n   * messages being downloaded or an expunge being processed.  For new\n   * messages this would both result in memory corruption (since we're\n   * alloc'ing msgcount instead of hdrmax pointers) and data loss of\n   * the new messages.  For an expunge, the restored hdrs would point\n   * to headers that have been freed.\n   *\n   * Since reopen is allowed, we could change this to call\n   * mutt_sort_headers() before and after instead, but the double sort\n   * is noticeably slower.\n   *\n   * So instead, just turn off reopen_allow for the duration of the\n   * swapped hdrs.  The imap_exec() below flushes the queue out,\n   * giving the opportunity to process any reopen events.\n   */\n  imap_disallow_reopen (ctx);\n  oldsort = Sort;\n  if (Sort != SORT_ORDER)\n  {\n    hdrs = ctx->hdrs;\n    ctx->hdrs = safe_malloc (ctx->msgcount * sizeof (HEADER*));\n    memcpy (ctx->hdrs, hdrs, ctx->msgcount * sizeof (HEADER*));\n\n    Sort = SORT_ORDER;\n    qsort (ctx->hdrs, ctx->msgcount, sizeof (HEADER*),\n           mutt_get_sort_func (SORT_ORDER));\n  }\n\n  rc = sync_helper (idata, MUTT_ACL_DELETE, MUTT_DELETED, \"\\\\Deleted\");\n  if (rc >= 0)\n    rc |= sync_helper (idata, MUTT_ACL_WRITE, MUTT_FLAG, \"\\\\Flagged\");\n  if (rc >= 0)\n    rc |= sync_helper (idata, MUTT_ACL_WRITE, MUTT_OLD, \"Old\");\n  if (rc >= 0)\n    rc |= sync_helper (idata, MUTT_ACL_SEEN, MUTT_READ, \"\\\\Seen\");\n  if (rc >= 0)\n    rc |= sync_helper (idata, MUTT_ACL_WRITE, MUTT_REPLIED, \"\\\\Answered\");\n\n  if ((oldsort != Sort) || hdrs)\n  {\n    Sort = oldsort;\n    FREE (&ctx->hdrs);\n    ctx->hdrs = hdrs;\n  }\n  imap_allow_reopen (ctx);\n\n  /* Flush the queued flags if any were changed in sync_helper.\n   * The real (non-flag) changes loop might have flushed quickdel_rc\n   * queued commands, so we double check the cmdbuf isn't empty. */\n  if (((rc > 0) || (quickdel_rc > 0)) && mutt_buffer_len (idata->cmdbuf))\n    if (imap_exec (idata, NULL, 0) != IMAP_CMD_OK)\n      rc = -1;\n\n  if (rc < 0)\n  {\n    if (ctx->closing)\n    {\n      if (mutt_yesorno (_(\"Error saving flags. Close anyway?\"), 0) == MUTT_YES)\n      {\n        rc = 0;\n        idata->state = IMAP_AUTHENTICATED;\n        goto out;\n      }\n    }\n    else\n      mutt_error _(\"Error saving flags\");\n    rc = -1;\n    goto out;\n  }\n\n  /* Update local record of server state to reflect the synchronization just\n   * completed.  imap_read_headers always overwrites hcache-origin flags, so\n   * there is no need to mutate the hcache after flag-only changes. */\n  for (n = 0; n < ctx->msgcount; n++)\n  {\n    HEADER_DATA(ctx->hdrs[n])->deleted = ctx->hdrs[n]->deleted;\n    HEADER_DATA(ctx->hdrs[n])->flagged = ctx->hdrs[n]->flagged;\n    HEADER_DATA(ctx->hdrs[n])->old = ctx->hdrs[n]->old;\n    HEADER_DATA(ctx->hdrs[n])->read = ctx->hdrs[n]->read;\n    HEADER_DATA(ctx->hdrs[n])->replied = ctx->hdrs[n]->replied;\n    ctx->hdrs[n]->changed = 0;\n  }\n  ctx->changed = 0;\n\n  /* We must send an EXPUNGE command if we're not closing. */\n  if (expunge && !(ctx->closing) &&\n      mutt_bit_isset(ctx->rights, MUTT_ACL_DELETE))\n  {\n    if (!ctx->quiet)\n      mutt_message _(\"Expunging messages from server...\");\n    /* Set expunge bit so we don't get spurious reopened messages */\n    idata->reopen |= IMAP_EXPUNGE_EXPECTED;\n    if (imap_exec (idata, \"EXPUNGE\", 0) != 0)\n    {\n      idata->reopen &= ~IMAP_EXPUNGE_EXPECTED;\n      imap_error (_(\"imap_sync_mailbox: EXPUNGE failed\"), idata->buf);\n      rc = -1;\n      goto out;\n    }\n    idata->reopen &= ~IMAP_EXPUNGE_EXPECTED;\n  }\n\n  if (expunge && ctx->closing)\n  {\n    imap_exec (idata, \"CLOSE\", IMAP_CMD_QUEUE);\n    idata->state = IMAP_AUTHENTICATED;\n  }\n\n  if (option (OPTMESSAGECACHECLEAN))\n    imap_cache_clean (idata);\n\n  rc = 0;\n\nout:\n  imap_disallow_reopen (ctx);\n  if (appendctx)\n  {\n    mx_fastclose_mailbox (appendctx);\n    FREE (&appendctx);\n  }\n  return rc;\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 0
      },
      {
        "idx": 296388,
        "reasoning": "This code snippet for `imap_logout` is **not directly vulnerable** to the described MITM issue. The commit message details a vulnerability related to STARTTLS handling during authentication, while this code focuses solely on the logout process *after* authentication is presumably complete, and doesn't involve any encryption negotiation or checking.\n\n\n\n",
        "func": "void imap_logout (IMAP_DATA** idata)\n{\n  /* we set status here to let imap_handle_untagged know we _expect_ to\n   * receive a bye response (so it doesn't freak out and close the conn) */\n  (*idata)->status = IMAP_BYE;\n  imap_cmd_start (*idata, \"LOGOUT\");\n  if (ImapPollTimeout <= 0 ||\n      mutt_socket_poll ((*idata)->conn, ImapPollTimeout) != 0)\n  {\n    while (imap_cmd_step (*idata) == IMAP_CMD_CONTINUE)\n      ;\n  }\n\n  mutt_socket_close ((*idata)->conn);\n  imap_free_idata (idata);\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 0
      },
      {
        "idx": 296389,
        "reasoning": "This code snippet focuses on accessing and checking the status of an IMAP mailbox and doesn't directly handle the authentication or STARTTLS negotiation process where the vulnerability lies. The commit message explicitly states the fix prevents a MITM attack during authentication, and this code doesn't appear to be involved in that stage of the connection, therefore it's not directly vulnerable.\n\n\n\n",
        "func": "int imap_access (const char* path)\n{\n  IMAP_DATA* idata;\n  IMAP_MBOX mx;\n  char buf[LONG_STRING*2];\n  char mailbox[LONG_STRING];\n  char mbox[LONG_STRING];\n  int rc;\n\n  if (imap_parse_path (path, &mx))\n    return -1;\n\n  if (!(idata = imap_conn_find (&mx.account,\n                                option (OPTIMAPPASSIVE) ? MUTT_IMAP_CONN_NONEW : 0)))\n  {\n    FREE (&mx.mbox);\n    return -1;\n  }\n\n  imap_fix_path (idata, mx.mbox, mailbox, sizeof (mailbox));\n  if (!*mailbox)\n    strfcpy (mailbox, \"INBOX\", sizeof (mailbox));\n\n  /* we may already be in the folder we're checking */\n  if (!ascii_strcmp(idata->mailbox, mx.mbox))\n  {\n    FREE (&mx.mbox);\n    return 0;\n  }\n  FREE (&mx.mbox);\n\n  if (imap_mboxcache_get (idata, mailbox, 0))\n  {\n    dprint (3, (debugfile, \"imap_access: found %s in cache\\n\", mailbox));\n    return 0;\n  }\n\n  imap_munge_mbox_name (idata, mbox, sizeof (mbox), mailbox);\n\n  if (mutt_bit_isset (idata->capabilities, IMAP4REV1))\n    snprintf (buf, sizeof (buf), \"STATUS %s (UIDVALIDITY)\", mbox);\n  else if (mutt_bit_isset (idata->capabilities, STATUS))\n    snprintf (buf, sizeof (buf), \"STATUS %s (UID-VALIDITY)\", mbox);\n  else\n  {\n    dprint (2, (debugfile, \"imap_access: STATUS not supported?\\n\"));\n    return -1;\n  }\n\n  if ((rc = imap_exec (idata, buf, IMAP_CMD_FAIL_OK)) < 0)\n  {\n    dprint (1, (debugfile, \"imap_access: Can't check STATUS of %s\\n\", mbox));\n    return rc;\n  }\n\n  return 0;\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 199990,
        "reasoning": "This code is vulnerable because it incorrectly transitions to the `IMAP_AUTHENTICATED` state upon receiving a `* PREAUTH` response *before* verifying encryption is enabled, mirroring the issue in CVE-2014-2567 and CVE-2020-12398. This allows an attacker to intercept and potentially modify messages sent through features like postpone or `fcc` because Mutt skips encryption checks assuming authentication implies security.\n\n\n\n",
        "func": "int imap_open_connection (IMAP_DATA* idata)\n{\n  if (mutt_socket_open (idata->conn) < 0)\n    return -1;\n\n  idata->state = IMAP_CONNECTED;\n\n  if (imap_cmd_step (idata) != IMAP_CMD_OK)\n  {\n    imap_close_connection (idata);\n    return -1;\n  }\n\n  if (ascii_strncasecmp (\"* OK\", idata->buf, 4) == 0)\n  {\n    if (ascii_strncasecmp (\"* OK [CAPABILITY\", idata->buf, 16)\n        && imap_check_capabilities (idata))\n      goto bail;\n#if defined(USE_SSL)\n    /* Attempt STARTTLS if available and desired. */\n    if (!idata->conn->ssf && (option(OPTSSLFORCETLS) ||\n                              mutt_bit_isset (idata->capabilities, STARTTLS)))\n    {\n      int rc;\n\n      if (option(OPTSSLFORCETLS))\n        rc = MUTT_YES;\n      else if ((rc = query_quadoption (OPT_SSLSTARTTLS,\n                                       _(\"Secure connection with TLS?\"))) == -1)\n\tgoto err_close_conn;\n      if (rc == MUTT_YES)\n      {\n\tif ((rc = imap_exec (idata, \"STARTTLS\", IMAP_CMD_FAIL_OK)) == -1)\n\t  goto bail;\n\tif (rc != -2)\n\t{\n\t  if (mutt_ssl_starttls (idata->conn))\n\t  {\n\t    mutt_error (_(\"Could not negotiate TLS connection\"));\n\t    mutt_sleep (1);\n\t    goto err_close_conn;\n\t  }\n\t  else\n\t  {\n\t    /* RFC 2595 demands we recheck CAPABILITY after TLS completes. */\n\t    if (imap_exec (idata, \"CAPABILITY\", 0))\n\t      goto bail;\n\t  }\n\t}\n      }\n    }\n\n    if (option(OPTSSLFORCETLS) && ! idata->conn->ssf)\n    {\n      mutt_error _(\"Encrypted connection unavailable\");\n      mutt_sleep (1);\n      goto err_close_conn;\n    }\n#endif\n  }\n  else if (ascii_strncasecmp (\"* PREAUTH\", idata->buf, 9) == 0)\n  {\n    idata->state = IMAP_AUTHENTICATED;\n    if (imap_check_capabilities (idata) != 0)\n      goto bail;\n    FREE (&idata->capstr);\n  }\n  else\n  {\n    imap_error (\"imap_open_connection()\", idata->buf);\n    goto bail;\n  }\n\n  return 0;\n\n#if defined(USE_SSL)\nerr_close_conn:\n  imap_close_connection (idata);\n#endif\nbail:\n  FREE (&idata->capstr);\n  return -1;\n}",
        "commit_message": "Prevent possible IMAP MITM via PREAUTH response.\n\nThis is similar to CVE-2014-2567 and CVE-2020-12398.  STARTTLS is not\nallowed in the Authenticated state, so previously Mutt would\nimplicitly mark the connection as authenticated and skip any\nencryption checking/enabling.\n\nNo credentials are exposed, but it does allow messages to be sent to\nan attacker, via postpone or fcc'ing for instance.\n\nReuse the $ssl_starttls quadoption \"in reverse\" to prompt to abort the\nconnection if it is unencrypted.\n\nThanks very much to Damian Poddebniak and Fabian Ising from the\nM\u00fcnster University of Applied Sciences for reporting this issue, and\ntheir help in testing the fix.",
        "cve_desc": "Mutt before 1.14.3 allows an IMAP fcc/postpone man-in-the-middle attack via a PREAUTH response.",
        "target": 1
      },
      {
        "idx": 202213,
        "reasoning": "The code is vulnerable because an invalid initial server response during IMAP connection doesn\u2019t reliably close the connection, leading to a potential bypass of the `$ssl_force_tls` setting. This allows authentication credentials to be sent over an unencrypted connection when a secure connection was intended, potentially exposing them to a man-in-the-middle attack.\n\n\n\n",
        "func": "int imap_open_connection (IMAP_DATA* idata)\n{\n  if (mutt_socket_open (idata->conn) < 0)\n    return -1;\n\n  idata->state = IMAP_CONNECTED;\n\n  if (imap_cmd_step (idata) != IMAP_CMD_OK)\n  {\n    imap_close_connection (idata);\n    return -1;\n  }\n\n  if (ascii_strncasecmp (\"* OK\", idata->buf, 4) == 0)\n  {\n    if (ascii_strncasecmp (\"* OK [CAPABILITY\", idata->buf, 16)\n        && imap_check_capabilities (idata))\n      goto bail;\n#if defined(USE_SSL)\n    /* Attempt STARTTLS if available and desired. */\n    if (!idata->conn->ssf && (option(OPTSSLFORCETLS) ||\n                              mutt_bit_isset (idata->capabilities, STARTTLS)))\n    {\n      int rc;\n\n      if (option(OPTSSLFORCETLS))\n        rc = MUTT_YES;\n      else if ((rc = query_quadoption (OPT_SSLSTARTTLS,\n                                       _(\"Secure connection with TLS?\"))) == -1)\n\tgoto err_close_conn;\n      if (rc == MUTT_YES)\n      {\n\tif ((rc = imap_exec (idata, \"STARTTLS\", IMAP_CMD_FAIL_OK)) == -1)\n\t  goto bail;\n\tif (rc != -2)\n\t{\n\t  if (mutt_ssl_starttls (idata->conn))\n\t  {\n\t    mutt_error (_(\"Could not negotiate TLS connection\"));\n\t    mutt_sleep (1);\n\t    goto err_close_conn;\n\t  }\n\t  else\n\t  {\n\t    /* RFC 2595 demands we recheck CAPABILITY after TLS completes. */\n\t    if (imap_exec (idata, \"CAPABILITY\", 0))\n\t      goto bail;\n\t  }\n\t}\n      }\n    }\n\n    if (option(OPTSSLFORCETLS) && ! idata->conn->ssf)\n    {\n      mutt_error _(\"Encrypted connection unavailable\");\n      mutt_sleep (1);\n      goto err_close_conn;\n    }\n#endif\n  }\n  else if (ascii_strncasecmp (\"* PREAUTH\", idata->buf, 9) == 0)\n  {\n#if defined(USE_SSL)\n    /* Unless using a secure $tunnel, an unencrypted PREAUTH response\n     * may be a MITM attack.  The only way to stop \"STARTTLS\" MITM\n     * attacks is via $ssl_force_tls: an attacker can easily spoof\n     * \"* OK\" and strip the STARTTLS capability.  So consult\n     * $ssl_force_tls, not $ssl_starttls, to decide whether to\n     * abort. Note that if using $tunnel and $tunnel_is_secure,\n     * conn->ssf will be set to 1. */\n    if (!idata->conn->ssf && option(OPTSSLFORCETLS))\n    {\n      mutt_error _(\"Encrypted connection unavailable\");\n      mutt_sleep (1);\n      goto err_close_conn;\n    }\n#endif\n\n    idata->state = IMAP_AUTHENTICATED;\n    if (imap_check_capabilities (idata) != 0)\n      goto bail;\n    FREE (&idata->capstr);\n  }\n  else\n  {\n    imap_error (\"imap_open_connection()\", idata->buf);\n    goto bail;\n  }\n\n  return 0;\n\n#if defined(USE_SSL)\nerr_close_conn:\n  imap_close_connection (idata);\n#endif\nbail:\n  FREE (&idata->capstr);\n  return -1;\n}",
        "commit_message": "Ensure IMAP connection is closed after a connection error.\n\nDuring connection, if the server provided an illegal initial response,\nMutt \"bailed\", but did not actually close the connection.  The calling\ncode unfortunately relied on the connection status to decide to\ncontinue with authentication, instead of checking the \"bail\" return\nvalue.\n\nThis could result in authentication credentials being sent over an\nunencrypted connection, without $ssl_force_tls being consulted.\n\nFix this by strictly closing the connection on any invalid response\nduring connection.  The fix is intentionally small, to ease\nbackporting.  A better fix would include removing the 'err_close_conn'\nlabel, and perhaps adding return value checking in the caller (though\nthis change obviates the need for that).\n\nThis addresses CVE-2020-28896.  Thanks to Gabriel Salles-Loustau for\nreporting the problem, and providing test cases to reproduce.",
        "cve_desc": "Mutt before 2.0.2 and NeoMutt before 2020-11-20 did not ensure that $ssl_force_tls was processed if an IMAP server's initial server response was invalid. The connection was not properly closed, and the code could continue attempting to authenticate. This could result in authentication credentials being exposed on an unencrypted connection, or to a machine-in-the-middle.",
        "target": 1
      },
      {
        "idx": 204435,
        "reasoning": "This code is vulnerable to a directory traversal attack because the `path` variable, potentially controlled by a user via the mailbox name, is used to construct a file path without proper sanitization. Specifically, an attacker could craft a mailbox name containing \"..\" sequences to navigate outside the intended cache directory when `imap_cachepath` and `url_ciss_tostring` are called, potentially leading to arbitrary file access or overwrites.",
        "func": "header_cache_t* imap_hcache_open (IMAP_DATA* idata, const char* path)\n{\n  IMAP_MBOX mx;\n  ciss_url_t url;\n  char cachepath[LONG_STRING];\n  char mbox[LONG_STRING];\n\n  if (path)\n    imap_cachepath (idata, path, mbox, sizeof (mbox));\n  else\n  {\n    if (!idata->ctx || imap_parse_path (idata->ctx->path, &mx) < 0)\n      return NULL;\n\n    imap_cachepath (idata, mx.mbox, mbox, sizeof (mbox));\n    FREE (&mx.mbox);\n  }\n\n  mutt_account_tourl (&idata->conn->account, &url);\n  url.path = mbox;\n  url_ciss_tostring (&url, cachepath, sizeof (cachepath), U_PATH);\n\n  return mutt_hcache_open (HeaderCache, cachepath, imap_hcache_namer);\n}",
        "commit_message": "Selectively cache headers.\n\nThanks to NeoMutt and Jeriko One for the patch, which was slightly\nmodified to apply to the Mutt code.",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. imap/util.c mishandles \"..\" directory traversal in a mailbox name.",
        "target": 1
      },
      {
        "idx": 208329,
        "reasoning": "This code is vulnerable to an integer underflow because `dlen` is decremented *before* being checked for a zero value within the loop, potentially allowing it to become negative. A negative `dlen` then leads to out-of-bounds writes when `pt++` is used, as the code continues writing past the allocated buffer's end, confirmed by the CVE description.\n\n\n\n",
        "func": "static void _imap_quote_string (char *dest, size_t dlen, const char *src,\n                                const char *to_quote)\n{\n  char *pt;\n  const char *s;\n\n  pt = dest;\n  s  = src;\n\n  *pt++ = '\"';\n  /* save room for trailing quote-char */\n  dlen -= 2;\n\n  for (; *s && dlen; s++)\n  {\n    if (strchr (to_quote, *s))\n    {\n      dlen -= 2;\n      if (!dlen)\n\tbreak;\n      *pt++ = '\\\\';\n      *pt++ = *s;\n    }\n    else\n    {\n      *pt++ = *s;\n      dlen--;\n    }\n  }\n  *pt++ = '\"';\n  *pt = 0;\n}",
        "commit_message": "Fix imap_quote_string() length check errors.\n\nThe function wasn't properly checking for dlen<2 before quoting, and\nwasn't properly pre-adjusting dlen to include the initial quote.\n\nThanks to Jeriko One for reporting these issues.",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. imap_quote_string in imap/util.c has an integer underflow.",
        "target": 1
      },
      {
        "idx": 208359,
        "reasoning": "The code is vulnerable because it doesn't adequately validate the `litlen` value obtained from `imap_get_literal_count` before using it to manipulate the `idata->buf` buffer, potentially leading to a buffer overflow. Specifically, if `imap_get_literal_count` returns a large value for `litlen`, the subsequent `idata->buf + litlen` operation could write beyond the bounds of the buffer, as highlighted by the CVE description.",
        "func": "static void cmd_parse_status (IMAP_DATA* idata, char* s)\n{\n  char* mailbox;\n  char* value;\n  BUFFY* inc;\n  IMAP_MBOX mx;\n  unsigned long ulcount;\n  unsigned int count;\n  IMAP_STATUS *status;\n  unsigned int olduv, oldun;\n  unsigned int litlen;\n  short new = 0;\n  short new_msg_count = 0;\n\n  mailbox = imap_next_word (s);\n\n  /* We need a real tokenizer. */\n  if (!imap_get_literal_count (mailbox, &litlen))\n  {\n    if (imap_cmd_step (idata) != IMAP_CMD_CONTINUE)\n    {\n      idata->status = IMAP_FATAL;\n      return;\n    }\n    mailbox = idata->buf;\n    s = mailbox + litlen;\n    *s = '\\0';\n    s++;\n    SKIPWS(s);\n  }\n  else\n  {\n    s = imap_next_word (mailbox);\n    *(s - 1) = '\\0';\n    imap_unmunge_mbox_name (idata, mailbox);\n  }\n\n  status = imap_mboxcache_get (idata, mailbox, 1);\n  olduv = status->uidvalidity;\n  oldun = status->uidnext;\n\n  if (*s++ != '(')\n  {\n    dprint (1, (debugfile, \"Error parsing STATUS\\n\"));\n    return;\n  }\n  while (*s && *s != ')')\n  {\n    value = imap_next_word (s);\n\n    errno = 0;\n    ulcount = strtoul (value, &value, 10);\n    if ((errno == ERANGE && ulcount == ULONG_MAX) ||\n        ((unsigned int) ulcount != ulcount))\n    {\n      dprint (1, (debugfile, \"Error parsing STATUS number\\n\"));\n      return;\n    }\n    count = (unsigned int) ulcount;\n\n    if (!ascii_strncmp (\"MESSAGES\", s, 8))\n    {\n      status->messages = count;\n      new_msg_count = 1;\n    }\n    else if (!ascii_strncmp (\"RECENT\", s, 6))\n      status->recent = count;\n    else if (!ascii_strncmp (\"UIDNEXT\", s, 7))\n      status->uidnext = count;\n    else if (!ascii_strncmp (\"UIDVALIDITY\", s, 11))\n      status->uidvalidity = count;\n    else if (!ascii_strncmp (\"UNSEEN\", s, 6))\n      status->unseen = count;\n\n    s = value;\n    if (*s && *s != ')')\n      s = imap_next_word (s);\n  }\n  dprint (3, (debugfile, \"%s (UIDVALIDITY: %u, UIDNEXT: %u) %d messages, %d recent, %d unseen\\n\",\n              status->name, status->uidvalidity, status->uidnext,\n              status->messages, status->recent, status->unseen));\n\n  /* caller is prepared to handle the result herself */\n  if (idata->cmddata && idata->cmdtype == IMAP_CT_STATUS)\n  {\n    memcpy (idata->cmddata, status, sizeof (IMAP_STATUS));\n    return;\n  }\n\n  dprint (3, (debugfile, \"Running default STATUS handler\\n\"));\n\n  /* should perhaps move this code back to imap_buffy_check */\n  for (inc = Incoming; inc; inc = inc->next)\n  {\n    if (inc->magic != MUTT_IMAP)\n      continue;\n    \n    if (imap_parse_path (inc->path, &mx) < 0)\n    {\n      dprint (1, (debugfile, \"Error parsing mailbox %s, skipping\\n\", inc->path));\n      continue;\n    }\n    /* dprint (2, (debugfile, \"Buffy entry: [%s] mbox: [%s]\\n\", inc->path, NONULL(mx.mbox))); */\n    \n    if (imap_account_match (&idata->conn->account, &mx.account))\n    {\n      if (mx.mbox)\n      {\n\tvalue = safe_strdup (mx.mbox);\n\timap_fix_path (idata, mx.mbox, value, mutt_strlen (value) + 1);\n\tFREE (&mx.mbox);\n      }\n      else\n\tvalue = safe_strdup (\"INBOX\");\n\n      if (value && !imap_mxcmp (mailbox, value))\n      {\n        dprint (3, (debugfile, \"Found %s in buffy list (OV: %u ON: %u U: %d)\\n\",\n                    mailbox, olduv, oldun, status->unseen));\n        \n\tif (option(OPTMAILCHECKRECENT))\n\t{\n\t  if (olduv && olduv == status->uidvalidity)\n\t  {\n\t    if (oldun < status->uidnext)\n\t      new = (status->unseen > 0);\n\t  }\n\t  else if (!olduv && !oldun)\n\t    /* first check per session, use recent. might need a flag for this. */\n\t    new = (status->recent > 0);\n\t  else\n\t    new = (status->unseen > 0);\n\t}\n\telse\n          new = (status->unseen > 0);\n\n#ifdef USE_SIDEBAR\n        if ((inc->new != new) ||\n            (inc->msg_count != status->messages) ||\n            (inc->msg_unread != status->unseen))\n          mutt_set_current_menu_redraw (REDRAW_SIDEBAR);\n#endif\n        inc->new = new;\n        if (new_msg_count)\n          inc->msg_count = status->messages;\n        inc->msg_unread = status->unseen;\n\n\tif (inc->new)\n\t  /* force back to keep detecting new mail until the mailbox is\n\t     opened */\n\t  status->uidnext = oldun;\n\n        FREE (&value);\n        return;\n      }\n\n      FREE (&value);\n    }\n\n    FREE (&mx.mbox);\n  }\n}",
        "commit_message": "Verify IMAP status mailbox literal count size.\n\nEnsure the length isn't bigger than the idata->buf.\n\nThanks to Jeriko One fo the bug report and patch, which this commit is\nbased upon.",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. imap/command.c mishandles a long IMAP status mailbox literal count size.",
        "target": 1
      }
    ]
  },
  "mysql-wsrep": {
    "0": [],
    "1": []
  },
  "nDPI": {
    "0": [
      {
        "idx": 233133,
        "reasoning": "This code snippet is not directly vulnerable to a heap buffer overflow read because it simply sets a function pointer for custom memory allocation. It doesn't perform any memory access or manipulation itself, therefore there's no opportunity for an overflow to occur within *this* code. \n\n\n\n",
        "func": "void set_ndpi_flow_malloc(void *(*__ndpi_flow_malloc)(size_t size)) {\n  _ndpi_flow_malloc = __ndpi_flow_malloc;\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 0
      },
      {
        "idx": 233134,
        "reasoning": "This code is safe and does not exhibit a heap buffer overflow read vulnerability. The `switch` statement simply checks the value of `category` against a defined set of integer constants and returns 0 or 1; there's no memory access or manipulation involved that could lead to a buffer overflow. \n\n\n\n",
        "func": "int ndpi_is_custom_category(ndpi_protocol_category_t category) {\n  switch (category) {\n  case NDPI_PROTOCOL_CATEGORY_CUSTOM_1:\n  case NDPI_PROTOCOL_CATEGORY_CUSTOM_2:\n  case NDPI_PROTOCOL_CATEGORY_CUSTOM_3:\n  case NDPI_PROTOCOL_CATEGORY_CUSTOM_4:\n  case NDPI_PROTOCOL_CATEGORY_CUSTOM_5:\n    return(1);\n    break;\n\n  default:\n    return(0);\n    break;\n  }\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 0
      },
      {
        "idx": 233135,
        "reasoning": "This code is flagged as safe because the commit message explicitly states a check for a heap buffer overflow read was *added*, implying a previously identified potential vulnerability was mitigated. The code itself doesn't exhibit any immediately obvious vulnerabilities like unchecked string copies or out-of-bounds array accesses after the added check, and the logic appears to handle string manipulation and parsing reasonably carefully.\n\n\n\n",
        "func": "int ndpi_handle_rule(struct ndpi_detection_module_struct *ndpi_str, char *rule, u_int8_t do_add) {\n  char *at, *proto, *elem;\n  ndpi_proto_defaults_t *def;\n  u_int16_t subprotocol_id, i;\n\n  at = strrchr(rule, '@');\n  if(at == NULL) {\n    NDPI_LOG_ERR(ndpi_str, \"Invalid rule '%s'\\n\", rule);\n    return(-1);\n  } else\n    at[0] = 0, proto = &at[1];\n\n  for (i = 0; proto[i] != '\\0'; i++) {\n    switch (proto[i]) {\n    case '/':\n    case '&':\n    case '^':\n    case ':':\n    case ';':\n    case '\\'':\n    case '\"':\n    case ' ':\n      proto[i] = '_';\n      break;\n    }\n  }\n\n  for (i = 0, def = NULL; i < (int) ndpi_str->ndpi_num_supported_protocols; i++) {\n    if(ndpi_str->proto_defaults[i].protoName && strcasecmp(ndpi_str->proto_defaults[i].protoName, proto) == 0) {\n      def = &ndpi_str->proto_defaults[i];\n      subprotocol_id = i;\n      break;\n    }\n  }\n\n  if(def == NULL) {\n    if(!do_add) {\n      /* We need to remove a rule */\n      NDPI_LOG_ERR(ndpi_str, \"Unable to find protocol '%s': skipping rule '%s'\\n\", proto, rule);\n      return(-3);\n    } else {\n      ndpi_port_range ports_a[MAX_DEFAULT_PORTS], ports_b[MAX_DEFAULT_PORTS];\n      u_int16_t no_master[2] = {NDPI_PROTOCOL_NO_MASTER_PROTO, NDPI_PROTOCOL_NO_MASTER_PROTO};\n\n      if(ndpi_str->ndpi_num_custom_protocols >= (NDPI_MAX_NUM_CUSTOM_PROTOCOLS - 1)) {\n\tNDPI_LOG_ERR(ndpi_str, \"Too many protocols defined (%u): skipping protocol %s\\n\",\n\t\t     ndpi_str->ndpi_num_custom_protocols, proto);\n\treturn(-2);\n      }\n\n      ndpi_set_proto_defaults(\n\t\t\t      ndpi_str, NDPI_PROTOCOL_ACCEPTABLE, ndpi_str->ndpi_num_supported_protocols,\n\t\t\t      0 /* can_have_a_subprotocol */, no_master, no_master, proto,\n\t\t\t      NDPI_PROTOCOL_CATEGORY_UNSPECIFIED, /* TODO add protocol category support in rules */\n\t\t\t      ndpi_build_default_ports(ports_a, 0, 0, 0, 0, 0) /* TCP */,\n\t\t\t      ndpi_build_default_ports(ports_b, 0, 0, 0, 0, 0) /* UDP */);\n      def = &ndpi_str->proto_defaults[ndpi_str->ndpi_num_supported_protocols];\n      subprotocol_id = ndpi_str->ndpi_num_supported_protocols;\n      ndpi_str->ndpi_num_supported_protocols++, ndpi_str->ndpi_num_custom_protocols++;\n    }\n  }\n\n  while ((elem = strsep(&rule, \",\")) != NULL) {\n    char *attr = elem, *value = NULL;\n    ndpi_port_range range;\n    int is_tcp = 0, is_udp = 0, is_ip = 0;\n\n    if(strncmp(attr, \"tcp:\", 4) == 0)\n      is_tcp = 1, value = &attr[4];\n    else if(strncmp(attr, \"udp:\", 4) == 0)\n      is_udp = 1, value = &attr[4];\n    else if(strncmp(attr, \"ip:\", 3) == 0)\n      is_ip = 1, value = &attr[3];\n    else if(strncmp(attr, \"host:\", 5) == 0) {\n      /* host:\"<value>\",host:\"<value>\",.....@<subproto> */\n      value = &attr[5];\n      if(value[0] == '\"')\n\tvalue++; /* remove leading \" */\n      if(value[strlen(value) - 1] == '\"')\n\tvalue[strlen(value) - 1] = '\\0'; /* remove trailing \" */\n    }\n\n    if(is_tcp || is_udp) {\n      u_int p_low, p_high;\n\n      if(sscanf(value, \"%u-%u\", &p_low, &p_high) == 2)\n\trange.port_low = p_low, range.port_high = p_high;\n      else\n\trange.port_low = range.port_high = atoi(&elem[4]);\n\n      if(do_add)\n\taddDefaultPort(ndpi_str, &range, def, 1 /* Custom user proto */,\n\t\t       is_tcp ? &ndpi_str->tcpRoot : &ndpi_str->udpRoot, __FUNCTION__, __LINE__);\n      else\n\tremoveDefaultPort(&range, def, is_tcp ? &ndpi_str->tcpRoot : &ndpi_str->udpRoot);\n    } else if(is_ip) {\n      /* NDPI_PROTOCOL_TOR */\n      ndpi_add_host_ip_subprotocol(ndpi_str, value, subprotocol_id);\n    } else {\n      if(do_add)\n\tndpi_add_host_url_subprotocol(ndpi_str, value, subprotocol_id, NDPI_PROTOCOL_CATEGORY_UNSPECIFIED,\n\t\t\t\t      NDPI_PROTOCOL_ACCEPTABLE);\n      else\n\tndpi_remove_host_url_subprotocol(ndpi_str, value, subprotocol_id);\n    }\n  }\n\n  return(0);\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 0
      },
      {
        "idx": 233136,
        "reasoning": "This code is not directly vulnerable to a heap buffer overflow *read* as the commit message claims to address. While `ndpi_calloc` allocates memory and then zeroes it, the potential vulnerability would exist in code *using* the allocated memory \u2013 this snippet only handles allocation and initialization, not subsequent reads that could exceed bounds. \n\n\n\n",
        "func": "void *ndpi_calloc(unsigned long count, size_t size) {\n  size_t len = count * size;\n  void *p = ndpi_malloc(len);\n\n  if(p)\n    memset(p, 0, len);\n\n  return(p);\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 0
      },
      {
        "idx": 233137,
        "reasoning": "This code is likely safe regarding heap buffer overflows despite the commit message suggesting a previous concern. The commit message indicates a *check* was added, implying a potential issue was addressed, and the code now explicitly frees the `ret` pointer only when `ndpi_tdelete` returns a valid node, preventing a use-after-free or double-free scenario that could lead to exploitation.\n\n\n\n",
        "func": "static int removeDefaultPort(ndpi_port_range *range, ndpi_proto_defaults_t *def, ndpi_default_ports_tree_node_t **root) {\n  ndpi_default_ports_tree_node_t node;\n  u_int16_t port;\n\n  for (port = range->port_low; port <= range->port_high; port++) {\n    ndpi_default_ports_tree_node_t *ret;\n\n    node.proto = def, node.default_port = port;\n    ret = (ndpi_default_ports_tree_node_t *) ndpi_tdelete(\n\t\t\t\t\t\t\t  &node, (void *) root, ndpi_default_ports_tree_node_t_cmp); /* Add it to the tree */\n\n    if(ret != NULL) {\n      ndpi_free((ndpi_default_ports_tree_node_t *) ret);\n      return(0);\n    }\n  }\n\n  return(-1);\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195787,
        "reasoning": "The code is vulnerable to a heap-based buffer over-read because the `packet->line[packet->parsed_lines].len` calculation relies on pointer arithmetic from `packet->payload` without sufficient bounds checking, potentially reading beyond the allocated buffer. Specifically, the final length calculation `packet->line[packet->parsed_lines].len = (u_int16_t)(((unsigned long) &packet->payload[packet->payload_packet_len]) - ((unsigned long) packet->line[packet->parsed_lines].ptr));` can result in reading past the end of `packet->payload` if `packet->line[packet->parsed_lines].ptr` is close to the end of the buffer.",
        "func": "void ndpi_parse_packet_line_info(struct ndpi_detection_module_struct *ndpi_str, struct ndpi_flow_struct *flow) {\n  u_int32_t a;\n  struct ndpi_packet_struct *packet = &flow->packet;\n\n  if((packet->payload_packet_len < 3) || (packet->payload == NULL))\n    return;\n\n  if(packet->packet_lines_parsed_complete != 0)\n    return;\n\n  packet->packet_lines_parsed_complete = 1;\n  ndpi_reset_packet_line_info(packet);\n\n  packet->line[packet->parsed_lines].ptr = packet->payload;\n  packet->line[packet->parsed_lines].len = 0;\n\n  for (a = 0; (a < packet->payload_packet_len) && (packet->parsed_lines < NDPI_MAX_PARSE_LINES_PER_PACKET); a++) {\n    if((a + 1) >= packet->payload_packet_len)\n      return; /* Return if only one byte remains (prevent invalid reads past end-of-buffer) */\n\n    if(get_u_int16_t(packet->payload, a) == ntohs(0x0d0a)) {\n      /* If end of line char sequence CR+NL \"\\r\\n\", process line */\n\n      if(((a + 3) <= packet->payload_packet_len)\n\t && (get_u_int16_t(packet->payload, a+2) == ntohs(0x0d0a))) {\n\t/* \\r\\n\\r\\n */\n\tint diff; /* No unsigned ! */\n\tu_int32_t a1 = a + 4;\n\n\tdiff = ndpi_min(packet->payload_packet_len-a1, sizeof(flow->initial_binary_bytes));\n\n\tif(diff > 0) {\n\t  memcpy(&flow->initial_binary_bytes, &packet->payload[a1], diff);\n\t  flow->initial_binary_bytes_len = diff;\n\t}\n      }\n\n      packet->line[packet->parsed_lines].len =\n\t(u_int16_t)(((unsigned long) &packet->payload[a]) - ((unsigned long) packet->line[packet->parsed_lines].ptr));\n\n      /* First line of a HTTP response parsing. Expected a \"HTTP/1.? ???\" */\n      if(packet->parsed_lines == 0 && packet->line[0].len >= NDPI_STATICSTRING_LEN(\"HTTP/1.X 200 \") &&\n\t strncasecmp((const char *) packet->line[0].ptr, \"HTTP/1.\", NDPI_STATICSTRING_LEN(\"HTTP/1.\")) == 0 &&\n\t packet->line[0].ptr[NDPI_STATICSTRING_LEN(\"HTTP/1.X \")] > '0' && /* response code between 000 and 699 */\n\t packet->line[0].ptr[NDPI_STATICSTRING_LEN(\"HTTP/1.X \")] < '6') {\n\tpacket->http_response.ptr = &packet->line[0].ptr[NDPI_STATICSTRING_LEN(\"HTTP/1.1 \")];\n\tpacket->http_response.len = packet->line[0].len - NDPI_STATICSTRING_LEN(\"HTTP/1.1 \");\n\tpacket->http_num_headers++;\n\n\t/* Set server HTTP response code */\n\tif(packet->payload_packet_len >= 12) {\n\t  char buf[4];\n\n\t  /* Set server HTTP response code */\n\t  strncpy(buf, (char *) &packet->payload[9], 3);\n\t  buf[3] = '\\0';\n\n\t  flow->http.response_status_code = atoi(buf);\n\t  /* https://en.wikipedia.org/wiki/List_of_HTTP_status_codes */\n\t  if((flow->http.response_status_code < 100) || (flow->http.response_status_code > 509))\n\t    flow->http.response_status_code = 0; /* Out of range */\n\t}\n      }\n\n      /* \"Server:\" header line in HTTP response */\n      if(packet->line[packet->parsed_lines].len > NDPI_STATICSTRING_LEN(\"Server:\") + 1 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr,\n\t\t     \"Server:\", NDPI_STATICSTRING_LEN(\"Server:\")) == 0) {\n\t// some stupid clients omit a space and place the servername directly after the colon\n\tif(packet->line[packet->parsed_lines].ptr[NDPI_STATICSTRING_LEN(\"Server:\")] == ' ') {\n\t  packet->server_line.ptr =\n\t    &packet->line[packet->parsed_lines].ptr[NDPI_STATICSTRING_LEN(\"Server:\") + 1];\n\t  packet->server_line.len =\n\t    packet->line[packet->parsed_lines].len - (NDPI_STATICSTRING_LEN(\"Server:\") + 1);\n\t} else {\n\t  packet->server_line.ptr = &packet->line[packet->parsed_lines].ptr[NDPI_STATICSTRING_LEN(\"Server:\")];\n\t  packet->server_line.len = packet->line[packet->parsed_lines].len - NDPI_STATICSTRING_LEN(\"Server:\");\n\t}\n\tpacket->http_num_headers++;\n      }\n      /* \"Host:\" header line in HTTP request */\n      if(packet->line[packet->parsed_lines].len > 6 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Host:\", 5) == 0) {\n\t// some stupid clients omit a space and place the hostname directly after the colon\n\tif(packet->line[packet->parsed_lines].ptr[5] == ' ') {\n\t  packet->host_line.ptr = &packet->line[packet->parsed_lines].ptr[6];\n\t  packet->host_line.len = packet->line[packet->parsed_lines].len - 6;\n\t} else {\n\t  packet->host_line.ptr = &packet->line[packet->parsed_lines].ptr[5];\n\t  packet->host_line.len = packet->line[packet->parsed_lines].len - 5;\n\t}\n\tpacket->http_num_headers++;\n      }\n      /* \"X-Forwarded-For:\" header line in HTTP request. Commonly used for HTTP proxies. */\n      if(packet->line[packet->parsed_lines].len > 17 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"X-Forwarded-For:\", 16) == 0) {\n\t// some stupid clients omit a space and place the hostname directly after the colon\n\tif(packet->line[packet->parsed_lines].ptr[16] == ' ') {\n\t  packet->forwarded_line.ptr = &packet->line[packet->parsed_lines].ptr[17];\n\t  packet->forwarded_line.len = packet->line[packet->parsed_lines].len - 17;\n\t} else {\n\t  packet->forwarded_line.ptr = &packet->line[packet->parsed_lines].ptr[16];\n\t  packet->forwarded_line.len = packet->line[packet->parsed_lines].len - 16;\n\t}\n\tpacket->http_num_headers++;\n      }\n      /* \"Content-Type:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 14 &&\n\t (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-Type: \", 14) == 0 ||\n\t  strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-type: \", 14) == 0)) {\n\tpacket->content_line.ptr = &packet->line[packet->parsed_lines].ptr[14];\n\tpacket->content_line.len = packet->line[packet->parsed_lines].len - 14;\n\n\twhile ((packet->content_line.len > 0) && (packet->content_line.ptr[0] == ' '))\n\t  packet->content_line.len--, packet->content_line.ptr++;\n\n\tpacket->http_num_headers++;\n      }\n      /* \"Content-Type:\" header line in HTTP AGAIN. Probably a bogus response without space after \":\" */\n      if((packet->content_line.len == 0) && (packet->line[packet->parsed_lines].len > 13) &&\n\t (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-type:\", 13) == 0)) {\n\tpacket->content_line.ptr = &packet->line[packet->parsed_lines].ptr[13];\n\tpacket->content_line.len = packet->line[packet->parsed_lines].len - 13;\n\tpacket->http_num_headers++;\n      }\n\n      if(packet->content_line.len > 0) {\n\t/* application/json; charset=utf-8 */\n\tchar separator[] = {';', '\\r', '\\0'};\n\tint i;\n\n\tfor (i = 0; separator[i] != '\\0'; i++) {\n\t  char *c = memchr((char *) packet->content_line.ptr, separator[i], packet->content_line.len);\n\n\t  if(c != NULL)\n\t    packet->content_line.len = c - (char *) packet->content_line.ptr;\n\t}\n      }\n\n      /* \"Accept:\" header line in HTTP request. */\n      if(packet->line[packet->parsed_lines].len > 8 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Accept: \", 8) == 0) {\n\tpacket->accept_line.ptr = &packet->line[packet->parsed_lines].ptr[8];\n\tpacket->accept_line.len = packet->line[packet->parsed_lines].len - 8;\n\tpacket->http_num_headers++;\n      }\n      /* \"Referer:\" header line in HTTP request. */\n      if(packet->line[packet->parsed_lines].len > 9 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Referer: \", 9) == 0) {\n\tpacket->referer_line.ptr = &packet->line[packet->parsed_lines].ptr[9];\n\tpacket->referer_line.len = packet->line[packet->parsed_lines].len - 9;\n\tpacket->http_num_headers++;\n      }\n      /* \"User-Agent:\" header line in HTTP request. */\n      if(packet->line[packet->parsed_lines].len > 12 &&\n\t (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"User-Agent: \", 12) == 0 ||\n\t  strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"User-agent: \", 12) == 0)) {\n\tpacket->user_agent_line.ptr = &packet->line[packet->parsed_lines].ptr[12];\n\tpacket->user_agent_line.len = packet->line[packet->parsed_lines].len - 12;\n\tpacket->http_num_headers++;\n      }\n      /* \"Content-Encoding:\" header line in HTTP response (and request?). */\n      if(packet->line[packet->parsed_lines].len > 18 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-Encoding: \", 18) == 0) {\n\tpacket->http_encoding.ptr = &packet->line[packet->parsed_lines].ptr[18];\n\tpacket->http_encoding.len = packet->line[packet->parsed_lines].len - 18;\n\tpacket->http_num_headers++;\n      }\n      /* \"Transfer-Encoding:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 19 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Transfer-Encoding: \", 19) == 0) {\n\tpacket->http_transfer_encoding.ptr = &packet->line[packet->parsed_lines].ptr[19];\n\tpacket->http_transfer_encoding.len = packet->line[packet->parsed_lines].len - 19;\n\tpacket->http_num_headers++;\n      }\n      /* \"Content-Length:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 16 &&\n\t ((strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-Length: \", 16) == 0) ||\n\t  (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"content-length: \", 16) == 0))) {\n\tpacket->http_contentlen.ptr = &packet->line[packet->parsed_lines].ptr[16];\n\tpacket->http_contentlen.len = packet->line[packet->parsed_lines].len - 16;\n\tpacket->http_num_headers++;\n      }\n      /* \"Content-Disposition\"*/\n      if(packet->line[packet->parsed_lines].len > 21 &&\n\t ((strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Content-Disposition: \", 21) == 0))) {\n\tpacket->content_disposition_line.ptr = &packet->line[packet->parsed_lines].ptr[21];\n\tpacket->content_disposition_line.len = packet->line[packet->parsed_lines].len - 21;\n\tpacket->http_num_headers++;\n      }\n      /* \"Cookie:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 8 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Cookie: \", 8) == 0) {\n\tpacket->http_cookie.ptr = &packet->line[packet->parsed_lines].ptr[8];\n\tpacket->http_cookie.len = packet->line[packet->parsed_lines].len - 8;\n\tpacket->http_num_headers++;\n      }\n      /* \"Origin:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 8 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Origin: \", 8) == 0) {\n\tpacket->http_origin.ptr = &packet->line[packet->parsed_lines].ptr[8];\n\tpacket->http_origin.len = packet->line[packet->parsed_lines].len - 8;\n\tpacket->http_num_headers++;\n      }\n      /* \"X-Session-Type:\" header line in HTTP. */\n      if(packet->line[packet->parsed_lines].len > 16 &&\n\t strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"X-Session-Type: \", 16) == 0) {\n\tpacket->http_x_session_type.ptr = &packet->line[packet->parsed_lines].ptr[16];\n\tpacket->http_x_session_type.len = packet->line[packet->parsed_lines].len - 16;\n\tpacket->http_num_headers++;\n      }\n      /* Identification and counting of other HTTP headers.\n       * We consider the most common headers, but there are many others,\n       * which can be seen at references below:\n       * - https://tools.ietf.org/html/rfc7230\n       * - https://en.wikipedia.org/wiki/List_of_HTTP_header_fields\n       */\n      if((packet->line[packet->parsed_lines].len > 6 &&\n\t  (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Date: \", 6) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Vary: \", 6) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"ETag: \", 6) == 0)) ||\n\t (packet->line[packet->parsed_lines].len > 8 &&\n\t  strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Pragma: \", 8) == 0) ||\n\t (packet->line[packet->parsed_lines].len > 9 &&\n\t  strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Expires: \", 9) == 0) ||\n\t (packet->line[packet->parsed_lines].len > 12 &&\n\t  (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Set-Cookie: \", 12) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Keep-Alive: \", 12) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Connection: \", 12) == 0)) ||\n\t (packet->line[packet->parsed_lines].len > 15 &&\n\t  (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Last-Modified: \", 15) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Accept-Ranges: \", 15) == 0)) ||\n\t (packet->line[packet->parsed_lines].len > 17 &&\n\t  (strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Accept-Language: \", 17) == 0 ||\n\t   strncasecmp((const char *) packet->line[packet->parsed_lines].ptr, \"Accept-Encoding: \", 17) == 0)) ||\n\t (packet->line[packet->parsed_lines].len > 27 &&\n\t  strncasecmp((const char *) packet->line[packet->parsed_lines].ptr,\n\t\t      \"Upgrade-Insecure-Requests: \", 27) == 0)) {\n\t/* Just count. In the future, if needed, this if can be splited to parse these headers */\n\tpacket->http_num_headers++;\n      }\n\n      if(packet->line[packet->parsed_lines].len == 0) {\n\tpacket->empty_line_position = a;\n\tpacket->empty_line_position_set = 1;\n      }\n\n      if(packet->parsed_lines >= (NDPI_MAX_PARSE_LINES_PER_PACKET - 1))\n\treturn;\n\n      packet->parsed_lines++;\n      packet->line[packet->parsed_lines].ptr = &packet->payload[a + 2];\n      packet->line[packet->parsed_lines].len = 0;\n\n      a++; /* next char in the payload */\n    }\n  }\n\n  if(packet->parsed_lines >= 1) {\n    packet->line[packet->parsed_lines].len =\n      (u_int16_t)(((unsigned long) &packet->payload[packet->payload_packet_len]) -\n\t\t  ((unsigned long) packet->line[packet->parsed_lines].ptr));\n    packet->parsed_lines++;\n  }\n}",
        "commit_message": "Added check for heap buffer overflow read",
        "cve_desc": "In nDPI through 3.2, the packet parsing code is vulnerable to a heap-based buffer over-read in ndpi_parse_packet_line_info in lib/ndpi_main.c.",
        "target": 1
      }
    ]
  },
  "nanopb": {
    "0": [],
    "1": []
  },
  "nasm": {
    "0": [
      {
        "idx": 286655,
        "reasoning": "This code snippet is not vulnerable because it only deals with freeing memory associated with macro tables\u2014`smacros` and `mmacros`. The commit message and bug report relate to a preprocessor issue with handling unterminated strings, which is entirely separate from the memory freeing operations performed in this function.\n\n\n\n",
        "func": "static void free_macros(void)\n{\n    free_smacro_table(&smacros);\n    free_mmacro_table(&mmacros);\n}",
        "commit_message": "preproc: Don't access offsting byte on unterminated strings\n\nhttps://bugzilla.nasm.us/show_bug.cgi?id=3392446\n\nSigned-off-by: Cyrill Gorcunov <gorcunov@gmail.com>",
        "cve_desc": "Netwide Assembler (NASM) 2.13.02rc2 has a heap-based buffer over-read in the function tokenize in asm/preproc.c, related to an unterminated string.",
        "target": 0
      },
      {
        "idx": 286657,
        "reasoning": "This code addresses a potential out-of-bounds read vulnerability by preventing access to a byte beyond the end of unterminated strings within the `TOK_STRING` handling section. The fix ensures that the code checks for a proper closing quote and null terminator before accessing `ep[0]` and `ep[1]`, thus mitigating the risk of reading invalid memory.\n\n\n\n",
        "func": "static int ppscan(void *private_data, struct tokenval *tokval)\n{\n    Token **tlineptr = private_data;\n    Token *tline;\n    char ourcopy[MAX_KEYWORD+1], *p, *r, *s;\n\n    do {\n        tline = *tlineptr;\n        *tlineptr = tline ? tline->next : NULL;\n    } while (tline && (tline->type == TOK_WHITESPACE ||\n                       tline->type == TOK_COMMENT));\n\n    if (!tline)\n        return tokval->t_type = TOKEN_EOS;\n\n    tokval->t_charptr = tline->text;\n\n    if (tline->text[0] == '$' && !tline->text[1])\n        return tokval->t_type = TOKEN_HERE;\n    if (tline->text[0] == '$' && tline->text[1] == '$' && !tline->text[2])\n        return tokval->t_type = TOKEN_BASE;\n\n    if (tline->type == TOK_ID) {\n        p = tokval->t_charptr = tline->text;\n        if (p[0] == '$') {\n            tokval->t_charptr++;\n            return tokval->t_type = TOKEN_ID;\n        }\n\n        for (r = p, s = ourcopy; *r; r++) {\n            if (r >= p+MAX_KEYWORD)\n                return tokval->t_type = TOKEN_ID; /* Not a keyword */\n            *s++ = nasm_tolower(*r);\n        }\n        *s = '\\0';\n        /* right, so we have an identifier sitting in temp storage. now,\n         * is it actually a register or instruction name, or what? */\n        return nasm_token_hash(ourcopy, tokval);\n    }\n\n    if (tline->type == TOK_NUMBER) {\n        bool rn_error;\n        tokval->t_integer = readnum(tline->text, &rn_error);\n        tokval->t_charptr = tline->text;\n        if (rn_error)\n            return tokval->t_type = TOKEN_ERRNUM;\n        else\n            return tokval->t_type = TOKEN_NUM;\n    }\n\n    if (tline->type == TOK_FLOAT) {\n        return tokval->t_type = TOKEN_FLOAT;\n    }\n\n    if (tline->type == TOK_STRING) {\n        char bq, *ep;\n\n        bq = tline->text[0];\n        tokval->t_charptr = tline->text;\n        tokval->t_inttwo = nasm_unquote(tline->text, &ep);\n\n        if (ep[0] != bq || ep[1] != '\\0')\n            return tokval->t_type = TOKEN_ERRSTR;\n        else\n            return tokval->t_type = TOKEN_STR;\n    }\n\n    if (tline->type == TOK_OTHER) {\n        if (!strcmp(tline->text, \"<<\"))\n            return tokval->t_type = TOKEN_SHL;\n        if (!strcmp(tline->text, \">>\"))\n            return tokval->t_type = TOKEN_SHR;\n        if (!strcmp(tline->text, \"//\"))\n            return tokval->t_type = TOKEN_SDIV;\n        if (!strcmp(tline->text, \"%%\"))\n            return tokval->t_type = TOKEN_SMOD;\n        if (!strcmp(tline->text, \"==\"))\n            return tokval->t_type = TOKEN_EQ;\n        if (!strcmp(tline->text, \"<>\"))\n            return tokval->t_type = TOKEN_NE;\n        if (!strcmp(tline->text, \"!=\"))\n            return tokval->t_type = TOKEN_NE;\n        if (!strcmp(tline->text, \"<=\"))\n            return tokval->t_type = TOKEN_LE;\n        if (!strcmp(tline->text, \">=\"))\n            return tokval->t_type = TOKEN_GE;\n        if (!strcmp(tline->text, \"&&\"))\n            return tokval->t_type = TOKEN_DBL_AND;\n        if (!strcmp(tline->text, \"^^\"))\n            return tokval->t_type = TOKEN_DBL_XOR;\n        if (!strcmp(tline->text, \"||\"))\n            return tokval->t_type = TOKEN_DBL_OR;\n    }\n\n    /*\n     * We have no other options: just return the first character of\n     * the token text.\n     */\n    return tokval->t_type = tline->text[0];\n}",
        "commit_message": "preproc: Don't access offsting byte on unterminated strings\n\nhttps://bugzilla.nasm.us/show_bug.cgi?id=3392446\n\nSigned-off-by: Cyrill Gorcunov <gorcunov@gmail.com>",
        "cve_desc": "Netwide Assembler (NASM) 2.13.02rc2 has a heap-based buffer over-read in the function tokenize in asm/preproc.c, related to an unterminated string.",
        "target": 0
      },
      {
        "idx": 286658,
        "reasoning": "This code addresses a potential vulnerability by preventing access to an offset byte on unterminated strings when constructing file paths. The fix ensures that `len+1` bytes are copied from `file` to `sl->str+prefix_len`, explicitly including the null terminator, thus preventing a read beyond the allocated buffer's bounds.\n\n\n\n",
        "func": "static FILE *inc_fopen_search(const char *file, StrList **slpath,\n                              enum incopen_mode omode, enum file_flags fmode)\n{\n    FILE *fp;\n    char *prefix = \"\";\n    const IncPath *ip = ipath;\n    int len = strlen(file);\n    size_t prefix_len = 0;\n    StrList *sl;\n    size_t path_len;\n    bool found;\n\n    while (1) {\n        path_len = prefix_len + len + 1;\n\n        sl = nasm_malloc(path_len + sizeof sl->next);\n        memcpy(sl->str, prefix, prefix_len);\n        memcpy(sl->str+prefix_len, file, len+1);\n        sl->next = NULL;\n\n        if (omode == INC_PROBE) {\n            fp = NULL;\n            found = nasm_file_exists(sl->str);\n        } else {\n            fp = nasm_open_read(sl->str, fmode);\n            found = (fp != NULL);\n        }\n        if (found) {\n            *slpath = sl;\n            return fp;\n        }\n\n        nasm_free(sl);\n\n        if (!ip)\n            return NULL;\n\n        prefix = ip->path;\n        prefix_len = strlen(prefix);\n        ip = ip->next;\n    }\n}",
        "commit_message": "preproc: Don't access offsting byte on unterminated strings\n\nhttps://bugzilla.nasm.us/show_bug.cgi?id=3392446\n\nSigned-off-by: Cyrill Gorcunov <gorcunov@gmail.com>",
        "cve_desc": "Netwide Assembler (NASM) 2.13.02rc2 has a heap-based buffer over-read in the function tokenize in asm/preproc.c, related to an unterminated string.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 198982,
        "reasoning": "The `tokenize` function is vulnerable to a heap-based buffer over-read because it doesn't properly handle unterminated strings, potentially accessing memory beyond the allocated buffer when `nasm_skip_string` reaches the end of the input without finding a terminator. Specifically, the code attempts to increment `p` after `nasm_skip_string` even when the string is unterminated, leading to an out-of-bounds read when calculating the token length (`p - line`).",
        "func": "static Token *tokenize(char *line)\n{\n    char c, *p = line;\n    enum pp_token_type type;\n    Token *list = NULL;\n    Token *t, **tail = &list;\n\n    while (*line) {\n        p = line;\n        if (*p == '%') {\n            p++;\n            if (*p == '+' && !nasm_isdigit(p[1])) {\n                p++;\n                type = TOK_PASTE;\n            } else if (nasm_isdigit(*p) ||\n                       ((*p == '-' || *p == '+') && nasm_isdigit(p[1]))) {\n                do {\n                    p++;\n                }\n                while (nasm_isdigit(*p));\n                type = TOK_PREPROC_ID;\n            } else if (*p == '{') {\n                p++;\n                while (*p) {\n                    if (*p == '}')\n                        break;\n                    p[-1] = *p;\n                    p++;\n                }\n                if (*p != '}')\n                    nasm_error(ERR_WARNING | ERR_PASS1,\n\t\t\t       \"unterminated %%{ construct\");\n                p[-1] = '\\0';\n                if (*p)\n                    p++;\n                type = TOK_PREPROC_ID;\n            } else if (*p == '[') {\n                int lvl = 1;\n                line += 2;      /* Skip the leading %[ */\n                p++;\n                while (lvl && (c = *p++)) {\n                    switch (c) {\n                    case ']':\n                        lvl--;\n                        break;\n                    case '%':\n                        if (*p == '[')\n                            lvl++;\n                        break;\n                    case '\\'':\n                    case '\\\"':\n                    case '`':\n                        p = nasm_skip_string(p - 1) + 1;\n                        break;\n                    default:\n                        break;\n                    }\n                }\n                p--;\n                if (*p)\n                    *p++ = '\\0';\n                if (lvl)\n                    nasm_error(ERR_NONFATAL|ERR_PASS1,\n\t\t\t       \"unterminated %%[ construct\");\n                type = TOK_INDIRECT;\n            } else if (*p == '?') {\n                type = TOK_PREPROC_Q; /* %? */\n                p++;\n                if (*p == '?') {\n                    type = TOK_PREPROC_QQ; /* %?? */\n                    p++;\n                }\n            } else if (*p == '!') {\n                type = TOK_PREPROC_ID;\n                p++;\n                if (isidchar(*p)) {\n                    do {\n                        p++;\n                    }\n                    while (isidchar(*p));\n                } else if (*p == '\\'' || *p == '\\\"' || *p == '`') {\n                    p = nasm_skip_string(p);\n                    if (*p)\n                        p++;\n                    else\n                        nasm_error(ERR_NONFATAL|ERR_PASS1,\n\t\t\t\t   \"unterminated %%! string\");\n                } else {\n                    /* %! without string or identifier */\n                    type = TOK_OTHER; /* Legacy behavior... */\n                }\n            } else if (isidchar(*p) ||\n                       ((*p == '!' || *p == '%' || *p == '$') &&\n                        isidchar(p[1]))) {\n                do {\n                    p++;\n                }\n                while (isidchar(*p));\n                type = TOK_PREPROC_ID;\n            } else {\n                type = TOK_OTHER;\n                if (*p == '%')\n                    p++;\n            }\n        } else if (isidstart(*p) || (*p == '$' && isidstart(p[1]))) {\n            type = TOK_ID;\n            p++;\n            while (*p && isidchar(*p))\n                p++;\n        } else if (*p == '\\'' || *p == '\"' || *p == '`') {\n            /*\n             * A string token.\n             */\n            type = TOK_STRING;\n            p = nasm_skip_string(p);\n\n            if (*p) {\n                p++;\n            } else {\n                nasm_error(ERR_WARNING|ERR_PASS1, \"unterminated string\");\n                /* Handling unterminated strings by UNV */\n                /* type = -1; */\n            }\n        } else if (p[0] == '$' && p[1] == '$') {\n            type = TOK_OTHER;   /* TOKEN_BASE */\n            p += 2;\n        } else if (isnumstart(*p)) {\n            bool is_hex = false;\n            bool is_float = false;\n            bool has_e = false;\n            char c, *r;\n\n            /*\n             * A numeric token.\n             */\n\n            if (*p == '$') {\n                p++;\n                is_hex = true;\n            }\n\n            for (;;) {\n                c = *p++;\n\n                if (!is_hex && (c == 'e' || c == 'E')) {\n                    has_e = true;\n                    if (*p == '+' || *p == '-') {\n                        /*\n                         * e can only be followed by +/- if it is either a\n                         * prefixed hex number or a floating-point number\n                         */\n                        p++;\n                        is_float = true;\n                    }\n                } else if (c == 'H' || c == 'h' || c == 'X' || c == 'x') {\n                    is_hex = true;\n                } else if (c == 'P' || c == 'p') {\n                    is_float = true;\n                    if (*p == '+' || *p == '-')\n                        p++;\n                } else if (isnumchar(c))\n                    ; /* just advance */\n                else if (c == '.') {\n                    /*\n                     * we need to deal with consequences of the legacy\n                     * parser, like \"1.nolist\" being two tokens\n                     * (TOK_NUMBER, TOK_ID) here; at least give it\n                     * a shot for now.  In the future, we probably need\n                     * a flex-based scanner with proper pattern matching\n                     * to do it as well as it can be done.  Nothing in\n                     * the world is going to help the person who wants\n                     * 0x123.p16 interpreted as two tokens, though.\n                     */\n                    r = p;\n                    while (*r == '_')\n                        r++;\n\n                    if (nasm_isdigit(*r) || (is_hex && nasm_isxdigit(*r)) ||\n                        (!is_hex && (*r == 'e' || *r == 'E')) ||\n                        (*r == 'p' || *r == 'P')) {\n                        p = r;\n                        is_float = true;\n                    } else\n                        break;  /* Terminate the token */\n                } else\n                    break;\n            }\n            p--;        /* Point to first character beyond number */\n\n            if (p == line+1 && *line == '$') {\n                type = TOK_OTHER; /* TOKEN_HERE */\n            } else {\n                if (has_e && !is_hex) {\n                    /* 1e13 is floating-point, but 1e13h is not */\n                    is_float = true;\n                }\n\n                type = is_float ? TOK_FLOAT : TOK_NUMBER;\n            }\n        } else if (nasm_isspace(*p)) {\n            type = TOK_WHITESPACE;\n            p = nasm_skip_spaces(p);\n            /*\n             * Whitespace just before end-of-line is discarded by\n             * pretending it's a comment; whitespace just before a\n             * comment gets lumped into the comment.\n             */\n            if (!*p || *p == ';') {\n                type = TOK_COMMENT;\n                while (*p)\n                    p++;\n            }\n        } else if (*p == ';') {\n            type = TOK_COMMENT;\n            while (*p)\n                p++;\n        } else {\n            /*\n             * Anything else is an operator of some kind. We check\n             * for all the double-character operators (>>, <<, //,\n             * %%, <=, >=, ==, !=, <>, &&, ||, ^^), but anything\n             * else is a single-character operator.\n             */\n            type = TOK_OTHER;\n            if ((p[0] == '>' && p[1] == '>') ||\n                (p[0] == '<' && p[1] == '<') ||\n                (p[0] == '/' && p[1] == '/') ||\n                (p[0] == '<' && p[1] == '=') ||\n                (p[0] == '>' && p[1] == '=') ||\n                (p[0] == '=' && p[1] == '=') ||\n                (p[0] == '!' && p[1] == '=') ||\n                (p[0] == '<' && p[1] == '>') ||\n                (p[0] == '&' && p[1] == '&') ||\n                (p[0] == '|' && p[1] == '|') ||\n                (p[0] == '^' && p[1] == '^')) {\n                p++;\n            }\n            p++;\n        }\n\n        /* Handling unterminated string by UNV */\n        /*if (type == -1)\n          {\n          *tail = t = new_Token(NULL, TOK_STRING, line, p-line+1);\n          t->text[p-line] = *line;\n          tail = &t->next;\n          }\n          else */\n        if (type != TOK_COMMENT) {\n            *tail = t = new_Token(NULL, type, line, p - line);\n            tail = &t->next;\n        }\n        line = p;\n    }\n    return list;\n}",
        "commit_message": "preproc: Don't access offsting byte on unterminated strings\n\nhttps://bugzilla.nasm.us/show_bug.cgi?id=3392446\n\nSigned-off-by: Cyrill Gorcunov <gorcunov@gmail.com>",
        "cve_desc": "Netwide Assembler (NASM) 2.13.02rc2 has a heap-based buffer over-read in the function tokenize in asm/preproc.c, related to an unterminated string.",
        "target": 1
      },
      {
        "idx": 212372,
        "reasoning": "The code is vulnerable because the flattening of a subexpression within `parse_eops` doesn't fully handle the associated data buffer, potentially leading to a use-after-free if the original `eop` is freed while the `subexpr` still points to its data. Although the commit message states it *partially* resolves a related issue (BR 3392707), the vulnerability persists under certain conditions (-gcv8), indicating incomplete mitigation and a potential for memory corruption as highlighted by the provided CVE description regarding heap use-after-free in other parts of NASM.",
        "func": "static int parse_eops(extop **result, bool critical, int elem)\n{\n    extop *eop = NULL, *prev = NULL;\n    extop **tail = result;\n    int sign;\n    int i = tokval.t_type;\n    int oper_num = 0;\n    bool do_subexpr = false;\n\n    *tail = NULL;\n\n    /* End of string is obvious; ) ends a sub-expression list e.g. DUP */\n    for (i = tokval.t_type; i != TOKEN_EOS; i = stdscan(NULL, &tokval)) {\n        char endparen = ')';   /* Is a right paren the end of list? */\n\n        if (i == ')')\n            break;\n\n        if (!eop) {\n            nasm_new(eop);\n            eop->dup  = 1;\n            eop->elem = elem;\n            do_subexpr = false;\n        }\n        sign = +1;\n\n        /*\n         * end_expression_next() here is to distinguish this from\n         * a string used as part of an expression...\n         */\n        if (i == TOKEN_QMARK) {\n            eop->type = EOT_DB_RESERVE;\n        } else if (do_subexpr && i == '(') {\n            extop *subexpr;\n\n            stdscan(NULL, &tokval); /* Skip paren */\n            if (parse_eops(&eop->val.subexpr, critical, eop->elem) < 0)\n                goto fail;\n\n            subexpr = eop->val.subexpr;\n            if (!subexpr) {\n                /* Subexpression is empty */\n                eop->type = EOT_NOTHING;\n            } else if (!subexpr->next) {\n                /* Subexpression is a single element, flatten */\n                eop->val   = subexpr->val;\n                eop->type  = subexpr->type;\n                eop->dup  *= subexpr->dup;\n                nasm_free(subexpr);\n            } else {\n                eop->type = EOT_EXTOP;\n            }\n\n            /* We should have ended on a closing paren */\n            if (tokval.t_type != ')') {\n                nasm_nonfatal(\"expected `)' after subexpression, got `%s'\",\n                              i == TOKEN_EOS ?\n                              \"end of line\" : tokval.t_charptr);\n                goto fail;\n            }\n            endparen = 0;       /* This time the paren is not the end */\n        } else if (i == '%') {\n            /* %(expression_list) */\n            do_subexpr = true;\n            continue;\n        } else if (i == TOKEN_SIZE) {\n            /* Element size override */\n            eop->elem = tokval.t_inttwo;\n            do_subexpr = true;\n            continue;\n        } else if (i == TOKEN_STR && end_expression_next()) {\n            eop->type            = EOT_DB_STRING;\n            eop->val.string.data = tokval.t_charptr;\n            eop->val.string.len  = tokval.t_inttwo;\n        } else if (i == TOKEN_STRFUNC) {\n            bool parens = false;\n            const char *funcname = tokval.t_charptr;\n            enum strfunc func = tokval.t_integer;\n\n            i = stdscan(NULL, &tokval);\n            if (i == '(') {\n                parens = true;\n                endparen = 0;\n                i = stdscan(NULL, &tokval);\n            }\n            if (i != TOKEN_STR) {\n                nasm_nonfatal(\"%s must be followed by a string constant\",\n                              funcname);\n                eop->type = EOT_NOTHING;\n            } else {\n                eop->type = EOT_DB_STRING_FREE;\n                eop->val.string.len =\n                    string_transform(tokval.t_charptr, tokval.t_inttwo,\n                                     &eop->val.string.data, func);\n                if (eop->val.string.len == (size_t)-1) {\n                    nasm_nonfatal(\"invalid input string to %s\", funcname);\n                    eop->type = EOT_NOTHING;\n                }\n            }\n            if (parens && i && i != ')') {\n                i = stdscan(NULL, &tokval);\n                if (i != ')')\n                    nasm_nonfatal(\"unterminated %s function\", funcname);\n            }\n        } else if (i == '-' || i == '+') {\n            char *save = stdscan_get();\n            struct tokenval tmptok;\n\n            sign = (i == '-') ? -1 : 1;\n            if (stdscan(NULL, &tmptok) != TOKEN_FLOAT) {\n                stdscan_set(save);\n                goto is_expression;\n            } else {\n                tokval = tmptok;\n                goto is_float;\n            }\n        } else if (i == TOKEN_FLOAT) {\n            enum floatize fmt;\n        is_float:\n            eop->type = EOT_DB_FLOAT;\n\n            fmt = float_deffmt(eop->elem);\n            if (fmt == FLOAT_ERR) {\n                nasm_nonfatal(\"no %d-bit floating-point format supported\",\n                              eop->elem << 3);\n                eop->val.string.len = 0;\n            } else if (eop->elem < 1) {\n                nasm_nonfatal(\"floating-point constant\"\n                              \" encountered in unknown instruction\");\n                /*\n                 * fix suggested by Pedro Gimeno... original line was:\n                 * eop->type = EOT_NOTHING;\n                 */\n                eop->val.string.len = 0;\n            } else {\n                eop->val.string.len = eop->elem;\n\n                eop = nasm_realloc(eop, sizeof(extop) + eop->val.string.len);\n                eop->val.string.data = (char *)eop + sizeof(extop);\n                if (!float_const(tokval.t_charptr, sign,\n                                 (uint8_t *)eop->val.string.data, fmt))\n                    eop->val.string.len = 0;\n            }\n            if (!eop->val.string.len)\n                eop->type = EOT_NOTHING;\n        } else {\n            /* anything else, assume it is an expression */\n            expr *value;\n\n        is_expression:\n            value = evaluate(stdscan, NULL, &tokval, NULL,\n                             critical, NULL);\n            i = tokval.t_type;\n            if (!value)                  /* Error in evaluator */\n                goto fail;\n            if (tokval.t_flag & TFLAG_DUP) {\n                /* Expression followed by DUP */\n                if (!is_simple(value)) {\n                    nasm_nonfatal(\"non-constant argument supplied to DUP\");\n                    goto fail;\n                } else if (value->value < 0) {\n                    nasm_nonfatal(\"negative argument supplied to DUP\");\n                    goto fail;\n                }\n                eop->dup *= (size_t)value->value;\n                do_subexpr = true;\n                continue;\n            }\n            if (value_to_extop(value, eop, location.segment)) {\n                nasm_nonfatal(\"expression is not simple or relocatable\");\n            }\n        }\n\n        if (eop->dup == 0 || eop->type == EOT_NOTHING) {\n            nasm_free(eop);\n        } else if (eop->type == EOT_DB_RESERVE &&\n                   prev && prev->type == EOT_DB_RESERVE &&\n                   prev->elem == eop->elem) {\n            /* Coalesce multiple EOT_DB_RESERVE */\n            prev->dup += eop->dup;\n            nasm_free(eop);\n        } else {\n            /* Add this eop to the end of the chain */\n            prev = eop;\n            *tail = eop;\n            tail = &eop->next;\n        }\n\n        oper_num++;\n        eop = NULL;             /* Done with this operand */\n\n        /*\n         * We're about to call stdscan(), which will eat the\n         * comma that we're currently sitting on between\n         * arguments. However, we'd better check first that it\n         * _is_ a comma.\n         */\n        if (i == TOKEN_EOS || i == endparen)\t/* Already at end? */\n            break;\n        if (i != ',') {\n            i = stdscan(NULL, &tokval);\t\t/* eat the comma or final paren */\n            if (i == TOKEN_EOS || i == ')')\t/* got end of expression */\n                break;\n            if (i != ',') {\n                nasm_nonfatal(\"comma expected after operand\");\n                goto fail;\n            }\n        }\n    }\n\n    return oper_num;\n\nfail:\n    if (eop)\n        nasm_free(eop);\n    return -1;\n}",
        "commit_message": "parser: when flattening an eop, must preserve any data buffer\n\nAn eop may have a data buffer associated with it as part of the same\nmemory allocation. Therefore, we need to move \"subexpr\" up instead of\nmerging it into \"eop\".\n\nThis *partially* resolves BR 3392707, but that test case still\ntriggers a violation when using -gcv8.\n\nReported-by: Suhwan <prada960808@gmail.com>\nSigned-off-by: H. Peter Anvin (Intel) <hpa@zytor.com>",
        "cve_desc": "In Netwide Assembler (NASM) 2.15rc10, there is heap use-after-free in saa_wbytes in nasmlib/saa.c.",
        "target": 1
      }
    ]
  },
  "neomutt": {
    "0": [
      {
        "idx": 73222,
        "reasoning": "This code is likely safe as it uses `cache_expand` to construct the file path, which presumably incorporates sanitization to prevent path traversal vulnerabilities. Additionally, `mutt_file_fopen` is used for file opening, and while not a guarantee, it *may* offer some level of security checks, and the code doesn't directly use user-supplied input in a dangerous way within the file path construction or reading process.\n\n\n\n",
        "func": "static int active_get_cache(struct NntpServer *nserv)\n{\n  char buf[HUGE_STRING];\n  char file[PATH_MAX];\n  time_t t;\n\n  cache_expand(file, sizeof(file), &nserv->conn->account, \".active\");\n  mutt_debug(1, \"Parsing %s\\n\", file);\n  FILE *fp = mutt_file_fopen(file, \"r\");\n  if (!fp)\n    return -1;\n\n  if (fgets(buf, sizeof(buf), fp) == NULL || sscanf(buf, \"%ld%s\", &t, file) != 1 || t == 0)\n  {\n    mutt_file_fclose(&fp);\n    return -1;\n  }\n  nserv->newgroups_time = t;\n\n  mutt_message(_(\"Loading list of groups from cache...\"));\n  while (fgets(buf, sizeof(buf), fp))\n    nntp_add_group(buf, nserv);\n  nntp_add_group(NULL, NULL);\n  mutt_file_fclose(&fp);\n  mutt_clear_error();\n  return 0;\n}\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 0
      },
      {
        "idx": 73223,
        "reasoning": "This code appears safe as it focuses on sanitizing and constructing cache paths, not directly handling user-controlled input in a dangerous way. While `src` is an input, it's used within functions designed to handle path construction (`url_tostring`, `mutt_str_strfcpy`) and further sanitized with `mutt_expand_path` and `mutt_encode_path` before being used in `snprintf`, mitigating potential path manipulation vulnerabilities.\n\n\n\n",
        "func": "static void cache_expand(char *dst, size_t dstlen, struct Account *acct, char *src)\n{\n  char *c = NULL;\n  char file[PATH_MAX];\n\n  /* server subdirectory */\n  if (acct)\n  {\n    struct Url url;\n\n    mutt_account_tourl(acct, &url);\n    url.path = src;\n    url_tostring(&url, file, sizeof(file), U_PATH);\n  }\n  else\n    mutt_str_strfcpy(file, src ? src : \"\", sizeof(file));\n\n  snprintf(dst, dstlen, \"%s/%s\", NewsCacheDir, file);\n\n  /* remove trailing slash */\n  c = dst + strlen(dst) - 1;\n  if (*c == '/')\n    *c = '\\0';\n  mutt_expand_path(dst, dstlen);\n  mutt_encode_path(dst, dstlen, dst);\n}\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 0
      },
      {
        "idx": 73224,
        "reasoning": "This code snippet appears safe as it primarily focuses on data structure management and flag setting within the `nntp_data` structure and associated contexts. There are no apparent issues like buffer overflows, format string vulnerabilities, or insecure file handling that would immediately flag it as vulnerable, and the commit message suggests a sanitization effort rather than addressing a security flaw.\n\n\n\n",
        "func": "struct NntpData *mutt_newsgroup_catchup(struct NntpServer *nserv, char *group)\n{\n  struct NntpData *nntp_data = NULL;\n\n  if (!nserv || !nserv->groups_hash || !group || !*group)\n    return NULL;\n\n  nntp_data = mutt_hash_find(nserv->groups_hash, group);\n  if (!nntp_data)\n    return NULL;\n\n  if (nntp_data->newsrc_ent)\n  {\n    mutt_mem_realloc(&nntp_data->newsrc_ent, sizeof(struct NewsrcEntry));\n    nntp_data->newsrc_len = 1;\n    nntp_data->newsrc_ent[0].first = 1;\n    nntp_data->newsrc_ent[0].last = nntp_data->last_message;\n  }\n  nntp_data->unread = 0;\n  if (Context && Context->data == nntp_data)\n  {\n    for (unsigned int i = 0; i < Context->msgcount; i++)\n      mutt_set_flag(Context, Context->hdrs[i], MUTT_READ, 1);\n  }\n  return nntp_data;\n}\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 0
      },
      {
        "idx": 73225,
        "reasoning": "This code snippet appears safe as it primarily deals with internal data structure manipulation and doesn't directly handle external input that could lead to vulnerabilities like injection or buffer overflows. The functions used, such as `mutt_hash_find` and `mutt_mem_realloc`, are likely internal library functions designed to handle memory management safely within the neomutt context, and there's no apparent path for untrusted data to influence control flow.\n\n\n\n",
        "func": "struct NntpData *mutt_newsgroup_uncatchup(struct NntpServer *nserv, char *group)\n{\n  struct NntpData *nntp_data = NULL;\n\n  if (!nserv || !nserv->groups_hash || !group || !*group)\n    return NULL;\n\n  nntp_data = mutt_hash_find(nserv->groups_hash, group);\n  if (!nntp_data)\n    return NULL;\n\n  if (nntp_data->newsrc_ent)\n  {\n    mutt_mem_realloc(&nntp_data->newsrc_ent, sizeof(struct NewsrcEntry));\n    nntp_data->newsrc_len = 1;\n    nntp_data->newsrc_ent[0].first = 1;\n    nntp_data->newsrc_ent[0].last = nntp_data->first_message - 1;\n  }\n  if (Context && Context->data == nntp_data)\n  {\n    nntp_data->unread = Context->msgcount;\n    for (unsigned int i = 0; i < Context->msgcount; i++)\n      mutt_set_flag(Context, Context->hdrs[i], MUTT_READ, 0);\n  }\n  else\n  {\n    nntp_data->unread = nntp_data->last_message;\n    if (nntp_data->newsrc_ent)\n      nntp_data->unread -= nntp_data->newsrc_ent[0].last;\n  }\n  return nntp_data;\n}\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 0
      },
      {
        "idx": 73226,
        "reasoning": "This code snippet is not vulnerable because it primarily handles data structure manipulation \u2013 unsubscribing from an NNTP newsgroup and updating internal flags/data related to that subscription. There's no external input directly used in a way that could lead to injection flaws, path traversal, or other common vulnerabilities; it relies on pre-existing data within the `nserv` structure and the provided `group` name which is already validated by the initial `if` statement.",
        "func": "struct NntpData *mutt_newsgroup_unsubscribe(struct NntpServer *nserv, char *group)\n{\n  struct NntpData *nntp_data = NULL;\n\n  if (!nserv || !nserv->groups_hash || !group || !*group)\n    return NULL;\n\n  nntp_data = mutt_hash_find(nserv->groups_hash, group);\n  if (!nntp_data)\n    return NULL;\n\n  nntp_data->subscribed = false;\n  if (!SaveUnsubscribed)\n  {\n    nntp_data->newsrc_len = 0;\n    FREE(&nntp_data->newsrc_ent);\n  }\n  return nntp_data;\n}\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3622,
        "reasoning": "This code is vulnerable to a path traversal attack because the `path` argument, which is user-controlled (likely derived from a newsgroup name), is directly incorporated into the cache filename without sanitization.  Specifically, a malicious user could provide a `path` containing `/` characters, allowing them to write the cache file to an arbitrary location on the filesystem, as described in the CVE.",
        "func": " static int nntp_hcache_namer(const char *path, char *dest, size_t destlen)\n {\n  return snprintf(dest, destlen, \"%s.hcache\", path);\n }\n",
        "commit_message": "sanitise cache paths\n\nCo-authored-by: JerikoOne <jeriko.one@gmx.us>",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. newsrc.c does not properly restrict '/' characters that may have unsafe interaction with cache pathnames.",
        "target": 1
      },
      {
        "idx": 3626,
        "reasoning": "The `nntp_add_group` function is vulnerable to a stack-based buffer overflow due to the use of `sscanf` with the `%[^\\n]` format specifier to read the `desc` field directly into a fixed-size stack buffer (`desc[HUGE_STRING]`). If the NNTP server sends a description longer than `HUGE_STRING - 1` characters, `sscanf` will write beyond the bounds of the buffer, potentially overwriting other data on the stack and leading to a crash or arbitrary code execution.",
        "func": "int nntp_add_group(char *line, void *data)\n {\n   struct NntpServer *nserv = data;\n   struct NntpData *nntp_data = NULL;\n  char group[LONG_STRING];\n   char desc[HUGE_STRING] = \"\";\n   char mod;\n   anum_t first, last;\n \n   if (!nserv || !line)\n     return 0;\n \n  if (sscanf(line, \"%s \" ANUM \" \" ANUM \" %c %[^\\n]\", group, &last, &first, &mod, desc) < 4)\n     return 0;\n \n   nntp_data = nntp_data_find(nserv, group);\n   nntp_data->deleted = false;\n  nntp_data->first_message = first;\n  nntp_data->last_message = last;\n  nntp_data->allowed = (mod == 'y') || (mod == 'm');\n  mutt_str_replace(&nntp_data->desc, desc);\n  if (nntp_data->newsrc_ent || nntp_data->last_cached)\n    nntp_group_unread_stat(nntp_data);\n  else if (nntp_data->last_message && nntp_data->first_message <= nntp_data->last_message)\n    nntp_data->unread = nntp_data->last_message - nntp_data->first_message + 1;\n  else\n    nntp_data->unread = 0;\n  return 0;\n}\n",
        "commit_message": "Set length modifiers for group and desc\n\nnntp_add_group parses a line controlled by the connected nntp server.\nRestrict the maximum lengths read into the stack buffers group, and\ndesc.",
        "cve_desc": "An issue was discovered in NeoMutt before 2018-07-16. nntp_add_group in newsrc.c has a stack-based buffer overflow because of incorrect sscanf usage.",
        "target": 1
      },
      {
        "idx": 3633,
        "reasoning": "The code is vulnerable to a stack-based buffer overflow because the `tmp` buffer, used to store the `INTERNALDATE` value, has a fixed size (`SHORT_STRING`) and the code doesn't check if the incoming `INTERNALDATE` string exceeds this size before copying it with `strcpy`-like behavior via `*ptmp++ = *s++`. This allows a malicious server to send a very long `INTERNALDATE` string, overwriting adjacent stack memory and potentially leading to arbitrary code execution.",
        "func": "static int msg_parse_fetch(struct ImapHeader *h, char *s)\n{\n  char tmp[SHORT_STRING];\n  char *ptmp = NULL;\n\n  if (!s)\n    return -1;\n\n  while (*s)\n  {\n    SKIPWS(s);\n\n    if (mutt_str_strncasecmp(\"FLAGS\", s, 5) == 0)\n    {\n      s = msg_parse_flags(h, s);\n      if (!s)\n        return -1;\n    }\n    else if (mutt_str_strncasecmp(\"UID\", s, 3) == 0)\n    {\n      s += 3;\n      SKIPWS(s);\n      if (mutt_str_atoui(s, &h->data->uid) < 0)\n        return -1;\n\n      s = imap_next_word(s);\n    }\n    else if (mutt_str_strncasecmp(\"INTERNALDATE\", s, 12) == 0)\n    {\n      s += 12;\n      SKIPWS(s);\n      if (*s != '\\\"')\n      {\n        mutt_debug(1, \"bogus INTERNALDATE entry: %s\\n\", s);\n        return -1;\n       }\n       s++;\n       ptmp = tmp;\n      while (*s && *s != '\\\"')\n         *ptmp++ = *s++;\n       if (*s != '\\\"')\n         return -1;\n      s++; /* skip past the trailing \" */\n      *ptmp = '\\0';\n      h->received = mutt_date_parse_imap(tmp);\n    }\n    else if (mutt_str_strncasecmp(\"RFC822.SIZE\", s, 11) == 0)\n    {\n       s += 11;\n       SKIPWS(s);\n       ptmp = tmp;\n      while (isdigit((unsigned char) *s))\n         *ptmp++ = *s++;\n       *ptmp = '\\0';\n       if (mutt_str_atol(tmp, &h->content_length) < 0)\n        return -1;\n    }\n    else if ((mutt_str_strncasecmp(\"BODY\", s, 4) == 0) ||\n             (mutt_str_strncasecmp(\"RFC822.HEADER\", s, 13) == 0))\n    {\n      /* handle above, in msg_fetch_header */\n      return -2;\n    }\n    else if (*s == ')')\n      s++; /* end of request */\n    else if (*s)\n    {\n      /* got something i don't understand */\n      imap_error(\"msg_parse_fetch\", s);\n      return -1;\n    }\n  }\n\n  return 0;\n}\n",
        "commit_message": "Don't overflow stack buffer in msg_parse_fetch",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. imap/message.c has a stack-based buffer overflow for a FETCH response with a long INTERNALDATE field.",
        "target": 1
      },
      {
        "idx": 3637,
        "reasoning": "This code is vulnerable to an integer underflow because `ctx->hdrs[i]->index` is assigned `index - 1` without checking if `index` is zero. If a zero-length UID is received (index = 0), `ctx->hdrs[i]->index` will become -1, potentially leading to out-of-bounds access when used as an array index elsewhere in the program, as described in the CVE.\n\n\n\n",
        "func": "static int fetch_uidl(char *line, void *data)\n{\n  int i, index;\n  struct Context *ctx = (struct Context *) data;\n  struct PopData *pop_data = (struct PopData *) ctx->data;\n  char *endp = NULL;\n\n  errno = 0;\n  index = strtol(line, &endp, 10);\n  if (errno)\n    return -1;\n  while (*endp == ' ')\n     endp++;\n   memmove(line, endp, strlen(endp) + 1);\n \n   for (i = 0; i < ctx->msgcount; i++)\n     if (mutt_str_strcmp(line, ctx->hdrs[i]->data) == 0)\n       break;\n\n  if (i == ctx->msgcount)\n  {\n    mutt_debug(1, \"new header %d %s\\n\", index, line);\n\n    if (i >= ctx->hdrmax)\n      mx_alloc_memory(ctx);\n\n    ctx->msgcount++;\n    ctx->hdrs[i] = mutt_header_new();\n    ctx->hdrs[i]->data = mutt_str_strdup(line);\n  }\n  else if (ctx->hdrs[i]->index != index - 1)\n    pop_data->clear_cache = true;\n\n  ctx->hdrs[i]->refno = index;\n  ctx->hdrs[i]->index = index - 1;\n\n  return 0;\n}\n",
        "commit_message": "Ensure UID in fetch_uidl",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. pop.c mishandles a zero-length UID.",
        "target": 1
      },
      {
        "idx": 3638,
        "reasoning": "This code is vulnerable to command injection because it directly incorporates the user-supplied `path` into an IMAP command string (`mbox`) without proper sanitization, specifically within the `snprintf` call constructing the `mailboxes` command.  The `path` could contain backticks (`) or other shell metacharacters, allowing a malicious IMAP server to inject and execute arbitrary commands on the client machine when `mutt_parse_rc_line` processes the crafted response.",
        "func": "int imap_subscribe(char *path, bool subscribe)\n{\n  struct ImapData *idata = NULL;\n  char buf[LONG_STRING];\n  char mbox[LONG_STRING];\n   char errstr[STRING];\n   struct Buffer err, token;\n   struct ImapMbox mx;\n \n   if (!mx_is_imap(path) || imap_parse_path(path, &mx) || !mx.mbox)\n   {\n    mutt_error(_(\"Bad mailbox name\"));\n    return -1;\n  }\n  idata = imap_conn_find(&(mx.account), 0);\n  if (!idata)\n    goto fail;\n\n  imap_fix_path(idata, mx.mbox, buf, sizeof(buf));\n  if (!*buf)\n    mutt_str_strfcpy(buf, \"INBOX\", sizeof(buf));\n\n  if (ImapCheckSubscribed)\n  {\n    mutt_buffer_init(&token);\n     mutt_buffer_init(&err);\n     err.data = errstr;\n     err.dsize = sizeof(errstr);\n    snprintf(mbox, sizeof(mbox), \"%smailboxes \\\"%s\\\"\", subscribe ? \"\" : \"un\", path);\n     if (mutt_parse_rc_line(mbox, &token, &err))\n       mutt_debug(1, \"Error adding subscribed mailbox: %s\\n\", errstr);\n     FREE(&token.data);\n  }\n\n  if (subscribe)\n    mutt_message(_(\"Subscribing to %s...\"), buf);\n  else\n    mutt_message(_(\"Unsubscribing from %s...\"), buf);\n  imap_munge_mbox_name(idata, mbox, sizeof(mbox), buf);\n\n  snprintf(buf, sizeof(buf), \"%sSUBSCRIBE %s\", subscribe ? \"\" : \"UN\", mbox);\n\n  if (imap_exec(idata, buf, 0) < 0)\n    goto fail;\n\n  imap_unmunge_mbox_name(idata, mx.mbox);\n  if (subscribe)\n    mutt_message(_(\"Subscribed to %s\"), mx.mbox);\n  else\n    mutt_message(_(\"Unsubscribed from %s\"), mx.mbox);\n  FREE(&mx.mbox);\n  return 0;\n\nfail:\n  FREE(&mx.mbox);\n  return -1;\n}\n",
        "commit_message": "Quote path in imap_subscribe",
        "cve_desc": "An issue was discovered in Mutt before 1.10.1 and NeoMutt before 2018-07-16. They allow remote IMAP servers to execute arbitrary commands via backquote characters, related to the mailboxes command associated with a manual subscription or unsubscription.",
        "target": 1
      }
    ]
  },
  "net": {
    "0": [
      {
        "idx": 281011,
        "reasoning": "The provided code snippet `sctp_assoc_clean_asconf_ack_cache` is not directly related to the vulnerability described in the commit message. The vulnerability stems from improper handling of authentication capabilities during INIT collisions in SCTP associations, specifically a missing update to `asoc->peer.auth_capable`, while this code manages a list of acknowledged chunks and doesn't involve authentication key initialization or HMAC calculation.\n\n\n\n",
        "func": "void sctp_assoc_clean_asconf_ack_cache(const struct sctp_association *asoc)\n{\n\tstruct sctp_chunk *ack;\n\tstruct sctp_chunk *tmp;\n\n\t/* We can remove all the entries from the queue up to\n\t * the \"Peer-Sequence-Number\".\n\t */\n\tlist_for_each_entry_safe(ack, tmp, &asoc->asconf_ack_list,\n\t\t\t\ttransmitted_list) {\n\t\tif (ack->subh.addip_hdr->serial ==\n\t\t\t\thtonl(asoc->peer.addip_serial))\n\t\t\tbreak;\n\n\t\tlist_del_init(&ack->transmitted_list);\n\t\tsctp_chunk_free(ack);\n\t}\n}",
        "commit_message": "net: sctp: inherit auth_capable on INIT collisions\n\nJason reported an oops caused by SCTP on his ARM machine with\nSCTP authentication enabled:\n\nInternal error: Oops: 17 [#1] ARM\nCPU: 0 PID: 104 Comm: sctp-test Not tainted 3.13.0-68744-g3632f30c9b20-dirty #1\ntask: c6eefa40 ti: c6f52000 task.ti: c6f52000\nPC is at sctp_auth_calculate_hmac+0xc4/0x10c\nLR is at sg_init_table+0x20/0x38\npc : [<c024bb80>]    lr : [<c00f32dc>]    psr: 40000013\nsp : c6f538e8  ip : 00000000  fp : c6f53924\nr10: c6f50d80  r9 : 00000000  r8 : 00010000\nr7 : 00000000  r6 : c7be4000  r5 : 00000000  r4 : c6f56254\nr3 : c00c8170  r2 : 00000001  r1 : 00000008  r0 : c6f1e660\nFlags: nZcv  IRQs on  FIQs on  Mode SVC_32  ISA ARM  Segment user\nControl: 0005397f  Table: 06f28000  DAC: 00000015\nProcess sctp-test (pid: 104, stack limit = 0xc6f521c0)\nStack: (0xc6f538e8 to 0xc6f54000)\n[...]\nBacktrace:\n[<c024babc>] (sctp_auth_calculate_hmac+0x0/0x10c) from [<c0249af8>] (sctp_packet_transmit+0x33c/0x5c8)\n[<c02497bc>] (sctp_packet_transmit+0x0/0x5c8) from [<c023e96c>] (sctp_outq_flush+0x7fc/0x844)\n[<c023e170>] (sctp_outq_flush+0x0/0x844) from [<c023ef78>] (sctp_outq_uncork+0x24/0x28)\n[<c023ef54>] (sctp_outq_uncork+0x0/0x28) from [<c0234364>] (sctp_side_effects+0x1134/0x1220)\n[<c0233230>] (sctp_side_effects+0x0/0x1220) from [<c02330b0>] (sctp_do_sm+0xac/0xd4)\n[<c0233004>] (sctp_do_sm+0x0/0xd4) from [<c023675c>] (sctp_assoc_bh_rcv+0x118/0x160)\n[<c0236644>] (sctp_assoc_bh_rcv+0x0/0x160) from [<c023d5bc>] (sctp_inq_push+0x6c/0x74)\n[<c023d550>] (sctp_inq_push+0x0/0x74) from [<c024a6b0>] (sctp_rcv+0x7d8/0x888)\n\nWhile we already had various kind of bugs in that area\nec0223ec48a9 (\"net: sctp: fix sctp_sf_do_5_1D_ce to verify if\nwe/peer is AUTH capable\") and b14878ccb7fa (\"net: sctp: cache\nauth_enable per endpoint\"), this one is a bit of a different\nkind.\n\nGiving a bit more background on why SCTP authentication is\nneeded can be found in RFC4895:\n\n  SCTP uses 32-bit verification tags to protect itself against\n  blind attackers. These values are not changed during the\n  lifetime of an SCTP association.\n\n  Looking at new SCTP extensions, there is the need to have a\n  method of proving that an SCTP chunk(s) was really sent by\n  the original peer that started the association and not by a\n  malicious attacker.\n\nTo cause this bug, we're triggering an INIT collision between\npeers; normal SCTP handshake where both sides intent to\nauthenticate packets contains RANDOM; CHUNKS; HMAC-ALGO\nparameters that are being negotiated among peers:\n\n  ---------- INIT[RANDOM; CHUNKS; HMAC-ALGO] ---------->\n  <------- INIT-ACK[RANDOM; CHUNKS; HMAC-ALGO] ---------\n  -------------------- COOKIE-ECHO -------------------->\n  <-------------------- COOKIE-ACK ---------------------\n\nRFC4895 says that each endpoint therefore knows its own random\nnumber and the peer's random number *after* the association\nhas been established. The local and peer's random number along\nwith the shared key are then part of the secret used for\ncalculating the HMAC in the AUTH chunk.\n\nNow, in our scenario, we have 2 threads with 1 non-blocking\nSEQ_PACKET socket each, setting up common shared SCTP_AUTH_KEY\nand SCTP_AUTH_ACTIVE_KEY properly, and each of them calling\nsctp_bindx(3), listen(2) and connect(2) against each other,\nthus the handshake looks similar to this, e.g.:\n\n  ---------- INIT[RANDOM; CHUNKS; HMAC-ALGO] ---------->\n  <------- INIT-ACK[RANDOM; CHUNKS; HMAC-ALGO] ---------\n  <--------- INIT[RANDOM; CHUNKS; HMAC-ALGO] -----------\n  -------- INIT-ACK[RANDOM; CHUNKS; HMAC-ALGO] -------->\n  ...\n\nSince such collisions can also happen with verification tags,\nthe RFC4895 for AUTH rather vaguely says under section 6.1:\n\n  In case of INIT collision, the rules governing the handling\n  of this Random Number follow the same pattern as those for\n  the Verification Tag, as explained in Section 5.2.4 of\n  RFC 2960 [5]. Therefore, each endpoint knows its own Random\n  Number and the peer's Random Number after the association\n  has been established.\n\nIn RFC2960, section 5.2.4, we're eventually hitting Action B:\n\n  B) In this case, both sides may be attempting to start an\n     association at about the same time but the peer endpoint\n     started its INIT after responding to the local endpoint's\n     INIT. Thus it may have picked a new Verification Tag not\n     being aware of the previous Tag it had sent this endpoint.\n     The endpoint should stay in or enter the ESTABLISHED\n     state but it MUST update its peer's Verification Tag from\n     the State Cookie, stop any init or cookie timers that may\n     running and send a COOKIE ACK.\n\nIn other words, the handling of the Random parameter is the\nsame as behavior for the Verification Tag as described in\nAction B of section 5.2.4.\n\nLooking at the code, we exactly hit the sctp_sf_do_dupcook_b()\ncase which triggers an SCTP_CMD_UPDATE_ASSOC command to the\nside effect interpreter, and in fact it properly copies over\npeer_{random, hmacs, chunks} parameters from the newly created\nassociation to update the existing one.\n\nAlso, the old asoc_shared_key is being released and based on\nthe new params, sctp_auth_asoc_init_active_key() updated.\nHowever, the issue observed in this case is that the previous\nasoc->peer.auth_capable was 0, and has *not* been updated, so\nthat instead of creating a new secret, we're doing an early\nreturn from the function sctp_auth_asoc_init_active_key()\nleaving asoc->asoc_shared_key as NULL. However, we now have to\nauthenticate chunks from the updated chunk list (e.g. COOKIE-ACK).\n\nThat in fact causes the server side when responding with ...\n\n  <------------------ AUTH; COOKIE-ACK -----------------\n\n... to trigger a NULL pointer dereference, since in\nsctp_packet_transmit(), it discovers that an AUTH chunk is\nbeing queued for xmit, and thus it calls sctp_auth_calculate_hmac().\n\nSince the asoc->active_key_id is still inherited from the\nendpoint, and the same as encoded into the chunk, it uses\nasoc->asoc_shared_key, which is still NULL, as an asoc_key\nand dereferences it in ...\n\n  crypto_hash_setkey(desc.tfm, &asoc_key->data[0], asoc_key->len)\n\n... causing an oops. All this happens because sctp_make_cookie_ack()\ncalled with the *new* association has the peer.auth_capable=1\nand therefore marks the chunk with auth=1 after checking\nsctp_auth_send_cid(), but it is *actually* sent later on over\nthe then *updated* association's transport that didn't initialize\nits shared key due to peer.auth_capable=0. Since control chunks\nin that case are not sent by the temporary association which\nare scheduled for deletion, they are issued for xmit via\nSCTP_CMD_REPLY in the interpreter with the context of the\n*updated* association. peer.auth_capable was 0 in the updated\nassociation (which went from COOKIE_WAIT into ESTABLISHED state),\nsince all previous processing that performed sctp_process_init()\nwas being done on temporary associations, that we eventually\nthrow away each time.\n\nThe correct fix is to update to the new peer.auth_capable\nvalue as well in the collision case via sctp_assoc_update(),\nso that in case the collision migrated from 0 -> 1,\nsctp_auth_asoc_init_active_key() can properly recalculate\nthe secret. This therefore fixes the observed server panic.\n\nFixes: 730fc3d05cd4 (\"[SCTP]: Implete SCTP-AUTH parameter processing\")\nReported-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>\nSigned-off-by: Daniel Borkmann <dborkman@redhat.com>\nTested-by: Jason Gunthorpe <jgunthorpe@obsidianresearch.com>\nCc: Vlad Yasevich <vyasevich@gmail.com>\nAcked-by: Vlad Yasevich <vyasevich@gmail.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The sctp_assoc_update function in net/sctp/associola.c in the Linux kernel through 3.15.8, when SCTP authentication is enabled, allows remote attackers to cause a denial of service (NULL pointer dereference and OOPS) by starting to establish an association between two endpoints immediately after an exchange of INIT and INIT ACK chunks to establish an earlier association between these endpoints in the opposite direction.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200022,
        "reasoning": "This code is vulnerable because the `zext_32_to_64` function called within the `BPF_MOV` case doesn't properly update register bounds after a 32-bit move, leading to pessimistic bounds and breaking the expected invariant that constant scalars have equal min/max values. This broken invariant can allow sensitive kernel pointer information to leak into user space via BPF maps when involved in pointer arithmetic, as the verifier may incorrectly mark registers as unknown.",
        "func": "static int check_alu_op(struct bpf_verifier_env *env, struct bpf_insn *insn)\n{\n\tstruct bpf_reg_state *regs = cur_regs(env);\n\tu8 opcode = BPF_OP(insn->code);\n\tint err;\n\n\tif (opcode == BPF_END || opcode == BPF_NEG) {\n\t\tif (opcode == BPF_NEG) {\n\t\t\tif (BPF_SRC(insn->code) != 0 ||\n\t\t\t    insn->src_reg != BPF_REG_0 ||\n\t\t\t    insn->off != 0 || insn->imm != 0) {\n\t\t\t\tverbose(env, \"BPF_NEG uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0 ||\n\t\t\t    (insn->imm != 16 && insn->imm != 32 && insn->imm != 64) ||\n\t\t\t    BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\tverbose(env, \"BPF_END uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (is_pointer_value(env, insn->dst_reg)) {\n\t\t\tverbose(env, \"R%d pointer arithmetic prohibited\\n\",\n\t\t\t\tinsn->dst_reg);\n\t\t\treturn -EACCES;\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t} else if (opcode == BPF_MOV) {\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\n\t\t\t/* check src operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_MOV uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand, mark as required later */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tstruct bpf_reg_state *src_reg = regs + insn->src_reg;\n\t\t\tstruct bpf_reg_state *dst_reg = regs + insn->dst_reg;\n\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t/* case: R1 = R2\n\t\t\t\t * copy register state to dest reg\n\t\t\t\t */\n\t\t\t\tif (src_reg->type == SCALAR_VALUE && !src_reg->id)\n\t\t\t\t\t/* Assign src and dst registers the same ID\n\t\t\t\t\t * that will be used by find_equal_scalars()\n\t\t\t\t\t * to propagate min/max range.\n\t\t\t\t\t */\n\t\t\t\t\tsrc_reg->id = ++env->id_gen;\n\t\t\t\t*dst_reg = *src_reg;\n\t\t\t\tdst_reg->live |= REG_LIVE_WRITTEN;\n\t\t\t\tdst_reg->subreg_def = DEF_NOT_SUBREG;\n\t\t\t} else {\n\t\t\t\t/* R1 = (u32) R2 */\n\t\t\t\tif (is_pointer_value(env, insn->src_reg)) {\n\t\t\t\t\tverbose(env,\n\t\t\t\t\t\t\"R%d partial copy of pointer\\n\",\n\t\t\t\t\t\tinsn->src_reg);\n\t\t\t\t\treturn -EACCES;\n\t\t\t\t} else if (src_reg->type == SCALAR_VALUE) {\n\t\t\t\t\t*dst_reg = *src_reg;\n\t\t\t\t\t/* Make sure ID is cleared otherwise\n\t\t\t\t\t * dst_reg min/max could be incorrectly\n\t\t\t\t\t * propagated into src_reg by find_equal_scalars()\n\t\t\t\t\t */\n\t\t\t\t\tdst_reg->id = 0;\n\t\t\t\t\tdst_reg->live |= REG_LIVE_WRITTEN;\n\t\t\t\t\tdst_reg->subreg_def = env->insn_idx + 1;\n\t\t\t\t} else {\n\t\t\t\t\tmark_reg_unknown(env, regs,\n\t\t\t\t\t\t\t insn->dst_reg);\n\t\t\t\t}\n\t\t\t\tzext_32_to_64(dst_reg);\n\t\t\t}\n\t\t} else {\n\t\t\t/* case: R = imm\n\t\t\t * remember the value we stored into this reg\n\t\t\t */\n\t\t\t/* clear any state __mark_reg_known doesn't set */\n\t\t\tmark_reg_unknown(env, regs, insn->dst_reg);\n\t\t\tregs[insn->dst_reg].type = SCALAR_VALUE;\n\t\t\tif (BPF_CLASS(insn->code) == BPF_ALU64) {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t insn->imm);\n\t\t\t} else {\n\t\t\t\t__mark_reg_known(regs + insn->dst_reg,\n\t\t\t\t\t\t (u32)insn->imm);\n\t\t\t}\n\t\t}\n\n\t} else if (opcode > BPF_END) {\n\t\tverbose(env, \"invalid BPF_ALU opcode %x\\n\", opcode);\n\t\treturn -EINVAL;\n\n\t} else {\t/* all other ALU ops: and, sub, xor, add, ... */\n\n\t\tif (BPF_SRC(insn->code) == BPF_X) {\n\t\t\tif (insn->imm != 0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t\t/* check src1 operand */\n\t\t\terr = check_reg_arg(env, insn->src_reg, SRC_OP);\n\t\t\tif (err)\n\t\t\t\treturn err;\n\t\t} else {\n\t\t\tif (insn->src_reg != BPF_REG_0 || insn->off != 0) {\n\t\t\t\tverbose(env, \"BPF_ALU uses reserved fields\\n\");\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check src2 operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, SRC_OP);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\tif ((opcode == BPF_MOD || opcode == BPF_DIV) &&\n\t\t    BPF_SRC(insn->code) == BPF_K && insn->imm == 0) {\n\t\t\tverbose(env, \"div by zero\\n\");\n\t\t\treturn -EINVAL;\n\t\t}\n\n\t\tif ((opcode == BPF_LSH || opcode == BPF_RSH ||\n\t\t     opcode == BPF_ARSH) && BPF_SRC(insn->code) == BPF_K) {\n\t\t\tint size = BPF_CLASS(insn->code) == BPF_ALU64 ? 64 : 32;\n\n\t\t\tif (insn->imm < 0 || insn->imm >= size) {\n\t\t\t\tverbose(env, \"invalid shift %d\\n\", insn->imm);\n\t\t\t\treturn -EINVAL;\n\t\t\t}\n\t\t}\n\n\t\t/* check dest operand */\n\t\terr = check_reg_arg(env, insn->dst_reg, DST_OP_NO_MARK);\n\t\tif (err)\n\t\t\treturn err;\n\n\t\treturn adjust_reg_min_max_vals(env, insn);\n\t}\n\n\treturn 0;\n}",
        "commit_message": "bpf: Fix signed bounds propagation after mov32\n\nFor the case where both s32_{min,max}_value bounds are positive, the\n__reg_assign_32_into_64() directly propagates them to their 64 bit\ncounterparts, otherwise it pessimises them into [0,u32_max] universe and\ntries to refine them later on by learning through the tnum as per comment\nin mentioned function. However, that does not always happen, for example,\nin mov32 operation we call zext_32_to_64(dst_reg) which invokes the\n__reg_assign_32_into_64() as is without subsequent bounds update as\nelsewhere thus no refinement based on tnum takes place.\n\nThus, not calling into the __update_reg_bounds() / __reg_deduce_bounds() /\n__reg_bound_offset() triplet as we do, for example, in case of ALU ops via\nadjust_scalar_min_max_vals(), will lead to more pessimistic bounds when\ndumping the full register state:\n\nBefore fix:\n\n  0: (b4) w0 = -1\n  1: R0_w=invP4294967295\n     (id=0,imm=ffffffff,\n      smin_value=4294967295,smax_value=4294967295,\n      umin_value=4294967295,umax_value=4294967295,\n      var_off=(0xffffffff; 0x0),\n      s32_min_value=-1,s32_max_value=-1,\n      u32_min_value=-1,u32_max_value=-1)\n\n  1: (bc) w0 = w0\n  2: R0_w=invP4294967295\n     (id=0,imm=ffffffff,\n      smin_value=0,smax_value=4294967295,\n      umin_value=4294967295,umax_value=4294967295,\n      var_off=(0xffffffff; 0x0),\n      s32_min_value=-1,s32_max_value=-1,\n      u32_min_value=-1,u32_max_value=-1)\n\nTechnically, the smin_value=0 and smax_value=4294967295 bounds are not\nincorrect, but given the register is still a constant, they break assumptions\nabout const scalars that smin_value == smax_value and umin_value == umax_value.\n\nAfter fix:\n\n  0: (b4) w0 = -1\n  1: R0_w=invP4294967295\n     (id=0,imm=ffffffff,\n      smin_value=4294967295,smax_value=4294967295,\n      umin_value=4294967295,umax_value=4294967295,\n      var_off=(0xffffffff; 0x0),\n      s32_min_value=-1,s32_max_value=-1,\n      u32_min_value=-1,u32_max_value=-1)\n\n  1: (bc) w0 = w0\n  2: R0_w=invP4294967295\n     (id=0,imm=ffffffff,\n      smin_value=4294967295,smax_value=4294967295,\n      umin_value=4294967295,umax_value=4294967295,\n      var_off=(0xffffffff; 0x0),\n      s32_min_value=-1,s32_max_value=-1,\n      u32_min_value=-1,u32_max_value=-1)\n\nWithout the smin_value == smax_value and umin_value == umax_value invariant\nbeing intact for const scalars, it is possible to leak out kernel pointers\nfrom unprivileged user space if the latter is enabled. For example, when such\nregisters are involved in pointer arithmtics, then adjust_ptr_min_max_vals()\nwill taint the destination register into an unknown scalar, and the latter\ncan be exported and stored e.g. into a BPF map value.\n\nFixes: 3f50f132d840 (\"bpf: Verifier, do explicit ALU32 bounds tracking\")\nReported-by: Kuee K1r0a <liulin063@gmail.com>\nSigned-off-by: Daniel Borkmann <daniel@iogearbox.net>\nReviewed-by: John Fastabend <john.fastabend@gmail.com>\nAcked-by: Alexei Starovoitov <ast@kernel.org>",
        "cve_desc": "The check_alu_op() function in kernel/bpf/verifier.c in the Linux kernel through v5.16-rc5 did not properly update bounds while handling the mov32 instruction, which allows local users to obtain potentially sensitive address information, aka a \"pointer leak.\"",
        "target": 1
      },
      {
        "idx": 200319,
        "reasoning": "The code is vulnerable to a null pointer dereference because it doesn't check the return value of `kmalloc` before potentially using the allocated memory pointed to by `new_ra`. Although the CVE description notes a dispute regarding usage, the code *does* use `new_ra` after the `kmalloc` call without verifying it succeeded, creating a potential crash scenario if allocation fails.",
        "func": "int ip_ra_control(struct sock *sk, unsigned char on,\n\t\t  void (*destructor)(struct sock *))\n{\n\tstruct ip_ra_chain *ra, *new_ra;\n\tstruct ip_ra_chain __rcu **rap;\n\tstruct net *net = sock_net(sk);\n\n\tif (sk->sk_type != SOCK_RAW || inet_sk(sk)->inet_num == IPPROTO_RAW)\n\t\treturn -EINVAL;\n\n\tnew_ra = on ? kmalloc(sizeof(*new_ra), GFP_KERNEL) : NULL;\n\n\tmutex_lock(&net->ipv4.ra_mutex);\n\tfor (rap = &net->ipv4.ra_chain;\n\t     (ra = rcu_dereference_protected(*rap,\n\t\t\tlockdep_is_held(&net->ipv4.ra_mutex))) != NULL;\n\t     rap = &ra->next) {\n\t\tif (ra->sk == sk) {\n\t\t\tif (on) {\n\t\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\t\t\tkfree(new_ra);\n\t\t\t\treturn -EADDRINUSE;\n\t\t\t}\n\t\t\t/* dont let ip_call_ra_chain() use sk again */\n\t\t\tra->sk = NULL;\n\t\t\tRCU_INIT_POINTER(*rap, ra->next);\n\t\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\t\t\tif (ra->destructor)\n\t\t\t\tra->destructor(sk);\n\t\t\t/*\n\t\t\t * Delay sock_put(sk) and kfree(ra) after one rcu grace\n\t\t\t * period. This guarantee ip_call_ra_chain() dont need\n\t\t\t * to mess with socket refcounts.\n\t\t\t */\n\t\t\tra->saved_sk = sk;\n\t\t\tcall_rcu(&ra->rcu, ip_ra_destroy_rcu);\n\t\t\treturn 0;\n\t\t}\n\t}\n\tif (!new_ra) {\n\t\tmutex_unlock(&net->ipv4.ra_mutex);\n\t\treturn -ENOBUFS;\n\t}\n\tnew_ra->sk = sk;\n\tnew_ra->destructor = destructor;\n\n\tRCU_INIT_POINTER(new_ra->next, ra);\n\trcu_assign_pointer(*rap, new_ra);\n\tsock_hold(sk);\n\tmutex_unlock(&net->ipv4.ra_mutex);\n\n\treturn 0;\n}",
        "commit_message": "ip_sockglue: Fix missing-check bug in ip_ra_control()\n\nIn function ip_ra_control(), the pointer new_ra is allocated a memory\nspace via kmalloc(). And it is used in the following codes. However,\nwhen  there is a memory allocation error, kmalloc() fails. Thus null\npointer dereference may happen. And it will cause the kernel to crash.\nTherefore, we should check the return value and handle the error.\n\nSigned-off-by: Gen Zhang <blackgod016574@gmail.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "An issue was discovered in ip_ra_control in net/ipv4/ip_sockglue.c in the Linux kernel through 5.1.5. There is an unchecked kmalloc of new_ra, which might allow an attacker to cause a denial of service (NULL pointer dereference and system crash). NOTE: this is disputed because new_ra is never used if it is NULL",
        "target": 1
      },
      {
        "idx": 204100,
        "reasoning": "This code is vulnerable to memory corruption and read overflows due to insufficient input validation when parsing PPP Configuration Request (CR) packets, specifically within the `ppp_cp_parse_cr` function. The lack of proper range checks on `opt[1]` and `len` allows for out-of-bounds memory access during `memcpy` operations, potentially leading to crashes or denial-of-service as described in the CVE.",
        "func": "static void ppp_cp_parse_cr(struct net_device *dev, u16 pid, u8 id,\n\t\t\t    unsigned int req_len, const u8 *data)\n{\n\tstatic u8 const valid_accm[6] = { LCP_OPTION_ACCM, 6, 0, 0, 0, 0 };\n\tconst u8 *opt;\n\tu8 *out;\n\tunsigned int len = req_len, nak_len = 0, rej_len = 0;\n\n\tif (!(out = kmalloc(len, GFP_ATOMIC))) {\n\t\tdev->stats.rx_dropped++;\n\t\treturn;\t/* out of memory, ignore CR packet */\n\t}\n\n\tfor (opt = data; len; len -= opt[1], opt += opt[1]) {\n\t\tif (len < 2 || len < opt[1]) {\n\t\t\tdev->stats.rx_errors++;\n\t\t\tkfree(out);\n\t\t\treturn; /* bad packet, drop silently */\n\t\t}\n\n\t\tif (pid == PID_LCP)\n\t\t\tswitch (opt[0]) {\n\t\t\tcase LCP_OPTION_MRU:\n\t\t\t\tcontinue; /* MRU always OK and > 1500 bytes? */\n\n\t\t\tcase LCP_OPTION_ACCM: /* async control character map */\n\t\t\t\tif (!memcmp(opt, valid_accm,\n\t\t\t\t\t    sizeof(valid_accm)))\n\t\t\t\t\tcontinue;\n\t\t\t\tif (!rej_len) { /* NAK it */\n\t\t\t\t\tmemcpy(out + nak_len, valid_accm,\n\t\t\t\t\t       sizeof(valid_accm));\n\t\t\t\t\tnak_len += sizeof(valid_accm);\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\tcase LCP_OPTION_MAGIC:\n\t\t\t\tif (opt[1] != 6 || (!opt[2] && !opt[3] &&\n\t\t\t\t\t\t    !opt[4] && !opt[5]))\n\t\t\t\t\tbreak; /* reject invalid magic number */\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t/* reject this option */\n\t\tmemcpy(out + rej_len, opt, opt[1]);\n\t\trej_len += opt[1];\n\t}\n\n\tif (rej_len)\n\t\tppp_cp_event(dev, pid, RCR_BAD, CP_CONF_REJ, id, rej_len, out);\n\telse if (nak_len)\n\t\tppp_cp_event(dev, pid, RCR_BAD, CP_CONF_NAK, id, nak_len, out);\n\telse\n\t\tppp_cp_event(dev, pid, RCR_GOOD, CP_CONF_ACK, id, req_len, data);\n\n\tkfree(out);\n}",
        "commit_message": "hdlc_ppp: add range checks in ppp_cp_parse_cr()\n\nThere are a couple bugs here:\n1) If opt[1] is zero then this results in a forever loop.  If the value\n   is less than 2 then it is invalid.\n2) It assumes that \"len\" is more than sizeof(valid_accm) or 6 which can\n   result in memory corruption.\n\nIn the case of LCP_OPTION_ACCM, then  we should check \"opt[1]\" instead\nof \"len\" because, if \"opt[1]\" is less than sizeof(valid_accm) then\n\"nak_len\" gets out of sync and it can lead to memory corruption in the\nnext iterations through the loop.  In case of LCP_OPTION_MAGIC, the\nonly valid value for opt[1] is 6, but the code is trying to log invalid\ndata so we should only discard the data when \"len\" is less than 6\nbecause that leads to a read overflow.\n\nReported-by: ChenNan Of Chaitin Security Research Lab  <whutchennan@gmail.com>\nFixes: e022c2f07ae5 (\"WAN: new synchronous PPP implementation for generic HDLC.\")\nSigned-off-by: Dan Carpenter <dan.carpenter@oracle.com>\nReviewed-by: Eric Dumazet <edumazet@google.com>\nReviewed-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "A flaw was found in the HDLC_PPP module of the Linux kernel in versions before 5.9-rc7. Memory corruption and a read overflow is caused by improper input validation in the ppp_cp_parse_cr function which can cause the system to crash or cause a denial of service. The highest threat from this vulnerability is to data confidentiality and integrity as well as system availability.",
        "target": 1
      },
      {
        "idx": 205721,
        "reasoning": "The code is vulnerable because it doesn't properly handle UDP packets with a zero payload during GRO (Generic Receive Offload) processing, leading to an out-of-bounds read in `skb_gro_receive`. Specifically, the `skb_gro_receive` function calculates `gso_size` based on `skb_gro_len(skb)`, which can be problematic with zero-payload packets, ultimately causing the KASAN error reported.",
        "func": "static struct sk_buff *udp_gro_receive_segment(struct list_head *head,\n\t\t\t\t\t       struct sk_buff *skb)\n{\n\tstruct udphdr *uh = udp_hdr(skb);\n\tstruct sk_buff *pp = NULL;\n\tstruct udphdr *uh2;\n\tstruct sk_buff *p;\n\n\t/* requires non zero csum, for symmetry with GSO */\n\tif (!uh->check) {\n\t\tNAPI_GRO_CB(skb)->flush = 1;\n\t\treturn NULL;\n\t}\n\n\t/* pull encapsulating udp header */\n\tskb_gro_pull(skb, sizeof(struct udphdr));\n\tskb_gro_postpull_rcsum(skb, uh, sizeof(struct udphdr));\n\n\tlist_for_each_entry(p, head, list) {\n\t\tif (!NAPI_GRO_CB(p)->same_flow)\n\t\t\tcontinue;\n\n\t\tuh2 = udp_hdr(p);\n\n\t\t/* Match ports only, as csum is always non zero */\n\t\tif ((*(u32 *)&uh->source != *(u32 *)&uh2->source)) {\n\t\t\tNAPI_GRO_CB(p)->same_flow = 0;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* Terminate the flow on len mismatch or if it grow \"too much\".\n\t\t * Under small packet flood GRO count could elsewhere grow a lot\n\t\t * leading to execessive truesize values.\n\t\t * On len mismatch merge the first packet shorter than gso_size,\n\t\t * otherwise complete the GRO packet.\n\t\t */\n\t\tif (uh->len > uh2->len || skb_gro_receive(p, skb) ||\n\t\t    uh->len != uh2->len ||\n\t\t    NAPI_GRO_CB(p)->count >= UDP_GRO_CNT_MAX)\n\t\t\tpp = p;\n\n\t\treturn pp;\n\t}\n\n\t/* mismatch, but we never need to flush */\n\treturn NULL;\n}",
        "commit_message": "udp: fix GRO packet of death\n\nsyzbot was able to crash host by sending UDP packets with a 0 payload.\n\nTCP does not have this issue since we do not aggregate packets without\npayload.\n\nSince dev_gro_receive() sets gso_size based on skb_gro_len(skb)\nit seems not worth trying to cope with padded packets.\n\nBUG: KASAN: slab-out-of-bounds in skb_gro_receive+0xf5f/0x10e0 net/core/skbuff.c:3826\nRead of size 16 at addr ffff88808893fff0 by task syz-executor612/7889\n\nCPU: 0 PID: 7889 Comm: syz-executor612 Not tainted 5.1.0-rc7+ #96\nHardware name: Google Google Compute Engine/Google Compute Engine, BIOS Google 01/01/2011\nCall Trace:\n __dump_stack lib/dump_stack.c:77 [inline]\n dump_stack+0x172/0x1f0 lib/dump_stack.c:113\n print_address_description.cold+0x7c/0x20d mm/kasan/report.c:187\n kasan_report.cold+0x1b/0x40 mm/kasan/report.c:317\n __asan_report_load16_noabort+0x14/0x20 mm/kasan/generic_report.c:133\n skb_gro_receive+0xf5f/0x10e0 net/core/skbuff.c:3826\n udp_gro_receive_segment net/ipv4/udp_offload.c:382 [inline]\n call_gro_receive include/linux/netdevice.h:2349 [inline]\n udp_gro_receive+0xb61/0xfd0 net/ipv4/udp_offload.c:414\n udp4_gro_receive+0x763/0xeb0 net/ipv4/udp_offload.c:478\n inet_gro_receive+0xe72/0x1110 net/ipv4/af_inet.c:1510\n dev_gro_receive+0x1cd0/0x23c0 net/core/dev.c:5581\n napi_gro_frags+0x36b/0xd10 net/core/dev.c:5843\n tun_get_user+0x2f24/0x3fb0 drivers/net/tun.c:1981\n tun_chr_write_iter+0xbd/0x156 drivers/net/tun.c:2027\n call_write_iter include/linux/fs.h:1866 [inline]\n do_iter_readv_writev+0x5e1/0x8e0 fs/read_write.c:681\n do_iter_write fs/read_write.c:957 [inline]\n do_iter_write+0x184/0x610 fs/read_write.c:938\n vfs_writev+0x1b3/0x2f0 fs/read_write.c:1002\n do_writev+0x15e/0x370 fs/read_write.c:1037\n __do_sys_writev fs/read_write.c:1110 [inline]\n __se_sys_writev fs/read_write.c:1107 [inline]\n __x64_sys_writev+0x75/0xb0 fs/read_write.c:1107\n do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290\n entry_SYSCALL_64_after_hwframe+0x49/0xbe\nRIP: 0033:0x441cc0\nCode: 05 48 3d 01 f0 ff ff 0f 83 9d 09 fc ff c3 66 2e 0f 1f 84 00 00 00 00 00 66 90 83 3d 51 93 29 00 00 75 14 b8 14 00 00 00 0f 05 <48> 3d 01 f0 ff ff 0f 83 74 09 fc ff c3 48 83 ec 08 e8 ba 2b 00 00\nRSP: 002b:00007ffe8c716118 EFLAGS: 00000246 ORIG_RAX: 0000000000000014\nRAX: ffffffffffffffda RBX: 00007ffe8c716150 RCX: 0000000000441cc0\nRDX: 0000000000000001 RSI: 00007ffe8c716170 RDI: 00000000000000f0\nRBP: 0000000000000000 R08: 000000000000ffff R09: 0000000000a64668\nR10: 0000000020000040 R11: 0000000000000246 R12: 000000000000c2d9\nR13: 0000000000402b50 R14: 0000000000000000 R15: 0000000000000000\n\nAllocated by task 5143:\n save_stack+0x45/0xd0 mm/kasan/common.c:75\n set_track mm/kasan/common.c:87 [inline]\n __kasan_kmalloc mm/kasan/common.c:497 [inline]\n __kasan_kmalloc.constprop.0+0xcf/0xe0 mm/kasan/common.c:470\n kasan_slab_alloc+0xf/0x20 mm/kasan/common.c:505\n slab_post_alloc_hook mm/slab.h:437 [inline]\n slab_alloc mm/slab.c:3393 [inline]\n kmem_cache_alloc+0x11a/0x6f0 mm/slab.c:3555\n mm_alloc+0x1d/0xd0 kernel/fork.c:1030\n bprm_mm_init fs/exec.c:363 [inline]\n __do_execve_file.isra.0+0xaa3/0x23f0 fs/exec.c:1791\n do_execveat_common fs/exec.c:1865 [inline]\n do_execve fs/exec.c:1882 [inline]\n __do_sys_execve fs/exec.c:1958 [inline]\n __se_sys_execve fs/exec.c:1953 [inline]\n __x64_sys_execve+0x8f/0xc0 fs/exec.c:1953\n do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290\n entry_SYSCALL_64_after_hwframe+0x49/0xbe\n\nFreed by task 5351:\n save_stack+0x45/0xd0 mm/kasan/common.c:75\n set_track mm/kasan/common.c:87 [inline]\n __kasan_slab_free+0x102/0x150 mm/kasan/common.c:459\n kasan_slab_free+0xe/0x10 mm/kasan/common.c:467\n __cache_free mm/slab.c:3499 [inline]\n kmem_cache_free+0x86/0x260 mm/slab.c:3765\n __mmdrop+0x238/0x320 kernel/fork.c:677\n mmdrop include/linux/sched/mm.h:49 [inline]\n finish_task_switch+0x47b/0x780 kernel/sched/core.c:2746\n context_switch kernel/sched/core.c:2880 [inline]\n __schedule+0x81b/0x1cc0 kernel/sched/core.c:3518\n preempt_schedule_irq+0xb5/0x140 kernel/sched/core.c:3745\n retint_kernel+0x1b/0x2d\n arch_local_irq_restore arch/x86/include/asm/paravirt.h:767 [inline]\n kmem_cache_free+0xab/0x260 mm/slab.c:3766\n anon_vma_chain_free mm/rmap.c:134 [inline]\n unlink_anon_vmas+0x2ba/0x870 mm/rmap.c:401\n free_pgtables+0x1af/0x2f0 mm/memory.c:394\n exit_mmap+0x2d1/0x530 mm/mmap.c:3144\n __mmput kernel/fork.c:1046 [inline]\n mmput+0x15f/0x4c0 kernel/fork.c:1067\n exec_mmap fs/exec.c:1046 [inline]\n flush_old_exec+0x8d9/0x1c20 fs/exec.c:1279\n load_elf_binary+0x9bc/0x53f0 fs/binfmt_elf.c:864\n search_binary_handler fs/exec.c:1656 [inline]\n search_binary_handler+0x17f/0x570 fs/exec.c:1634\n exec_binprm fs/exec.c:1698 [inline]\n __do_execve_file.isra.0+0x1394/0x23f0 fs/exec.c:1818\n do_execveat_common fs/exec.c:1865 [inline]\n do_execve fs/exec.c:1882 [inline]\n __do_sys_execve fs/exec.c:1958 [inline]\n __se_sys_execve fs/exec.c:1953 [inline]\n __x64_sys_execve+0x8f/0xc0 fs/exec.c:1953\n do_syscall_64+0x103/0x610 arch/x86/entry/common.c:290\n entry_SYSCALL_64_after_hwframe+0x49/0xbe\n\nThe buggy address belongs to the object at ffff88808893f7c0\n which belongs to the cache mm_struct of size 1496\nThe buggy address is located 600 bytes to the right of\n 1496-byte region [ffff88808893f7c0, ffff88808893fd98)\nThe buggy address belongs to the page:\npage:ffffea0002224f80 count:1 mapcount:0 mapping:ffff88821bc40ac0 index:0xffff88808893f7c0 compound_mapcount: 0\nflags: 0x1fffc0000010200(slab|head)\nraw: 01fffc0000010200 ffffea00025b4f08 ffffea00027b9d08 ffff88821bc40ac0\nraw: ffff88808893f7c0 ffff88808893e440 0000000100000001 0000000000000000\npage dumped because: kasan: bad access detected\n\nMemory state around the buggy address:\n ffff88808893fe80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc\n ffff88808893ff00: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc\n>ffff88808893ff80: fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc fc\n                                                             ^\n ffff888088940000: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n ffff888088940080: 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00\n\nFixes: e20cf8d3f1f7 (\"udp: implement GRO for plain UDP sockets.\")\nSigned-off-by: Eric Dumazet <edumazet@google.com>\nCc: Paolo Abeni <pabeni@redhat.com>\nReported-by: syzbot <syzkaller@googlegroups.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "udp_gro_receive_segment in net/ipv4/udp_offload.c in the Linux kernel 5.x before 5.0.13 allows remote attackers to cause a denial of service (slab-out-of-bounds memory corruption) or possibly have unspecified other impact via UDP packets with a 0 payload, because of mishandling of padded packets, aka the \"GRO packet of death\" issue.",
        "target": 1
      },
      {
        "idx": 207977,
        "reasoning": "This code is vulnerable to a use-after-free due to the lack of proper orphaning of frag structures when using `skb_zerocopy`. Specifically, the `skb_zerocopy` function copies data between SKBs without releasing the original frag pointers, leading to potential memory corruption if the original SKB is freed before the copied data is accessed.",
        "func": "nfqnl_build_packet_message(struct net *net, struct nfqnl_instance *queue,\n\t\t\t   struct nf_queue_entry *entry,\n\t\t\t   __be32 **packet_id_ptr)\n{\n\tsize_t size;\n\tsize_t data_len = 0, cap_len = 0;\n\tunsigned int hlen = 0;\n\tstruct sk_buff *skb;\n\tstruct nlattr *nla;\n\tstruct nfqnl_msg_packet_hdr *pmsg;\n\tstruct nlmsghdr *nlh;\n\tstruct nfgenmsg *nfmsg;\n\tstruct sk_buff *entskb = entry->skb;\n\tstruct net_device *indev;\n\tstruct net_device *outdev;\n\tstruct nf_conn *ct = NULL;\n\tenum ip_conntrack_info uninitialized_var(ctinfo);\n\tbool csum_verify;\n\n\tsize =    nlmsg_total_size(sizeof(struct nfgenmsg))\n\t\t+ nla_total_size(sizeof(struct nfqnl_msg_packet_hdr))\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* ifindex */\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* ifindex */\n#ifdef CONFIG_BRIDGE_NETFILTER\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* ifindex */\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* ifindex */\n#endif\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* mark */\n\t\t+ nla_total_size(sizeof(struct nfqnl_msg_packet_hw))\n\t\t+ nla_total_size(sizeof(u_int32_t))\t/* skbinfo */\n\t\t+ nla_total_size(sizeof(u_int32_t));\t/* cap_len */\n\n\tif (entskb->tstamp.tv64)\n\t\tsize += nla_total_size(sizeof(struct nfqnl_msg_packet_timestamp));\n\n\tif (entry->hook <= NF_INET_FORWARD ||\n\t   (entry->hook == NF_INET_POST_ROUTING && entskb->sk == NULL))\n\t\tcsum_verify = !skb_csum_unnecessary(entskb);\n\telse\n\t\tcsum_verify = false;\n\n\toutdev = entry->outdev;\n\n\tswitch ((enum nfqnl_config_mode)ACCESS_ONCE(queue->copy_mode)) {\n\tcase NFQNL_COPY_META:\n\tcase NFQNL_COPY_NONE:\n\t\tbreak;\n\n\tcase NFQNL_COPY_PACKET:\n\t\tif (!(queue->flags & NFQA_CFG_F_GSO) &&\n\t\t    entskb->ip_summed == CHECKSUM_PARTIAL &&\n\t\t    skb_checksum_help(entskb))\n\t\t\treturn NULL;\n\n\t\tdata_len = ACCESS_ONCE(queue->copy_range);\n\t\tif (data_len > entskb->len)\n\t\t\tdata_len = entskb->len;\n\n\t\thlen = skb_zerocopy_headlen(entskb);\n\t\thlen = min_t(unsigned int, hlen, data_len);\n\t\tsize += sizeof(struct nlattr) + hlen;\n\t\tcap_len = entskb->len;\n\t\tbreak;\n\t}\n\n\tif (queue->flags & NFQA_CFG_F_CONNTRACK)\n\t\tct = nfqnl_ct_get(entskb, &size, &ctinfo);\n\n\tif (queue->flags & NFQA_CFG_F_UID_GID) {\n\t\tsize +=  (nla_total_size(sizeof(u_int32_t))\t/* uid */\n\t\t\t+ nla_total_size(sizeof(u_int32_t)));\t/* gid */\n\t}\n\n\tskb = nfnetlink_alloc_skb(net, size, queue->peer_portid,\n\t\t\t\t  GFP_ATOMIC);\n\tif (!skb)\n\t\treturn NULL;\n\n\tnlh = nlmsg_put(skb, 0, 0,\n\t\t\tNFNL_SUBSYS_QUEUE << 8 | NFQNL_MSG_PACKET,\n\t\t\tsizeof(struct nfgenmsg), 0);\n\tif (!nlh) {\n\t\tkfree_skb(skb);\n\t\treturn NULL;\n\t}\n\tnfmsg = nlmsg_data(nlh);\n\tnfmsg->nfgen_family = entry->pf;\n\tnfmsg->version = NFNETLINK_V0;\n\tnfmsg->res_id = htons(queue->queue_num);\n\n\tnla = __nla_reserve(skb, NFQA_PACKET_HDR, sizeof(*pmsg));\n\tpmsg = nla_data(nla);\n\tpmsg->hw_protocol\t= entskb->protocol;\n\tpmsg->hook\t\t= entry->hook;\n\t*packet_id_ptr\t\t= &pmsg->packet_id;\n\n\tindev = entry->indev;\n\tif (indev) {\n#ifndef CONFIG_BRIDGE_NETFILTER\n\t\tif (nla_put_be32(skb, NFQA_IFINDEX_INDEV, htonl(indev->ifindex)))\n\t\t\tgoto nla_put_failure;\n#else\n\t\tif (entry->pf == PF_BRIDGE) {\n\t\t\t/* Case 1: indev is physical input device, we need to\n\t\t\t * look for bridge group (when called from\n\t\t\t * netfilter_bridge) */\n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\n\t\t\t\t\t htonl(indev->ifindex)) ||\n\t\t\t/* this is the bridge group \"brX\" */\n\t\t\t/* rcu_read_lock()ed by __nf_queue */\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_INDEV,\n\t\t\t\t\t htonl(br_port_get_rcu(indev)->br->dev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t} else {\n\t\t\t/* Case 2: indev is bridge group, we need to look for\n\t\t\t * physical device (when called from ipv4) */\n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_INDEV,\n\t\t\t\t\t htonl(indev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tif (entskb->nf_bridge && entskb->nf_bridge->physindev &&\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_PHYSINDEV,\n\t\t\t\t\t htonl(entskb->nf_bridge->physindev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n#endif\n\t}\n\n\tif (outdev) {\n#ifndef CONFIG_BRIDGE_NETFILTER\n\t\tif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV, htonl(outdev->ifindex)))\n\t\t\tgoto nla_put_failure;\n#else\n\t\tif (entry->pf == PF_BRIDGE) {\n\t\t\t/* Case 1: outdev is physical output device, we need to\n\t\t\t * look for bridge group (when called from\n\t\t\t * netfilter_bridge) */\n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\n\t\t\t\t\t htonl(outdev->ifindex)) ||\n\t\t\t/* this is the bridge group \"brX\" */\n\t\t\t/* rcu_read_lock()ed by __nf_queue */\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\n\t\t\t\t\t htonl(br_port_get_rcu(outdev)->br->dev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t} else {\n\t\t\t/* Case 2: outdev is bridge group, we need to look for\n\t\t\t * physical output device (when called from ipv4) */\n\t\t\tif (nla_put_be32(skb, NFQA_IFINDEX_OUTDEV,\n\t\t\t\t\t htonl(outdev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t\tif (entskb->nf_bridge && entskb->nf_bridge->physoutdev &&\n\t\t\t    nla_put_be32(skb, NFQA_IFINDEX_PHYSOUTDEV,\n\t\t\t\t\t htonl(entskb->nf_bridge->physoutdev->ifindex)))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n#endif\n\t}\n\n\tif (entskb->mark &&\n\t    nla_put_be32(skb, NFQA_MARK, htonl(entskb->mark)))\n\t\tgoto nla_put_failure;\n\n\tif (indev && entskb->dev &&\n\t    entskb->mac_header != entskb->network_header) {\n\t\tstruct nfqnl_msg_packet_hw phw;\n\t\tint len;\n\n\t\tmemset(&phw, 0, sizeof(phw));\n\t\tlen = dev_parse_header(entskb, phw.hw_addr);\n\t\tif (len) {\n\t\t\tphw.hw_addrlen = htons(len);\n\t\t\tif (nla_put(skb, NFQA_HWADDR, sizeof(phw), &phw))\n\t\t\t\tgoto nla_put_failure;\n\t\t}\n\t}\n\n\tif (entskb->tstamp.tv64) {\n\t\tstruct nfqnl_msg_packet_timestamp ts;\n\t\tstruct timeval tv = ktime_to_timeval(entskb->tstamp);\n\t\tts.sec = cpu_to_be64(tv.tv_sec);\n\t\tts.usec = cpu_to_be64(tv.tv_usec);\n\n\t\tif (nla_put(skb, NFQA_TIMESTAMP, sizeof(ts), &ts))\n\t\t\tgoto nla_put_failure;\n\t}\n\n\tif ((queue->flags & NFQA_CFG_F_UID_GID) && entskb->sk &&\n\t    nfqnl_put_sk_uidgid(skb, entskb->sk) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (ct && nfqnl_ct_put(skb, ct, ctinfo) < 0)\n\t\tgoto nla_put_failure;\n\n\tif (cap_len > data_len &&\n\t    nla_put_be32(skb, NFQA_CAP_LEN, htonl(cap_len)))\n\t\tgoto nla_put_failure;\n\n\tif (nfqnl_put_packet_info(skb, entskb, csum_verify))\n\t\tgoto nla_put_failure;\n\n\tif (data_len) {\n\t\tstruct nlattr *nla;\n\n\t\tif (skb_tailroom(skb) < sizeof(*nla) + hlen)\n\t\t\tgoto nla_put_failure;\n\n\t\tnla = (struct nlattr *)skb_put(skb, sizeof(*nla));\n\t\tnla->nla_type = NFQA_PAYLOAD;\n\t\tnla->nla_len = nla_attr_size(data_len);\n\n\t\tskb_zerocopy(skb, entskb, data_len, hlen);\n\t}\n\n\tnlh->nlmsg_len = skb->len;\n\treturn skb;\n\nnla_put_failure:\n\tkfree_skb(skb);\n\tnet_err_ratelimited(\"nf_queue: error creating packet message\\n\");\n\treturn NULL;\n}",
        "commit_message": "core, nfqueue, openvswitch: Orphan frags in skb_zerocopy and handle errors\n\nskb_zerocopy can copy elements of the frags array between skbs, but it doesn't\norphan them. Also, it doesn't handle errors, so this patch takes care of that\nas well, and modify the callers accordingly. skb_tx_error() is also added to\nthe callers so they will signal the failed delivery towards the creator of the\nskb.\n\nSigned-off-by: Zoltan Kiss <zoltan.kiss@citrix.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "Use-after-free vulnerability in the nfqnl_zcopy function in net/netfilter/nfnetlink_queue_core.c in the Linux kernel through 3.13.6 allows attackers to obtain sensitive information from kernel memory by leveraging the absence of a certain orphaning operation. NOTE: the affected code was moved to the skb_zerocopy function in net/core/skbuff.c before the vulnerability was announced.",
        "target": 1
      }
    ]
  },
  "net-next": {
    "0": [
      {
        "idx": 453269,
        "reasoning": "This code snippet focuses on initialization and registration routines and doesn't contain any direct device dereferences that could lead to a NULL pointer dereference vulnerability as described in the commit message. The commit message specifically addresses a potential issue in `rds_iw_laddr_check`, which is *not* present in the provided `rds_iw_init` code; therefore, this snippet isn't flagged as vulnerable.\n\n\n\n",
        "func": "int rds_iw_init(void)\n{\n\tint ret;\n\n\tINIT_LIST_HEAD(&rds_iw_devices);\n\n\tret = ib_register_client(&rds_iw_client);\n\tif (ret)\n\t\tgoto out;\n\n\tret = rds_iw_sysctl_init();\n\tif (ret)\n\t\tgoto out_ibreg;\n\n\tret = rds_iw_recv_init();\n\tif (ret)\n\t\tgoto out_sysctl;\n\n\tret = rds_trans_register(&rds_iw_transport);\n\tif (ret)\n\t\tgoto out_recv;\n\n\trds_info_register_func(RDS_INFO_IWARP_CONNECTIONS, rds_iw_ic_info);\n\n\tgoto out;\n\nout_recv:\n\trds_iw_recv_exit();\nout_sysctl:\n\trds_iw_sysctl_exit();\nout_ibreg:\n\tib_unregister_client(&rds_iw_client);\nout:\n\treturn ret;\n}",
        "commit_message": "rds: prevent dereference of a NULL device in rds_iw_laddr_check\n\nBinding might result in a NULL device which is later dereferenced\nwithout checking.\n\nSigned-off-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "target": 0
      },
      {
        "idx": 453270,
        "reasoning": "This code is **not vulnerable** as the commit message explicitly addresses and prevents a potential NULL device dereference. The commit adds checks to ensure the `device` pointer is valid before any operations are performed on it, mitigating the risk described in the commit message.\n\n\n\n",
        "func": "static void rds_iw_add_one(struct ib_device *device)\n{\n\tstruct rds_iw_device *rds_iwdev;\n\tstruct ib_device_attr *dev_attr;\n\n\t/* Only handle iwarp devices */\n\tif (device->node_type != RDMA_NODE_RNIC)\n\t\treturn;\n\n\tdev_attr = kmalloc(sizeof *dev_attr, GFP_KERNEL);\n\tif (!dev_attr)\n\t\treturn;\n\n\tif (ib_query_device(device, dev_attr)) {\n\t\trdsdebug(\"Query device failed for %s\\n\", device->name);\n\t\tgoto free_attr;\n\t}\n\n\trds_iwdev = kmalloc(sizeof *rds_iwdev, GFP_KERNEL);\n\tif (!rds_iwdev)\n\t\tgoto free_attr;\n\n\tspin_lock_init(&rds_iwdev->spinlock);\n\n\trds_iwdev->dma_local_lkey = !!(dev_attr->device_cap_flags & IB_DEVICE_LOCAL_DMA_LKEY);\n\trds_iwdev->max_wrs = dev_attr->max_qp_wr;\n\trds_iwdev->max_sge = min(dev_attr->max_sge, RDS_IW_MAX_SGE);\n\n\trds_iwdev->dev = device;\n\trds_iwdev->pd = ib_alloc_pd(device);\n\tif (IS_ERR(rds_iwdev->pd))\n\t\tgoto free_dev;\n\n\tif (!rds_iwdev->dma_local_lkey) {\n\t\trds_iwdev->mr = ib_get_dma_mr(rds_iwdev->pd,\n\t\t\t\t\tIB_ACCESS_REMOTE_READ |\n\t\t\t\t\tIB_ACCESS_REMOTE_WRITE |\n\t\t\t\t\tIB_ACCESS_LOCAL_WRITE);\n\t\tif (IS_ERR(rds_iwdev->mr))\n\t\t\tgoto err_pd;\n\t} else\n\t\trds_iwdev->mr = NULL;\n\n\trds_iwdev->mr_pool = rds_iw_create_mr_pool(rds_iwdev);\n\tif (IS_ERR(rds_iwdev->mr_pool)) {\n\t\trds_iwdev->mr_pool = NULL;\n\t\tgoto err_mr;\n\t}\n\n\tINIT_LIST_HEAD(&rds_iwdev->cm_id_list);\n\tINIT_LIST_HEAD(&rds_iwdev->conn_list);\n\tlist_add_tail(&rds_iwdev->list, &rds_iw_devices);\n\n\tib_set_client_data(device, &rds_iw_client, rds_iwdev);\n\n\tgoto free_attr;\n\nerr_mr:\n\tif (rds_iwdev->mr)\n\t\tib_dereg_mr(rds_iwdev->mr);\nerr_pd:\n\tib_dealloc_pd(rds_iwdev->pd);\nfree_dev:\n\tkfree(rds_iwdev);\nfree_attr:\n\tkfree(dev_attr);\n}",
        "commit_message": "rds: prevent dereference of a NULL device in rds_iw_laddr_check\n\nBinding might result in a NULL device which is later dereferenced\nwithout checking.\n\nSigned-off-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "target": 0
      },
      {
        "idx": 453271,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message describes a fix to *prevent* a NULL device dereference elsewhere in the `rds` (Reliable Datagram Sockets) subsystem, and this `rds_iw_exit` function simply performs cleanup tasks \u2013 it doesn\u2019t contain the problematic dereference itself.\n\n\n\n",
        "func": "void rds_iw_exit(void)\n{\n\trds_info_deregister_func(RDS_INFO_IWARP_CONNECTIONS, rds_iw_ic_info);\n\trds_iw_destroy_nodev_conns();\n\tib_unregister_client(&rds_iw_client);\n\trds_iw_sysctl_exit();\n\trds_iw_recv_exit();\n\trds_trans_unregister(&rds_iw_transport);\n}",
        "commit_message": "rds: prevent dereference of a NULL device in rds_iw_laddr_check\n\nBinding might result in a NULL device which is later dereferenced\nwithout checking.\n\nSigned-off-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "target": 0
      },
      {
        "idx": 453272,
        "reasoning": "This code is safe and the commit message explicitly addresses a potential, but mitigated, vulnerability. The code now includes a check `!cm_id->device` before dereferencing `cm_id->device->node_type`, preventing a NULL pointer dereference if `rdma_bind_addr` fails to assign a device to the `cm_id`. \n\n\n\n",
        "func": "static int rds_iw_laddr_check(__be32 addr)\n{\n\tint ret;\n\tstruct rdma_cm_id *cm_id;\n\tstruct sockaddr_in sin;\n\n\t/* Create a CMA ID and try to bind it. This catches both\n\t * IB and iWARP capable NICs.\n\t */\n\tcm_id = rdma_create_id(NULL, NULL, RDMA_PS_TCP, IB_QPT_RC);\n\tif (IS_ERR(cm_id))\n\t\treturn PTR_ERR(cm_id);\n\n\tmemset(&sin, 0, sizeof(sin));\n\tsin.sin_family = AF_INET;\n\tsin.sin_addr.s_addr = addr;\n\n\t/* rdma_bind_addr will only succeed for IB & iWARP devices */\n\tret = rdma_bind_addr(cm_id, (struct sockaddr *)&sin);\n\t/* due to this, we will claim to support IB devices unless we\n\t   check node_type. */\n\tif (ret || !cm_id->device ||\n\t    cm_id->device->node_type != RDMA_NODE_RNIC)\n\t\tret = -EADDRNOTAVAIL;\n\n\trdsdebug(\"addr %pI4 ret %d node type %d\\n\",\n\t\t&addr, ret,\n\t\tcm_id->device ? cm_id->device->node_type : -1);\n\n\trdma_destroy_id(cm_id);\n\n\treturn ret;\n}",
        "commit_message": "rds: prevent dereference of a NULL device in rds_iw_laddr_check\n\nBinding might result in a NULL device which is later dereferenced\nwithout checking.\n\nSigned-off-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "target": 0
      },
      {
        "idx": 453273,
        "reasoning": "This code is **not vulnerable** to the issue described in the commit message. The commit message refers to a potential NULL device dereference during *binding*, while this code snippet handles the *removal* of an already bound device, and explicitly checks for a NULL `rds_iwdev` before proceeding with any operations on it, preventing the described dereference.\n\n\n\n",
        "func": "static void rds_iw_remove_one(struct ib_device *device)\n{\n\tstruct rds_iw_device *rds_iwdev;\n\tstruct rds_iw_cm_id *i_cm_id, *next;\n\n\trds_iwdev = ib_get_client_data(device, &rds_iw_client);\n\tif (!rds_iwdev)\n\t\treturn;\n\n\tspin_lock_irq(&rds_iwdev->spinlock);\n\tlist_for_each_entry_safe(i_cm_id, next, &rds_iwdev->cm_id_list, list) {\n\t\tlist_del(&i_cm_id->list);\n\t\tkfree(i_cm_id);\n\t}\n\tspin_unlock_irq(&rds_iwdev->spinlock);\n\n\trds_iw_destroy_conns(rds_iwdev);\n\n\tif (rds_iwdev->mr_pool)\n\t\trds_iw_destroy_mr_pool(rds_iwdev->mr_pool);\n\n\tif (rds_iwdev->mr)\n\t\tib_dereg_mr(rds_iwdev->mr);\n\n\twhile (ib_dealloc_pd(rds_iwdev->pd)) {\n\t\trdsdebug(\"Failed to dealloc pd %p\\n\", rds_iwdev->pd);\n\t\tmsleep(1);\n\t}\n\n\tlist_del(&rds_iwdev->list);\n\tkfree(rds_iwdev);\n}",
        "commit_message": "rds: prevent dereference of a NULL device in rds_iw_laddr_check\n\nBinding might result in a NULL device which is later dereferenced\nwithout checking.\n\nSigned-off-by: Sasha Levin <sasha.levin@oracle.com>\nSigned-off-by: David S. Miller <davem@davemloft.net>",
        "cve_desc": "The rds_iw_laddr_check function in net/rds/iw.c in the Linux kernel through 3.14 allows local users to cause a denial of service (NULL pointer dereference and system crash) or possibly have unspecified other impact via a bind system call for an RDS socket on a system that lacks RDS transports.",
        "target": 0
      }
    ],
    "1": []
  },
  "nettle": {
    "0": [
      {
        "idx": 499609,
        "reasoning": "This code change appears safe as it replaces a previous implementation of point comparison with `ecc_mod_mul_canonical`, a function designed for canonical modular multiplication\u2014a standard and generally secure operation in elliptic curve cryptography. The commit message indicates this is a cherry-picked fix, suggesting it addresses a specific consistency or correctness issue rather than introducing a new vulnerability.\n\n\n\n",
        "func": "equal_h (const struct ecc_modulo *p,\n\t const mp_limb_t *x1, const mp_limb_t *z1,\n\t const mp_limb_t *x2, const mp_limb_t *z2,\n\t mp_limb_t *scratch)\n{\n#define t0 scratch\n#define t1 (scratch + p->size)\n\n  ecc_mod_mul_canonical (p, t0, x1, z2, t0);\n  ecc_mod_mul_canonical (p, t1, x2, z1, t1);\n\n  return mpn_cmp (t0, t1, p->size) == 0;\n\n#undef t0\n#undef t1\n}",
        "commit_message": "Use ecc_mod_mul_canonical for point comparison.\n\n* eddsa-verify.c (equal_h): Use ecc_mod_mul_canonical.\n\n(cherry picked from commit 5b7608fde3a6d2ab82bffb35db1e4e330927c906)",
        "cve_desc": "A flaw was found in Nettle in versions before 3.7.2, where several Nettle signature verification functions (GOST DSA, EDDSA & ECDSA) result in the Elliptic Curve Cryptography point (ECC) multiply function being called with out-of-range scalers, possibly resulting in incorrect results. This flaw allows an attacker to force an invalid signature, causing an assertion failure or possible validation. The highest threat to this vulnerability is to confidentiality, integrity, as well as system availability.",
        "target": 0
      }
    ],
    "1": []
  },
  "nginx": {
    "0": [],
    "1": []
  },
  "node": {
    "0": [],
    "1": [
      {
        "idx": 216604,
        "reasoning": "This code is vulnerable to an integer overflow when calculating the new `position_` after an allocation, potentially leading to a smaller-than-expected increase and a subsequent buffer overflow. The overflow occurs because the original calculation could underestimate the required growth of the zone when requesting large allocations near the address space limit, as described in the commit message and CVE.",
        "func": "inline void* Zone::New(int size) {\n  ASSERT(scope_nesting_ > 0);\n  // Round up the requested size to fit the alignment.\n  size = RoundUp(size, kAlignment);\n\n  // If the allocation size is divisible by 8 then we return an 8-byte aligned\n  // address.\n  if (kPointerSize == 4 && kAlignment == 4) {\n    position_ += ((~size) & 4) & (reinterpret_cast<intptr_t>(position_) & 4);\n  } else {\n    ASSERT(kAlignment >= kPointerSize);\n  }\n\n  // Check if the requested size is available without expanding.\n  Address result = position_;\n\n  if (size > limit_ - position_) {\n     result = NewExpand(size);\n  } else {\n     position_ += size;\n  }\n\n  // Check that the result has the proper alignment and return it.\n  ASSERT(IsAddressAligned(result, kAlignment, 0));\n  allocation_size_ += size;\n  return reinterpret_cast<void*>(result);\n}",
        "commit_message": "deps: backport 3a9bfec from v8 upstream\n\nSome of the logic from `zone.cc` is found in `zone-inl.h` in this\nrelease stream.\n\nOriginal commit message:\n\n  Fix overflow issue in Zone::New\n\n  When requesting a large allocation near the end of the address space,\n  the computation could overflow and erroneously *not* grow the Zone\n  as required.\n\n\tBUG=chromium:606115\n\tLOG=y\n\n  Review-Url: https://codereview.chromium.org/1930873002\n  Cr-Commit-Position: refs/heads/master@{#35903}\n\nPR-URL: https://github.com/nodejs/node-private/pull/43\nReviewed-By: Ben Noordhuis <info@bnoordhuis.nl>\nReviewed-By: Rod Vagg <rod@vagg.org>",
        "cve_desc": "The Zone::New function in zone.cc in Google V8 before 5.0.71.47, as used in Google Chrome before 50.0.2661.102, does not properly determine when to expand certain memory allocations, which allows remote attackers to cause a denial of service (buffer overflow) or possibly have unspecified other impact via crafted JavaScript code.",
        "target": 1
      },
      {
        "idx": 216817,
        "reasoning": "The code is vulnerable to a use-after-free because the `WriteWrap` object passed to `DoWrite` is only associated with the *last* buffer in the queue, meaning if the stream is destroyed before the last buffer is processed, the `WriteWrap` object could be accessed after it's been freed. This aligns with the CVE description, where a `WriteWrap` object's lifetime isn't properly managed in relation to the stream's write operations, potentially leading to memory corruption.",
        "func": "int Http2Stream::DoWrite(WriteWrap* req_wrap,\n                         uv_buf_t* bufs,\n                         size_t nbufs,\n                         uv_stream_t* send_handle) {\n  CHECK_NULL(send_handle);\n  Http2Scope h2scope(this);\n  if (!IsWritable() || IsDestroyed()) {\n    req_wrap->Done(UV_EOF);\n    return 0;\n  }\n  Debug(this, \"queuing %d buffers to send\", id_, nbufs);\n  for (size_t i = 0; i < nbufs; ++i) {\n    // Store the req_wrap on the last write info in the queue, so that it is\n    // only marked as finished once all buffers associated with it are finished.\n    queue_.emplace(nghttp2_stream_write {\n      i == nbufs - 1 ? req_wrap : nullptr,\n      bufs[i]\n    });\n    IncrementAvailableOutboundLength(bufs[i].len);\n  }\n  CHECK_NE(nghttp2_session_resume_data(**session_, id_), NGHTTP2_ERR_NOMEM);\n  return 0;\n}",
        "commit_message": "src: use unique_ptr for WriteWrap\n\nThis commit attempts to avoid a use-after-free error by using unqiue_ptr\nand passing a reference to it.\n\nCVE-ID: CVE-2020-8265\nFixes: https://github.com/nodejs-private/node-private/issues/227\nPR-URL: https://github.com/nodejs-private/node-private/pull/238\nReviewed-By: Michael Dawson <midawson@redhat.com>\nReviewed-By: Tobias Nie\u00dfen <tniessen@tnie.de>\nReviewed-By: Richard Lau <rlau@redhat.com>",
        "cve_desc": "Node.js versions before 10.23.1, 12.20.1, 14.15.4, 15.5.1 are vulnerable to a use-after-free bug in its TLS implementation. When writing to a TLS enabled socket, node::StreamBase::Write calls node::TLSWrap::DoWrite with a freshly allocated WriteWrap object as first argument. If the DoWrite method does not return an error, this object is passed back to the caller as part of a StreamWriteResult structure. This may be exploited to corrupt memory leading to a Denial of Service or potentially other exploits.",
        "target": 1
      },
      {
        "idx": 216819,
        "reasoning": "The code is vulnerable because the `DoWrite` function always returns `UV_ENOSYS`, meaning the `WriteWrap` object passed to it is *always* returned to the caller without being properly handled or written to\u2014creating a scenario where the object could be freed prematurely and then accessed, leading to a use-after-free. The commit message itself acknowledges an attempt to *avoid* a use-after-free, confirming the existence of this vulnerability in prior code and highlighting that this `DoWrite` implementation doesn't address the underlying issue within the TLS stream writing process.",
        "func": "  int DoWrite(WriteWrap* w,\n              uv_buf_t* bufs,\n              size_t count,\n              uv_stream_t* send_handle) override {\n    return UV_ENOSYS;  // Not implemented (yet).\n  }",
        "commit_message": "src: use unique_ptr for WriteWrap\n\nThis commit attempts to avoid a use-after-free error by using unqiue_ptr\nand passing a reference to it.\n\nCVE-ID: CVE-2020-8265\nFixes: https://github.com/nodejs-private/node-private/issues/227\nPR-URL: https://github.com/nodejs-private/node-private/pull/238\nReviewed-By: Michael Dawson <midawson@redhat.com>\nReviewed-By: Tobias Nie\u00dfen <tniessen@tnie.de>\nReviewed-By: Richard Lau <rlau@redhat.com>",
        "cve_desc": "Node.js versions before 10.23.1, 12.20.1, 14.15.4, 15.5.1 are vulnerable to a use-after-free bug in its TLS implementation. When writing to a TLS enabled socket, node::StreamBase::Write calls node::TLSWrap::DoWrite with a freshly allocated WriteWrap object as first argument. If the DoWrite method does not return an error, this object is passed back to the caller as part of a StreamWriteResult structure. This may be exploited to corrupt memory leading to a Denial of Service or potentially other exploits.",
        "target": 1
      },
      {
        "idx": 216820,
        "reasoning": "This code is vulnerable to a use-after-free because the `WriteWrap` object passed to `DoWrite` might be deallocated before the `onwrite` callback completes, leading to access of freed memory. The vulnerability stems from passing ownership of the `WriteWrap` object to the callback without ensuring its lifetime extends beyond the callback's execution, as highlighted by the CVE description regarding TLS sockets and `DoWrite`.",
        "func": "int JSStream::DoWrite(WriteWrap* w,\n                      uv_buf_t* bufs,\n                      size_t count,\n                      uv_stream_t* send_handle) {\n  CHECK_NULL(send_handle);\n\n  HandleScope scope(env()->isolate());\n  Context::Scope context_scope(env()->context());\n\n  Local<Array> bufs_arr = Array::New(env()->isolate(), count);\n  Local<Object> buf;\n  for (size_t i = 0; i < count; i++) {\n    buf = Buffer::Copy(env(), bufs[i].base, bufs[i].len).ToLocalChecked();\n    bufs_arr->Set(i, buf);\n  }\n\n  Local<Value> argv[] = {\n    w->object(),\n    bufs_arr\n  };\n\n  TryCatch try_catch(env()->isolate());\n  Local<Value> value;\n  int value_int = UV_EPROTO;\n  if (!MakeCallback(env()->onwrite_string(),\n                    arraysize(argv),\n                    argv).ToLocal(&value) ||\n      !value->Int32Value(env()->context()).To(&value_int)) {\n    if (!try_catch.HasTerminated())\n      FatalException(env()->isolate(), try_catch);\n  }\n  return value_int;\n}",
        "commit_message": "src: use unique_ptr for WriteWrap\n\nThis commit attempts to avoid a use-after-free error by using unqiue_ptr\nand passing a reference to it.\n\nCVE-ID: CVE-2020-8265\nFixes: https://github.com/nodejs-private/node-private/issues/227\nPR-URL: https://github.com/nodejs-private/node-private/pull/238\nReviewed-By: Michael Dawson <midawson@redhat.com>\nReviewed-By: Tobias Nie\u00dfen <tniessen@tnie.de>\nReviewed-By: Richard Lau <rlau@redhat.com>",
        "cve_desc": "Node.js versions before 10.23.1, 12.20.1, 14.15.4, 15.5.1 are vulnerable to a use-after-free bug in its TLS implementation. When writing to a TLS enabled socket, node::StreamBase::Write calls node::TLSWrap::DoWrite with a freshly allocated WriteWrap object as first argument. If the DoWrite method does not return an error, this object is passed back to the caller as part of a StreamWriteResult structure. This may be exploited to corrupt memory leading to a Denial of Service or potentially other exploits.",
        "target": 1
      }
    ]
  },
  "opaque": {
    "0": [],
    "1": []
  },
  "openexr": {
    "0": [
      {
        "idx": 220371,
        "reasoning": "This code snippet is not inherently vulnerable because it simply adds a validated `DeepScanLineInputFile` to a vector. The commit message indicates a separate enforcement of sampling parameters elsewhere (`xSampling/ySampling==1`), and this function only handles adding the input file *after* validation has occurred\u2014it doesn't directly process or interpret the potentially problematic sampling values itself.\n\n\n\n",
        "func": "CompositeDeepScanLine::addSource(DeepScanLineInputFile* file)\n{\n    _Data->check_valid(file->header());\n    _Data->_file.push_back(file);\n}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 0
      },
      {
        "idx": 220372,
        "reasoning": "This code snippet defines a constructor for a task within the OpenEXR composite deep scanline process and doesn't exhibit any immediately obvious vulnerabilities like buffer overflows, format string bugs, or injection flaws. The constructor simply initializes member variables with provided data; the commit message indicates a change enforcing sampling parameters elsewhere, which isn't reflected in this specific code and doesn't introduce risk here.\n\n\n\n",
        "func": "    LineCompositeTask ( TaskGroup* group ,\n                        CompositeDeepScanLine::Data * data,\n                    int y,\n                    int start,\n                    vector<const char*>* names,\n                    vector<vector< vector<float *> > >* pointers,\n                    vector<unsigned int>* total_sizes,\n                    vector<unsigned int>* num_sources\n                  ) : Task(group) ,\n                     _Data(data),\n                     _y(y),\n                     _start(start),\n                     _names(names),\n                     _pointers(pointers),\n                     _total_sizes(total_sizes),\n                     _num_sources(num_sources)\n                     {}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 0
      },
      {
        "idx": 220373,
        "reasoning": "This code snippet is not inherently vulnerable because it simply sets a pointer to a `DeepCompositing` object. The commit message indicates a change related to sampling values elsewhere in the code, but this specific function only handles data member assignment and doesn't directly process or validate any input that could lead to exploitable conditions.\n\n\n\n",
        "func": "CompositeDeepScanLine::setCompositing(DeepCompositing* c)\n{\n  _Data->_comp=c;\n}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 0
      },
      {
        "idx": 220374,
        "reasoning": "This code snippet is not vulnerable because it simply initializes a member variable `_Data` with a new instance of a `Data` object\u2014a standard object construction pattern. The commit message refers to a change enforcing sampling values elsewhere in the `CompositeDeepScanLine` class, but this specific code doesn't directly handle input or perform operations that could introduce vulnerabilities like buffer overflows or injection flaws.\n\n\n\n",
        "func": "CompositeDeepScanLine::CompositeDeepScanLine() : _Data(new Data) {}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 0
      },
      {
        "idx": 220375,
        "reasoning": "This code snippet simply provides access to a data window object and doesn't perform any operations that could introduce vulnerabilities like buffer overflows or format string bugs. The commit message indicates a change to enforce sampling values elsewhere, but this specific code doesn't appear to be directly involved in that logic and therefore isn't flagged as vulnerable.\n\n\n\n",
        "func": "const IMATH_NAMESPACE::Box2i& CompositeDeepScanLine::dataWindow() const\n{\n  return  _Data->_dataWindow;\n}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195036,
        "reasoning": "This code is vulnerable because it dynamically adds channel names to the `_Data->_channels` vector without any bounds checking on the size of the `_bufferMap` vector, potentially leading to out-of-bounds writes when accessing elements based on the map's indices. While the provided snippet doesn't directly show the overflow, the dynamic resizing and mapping to `_bufferMap` create a pathway for an attacker to control the size and content of channel names, ultimately contributing to the heap-based buffer overflow described in the CVE, especially when combined with the `CompositeDeepScanLine`'s interaction with other parts of the library like `LineCompositeTask::execute`.\n\n\n\n",
        "func": "CompositeDeepScanLine::setFrameBuffer(const FrameBuffer& fr)\n{\n    \n    //\n    // count channels; build map between channels in frame buffer\n    // and channels in internal buffers\n    //\n    \n    _Data->_channels.resize(3);\n    _Data->_channels[0]=\"Z\";\n    _Data->_channels[1]=_Data->_zback ? \"ZBack\" : \"Z\";\n    _Data->_channels[2]=\"A\";\n    _Data->_bufferMap.resize(0);\n    \n    for(FrameBuffer::ConstIterator q=fr.begin();q!=fr.end();q++)\n    {\n        string name(q.name());\n        if(name==\"ZBack\")\n        {\n            _Data->_bufferMap.push_back(1);\n        }else if(name==\"Z\")\n        {\n            _Data->_bufferMap.push_back(0);\n        }else if(name==\"A\")\n        {\n            _Data->_bufferMap.push_back(2);\n        }else{\n            _Data->_bufferMap.push_back(static_cast<int>(_Data->_channels.size()));\n            _Data->_channels.push_back(name);\n        }\n    }\n    \n  _Data->_outputFrameBuffer=fr;\n}",
        "commit_message": "enforce xSampling/ySampling==1 in CompositeDeepScanLine (#1209)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 1
      },
      {
        "idx": 195086,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow due to insufficient validation of `sampleCountTableDataSize` and `packedDataSize`/`unpackedDataSize` against the actual allocated buffer sizes, potentially allowing an attacker to overwrite memory beyond the bounds of `data->sampleCountTableBuffer`. While the code checks against `data->maxSampleCountTableSize` and `compressorMaxDataSize`, the final check `cumulative_total_samples*data->combinedSampleSize > unpackedDataSize` appears to be insufficient to prevent overflows if `combinedSampleSize` is large, or if other factors contribute to exceeding the allocated memory.",
        "func": "readSampleCountForLineBlock(InputStreamMutex* streamData,\n                            DeepScanLineInputFile::Data* data,\n                            int lineBlockId)\n{\n    streamData->is->seekg(data->lineOffsets[lineBlockId]);\n\n    if (isMultiPart(data->version))\n    {\n        int partNumber;\n        OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, partNumber);\n\n        if (partNumber != data->partNumber)\n            throw IEX_NAMESPACE::ArgExc(\"Unexpected part number.\");\n    }\n\n    int minY;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, minY);\n\n    //\n    // Check the correctness of minY.\n    //\n\n    if (minY != data->minY + lineBlockId * data->linesInBuffer)\n        throw IEX_NAMESPACE::ArgExc(\"Unexpected data block y coordinate.\");\n\n    int maxY;\n    maxY = min(minY + data->linesInBuffer - 1, data->maxY);\n\n    uint64_t sampleCountTableDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, sampleCountTableDataSize);\n\n    \n    \n    if(sampleCountTableDataSize>static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"Bad sampleCountTableDataSize read from chunk \"<< lineBlockId << \": expected \" << data->maxSampleCountTableSize << \" or less, got \"<< sampleCountTableDataSize);\n    }\n    \n    uint64_t packedDataSize;\n    uint64_t unpackedDataSize;\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, packedDataSize);\n    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (*streamData->is, unpackedDataSize);\n\n    \n    \n    //\n    // We make a check on the data size requirements here.\n    // Whilst we wish to store 64bit sizes on disk, not all the compressors\n    // have been made to work with such data sizes and are still limited to\n    // using signed 32 bit (int) for the data size. As such, this version\n    // insists that we validate that the data size does not exceed the data\n    // type max limit.\n    // @TODO refactor the compressor code to ensure full 64-bit support.\n    //\n\n    int compressorMaxDataSize = std::numeric_limits<int>::max();\n    if (sampleCountTableDataSize > uint64_t(compressorMaxDataSize))\n    {\n        THROW (IEX_NAMESPACE::ArgExc, \"This version of the library does not \"\n              << \"support the allocation of data with size  > \"\n              << compressorMaxDataSize\n              << \" file table size    :\" << sampleCountTableDataSize << \".\\n\");\n    }\n    streamData->is->read(data->sampleCountTableBuffer, static_cast<int>(sampleCountTableDataSize));\n    \n    const char* readPtr;\n\n    //\n    // If the sample count table is compressed, we'll uncompress it.\n    //\n\n\n    if (sampleCountTableDataSize < static_cast<uint64_t>(data->maxSampleCountTableSize))\n    {\n        if(!data->sampleCountTableComp)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline data corrupt at chunk \" << lineBlockId << \" (sampleCountTableDataSize error)\");\n        }\n        data->sampleCountTableComp->uncompress(data->sampleCountTableBuffer,\n                                               static_cast<int>(sampleCountTableDataSize),\n                                               minY,\n                                               readPtr);\n    }\n    else readPtr = data->sampleCountTableBuffer;\n\n    char* base = data->sampleCountSliceBase;\n    int xStride = data->sampleCountXStride;\n    int yStride = data->sampleCountYStride;\n\n    // total number of samples in block: used to check samplecount table doesn't\n    // reference more data than exists\n    \n    size_t cumulative_total_samples=0;\n    \n    for (int y = minY; y <= maxY; y++)\n    {\n        int yInDataWindow = y - data->minY;\n        data->lineSampleCount[yInDataWindow] = 0;\n\n        int lastAccumulatedCount = 0;\n        for (int x = data->minX; x <= data->maxX; x++)\n        {\n            int accumulatedCount, count;\n\n            //\n            // Read the sample count for pixel (x, y).\n            //\n\n            Xdr::read <CharPtrIO> (readPtr, accumulatedCount);\n            \n            // sample count table should always contain monotonically\n            // increasing values.\n            if (accumulatedCount < lastAccumulatedCount)\n            {\n                THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \" (negative sample count detected)\");\n            }\n\n            count = accumulatedCount - lastAccumulatedCount;\n            lastAccumulatedCount = accumulatedCount;\n\n            //\n            // Store the data in both internal and external data structure.\n            //\n\n            data->sampleCount[yInDataWindow][x - data->minX] = count;\n            data->lineSampleCount[yInDataWindow] += count;\n            sampleCount(base, xStride, yStride, x, y) = count;\n        }\n        cumulative_total_samples+=data->lineSampleCount[yInDataWindow];\n        if(cumulative_total_samples*data->combinedSampleSize > unpackedDataSize)\n        {\n            THROW(IEX_NAMESPACE::ArgExc,\"Deep scanline sampleCount data corrupt at chunk \" << lineBlockId << \": pixel data only contains \" << unpackedDataSize \n            << \" bytes of data but table references at least \" << cumulative_total_samples*data->combinedSampleSize << \" bytes of sample data\" );            \n        }\n        data->gotSampleCount[y - data->minY] = true;\n    }\n}",
        "commit_message": "DeepScanlineInputFile now uses chunk size test from DeepTiledInputFile (#1205)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "OpenEXR 3.1.x before 3.1.4 has a heap-based buffer overflow in Imf_3_1::LineCompositeTask::execute (called from IlmThread_3_1::NullThreadPoolProvider::addTask and IlmThread_3_1::ThreadPool::addGlobalTask). NOTE: db217f2 may be inapplicable.",
        "target": 1
      },
      {
        "idx": 200458,
        "reasoning": "The code is vulnerable to a heap-based buffer overflow because the `partNumber` read from the input stream is used to index the `parts` vector without sufficient validation, potentially allowing an out-of-bounds access. Specifically, the check `partNumber<0 || partNumber> static_cast<int>(parts.size())` is flawed; it should be `partNumber < 0 || partNumber >= static_cast<int>(parts.size())` to prevent accessing `parts` at `parts.size()`, which is out of bounds. \n\n\n\n",
        "func": "MultiPartInputFile::Data::chunkOffsetReconstruction(OPENEXR_IMF_INTERNAL_NAMESPACE::IStream& is, const vector<InputPartData*>& parts)\n{\n    //\n    // Reconstruct broken chunk offset tables. Stop once we received any exception.\n    //\n\n    Int64 position = is.tellg();\n\n    \n    //\n    // check we understand all the parts available: if not, we cannot continue\n    // exceptions thrown here should trickle back up to the constructor\n    //\n    \n    for (size_t i = 0; i < parts.size(); i++)\n    {\n        Header& header=parts[i]->header;\n        \n        //\n        // do we have a valid type entry?\n        // we only need them for true multipart files or single part non-image (deep) files\n        //\n        if(!header.hasType() && (isMultiPart(version) || isNonImage(version)))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with missing type\");\n        }\n        if(!isSupportedType(header.type()))\n        {\n            throw IEX_NAMESPACE::ArgExc(\"cannot reconstruct incomplete file: part with unknown type \"+header.type());\n        }\n    }\n    \n    \n    // how many chunks should we read? We should stop when we reach the end\n    size_t total_chunks = 0;\n        \n    // for tiled-based parts, array of (pointers to) tileOffsets objects\n    // to create mapping between tile coordinates and chunk table indices\n    \n    \n    vector<TileOffsets*> tileOffsets(parts.size());\n    \n    // for scanline-based parts, number of scanlines in each chunk\n    vector<int> rowsizes(parts.size());\n        \n    for(size_t i = 0 ; i < parts.size() ; i++)\n    {\n        total_chunks += parts[i]->chunkOffsets.size();\n        if (isTiled(parts[i]->header.type()))\n        {\n            tileOffsets[i] = createTileOffsets(parts[i]->header);\n        }else{\n            tileOffsets[i] = NULL;\n            // (TODO) fix this so that it doesn't need to be revised for future compression types.\n            switch(parts[i]->header.compression())\n            {\n                case DWAB_COMPRESSION :\n                    rowsizes[i] = 256;\n                    break;\n                case PIZ_COMPRESSION :\n                case B44_COMPRESSION :\n                case B44A_COMPRESSION :\n                case DWAA_COMPRESSION :\n                    rowsizes[i]=32;\n                    break;\n                case ZIP_COMPRESSION :\n                case PXR24_COMPRESSION :\n                    rowsizes[i]=16;\n                    break;\n                case ZIPS_COMPRESSION :\n                case RLE_COMPRESSION :\n                case NO_COMPRESSION :\n                    rowsizes[i]=1;\n                    break;\n                default :\n                    throw(IEX_NAMESPACE::ArgExc(\"Unknown compression method in chunk offset reconstruction\"));\n            }\n        }\n     }\n        \n     try\n     {\n            \n        //\n        // \n        //\n        \n        Int64 chunk_start = position;\n        for (size_t i = 0; i < total_chunks ; i++)\n        {\n            //\n            // do we have a part number?\n            //\n            \n            int partNumber = 0;\n            if(isMultiPart(version))\n            {\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, partNumber);\n            }\n            \n            \n            \n            if(partNumber<0 || partNumber> static_cast<int>(parts.size()))\n            {\n                throw IEX_NAMESPACE::IoExc(\"part number out of range\");\n            }\n            \n            Header& header = parts[partNumber]->header;\n\n            // size of chunk NOT including multipart field\n            \n            Int64 size_of_chunk=0;\n\n            if (isTiled(header.type()))\n            {\n                //\n                // \n                //\n                int tilex,tiley,levelx,levely;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tilex);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, tiley);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levelx);\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, levely);\n                \n                //std::cout << \"chunk_start for \" << tilex <<',' << tiley << ',' << levelx << ' ' << levely << ':' << chunk_start << std::endl;\n                    \n                \n                if(!tileOffsets[partNumber])\n                {\n                    // this shouldn't actually happen - we should have allocated a valid\n                    // tileOffsets for any part which isTiled\n                    throw IEX_NAMESPACE::IoExc(\"part not tiled\");\n                    \n                }\n                \n                if(!tileOffsets[partNumber]->isValidTile(tilex,tiley,levelx,levely))\n                {\n                    throw IEX_NAMESPACE::IoExc(\"invalid tile coordinates\");\n                }\n                \n                (*tileOffsets[partNumber])(tilex,tiley,levelx,levely)=chunk_start;\n                \n                // compute chunk sizes - different procedure for deep tiles and regular\n                // ones\n                if(header.type()==DEEPTILE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    //add 40 byte header to packed sizes (tile coordinates, packed sizes, unpacked size)\n                    size_of_chunk=packed_offset+packed_sample+40;\n                }\n                else\n                {\n                    \n                    // regular image has 20 bytes of header, 4 byte chunksize;\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);\n                    size_of_chunk=chunksize+20;\n                }\n            }\n            else\n            {\n                int y_coordinate;\n                OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, y_coordinate);\n                \n                \n                if(y_coordinate < header.dataWindow().min.y || y_coordinate > header.dataWindow().max.y)\n                {\n                   throw IEX_NAMESPACE::IoExc(\"y out of range\");\n                }\n                y_coordinate -= header.dataWindow().min.y;\n                y_coordinate /= rowsizes[partNumber];   \n                \n                if(y_coordinate < 0 || y_coordinate >= int(parts[partNumber]->chunkOffsets.size()))\n                {\n                   throw IEX_NAMESPACE::IoExc(\"chunk index out of range\");\n                }\n                \n                parts[partNumber]->chunkOffsets[y_coordinate]=chunk_start;\n                \n                if(header.type()==DEEPSCANLINE)\n                {\n                    Int64 packed_offset;\n                    Int64 packed_sample;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_offset);\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, packed_sample);\n                    \n                    \n                    size_of_chunk=packed_offset+packed_sample+28;\n                }\n                else\n                {\n                    int chunksize;\n                    OPENEXR_IMF_INTERNAL_NAMESPACE::Xdr::read <OPENEXR_IMF_INTERNAL_NAMESPACE::StreamIO> (is, chunksize);   \n                    size_of_chunk=chunksize+8;\n                }\n                \n            }\n            \n            if(isMultiPart(version))\n            {\n                chunk_start+=4;\n            }\n            \n            chunk_start+=size_of_chunk;\n            \n            is.seekg(chunk_start);\n            \n        }\n        \n    }\n    catch (...)\n    {\n        //\n        // Suppress all exceptions.  This functions is\n        // called only to reconstruct the line offset\n        // table for incomplete files, and exceptions\n        // are likely.\n        //\n    }\n\n    // copy tiled part data back to chunk offsets\n    \n    for(size_t partNumber=0;partNumber<parts.size();partNumber++)\n    {\n        if(tileOffsets[partNumber])\n        {\n            size_t pos=0;\n            vector<vector<vector <Int64> > > offsets = tileOffsets[partNumber]->getOffsets();\n            for (size_t l = 0; l < offsets.size(); l++)\n                for (size_t y = 0; y < offsets[l].size(); y++)\n                    for (size_t x = 0; x < offsets[l][y].size(); x++)\n                    {\n                        parts[ partNumber ]->chunkOffsets[pos] = offsets[l][y][x];\n                        pos++;\n                    }\n           delete tileOffsets[partNumber];\n        }\n    }\n\n    is.clear();\n    is.seekg (position);\n}",
        "commit_message": "Fix #491, issue with part number range check reconstructing chunk offset table\n\nThe chunk offset was incorrectly testing for a part number that was the\nsame size (i.e. an invalid index)\n\nSigned-off-by: Kimball Thurston <kdt3rd@gmail.com>",
        "cve_desc": "A heap-based buffer overflow vulnerability exists in Academy Software Foundation OpenEXR 2.3.0 in chunkOffsetReconstruction in ImfMultiPartInputFile.cpp that can cause a denial of service via a crafted EXR file.",
        "target": 1
      },
      {
        "idx": 202941,
        "reasoning": "This code is vulnerable to a denial of service due to a potential mismatch between the expected tile size calculated by `tileOffsets` and the actual data read from the stream, especially in multipart files. While the `isValidTile` check prevents out-of-bounds *requests*, it doesn't validate the size of the data read after seeking, potentially leading to a buffer overflow in `readNextTileData` if `tileOffsets` returns an incorrect offset or size, aligning with the CVE description of a crafted EXR file causing a denial of service.",
        "func": "TiledInputFile::rawTileData (int &dx, int &dy,\n\t\t\t     int &lx, int &ly,\n                             const char *&pixelData,\n\t\t\t     int &pixelDataSize)\n{\n    try\n    {\n        Lock lock (*_data->_streamData);\n\n        if (!isValidTile (dx, dy, lx, ly))\n            throw IEX_NAMESPACE::ArgExc (\"Tried to read a tile outside \"\n\t\t\t       \"the image file's data window.\");\n\n        TileBuffer *tileBuffer = _data->getTileBuffer (0);\n\n        //\n        // if file is a multipart file, we have to seek to the required tile\n        // since we don't know where the file pointer is\n        //\n        int old_dx=dx;\n        int old_dy=dy;\n        int old_lx=lx;\n        int old_ly=ly;\n        if(isMultiPart(version()))\n        {\n            _data->_streamData->is->seekg(_data->tileOffsets(dx,dy,lx,ly));\n        }\n        readNextTileData (_data->_streamData, _data, dx, dy, lx, ly,\n\t\t\t  tileBuffer->buffer,\n                          pixelDataSize);\n        if(isMultiPart(version()))\n        {\n            if (old_dx!=dx || old_dy !=dy || old_lx!=lx || old_ly!=ly)\n            {\n                throw IEX_NAMESPACE::ArgExc (\"rawTileData read the wrong tile\");\n            }\n        }\n        pixelData = tileBuffer->buffer;\n    }\n    catch (IEX_NAMESPACE::BaseExc &e)\n    {\n        REPLACE_EXC (e, \"Error reading pixel data from image \"\n                     \"file \\\"\" << fileName() << \"\\\". \" << e.what());\n        throw;\n    }\n}",
        "commit_message": "Fix for #494: validate tile coordinates when doing copyPixels",
        "cve_desc": "A head-based buffer overflow exists in Academy Software Foundation OpenEXR 2.3.0 in writeTileData in ImfTiledOutputFile.cpp that can cause a denial of service via a crafted EXR file.",
        "target": 1
      },
      {
        "idx": 204346,
        "reasoning": "This code is vulnerable because the `while` loop continues reading headers until `header.readsNothing()` is true, but doesn't handle the case where no parts are present *before* reading any headers, potentially leading to a dereference of a null pointer within `header`. Specifically, the CVE describes a crafted multipart file with no parts triggering this issue, which aligns with the loop's behavior of attempting to read headers even from an empty multipart file.",
        "func": "MultiPartInputFile::initialize()\n{\n    readMagicNumberAndVersionField(*_data->is, _data->version);\n    \n    bool multipart = isMultiPart(_data->version);\n    bool tiled = isTiled(_data->version);\n\n    //\n    // Multipart files don't have and shouldn't have the tiled bit set.\n    //\n\n    if (tiled && multipart)\n        throw IEX_NAMESPACE::InputExc (\"Multipart files cannot have the tiled bit set\");\n\n    \n    int pos = 0;\n    while (true)\n    {\n        Header header;\n        header.readFrom(*_data->is, _data->version);\n\n        //\n        // If we read nothing then we stop reading.\n        //\n\n        if (header.readsNothing())\n        {\n            pos++;\n            break;\n        }\n\n        _data->_headers.push_back(header);\n        \n        if(multipart == false)\n          break;\n    }\n\n    //\n    // Perform usual check on headers.\n    //\n\n    for (size_t i = 0; i < _data->_headers.size(); i++)\n    {\n        //\n        // Silently invent a type if the file is a single part regular image.\n        //\n\n        if( _data->_headers[i].hasType() == false )\n        {\n            if(multipart)\n\n                throw IEX_NAMESPACE::ArgExc (\"Every header in a multipart file should have a type\");\n          \n            _data->_headers[i].setType(tiled ? TILEDIMAGE : SCANLINEIMAGE);\n        }\n        else\n        {\n            \n            //\n            // Silently fix the header type if it's wrong\n            // (happens when a regular Image file written by EXR_2.0 is rewritten by an older library,\n            //  so doesn't effect deep image types)\n            //\n\n            if(!multipart && !isNonImage(_data->version))\n            {\n                _data->_headers[i].setType(tiled ? TILEDIMAGE : SCANLINEIMAGE);\n            }\n        }\n         \n\n        \n        if( _data->_headers[i].hasName() == false )\n        {\n            if(multipart)\n                throw IEX_NAMESPACE::ArgExc (\"Every header in a multipart file should have a name\");\n        }\n        \n        if (isTiled(_data->_headers[i].type()))\n            _data->_headers[i].sanityCheck(true, multipart);\n        else\n            _data->_headers[i].sanityCheck(false, multipart);\n    }\n\n    //\n    // Check name uniqueness.\n    //\n\n    if (multipart)\n    {\n        set<string> names;\n        for (size_t i = 0; i < _data->_headers.size(); i++)\n        {\n        \n            if (names.find(_data->_headers[i].name()) != names.end())\n            {\n                throw IEX_NAMESPACE::InputExc (\"Header name \" + _data->_headers[i].name() +\n                                   \" is not a unique name.\");\n            }\n            names.insert(_data->_headers[i].name());\n        }\n    }\n    \n    //\n    // Check shared attributes compliance.\n    //\n\n    if (multipart && strictSharedAttribute)\n    {\n        for (size_t i = 1; i < _data->_headers.size(); i++)\n        {\n            vector <string> attrs;\n            if (_data->checkSharedAttributesValues (_data->_headers[0], _data->_headers[i], attrs))\n            {\n                string attrNames;\n                for (size_t j=0; j<attrs.size(); j++)\n                    attrNames += \" \" + attrs[j];\n                throw IEX_NAMESPACE::InputExc (\"Header name \" + _data->_headers[i].name() +\n                                     \" has non-conforming shared attributes: \"+\n                                     attrNames);\n            }\n        }\n    }\n\n    //\n    // Create InputParts and read chunk offset tables.\n    //\n        \n    for (size_t i = 0; i < _data->_headers.size(); i++)\n        _data->parts.push_back(\n                new InputPartData(_data, _data->_headers[i], i, _data->numThreads, _data->version));\n\n    _data->readChunkOffsetTables(_data->reconstructChunkOffsetTable);\n}",
        "commit_message": "add sanity check for reading multipart files with no parts (#840)\n\nSigned-off-by: Peter Hillman <peterh@wetafx.co.nz>",
        "cve_desc": "A flaw was found in OpenEXR's Multipart input file functionality. A crafted multi-part input file with no actual parts can trigger a NULL pointer dereference. The highest threat from this vulnerability is to system availability.",
        "target": 1
      }
    ]
  },
  "openfortivpn": {
    "0": [],
    "1": [
      {
        "idx": 197507,
        "reasoning": "This code is vulnerable because the `common_name` buffer, used as input to `X509_check_host`, is not initialized before being passed to the function, leading to undefined behavior and potentially bypassing hostname validation. As a result, a valid certificate may not be accepted, effectively disabling proper host name verification when using OpenSSL versions 1.0.2 and later.",
        "func": "static int ssl_verify_cert(struct tunnel *tunnel)\n{\n\tint ret = -1;\n\tint cert_valid = 0;\n\tunsigned char digest[SHA256LEN];\n\tunsigned int len;\n\tstruct x509_digest *elem;\n\tchar digest_str[SHA256STRLEN], *subject, *issuer;\n\tchar *line;\n\tint i;\n\tX509_NAME *subj;\n\tchar common_name[FIELD_SIZE + 1];\n\n\tSSL_set_verify(tunnel->ssl_handle, SSL_VERIFY_PEER, NULL);\n\n\tX509 *cert = SSL_get_peer_certificate(tunnel->ssl_handle);\n\tif (cert == NULL) {\n\t\tlog_error(\"Unable to get gateway certificate.\\n\");\n\t\treturn 1;\n\t}\n\n\tsubj = X509_get_subject_name(cert);\n\n#ifdef HAVE_X509_CHECK_HOST\n\t// Use OpenSSL native host validation if v >= 1.0.2.\n\t// correctly check return value of X509_check_host\n\tif (X509_check_host(cert, common_name, FIELD_SIZE, 0, NULL) == 1)\n\t\tcert_valid = 1;\n#else\n\t// Use explicit Common Name check if native validation not available.\n\t// Note: this will ignore Subject Alternative Name fields.\n\tif (subj\n\t    && X509_NAME_get_text_by_NID(subj, NID_commonName, common_name,\n\t                                 FIELD_SIZE) > 0\n\t    && strncasecmp(common_name, tunnel->config->gateway_host,\n\t                   FIELD_SIZE) == 0)\n\t\tcert_valid = 1;\n#endif\n\n\t// Try to validate certificate using local PKI\n\tif (cert_valid\n\t    && SSL_get_verify_result(tunnel->ssl_handle) == X509_V_OK) {\n\t\tlog_debug(\"Gateway certificate validation succeeded.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\tlog_debug(\"Gateway certificate validation failed.\\n\");\n\n\t// If validation failed, check if cert is in the white list\n\tif (X509_digest(cert, EVP_sha256(), digest, &len) <= 0\n\t    || len != SHA256LEN) {\n\t\tlog_error(\"Could not compute certificate sha256 digest.\\n\");\n\t\tgoto free_cert;\n\t}\n\t// Encode digest in base16\n\tfor (i = 0; i < SHA256LEN; i++)\n\t\tsprintf(&digest_str[2 * i], \"%02x\", digest[i]);\n\tdigest_str[SHA256STRLEN - 1] = '\\0';\n\t// Is it in whitelist?\n\tfor (elem = tunnel->config->cert_whitelist; elem != NULL;\n\t     elem = elem->next)\n\t\tif (memcmp(digest_str, elem->data, SHA256STRLEN - 1) == 0)\n\t\t\tbreak;\n\tif (elem != NULL) { // break before end of loop\n\t\tlog_debug(\"Gateway certificate digest found in white list.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\n\tsubject = X509_NAME_oneline(subj, NULL, 0);\n\tissuer = X509_NAME_oneline(X509_get_issuer_name(cert), NULL, 0);\n\n\tlog_error(\"Gateway certificate validation failed, and the certificate digest in not in the local whitelist. If you trust it, rerun with:\\n\");\n\tlog_error(\"    --trusted-cert %s\\n\", digest_str);\n\tlog_error(\"or add this line to your config file:\\n\");\n\tlog_error(\"    trusted-cert = %s\\n\", digest_str);\n\tlog_error(\"Gateway certificate:\\n\");\n\tlog_error(\"    subject:\\n\");\n\tfor (line = strtok(subject, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    issuer:\\n\");\n\tfor (line = strtok(issuer, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    sha256 digest:\\n\");\n\tlog_error(\"        %s\\n\", digest_str);\n\nfree_cert:\n\tX509_free(cert);\n\treturn ret;\n}",
        "commit_message": "supply proper input buffer to X509_check_host\n\nCVE-2020-7042 use of uninitialized memory in X509_check_host is fixed with\nthis commit\n\nthe uninitialized buffer common_name was passed as argument to X509_check_host\nwhich prevented proper host name validation when openssl >= 1.0.2 was in use.\nThis came in with #282 which went into openfortivpn 1.7.1.\nUnfortunately, this problem has stayed unnoticed because the return value\nwas not properly checked either (which is a separate issue, with CVE-2020-7041,\nand which has been fixed by the previous commit)",
        "cve_desc": "An issue was discovered in openfortivpn 1.11.0 when used with OpenSSL 1.0.2 or later. tunnel.c mishandles certificate validation because the hostname check operates on uninitialized memory. The outcome is that a valid certificate is never accepted (only a malformed certificate may be accepted).",
        "target": 1
      },
      {
        "idx": 198217,
        "reasoning": "This code is vulnerable because it incorrectly interprets the return value of `X509_check_host`. A negative return from `X509_check_host` indicates failure, but the code treats it as success (`cert_valid = 1`), leading to bypassing of proper hostname verification and potential man-in-the-middle attacks.",
        "func": "static int ssl_verify_cert(struct tunnel *tunnel)\n{\n\tint ret = -1;\n\tint cert_valid = 0;\n\tunsigned char digest[SHA256LEN];\n\tunsigned int len;\n\tstruct x509_digest *elem;\n\tchar digest_str[SHA256STRLEN], *subject, *issuer;\n\tchar *line;\n\tint i;\n\tX509_NAME *subj;\n\tchar common_name[FIELD_SIZE + 1];\n\n\tSSL_set_verify(tunnel->ssl_handle, SSL_VERIFY_PEER, NULL);\n\n\tX509 *cert = SSL_get_peer_certificate(tunnel->ssl_handle);\n\tif (cert == NULL) {\n\t\tlog_error(\"Unable to get gateway certificate.\\n\");\n\t\treturn 1;\n\t}\n\n\tsubj = X509_get_subject_name(cert);\n\n#ifdef HAVE_X509_CHECK_HOST\n\t// Use OpenSSL native host validation if v >= 1.0.2.\n\tif (X509_check_host(cert, common_name, FIELD_SIZE, 0, NULL))\n\t\tcert_valid = 1;\n#else\n\t// Use explicit Common Name check if native validation not available.\n\t// Note: this will ignore Subject Alternative Name fields.\n\tif (subj\n\t    && X509_NAME_get_text_by_NID(subj, NID_commonName, common_name,\n\t                                 FIELD_SIZE) > 0\n\t    && strncasecmp(common_name, tunnel->config->gateway_host,\n\t                   FIELD_SIZE) == 0)\n\t\tcert_valid = 1;\n#endif\n\n\t// Try to validate certificate using local PKI\n\tif (cert_valid\n\t    && SSL_get_verify_result(tunnel->ssl_handle) == X509_V_OK) {\n\t\tlog_debug(\"Gateway certificate validation succeeded.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\tlog_debug(\"Gateway certificate validation failed.\\n\");\n\n\t// If validation failed, check if cert is in the white list\n\tif (X509_digest(cert, EVP_sha256(), digest, &len) <= 0\n\t    || len != SHA256LEN) {\n\t\tlog_error(\"Could not compute certificate sha256 digest.\\n\");\n\t\tgoto free_cert;\n\t}\n\t// Encode digest in base16\n\tfor (i = 0; i < SHA256LEN; i++)\n\t\tsprintf(&digest_str[2 * i], \"%02x\", digest[i]);\n\tdigest_str[SHA256STRLEN - 1] = '\\0';\n\t// Is it in whitelist?\n\tfor (elem = tunnel->config->cert_whitelist; elem != NULL;\n\t     elem = elem->next)\n\t\tif (memcmp(digest_str, elem->data, SHA256STRLEN - 1) == 0)\n\t\t\tbreak;\n\tif (elem != NULL) { // break before end of loop\n\t\tlog_debug(\"Gateway certificate digest found in white list.\\n\");\n\t\tret = 0;\n\t\tgoto free_cert;\n\t}\n\n\tsubject = X509_NAME_oneline(subj, NULL, 0);\n\tissuer = X509_NAME_oneline(X509_get_issuer_name(cert), NULL, 0);\n\n\tlog_error(\"Gateway certificate validation failed, and the certificate digest in not in the local whitelist. If you trust it, rerun with:\\n\");\n\tlog_error(\"    --trusted-cert %s\\n\", digest_str);\n\tlog_error(\"or add this line to your config file:\\n\");\n\tlog_error(\"    trusted-cert = %s\\n\", digest_str);\n\tlog_error(\"Gateway certificate:\\n\");\n\tlog_error(\"    subject:\\n\");\n\tfor (line = strtok(subject, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    issuer:\\n\");\n\tfor (line = strtok(issuer, \"/\"); line != NULL;\n\t     line = strtok(NULL, \"/\"))\n\t\tlog_error(\"        %s\\n\", line);\n\tlog_error(\"    sha256 digest:\\n\");\n\tlog_error(\"        %s\\n\", digest_str);\n\nfree_cert:\n\tX509_free(cert);\n\treturn ret;\n}",
        "commit_message": "correctly check return value of X509_check_host\n\nCVE-2020-7041 incorrect use of X509_check_host (regarding return value)\nis fixed with this commit.\n\nThe flaw came in with #242 and prevented proper host name verification\nwhen openssl >= 1.0.2 was in use since openfortivpn 1.7.0.",
        "cve_desc": "An issue was discovered in openfortivpn 1.11.0 when used with OpenSSL 1.0.2 or later. tunnel.c mishandles certificate validation because an X509_check_host negative error code is interpreted as a successful return value.",
        "target": 1
      }
    ]
  },
  "openjpeg": {
    "0": [
      {
        "idx": 48403,
        "reasoning": "The commit message states the fix addresses an integer overflow issue, but the code snippet includes comments explicitly stating where potential overflows were considered and mitigated (\"can't be greater than p_image->x1 so won't overflow\").  Therefore, based on the provided snippet and commit message context, the code appears to be safe as the identified overflow concerns were already addressed before this commit.",
        "func": "static void opj_get_all_encoding_parameters(   const opj_image_t *p_image,\n                                        const opj_cp_t *p_cp,\n                                        OPJ_UINT32 tileno,\n                                        OPJ_INT32 * p_tx0,\n                                        OPJ_INT32 * p_tx1,\n                                        OPJ_INT32 * p_ty0,\n                                        OPJ_INT32 * p_ty1,\n                                        OPJ_UINT32 * p_dx_min,\n                                        OPJ_UINT32 * p_dy_min,\n                                        OPJ_UINT32 * p_max_prec,\n                                        OPJ_UINT32 * p_max_res,\n                                        OPJ_UINT32 ** p_resolutions )\n{\n\t/* loop*/\n\tOPJ_UINT32 compno, resno;\n\n\t/* pointers*/\n\tconst opj_tcp_t *tcp = 00;\n\tconst opj_tccp_t * l_tccp = 00;\n\tconst opj_image_comp_t * l_img_comp = 00;\n\n\t/* to store l_dx, l_dy, w and h for each resolution and component.*/\n\tOPJ_UINT32 * lResolutionPtr;\n\n\t/* position in x and y of tile*/\n\tOPJ_UINT32 p, q;\n\n\t/* non-corrected (in regard to image offset) tile offset */\n\tOPJ_UINT32 l_tx0, l_ty0;\n\n\t/* preconditions in debug*/\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(tileno < p_cp->tw * p_cp->th);\n\n\t/* initializations*/\n\ttcp = &p_cp->tcps [tileno];\n\tl_tccp = tcp->tccps;\n\tl_img_comp = p_image->comps;\n\n\t/* position in x and y of tile*/\n\tp = tileno % p_cp->tw;\n\tq = tileno / p_cp->tw;\n\n\t/* here calculation of tx0, tx1, ty0, ty1, maxprec, l_dx and l_dy */\n\tl_tx0 = p_cp->tx0 + p * p_cp->tdx; /* can't be greater than p_image->x1 so won't overflow */\n\t*p_tx0 = (OPJ_INT32)opj_uint_max(l_tx0, p_image->x0);\n\t*p_tx1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_tx0, p_cp->tdx), p_image->x1);\n\tl_ty0 = p_cp->ty0 + q * p_cp->tdy; /* can't be greater than p_image->y1 so won't overflow */\n\t*p_ty0 = (OPJ_INT32)opj_uint_max(l_ty0, p_image->y0);\n\t*p_ty1 = (OPJ_INT32)opj_uint_min(opj_uint_adds(l_ty0, p_cp->tdy), p_image->y1);\n\n\t/* max precision and resolution is 0 (can only grow)*/\n\t*p_max_prec = 0;\n\t*p_max_res = 0;\n\n\t/* take the largest value for dx_min and dy_min*/\n\t*p_dx_min = 0x7fffffff;\n\t*p_dy_min = 0x7fffffff;\n\n\tfor (compno = 0; compno < p_image->numcomps; ++compno) {\n\t\t/* aritmetic variables to calculate*/\n\t\tOPJ_UINT32 l_level_no;\n\t\tOPJ_INT32 l_rx0, l_ry0, l_rx1, l_ry1;\n\t\tOPJ_INT32 l_px0, l_py0, l_px1, py1;\n\t\tOPJ_UINT32 l_product;\n\t\tOPJ_INT32 l_tcx0, l_tcy0, l_tcx1, l_tcy1;\n\t\tOPJ_UINT32 l_pdx, l_pdy , l_pw , l_ph;\n\n\t\tlResolutionPtr = p_resolutions[compno];\n\n\t\tl_tcx0 = opj_int_ceildiv(*p_tx0, (OPJ_INT32)l_img_comp->dx);\n\t\tl_tcy0 = opj_int_ceildiv(*p_ty0, (OPJ_INT32)l_img_comp->dy);\n\t\tl_tcx1 = opj_int_ceildiv(*p_tx1, (OPJ_INT32)l_img_comp->dx);\n\t\tl_tcy1 = opj_int_ceildiv(*p_ty1, (OPJ_INT32)l_img_comp->dy);\n\n\t\tif (l_tccp->numresolutions > *p_max_res) {\n\t\t\t*p_max_res = l_tccp->numresolutions;\n\t\t}\n\n\t\t/* use custom size for precincts*/\n\t\tl_level_no = l_tccp->numresolutions;\n\t\tfor (resno = 0; resno < l_tccp->numresolutions; ++resno) {\n\t\t\tOPJ_UINT32 l_dx, l_dy;\n\n\t\t\t--l_level_no;\n\t\t\t\n\t\t\t/* precinct width and height*/\n\t\t\tl_pdx = l_tccp->prcw[resno];\n\t\t\tl_pdy = l_tccp->prch[resno];\n\t\t\t*lResolutionPtr++ = l_pdx;\n\t\t\t*lResolutionPtr++ = l_pdy;\n\t\t\tl_dx = l_img_comp->dx * (1u << (l_pdx + l_level_no));\n\t\t\tl_dy = l_img_comp->dy * (1u << (l_pdy + l_level_no));\n\t\t\t/* take the minimum size for l_dx for each comp and resolution*/\n\t\t\t*p_dx_min = (OPJ_UINT32)opj_int_min((OPJ_INT32)*p_dx_min, (OPJ_INT32)l_dx);\n\t\t\t*p_dy_min = (OPJ_UINT32)opj_int_min((OPJ_INT32)*p_dy_min, (OPJ_INT32)l_dy);\n\n\t\t\t/* various calculations of extents*/\n\t\t\tl_rx0 = opj_int_ceildivpow2(l_tcx0, (OPJ_INT32)l_level_no);\n\t\t\tl_ry0 = opj_int_ceildivpow2(l_tcy0, (OPJ_INT32)l_level_no);\n\t\t\tl_rx1 = opj_int_ceildivpow2(l_tcx1, (OPJ_INT32)l_level_no);\n\t\t\tl_ry1 = opj_int_ceildivpow2(l_tcy1, (OPJ_INT32)l_level_no);\n\t\t\tl_px0 = opj_int_floordivpow2(l_rx0, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tl_py0 = opj_int_floordivpow2(l_ry0, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\tl_px1 = opj_int_ceildivpow2(l_rx1, (OPJ_INT32)l_pdx) << l_pdx;\n\t\t\tpy1 = opj_int_ceildivpow2(l_ry1, (OPJ_INT32)l_pdy) << l_pdy;\n\t\t\tl_pw = (l_rx0==l_rx1)?0:(OPJ_UINT32)((l_px1 - l_px0) >> l_pdx);\n\t\t\tl_ph = (l_ry0==l_ry1)?0:(OPJ_UINT32)((py1 - l_py0) >> l_pdy);\n\t\t\t*lResolutionPtr++ = l_pw;\n\t\t\t*lResolutionPtr++ = l_ph;\n\t\t\tl_product = l_pw * l_ph;\n\t\t\t\n            /* update precision*/\n\t\t\tif (l_product > *p_max_prec) {\n\t\t\t\t*p_max_prec = l_product;\n\t\t\t}\n\n\t\t}\n\t\t++l_tccp;\n\t\t++l_img_comp;\n\t}\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 48404,
        "reasoning": "This code is likely safe; the commit message states it *fixes* an integer overflow issue, implying the previous version was vulnerable but this version addresses it. The provided snippet shows careful memory allocation with checks for allocation failures and appropriate cleanup via `opj_pi_destroy`, mitigating potential issues arising from incorrect size calculations that could lead to overflows.",
        "func": "static opj_pi_iterator_t * opj_pi_create(\tconst opj_image_t *image,\n                                    const opj_cp_t *cp,\n                                    OPJ_UINT32 tileno )\n{\n\t/* loop*/\n\tOPJ_UINT32 pino, compno;\n\t/* number of poc in the p_pi*/\n\tOPJ_UINT32 l_poc_bound;\n\n\t/* pointers to tile coding parameters and components.*/\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *tcp = 00;\n\tconst opj_tccp_t *tccp = 00;\n\n\t/* current packet iterator being allocated*/\n\topj_pi_iterator_t *l_current_pi = 00;\n\n\t/* preconditions in debug*/\n\tassert(cp != 00);\n\tassert(image != 00);\n\tassert(tileno < cp->tw * cp->th);\n\n\t/* initializations*/\n\ttcp = &cp->tcps[tileno];\n\tl_poc_bound = tcp->numpocs+1;\n\n\t/* memory allocations*/\n\tl_pi = (opj_pi_iterator_t*) opj_calloc((l_poc_bound), sizeof(opj_pi_iterator_t));\n\tif (!l_pi) {\n\t\treturn NULL;\n\t}\n\n\tl_current_pi = l_pi;\n\tfor (pino = 0; pino < l_poc_bound ; ++pino) {\n\n\t\tl_current_pi->comps = (opj_pi_comp_t*) opj_calloc(image->numcomps, sizeof(opj_pi_comp_t));\n\t\tif (! l_current_pi->comps) {\n\t\t\topj_pi_destroy(l_pi, l_poc_bound);\n\t\t\treturn NULL;\n\t\t}\n\n\t\tl_current_pi->numcomps = image->numcomps;\n\n\t\tfor (compno = 0; compno < image->numcomps; ++compno) {\n\t\t\topj_pi_comp_t *comp = &l_current_pi->comps[compno];\n\n\t\t\ttccp = &tcp->tccps[compno];\n\n\t\t\tcomp->resolutions = (opj_pi_resolution_t*) opj_calloc(tccp->numresolutions, sizeof(opj_pi_resolution_t));\n\t\t\tif (!comp->resolutions) {\n\t\t\t\topj_pi_destroy(l_pi, l_poc_bound);\n\t\t\t\treturn 00;\n\t\t\t}\n\n\t\t\tcomp->numresolutions = tccp->numresolutions;\n\t\t}\n\t\t++l_current_pi;\n\t}\n\treturn l_pi;\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 48405,
        "reasoning": "The commit message states the fix addresses an integer overflow issue, but the provided code snippet is for `opj_pi_create_encode`, not `opj_pi_create_decode` where the original issue was located. Therefore, based solely on this snippet, there's no evidence of the vulnerability being present, and it's not flagged as vulnerable in this specific function.\n\n\n\n",
        "func": "void opj_pi_create_encode( \topj_pi_iterator_t *pi,\n\t\t\t\t\t\t\topj_cp_t *cp,\n\t\t\t\t\t\t\tOPJ_UINT32 tileno,\n\t\t\t\t\t\t\tOPJ_UINT32 pino,\n\t\t\t\t\t\t\tOPJ_UINT32 tpnum,\n\t\t\t\t\t\t\tOPJ_INT32 tppos,\n\t\t\t\t\t\t\tJ2K_T2_MODE t2_mode)\n{\n\tconst OPJ_CHAR *prog;\n\tOPJ_INT32 i;\n\tOPJ_UINT32 incr_top=1,resetX=0;\n\topj_tcp_t *tcps =&cp->tcps[tileno];\n\topj_poc_t *tcp= &tcps->pocs[pino];\n\n\tprog = opj_j2k_convert_progression_order(tcp->prg);\n\n\tpi[pino].first = 1;\n\tpi[pino].poc.prg = tcp->prg;\n\n    if(!(cp->m_specific_param.m_enc.m_tp_on && ((!OPJ_IS_CINEMA(cp->rsiz) && (t2_mode == FINAL_PASS)) || OPJ_IS_CINEMA(cp->rsiz)))){\n\t\tpi[pino].poc.resno0 = tcp->resS;\n\t\tpi[pino].poc.resno1 = tcp->resE;\n\t\tpi[pino].poc.compno0 = tcp->compS;\n\t\tpi[pino].poc.compno1 = tcp->compE;\n\t\tpi[pino].poc.layno0 = tcp->layS;\n\t\tpi[pino].poc.layno1 = tcp->layE;\n\t\tpi[pino].poc.precno0 = tcp->prcS;\n\t\tpi[pino].poc.precno1 = tcp->prcE;\n\t\tpi[pino].poc.tx0 = (OPJ_INT32)tcp->txS;\n\t\tpi[pino].poc.ty0 = (OPJ_INT32)tcp->tyS;\n\t\tpi[pino].poc.tx1 = (OPJ_INT32)tcp->txE;\n\t\tpi[pino].poc.ty1 = (OPJ_INT32)tcp->tyE;\n\t}else {\n\t\tfor(i=tppos+1;i<4;i++){\n\t\t\tswitch(prog[i]){\n\t\t\tcase 'R':\n\t\t\t\tpi[pino].poc.resno0 = tcp->resS;\n\t\t\t\tpi[pino].poc.resno1 = tcp->resE;\n\t\t\t\tbreak;\n\t\t\tcase 'C':\n\t\t\t\tpi[pino].poc.compno0 = tcp->compS;\n\t\t\t\tpi[pino].poc.compno1 = tcp->compE;\n\t\t\t\tbreak;\n\t\t\tcase 'L':\n\t\t\t\tpi[pino].poc.layno0 = tcp->layS;\n\t\t\t\tpi[pino].poc.layno1 = tcp->layE;\n\t\t\t\tbreak;\n\t\t\tcase 'P':\n\t\t\t\tswitch(tcp->prg){\n\t\t\t\tcase OPJ_LRCP:\n\t\t\t\tcase OPJ_RLCP:\n\t\t\t\t\tpi[pino].poc.precno0 = tcp->prcS;\n\t\t\t\t\tpi[pino].poc.precno1 = tcp->prcE;\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tpi[pino].poc.tx0 = (OPJ_INT32)tcp->txS;\n\t\t\t\t\tpi[pino].poc.ty0 = (OPJ_INT32)tcp->tyS;\n\t\t\t\t\tpi[pino].poc.tx1 = (OPJ_INT32)tcp->txE;\n\t\t\t\t\tpi[pino].poc.ty1 = (OPJ_INT32)tcp->tyE;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\n\t\tif(tpnum==0){\n\t\t\tfor(i=tppos;i>=0;i--){\n\t\t\t\tswitch(prog[i]){\n\t\t\t\tcase 'C':\n\t\t\t\t\ttcp->comp_t = tcp->compS;\n\t\t\t\t\tpi[pino].poc.compno0 = tcp->comp_t;\n\t\t\t\t\tpi[pino].poc.compno1 = tcp->comp_t+1;\n\t\t\t\t\ttcp->comp_t+=1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'R':\n\t\t\t\t\ttcp->res_t = tcp->resS;\n\t\t\t\t\tpi[pino].poc.resno0 = tcp->res_t;\n\t\t\t\t\tpi[pino].poc.resno1 = tcp->res_t+1;\n\t\t\t\t\ttcp->res_t+=1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'L':\n\t\t\t\t\ttcp->lay_t = tcp->layS;\n\t\t\t\t\tpi[pino].poc.layno0 = tcp->lay_t;\n\t\t\t\t\tpi[pino].poc.layno1 = tcp->lay_t+1;\n\t\t\t\t\ttcp->lay_t+=1;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'P':\n\t\t\t\t\tswitch(tcp->prg){\n\t\t\t\t\tcase OPJ_LRCP:\n\t\t\t\t\tcase OPJ_RLCP:\n\t\t\t\t\t\ttcp->prc_t = tcp->prcS;\n\t\t\t\t\t\tpi[pino].poc.precno0 = tcp->prc_t;\n\t\t\t\t\t\tpi[pino].poc.precno1 = tcp->prc_t+1;\n\t\t\t\t\t\ttcp->prc_t+=1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\ttcp->tx0_t = tcp->txS;\n\t\t\t\t\t\ttcp->ty0_t = tcp->tyS;\n\t\t\t\t\t\tpi[pino].poc.tx0 = (OPJ_INT32)tcp->tx0_t;\n\t\t\t\t\t\tpi[pino].poc.tx1 = (OPJ_INT32)(tcp->tx0_t + tcp->dx - (tcp->tx0_t % tcp->dx));\n\t\t\t\t\t\tpi[pino].poc.ty0 = (OPJ_INT32)tcp->ty0_t;\n\t\t\t\t\t\tpi[pino].poc.ty1 = (OPJ_INT32)(tcp->ty0_t + tcp->dy - (tcp->ty0_t % tcp->dy));\n\t\t\t\t\t\ttcp->tx0_t = (OPJ_UINT32)pi[pino].poc.tx1;\n\t\t\t\t\t\ttcp->ty0_t = (OPJ_UINT32)pi[pino].poc.ty1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tincr_top=1;\n\t\t}else{\n\t\t\tfor(i=tppos;i>=0;i--){\n\t\t\t\tswitch(prog[i]){\n\t\t\t\tcase 'C':\n\t\t\t\t\tpi[pino].poc.compno0 = tcp->comp_t-1;\n\t\t\t\t\tpi[pino].poc.compno1 = tcp->comp_t;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'R':\n\t\t\t\t\tpi[pino].poc.resno0 = tcp->res_t-1;\n\t\t\t\t\tpi[pino].poc.resno1 = tcp->res_t;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'L':\n\t\t\t\t\tpi[pino].poc.layno0 = tcp->lay_t-1;\n\t\t\t\t\tpi[pino].poc.layno1 = tcp->lay_t;\n\t\t\t\t\tbreak;\n\t\t\t\tcase 'P':\n\t\t\t\t\tswitch(tcp->prg){\n\t\t\t\t\tcase OPJ_LRCP:\n\t\t\t\t\tcase OPJ_RLCP:\n\t\t\t\t\t\tpi[pino].poc.precno0 = tcp->prc_t-1;\n\t\t\t\t\t\tpi[pino].poc.precno1 = tcp->prc_t;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tpi[pino].poc.tx0 = (OPJ_INT32)(tcp->tx0_t - tcp->dx - (tcp->tx0_t % tcp->dx));\n\t\t\t\t\t\tpi[pino].poc.tx1 = (OPJ_INT32)tcp->tx0_t ;\n\t\t\t\t\t\tpi[pino].poc.ty0 = (OPJ_INT32)(tcp->ty0_t - tcp->dy - (tcp->ty0_t % tcp->dy));\n\t\t\t\t\t\tpi[pino].poc.ty1 = (OPJ_INT32)tcp->ty0_t ;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif(incr_top==1){\n\t\t\t\t\tswitch(prog[i]){\n\t\t\t\t\tcase 'R':\n\t\t\t\t\t\tif(tcp->res_t==tcp->resE){\n\t\t\t\t\t\t\tif(opj_pi_check_next_level(i-1,cp,tileno,pino,prog)){\n\t\t\t\t\t\t\t\ttcp->res_t = tcp->resS;\n\t\t\t\t\t\t\t\tpi[pino].poc.resno0 = tcp->res_t;\n\t\t\t\t\t\t\t\tpi[pino].poc.resno1 = tcp->res_t+1;\n\t\t\t\t\t\t\t\ttcp->res_t+=1;\n\t\t\t\t\t\t\t\tincr_top=1;\n\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\tpi[pino].poc.resno0 = tcp->res_t;\n\t\t\t\t\t\t\tpi[pino].poc.resno1 = tcp->res_t+1;\n\t\t\t\t\t\t\ttcp->res_t+=1;\n\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'C':\n\t\t\t\t\t\tif(tcp->comp_t ==tcp->compE){\n\t\t\t\t\t\t\tif(opj_pi_check_next_level(i-1,cp,tileno,pino,prog)){\n\t\t\t\t\t\t\t\ttcp->comp_t = tcp->compS;\n\t\t\t\t\t\t\t\tpi[pino].poc.compno0 = tcp->comp_t;\n\t\t\t\t\t\t\t\tpi[pino].poc.compno1 = tcp->comp_t+1;\n\t\t\t\t\t\t\t\ttcp->comp_t+=1;\n\t\t\t\t\t\t\t\tincr_top=1;\n\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\tpi[pino].poc.compno0 = tcp->comp_t;\n\t\t\t\t\t\t\tpi[pino].poc.compno1 = tcp->comp_t+1;\n\t\t\t\t\t\t\ttcp->comp_t+=1;\n\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'L':\n\t\t\t\t\t\tif(tcp->lay_t == tcp->layE){\n\t\t\t\t\t\t\tif(opj_pi_check_next_level(i-1,cp,tileno,pino,prog)){\n\t\t\t\t\t\t\t\ttcp->lay_t = tcp->layS;\n\t\t\t\t\t\t\t\tpi[pino].poc.layno0 = tcp->lay_t;\n\t\t\t\t\t\t\t\tpi[pino].poc.layno1 = tcp->lay_t+1;\n\t\t\t\t\t\t\t\ttcp->lay_t+=1;\n\t\t\t\t\t\t\t\tincr_top=1;\n\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\tpi[pino].poc.layno0 = tcp->lay_t;\n\t\t\t\t\t\t\tpi[pino].poc.layno1 = tcp->lay_t+1;\n\t\t\t\t\t\t\ttcp->lay_t+=1;\n\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\tcase 'P':\n\t\t\t\t\t\tswitch(tcp->prg){\n\t\t\t\t\t\tcase OPJ_LRCP:\n\t\t\t\t\t\tcase OPJ_RLCP:\n\t\t\t\t\t\t\tif(tcp->prc_t == tcp->prcE){\n\t\t\t\t\t\t\t\tif(opj_pi_check_next_level(i-1,cp,tileno,pino,prog)){\n\t\t\t\t\t\t\t\t\ttcp->prc_t = tcp->prcS;\n\t\t\t\t\t\t\t\t\tpi[pino].poc.precno0 = tcp->prc_t;\n\t\t\t\t\t\t\t\t\tpi[pino].poc.precno1 = tcp->prc_t+1;\n\t\t\t\t\t\t\t\t\ttcp->prc_t+=1;\n\t\t\t\t\t\t\t\t\tincr_top=1;\n\t\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\tpi[pino].poc.precno0 = tcp->prc_t;\n\t\t\t\t\t\t\t\tpi[pino].poc.precno1 = tcp->prc_t+1;\n\t\t\t\t\t\t\t\ttcp->prc_t+=1;\n\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\tif(tcp->tx0_t >= tcp->txE){\n\t\t\t\t\t\t\t\tif(tcp->ty0_t >= tcp->tyE){\n\t\t\t\t\t\t\t\t\tif(opj_pi_check_next_level(i-1,cp,tileno,pino,prog)){\n\t\t\t\t\t\t\t\t\t\ttcp->ty0_t = tcp->tyS;\n\t\t\t\t\t\t\t\t\t\tpi[pino].poc.ty0 = (OPJ_INT32)tcp->ty0_t;\n\t\t\t\t\t\t\t\t\t\tpi[pino].poc.ty1 = (OPJ_INT32)(tcp->ty0_t + tcp->dy - (tcp->ty0_t % tcp->dy));\n\t\t\t\t\t\t\t\t\t\ttcp->ty0_t = (OPJ_UINT32)pi[pino].poc.ty1;\n\t\t\t\t\t\t\t\t\t\tincr_top=1;resetX=1;\n\t\t\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\t\t\tincr_top=0;resetX=0;\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\t\tpi[pino].poc.ty0 = (OPJ_INT32)tcp->ty0_t;\n\t\t\t\t\t\t\t\t\tpi[pino].poc.ty1 = (OPJ_INT32)(tcp->ty0_t + tcp->dy - (tcp->ty0_t % tcp->dy));\n\t\t\t\t\t\t\t\t\ttcp->ty0_t = (OPJ_UINT32)pi[pino].poc.ty1;\n\t\t\t\t\t\t\t\t\tincr_top=0;resetX=1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tif(resetX==1){\n\t\t\t\t\t\t\t\t\ttcp->tx0_t = tcp->txS;\n\t\t\t\t\t\t\t\t\tpi[pino].poc.tx0 = (OPJ_INT32)tcp->tx0_t;\n\t\t\t\t\t\t\t\t\tpi[pino].poc.tx1 = (OPJ_INT32)(tcp->tx0_t + tcp->dx- (tcp->tx0_t % tcp->dx));\n\t\t\t\t\t\t\t\t\ttcp->tx0_t = (OPJ_UINT32)pi[pino].poc.tx1;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t}else{\n\t\t\t\t\t\t\t\tpi[pino].poc.tx0 = (OPJ_INT32)tcp->tx0_t;\n\t\t\t\t\t\t\t\tpi[pino].poc.tx1 = (OPJ_INT32)(tcp->tx0_t + tcp->dx- (tcp->tx0_t % tcp->dx));\n\t\t\t\t\t\t\t\ttcp->tx0_t = (OPJ_UINT32)pi[pino].poc.tx1;\n\t\t\t\t\t\t\t\tincr_top=0;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 48406,
        "reasoning": "This code is not directly related to the reported integer overflow fix in `opj_pi_create_decode` and doesn't exhibit any obvious integer overflow vulnerabilities itself. The function focuses on freeing allocated memory for progressive image information and uses `OPJ_UINT32` for loop counters and size parameters, which, while potentially subject to large values, doesn't demonstrate an overflow *within* the provided snippet.\n\n\n\n",
        "func": "void opj_pi_destroy(opj_pi_iterator_t *p_pi,\n                    OPJ_UINT32 p_nb_elements)\n{\n\tOPJ_UINT32 compno, pino;\n\topj_pi_iterator_t *l_current_pi = p_pi;\n    if (p_pi) {\n\t\tif (p_pi->include) {\n\t\t\topj_free(p_pi->include);\n\t\t\tp_pi->include = 00;\n\t\t}\n\t\tfor (pino = 0; pino < p_nb_elements; ++pino){\n\t\t\tif(l_current_pi->comps) {\n\t\t\t\topj_pi_comp_t *l_current_component = l_current_pi->comps;\n                for (compno = 0; compno < l_current_pi->numcomps; compno++){\n                    if(l_current_component->resolutions) {\n\t\t\t\t\t\topj_free(l_current_component->resolutions);\n\t\t\t\t\t\tl_current_component->resolutions = 00;\n\t\t\t\t\t}\n\n\t\t\t\t\t++l_current_component;\n\t\t\t\t}\n\t\t\t\topj_free(l_current_pi->comps);\n\t\t\t\tl_current_pi->comps = 0;\n\t\t\t}\n\t\t\t++l_current_pi;\n\t\t}\n\t\topj_free(p_pi);\n\t}\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 0
      },
      {
        "idx": 48407,
        "reasoning": "The commit message states the fix addresses an integer overflow issue in `opj_pi_create_decode` of `pi.c`, but the provided code snippet is for `opj_pi_initialise_encode`. Therefore, based solely on this snippet, there's no evidence of the vulnerability being present, and it's not flagged as vulnerable within this specific function.",
        "func": "opj_pi_iterator_t *opj_pi_initialise_encode(const opj_image_t *p_image,\n                                            opj_cp_t *p_cp,\n                                            OPJ_UINT32 p_tile_no,\n                                            J2K_T2_MODE p_t2_mode )\n{\n\t/* loop*/\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions*/\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set*/\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers*/\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug*/\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations*/\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif (! l_tmp_data) {\n\t\treturn 00;\n\t}\n\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif (! l_tmp_ptr) {\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi*/\n\tl_pi = opj_pi_create(p_image,p_cp,p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array*/\n\tfor (compno = 0; compno < p_image->numcomps; ++compno) {\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\n\t/* get encoding parameters*/\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations*/\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator*/\n\tl_pi->tp_on = (OPJ_BYTE)p_cp->m_specific_param.m_enc.m_tp_on;\n\tl_current_pi = l_pi;\n\n\t/* memory allocation for include*/\n\tl_current_pi->include = (OPJ_INT16*) opj_calloc(l_tcp->numlayers * l_step_l, sizeof(OPJ_INT16));\n\tif (!l_current_pi->include) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator*/\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\tl_current_pi->dx = l_dx_min;\n\tl_current_pi->dy = l_dy_min;\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor (compno = 0; compno < l_current_pi->numcomps; ++compno) {\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\n\t\t/* resolutions have already been initialized */\n\t\tfor (resno = 0; resno < l_current_comp->numresolutions; resno++) {\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino ) {\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\tl_current_pi->dx = l_dx_min;\n\t\tl_current_pi->dy = l_dy_min;\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor (compno = 0; compno < l_current_pi->numcomps; ++compno) {\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor (resno = 0; resno < l_current_comp->numresolutions; resno++) {\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\n    if (l_tcp->POC && (OPJ_IS_CINEMA(p_cp->rsiz) || p_t2_mode == FINAL_PASS)) {\n\t\topj_pi_update_encode_poc_and_final(p_cp,p_tile_no,l_tx0,l_tx1,l_ty0,l_ty1,l_max_prec,l_max_res,l_dx_min,l_dy_min);\n\t}\n\telse {\n\t\topj_pi_update_encode_not_poc(p_cp,p_image->numcomps,p_tile_no,l_tx0,l_tx1,l_ty0,l_ty1,l_max_prec,l_max_res,l_dx_min,l_dy_min);\n\t}\n\n\treturn l_pi;\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1745,
        "reasoning": "The code is vulnerable to an integer overflow because the `l_bound` variable, calculated as `l_tcp->numpocs + 1`, is used in a loop and to allocate memory for `l_current_pi->include` without sufficient bounds checking. A large value of `l_tcp->numpocs` can cause `l_bound` to overflow, leading to an excessively large memory allocation or out-of-bounds access when accessing `l_current_pi->include`, ultimately enabling arbitrary code execution.",
        "func": "opj_pi_iterator_t *opj_pi_create_decode(opj_image_t *p_image,\n\t\t\t\t\t\t\t\t\t\topj_cp_t *p_cp,\n\t\t\t\t\t\t\t\t\t\tOPJ_UINT32 p_tile_no)\n{\n\t/* loop */\n\tOPJ_UINT32 pino;\n\tOPJ_UINT32 compno, resno;\n\n\t/* to store w, h, dx and dy fro all components and resolutions */\n\tOPJ_UINT32 * l_tmp_data;\n\tOPJ_UINT32 ** l_tmp_ptr;\n\n\t/* encoding prameters to set */\n\tOPJ_UINT32 l_max_res;\n\tOPJ_UINT32 l_max_prec;\n\tOPJ_INT32 l_tx0,l_tx1,l_ty0,l_ty1;\n\tOPJ_UINT32 l_dx_min,l_dy_min;\n\tOPJ_UINT32 l_bound;\n\tOPJ_UINT32 l_step_p , l_step_c , l_step_r , l_step_l ;\n\tOPJ_UINT32 l_data_stride;\n\n\t/* pointers */\n\topj_pi_iterator_t *l_pi = 00;\n\topj_tcp_t *l_tcp = 00;\n\tconst opj_tccp_t *l_tccp = 00;\n\topj_pi_comp_t *l_current_comp = 00;\n\topj_image_comp_t * l_img_comp = 00;\n\topj_pi_iterator_t * l_current_pi = 00;\n\tOPJ_UINT32 * l_encoding_value_ptr = 00;\n\n\t/* preconditions in debug */\n\tassert(p_cp != 00);\n\tassert(p_image != 00);\n\tassert(p_tile_no < p_cp->tw * p_cp->th);\n\n\t/* initializations */\n\tl_tcp = &p_cp->tcps[p_tile_no];\n\tl_bound = l_tcp->numpocs+1;\n\n\tl_data_stride = 4 * OPJ_J2K_MAXRLVLS;\n\tl_tmp_data = (OPJ_UINT32*)opj_malloc(\n\t\tl_data_stride * p_image->numcomps * sizeof(OPJ_UINT32));\n\tif\n\t\t(! l_tmp_data)\n\t{\n\t\treturn 00;\n\t}\n\tl_tmp_ptr = (OPJ_UINT32**)opj_malloc(\n\t\tp_image->numcomps * sizeof(OPJ_UINT32 *));\n\tif\n\t\t(! l_tmp_ptr)\n\t{\n\t\topj_free(l_tmp_data);\n\t\treturn 00;\n\t}\n\n\t/* memory allocation for pi */\n\tl_pi = opj_pi_create(p_image, p_cp, p_tile_no);\n\tif (!l_pi) {\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\treturn 00;\n\t}\n\n\tl_encoding_value_ptr = l_tmp_data;\n\t/* update pointer array */\n\tfor\n\t\t(compno = 0; compno < p_image->numcomps; ++compno)\n\t{\n\t\tl_tmp_ptr[compno] = l_encoding_value_ptr;\n\t\tl_encoding_value_ptr += l_data_stride;\n\t}\n\t/* get encoding parameters */\n\topj_get_all_encoding_parameters(p_image,p_cp,p_tile_no,&l_tx0,&l_tx1,&l_ty0,&l_ty1,&l_dx_min,&l_dy_min,&l_max_prec,&l_max_res,l_tmp_ptr);\n\n\t/* step calculations */\n\tl_step_p = 1;\n\tl_step_c = l_max_prec * l_step_p;\n\tl_step_r = p_image->numcomps * l_step_c;\n\tl_step_l = l_max_res * l_step_r;\n\n\t/* set values for first packet iterator */\n \tl_current_pi = l_pi;\n \n \t/* memory allocation for include */\n\tl_current_pi->include = (OPJ_INT16*) opj_calloc((l_tcp->numlayers +1) * l_step_l, sizeof(OPJ_INT16));\n \tif\n \t\t(!l_current_pi->include)\n \t{\n\t\topj_free(l_tmp_data);\n\t\topj_free(l_tmp_ptr);\n\t\topj_pi_destroy(l_pi, l_bound);\n\t\treturn 00;\n\t}\n\n\t/* special treatment for the first packet iterator */\n\tl_current_comp = l_current_pi->comps;\n\tl_img_comp = p_image->comps;\n\tl_tccp = l_tcp->tccps;\n\n\tl_current_pi->tx0 = l_tx0;\n\tl_current_pi->ty0 = l_ty0;\n\tl_current_pi->tx1 = l_tx1;\n\tl_current_pi->ty1 = l_ty1;\n\n\t/*l_current_pi->dx = l_img_comp->dx;*/\n\t/*l_current_pi->dy = l_img_comp->dy;*/\n\n\tl_current_pi->step_p = l_step_p;\n\tl_current_pi->step_c = l_step_c;\n\tl_current_pi->step_r = l_step_r;\n\tl_current_pi->step_l = l_step_l;\n\n\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\tfor\n\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t{\n\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\tl_current_comp->dx = l_img_comp->dx;\n\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t/* resolutions have already been initialized */\n\t\tfor\n\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t{\n\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t++l_res;\n\t\t}\n\t\t++l_current_comp;\n\t\t++l_img_comp;\n\t\t++l_tccp;\n\t}\n\t++l_current_pi;\n\n\tfor (pino = 1 ; pino<l_bound ; ++pino )\n\t{\n\t\tl_current_comp = l_current_pi->comps;\n\t\tl_img_comp = p_image->comps;\n\t\tl_tccp = l_tcp->tccps;\n\n\t\tl_current_pi->tx0 = l_tx0;\n\t\tl_current_pi->ty0 = l_ty0;\n\t\tl_current_pi->tx1 = l_tx1;\n\t\tl_current_pi->ty1 = l_ty1;\n\t\t/*l_current_pi->dx = l_dx_min;*/\n\t\t/*l_current_pi->dy = l_dy_min;*/\n\t\tl_current_pi->step_p = l_step_p;\n\t\tl_current_pi->step_c = l_step_c;\n\t\tl_current_pi->step_r = l_step_r;\n\t\tl_current_pi->step_l = l_step_l;\n\n\t\t/* allocation for components and number of components has already been calculated by opj_pi_create */\n\t\tfor\n\t\t\t(compno = 0; compno < l_current_pi->numcomps; ++compno)\n\t\t{\n\t\t\topj_pi_resolution_t *l_res = l_current_comp->resolutions;\n\t\t\tl_encoding_value_ptr = l_tmp_ptr[compno];\n\n\t\t\tl_current_comp->dx = l_img_comp->dx;\n\t\t\tl_current_comp->dy = l_img_comp->dy;\n\t\t\t/* resolutions have already been initialized */\n\t\t\tfor\n\t\t\t\t(resno = 0; resno < l_current_comp->numresolutions; resno++)\n\t\t\t{\n\t\t\t\tl_res->pdx = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pdy = *(l_encoding_value_ptr++);\n\t\t\t\tl_res->pw =  *(l_encoding_value_ptr++);\n\t\t\t\tl_res->ph =  *(l_encoding_value_ptr++);\n\t\t\t\t++l_res;\n\t\t\t}\n\t\t\t++l_current_comp;\n\t\t\t++l_img_comp;\n\t\t\t++l_tccp;\n\t\t}\n\t\t/* special treatment*/\n\t\tl_current_pi->include = (l_current_pi-1)->include;\n\t\t++l_current_pi;\n\t}\n\topj_free(l_tmp_data);\n\tl_tmp_data = 00;\n\topj_free(l_tmp_ptr);\n\tl_tmp_ptr = 00;\n\tif\n\t\t(l_tcp->POC)\n\t{\n\t\topj_pi_update_decode_poc (l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\telse\n\t{\n\t\topj_pi_update_decode_not_poc(l_pi,l_tcp,l_max_prec,l_max_res);\n\t}\n\treturn l_pi;\n}\n",
        "commit_message": "Fix an integer overflow issue (#809)\n\nPrevent an integer overflow issue in function opj_pi_create_decode of\npi.c.",
        "cve_desc": "Integer overflow in the opj_pi_create_decode function in pi.c in OpenJPEG allows remote attackers to execute arbitrary code via a crafted JP2 file, which triggers an out-of-bounds read or write.",
        "target": 1
      },
      {
        "idx": 2477,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow because it allocates `l_data_size + 1` bytes but only stores `l_data_size` bytes of meaningful data, leading to an extra byte beyond the intended buffer being written to during subsequent operations like `opj_mqc_flush`. The `+1` offset introduced for a separate issue (issue #835) combined with the subsequent pointer increment `p_code_block->data += 1;` creates a discrepancy between the allocated size and the usable data region, causing the overflow.",
        "func": "static OPJ_BOOL opj_tcd_code_block_enc_allocate_data(opj_tcd_cblk_enc_t *\n        p_code_block)\n {\n     OPJ_UINT32 l_data_size;\n \n    /* The +1 is needed for https://github.com/uclouvain/openjpeg/issues/835 */\n    l_data_size = 1 + (OPJ_UINT32)((p_code_block->x1 - p_code_block->x0) *\n                                    (p_code_block->y1 - p_code_block->y0) * (OPJ_INT32)sizeof(OPJ_UINT32));\n \n     if (l_data_size > p_code_block->data_size) {\n        if (p_code_block->data) {\n            /* We refer to data - 1 since below we incremented it */\n            opj_free(p_code_block->data - 1);\n        }\n        p_code_block->data = (OPJ_BYTE*) opj_malloc(l_data_size + 1);\n        if (! p_code_block->data) {\n            p_code_block->data_size = 0U;\n            return OPJ_FALSE;\n        }\n        p_code_block->data_size = l_data_size;\n\n        /* We reserve the initial byte as a fake byte to a non-FF value */\n        /* and increment the data pointer, so that opj_mqc_init_enc() */\n        /* can do bp = data - 1, and opj_mqc_byteout() can safely dereference */\n        /* it. */\n        p_code_block->data[0] = 0;\n        p_code_block->data += 1; /*why +1 ?*/\n    }\n    return OPJ_TRUE;\n}\n",
        "commit_message": "Encoder: grow buffer size in opj_tcd_code_block_enc_allocate_data() to avoid write heap buffer overflow in opj_mqc_flush (#982)",
        "cve_desc": "An off-by-one error was discovered in opj_tcd_code_block_enc_allocate_data in lib/openjp2/tcd.c in OpenJPEG 2.2.0. The vulnerability causes an out-of-bounds write, which may lead to remote denial of service (heap-based buffer overflow affecting opj_mqc_flush in lib/openjp2/mqc.c and opj_t1_encode_cblk in lib/openjp2/t1.c) or possibly remote code execution.",
        "target": 1
      },
      {
        "idx": 2486,
        "reasoning": "The `pgxtoimage` function is vulnerable to a stack-based buffer overflow due to the use of `fscanf` with the `temp` buffer, which has a fixed size of 32 bytes, to read potentially unbounded input from the file. If the input PGX file contains values exceeding this buffer size during the `fscanf` call, it will result in a write beyond the allocated memory on the stack, as described in the CVE.",
        "func": "opj_image_t* pgxtoimage(const char *filename, opj_cparameters_t *parameters)\n{\n    FILE *f = NULL;\n    int w, h, prec;\n    int i, numcomps, max;\n    OPJ_COLOR_SPACE color_space;\n    opj_image_cmptparm_t cmptparm;  /* maximum of 1 component  */\n    opj_image_t * image = NULL;\n    int adjustS, ushift, dshift, force8;\n\n    char endian1, endian2, sign;\n    char signtmp[32];\n\n    char temp[32];\n    int bigendian;\n    opj_image_comp_t *comp = NULL;\n\n    numcomps = 1;\n    color_space = OPJ_CLRSPC_GRAY;\n\n    memset(&cmptparm, 0, sizeof(opj_image_cmptparm_t));\n\n    max = 0;\n\n    f = fopen(filename, \"rb\");\n    if (!f) {\n        fprintf(stderr, \"Failed to open %s for reading !\\n\", filename);\n        return NULL;\n     }\n \n     fseek(f, 0, SEEK_SET);\n    if (fscanf(f, \"PG%[ \\t]%c%c%[ \\t+-]%d%[ \\t]%d%[ \\t]%d\", temp, &endian1,\n                &endian2, signtmp, &prec, temp, &w, temp, &h) != 9) {\n         fclose(f);\n         fprintf(stderr,\n                \"ERROR: Failed to read the right number of element from the fscanf() function!\\n\");\n        return NULL;\n    }\n\n    i = 0;\n    sign = '+';\n    while (signtmp[i] != '\\0') {\n        if (signtmp[i] == '-') {\n            sign = '-';\n        }\n        i++;\n    }\n\n    fgetc(f);\n    if (endian1 == 'M' && endian2 == 'L') {\n        bigendian = 1;\n    } else if (endian2 == 'M' && endian1 == 'L') {\n        bigendian = 0;\n    } else {\n        fclose(f);\n        fprintf(stderr, \"Bad pgx header, please check input file\\n\");\n        return NULL;\n    }\n\n    /* initialize image component */\n\n    cmptparm.x0 = (OPJ_UINT32)parameters->image_offset_x0;\n    cmptparm.y0 = (OPJ_UINT32)parameters->image_offset_y0;\n    cmptparm.w = !cmptparm.x0 ? (OPJ_UINT32)((w - 1) * parameters->subsampling_dx +\n                 1) : cmptparm.x0 + (OPJ_UINT32)(w - 1) * (OPJ_UINT32)parameters->subsampling_dx\n                 + 1;\n    cmptparm.h = !cmptparm.y0 ? (OPJ_UINT32)((h - 1) * parameters->subsampling_dy +\n                 1) : cmptparm.y0 + (OPJ_UINT32)(h - 1) * (OPJ_UINT32)parameters->subsampling_dy\n                 + 1;\n\n    if (sign == '-') {\n        cmptparm.sgnd = 1;\n    } else {\n        cmptparm.sgnd = 0;\n    }\n    if (prec < 8) {\n        force8 = 1;\n        ushift = 8 - prec;\n        dshift = prec - ushift;\n        if (cmptparm.sgnd) {\n            adjustS = (1 << (prec - 1));\n        } else {\n            adjustS = 0;\n        }\n        cmptparm.sgnd = 0;\n        prec = 8;\n    } else {\n        ushift = dshift = force8 = adjustS = 0;\n    }\n\n    cmptparm.prec = (OPJ_UINT32)prec;\n    cmptparm.bpp = (OPJ_UINT32)prec;\n    cmptparm.dx = (OPJ_UINT32)parameters->subsampling_dx;\n    cmptparm.dy = (OPJ_UINT32)parameters->subsampling_dy;\n\n    /* create the image */\n    image = opj_image_create((OPJ_UINT32)numcomps, &cmptparm, color_space);\n    if (!image) {\n        fclose(f);\n        return NULL;\n    }\n    /* set image offset and reference grid */\n    image->x0 = cmptparm.x0;\n    image->y0 = cmptparm.x0;\n    image->x1 = cmptparm.w;\n    image->y1 = cmptparm.h;\n\n    /* set image data */\n\n    comp = &image->comps[0];\n\n    for (i = 0; i < w * h; i++) {\n        int v;\n        if (force8) {\n            v = readuchar(f) + adjustS;\n            v = (v << ushift) + (v >> dshift);\n            comp->data[i] = (unsigned char)v;\n\n            if (v > max) {\n                max = v;\n            }\n\n            continue;\n        }\n        if (comp->prec == 8) {\n            if (!comp->sgnd) {\n                v = readuchar(f);\n            } else {\n                v = (char) readuchar(f);\n            }\n        } else if (comp->prec <= 16) {\n            if (!comp->sgnd) {\n                v = readushort(f, bigendian);\n            } else {\n                v = (short) readushort(f, bigendian);\n            }\n        } else {\n            if (!comp->sgnd) {\n                v = (int)readuint(f, bigendian);\n            } else {\n                v = (int) readuint(f, bigendian);\n            }\n        }\n        if (v > max) {\n            max = v;\n        }\n        comp->data[i] = v;\n    }\n    fclose(f);\n    comp->bpp = (OPJ_UINT32)int_floorlog2(max) + 1;\n\n    return image;\n}\n",
        "commit_message": "pgxtoimage(): fix write stack buffer overflow (#997)",
        "cve_desc": "A stack-based buffer overflow was discovered in the pgxtoimage function in bin/jp2/convert.c in OpenJPEG 2.2.0. The vulnerability causes an out-of-bounds write, which may lead to remote denial of service or possibly remote code execution.",
        "target": 1
      },
      {
        "idx": 2489,
        "reasoning": "This code is vulnerable to an invalid write due to insufficient bounds checking when reading TGA image data with `fread`. Specifically, the code doesn't verify that `fread` successfully read the expected number of bytes for each pixel component (R, G, B, A), potentially leading to out-of-bounds writes to `image->comps[i].data` if the file is truncated or corrupted, as described in the CVE.",
        "func": "opj_image_t* tgatoimage(const char *filename, opj_cparameters_t *parameters)\n{\n    FILE *f;\n    opj_image_t *image;\n    unsigned int image_width, image_height, pixel_bit_depth;\n    unsigned int x, y;\n    int flip_image = 0;\n    opj_image_cmptparm_t cmptparm[4];   /* maximum 4 components */\n    int numcomps;\n    OPJ_COLOR_SPACE color_space;\n    OPJ_BOOL mono ;\n    OPJ_BOOL save_alpha;\n    int subsampling_dx, subsampling_dy;\n    int i;\n\n    f = fopen(filename, \"rb\");\n    if (!f) {\n        fprintf(stderr, \"Failed to open %s for reading !!\\n\", filename);\n        return 0;\n    }\n\n    if (!tga_readheader(f, &pixel_bit_depth, &image_width, &image_height,\n                        &flip_image)) {\n        fclose(f);\n        return NULL;\n    }\n\n    /* We currently only support 24 & 32 bit tga's ... */\n    if (!((pixel_bit_depth == 24) || (pixel_bit_depth == 32))) {\n        fclose(f);\n        return NULL;\n    }\n\n    /* initialize image components */\n    memset(&cmptparm[0], 0, 4 * sizeof(opj_image_cmptparm_t));\n\n    mono = (pixel_bit_depth == 8) ||\n           (pixel_bit_depth == 16);  /* Mono with & without alpha. */\n    save_alpha = (pixel_bit_depth == 16) ||\n                 (pixel_bit_depth == 32); /* Mono with alpha, or RGB with alpha */\n\n    if (mono) {\n        color_space = OPJ_CLRSPC_GRAY;\n        numcomps = save_alpha ? 2 : 1;\n    } else {\n        numcomps = save_alpha ? 4 : 3;\n         color_space = OPJ_CLRSPC_SRGB;\n     }\n \n     subsampling_dx = parameters->subsampling_dx;\n     subsampling_dy = parameters->subsampling_dy;\n \n    for (i = 0; i < numcomps; i++) {\n        cmptparm[i].prec = 8;\n        cmptparm[i].bpp = 8;\n        cmptparm[i].sgnd = 0;\n        cmptparm[i].dx = (OPJ_UINT32)subsampling_dx;\n        cmptparm[i].dy = (OPJ_UINT32)subsampling_dy;\n        cmptparm[i].w = image_width;\n        cmptparm[i].h = image_height;\n    }\n\n    /* create the image */\n    image = opj_image_create((OPJ_UINT32)numcomps, &cmptparm[0], color_space);\n\n    if (!image) {\n        fclose(f);\n        return NULL;\n    }\n\n\n    /* set image offset and reference grid */\n    image->x0 = (OPJ_UINT32)parameters->image_offset_x0;\n    image->y0 = (OPJ_UINT32)parameters->image_offset_y0;\n    image->x1 = !image->x0 ? (OPJ_UINT32)(image_width - 1)  *\n                (OPJ_UINT32)subsampling_dx + 1 : image->x0 + (OPJ_UINT32)(image_width - 1)  *\n                (OPJ_UINT32)subsampling_dx + 1;\n    image->y1 = !image->y0 ? (OPJ_UINT32)(image_height - 1) *\n                (OPJ_UINT32)subsampling_dy + 1 : image->y0 + (OPJ_UINT32)(image_height - 1) *\n                (OPJ_UINT32)subsampling_dy + 1;\n\n    /* set image data */\n    for (y = 0; y < image_height; y++) {\n        int index;\n\n        if (flip_image) {\n            index = (int)((image_height - y - 1) * image_width);\n        } else {\n            index = (int)(y * image_width);\n        }\n\n        if (numcomps == 3) {\n            for (x = 0; x < image_width; x++) {\n                unsigned char r, g, b;\n\n                if (!fread(&b, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n                if (!fread(&g, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n                if (!fread(&r, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n\n                image->comps[0].data[index] = r;\n                image->comps[1].data[index] = g;\n                image->comps[2].data[index] = b;\n                index++;\n            }\n        } else if (numcomps == 4) {\n            for (x = 0; x < image_width; x++) {\n                unsigned char r, g, b, a;\n                if (!fread(&b, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n                if (!fread(&g, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n                if (!fread(&r, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n                if (!fread(&a, 1, 1, f)) {\n                    fprintf(stderr,\n                            \"\\nError: fread return a number of element different from the expected.\\n\");\n                    opj_image_destroy(image);\n                    fclose(f);\n                    return NULL;\n                }\n\n                image->comps[0].data[index] = r;\n                image->comps[1].data[index] = g;\n                image->comps[2].data[index] = b;\n                image->comps[3].data[index] = a;\n                index++;\n            }\n        } else {\n            fprintf(stderr, \"Currently unsupported bit depth : %s\\n\", filename);\n        }\n    }\n    fclose(f);\n    return image;\n}\n",
        "commit_message": "tgatoimage(): avoid excessive memory allocation attempt, and fixes unaligned load (#995)",
        "cve_desc": "An invalid write access was discovered in bin/jp2/convert.c in OpenJPEG 2.2.0, triggering a crash in the tgatoimage function. The vulnerability may lead to remote denial of service or possibly unspecified other impact.",
        "target": 1
      }
    ]
  },
  "openldap": {
    "0": [
      {
        "idx": 342670,
        "reasoning": "This code addresses a previously identified double-free vulnerability by ensuring proper memory management of LDAP controls. The commit explicitly frees the old `rs->sr_ctrls` *only if* `REP_CTRLS_MUSTBEFREED` is set, preventing a double-free if the controls weren't previously allocated by the server and thus shouldn't be freed here. \n\n\n\n",
        "func": "int slap_add_ctrls(\n\tOperation *op,\n\tSlapReply *rs,\n\tLDAPControl **ctrls )\n{\n\tint i = 0, j;\n\tLDAPControl **ctrlsp;\n\n\tif ( rs->sr_ctrls ) {\n\t\tfor ( ; rs->sr_ctrls[ i ]; i++ ) ;\n\t}\n\n\tfor ( j=0; ctrls[j]; j++ ) ;\n\n\tctrlsp = op->o_tmpalloc(( i+j+1 )*sizeof(LDAPControl *), op->o_tmpmemctx );\n\ti = 0;\n\tif ( rs->sr_ctrls ) {\n\t\tfor ( ; rs->sr_ctrls[i]; i++ )\n\t\t\tctrlsp[i] = rs->sr_ctrls[i];\n\t}\n\tfor ( j=0; ctrls[j]; j++)\n\t\tctrlsp[i++] = ctrls[j];\n\tctrlsp[i] = NULL;\n\n\tif ( rs->sr_flags & REP_CTRLS_MUSTBEFREED )\n\t\top->o_tmpfree( rs->sr_ctrls, op->o_tmpmemctx );\n\trs->sr_ctrls = ctrlsp;\n\trs->sr_flags |= REP_CTRLS_MUSTBEFREED;\n\treturn i;\n}",
        "commit_message": "ITS#9408 fix vrfilter double-free",
        "cve_desc": "A flaw was discovered in OpenLDAP before 2.4.57 leading to a slapd crash in the Values Return Filter control handling, resulting in denial of service (double free and out-of-bounds read).",
        "target": 0
      },
      {
        "idx": 342671,
        "reasoning": "This code addresses a previously identified double-free vulnerability (ITS#9408) by ensuring `vrFilter_free` is only called if `op->o_vrFilter` is not NULL, preventing a potential crash. The commit message explicitly states it's a fix for a double-free, and the code snippet demonstrates a conditional free operation, indicating the vulnerability has been mitigated.",
        "func": "static int parseValuesReturnFilter (\n\tOperation *op,\n\tSlapReply *rs,\n\tLDAPControl *ctrl )\n{\n\tBerElement\t*ber;\n\tstruct berval\tfstr = BER_BVNULL;\n\n\tif ( op->o_valuesreturnfilter != SLAP_CONTROL_NONE ) {\n\t\trs->sr_text = \"valuesReturnFilter control specified multiple times\";\n\t\treturn LDAP_PROTOCOL_ERROR;\n\t}\n\n\tif ( BER_BVISNULL( &ctrl->ldctl_value )) {\n\t\trs->sr_text = \"valuesReturnFilter control value is absent\";\n\t\treturn LDAP_PROTOCOL_ERROR;\n\t}\n\n\tif ( BER_BVISEMPTY( &ctrl->ldctl_value )) {\n\t\trs->sr_text = \"valuesReturnFilter control value is empty\";\n\t\treturn LDAP_PROTOCOL_ERROR;\n\t}\n\n\tber = ber_init( &(ctrl->ldctl_value) );\n\tif (ber == NULL) {\n\t\trs->sr_text = \"internal error\";\n\t\treturn LDAP_OTHER;\n\t}\n\n\trs->sr_err = get_vrFilter( op, ber,\n\t\t(ValuesReturnFilter **)&(op->o_vrFilter), &rs->sr_text);\n\n\t(void) ber_free( ber, 1 );\n\n\tif( rs->sr_err != LDAP_SUCCESS ) {\n\t\tif( rs->sr_err == SLAPD_DISCONNECT ) {\n\t\t\trs->sr_err = LDAP_PROTOCOL_ERROR;\n\t\t\tsend_ldap_disconnect( op, rs );\n\t\t\trs->sr_err = SLAPD_DISCONNECT;\n\t\t} else {\n\t\t\tsend_ldap_result( op, rs );\n\t\t}\n\t\tif( op->o_vrFilter != NULL) {\n\t\t\tvrFilter_free( op, op->o_vrFilter );\n\t\t\top->o_vrFilter = NULL;\n\t\t}\n\t}\n#ifdef LDAP_DEBUG\n\telse {\n\t\tvrFilter2bv( op, op->o_vrFilter, &fstr );\n\t}\n\n\tDebug( LDAP_DEBUG_ARGS, \"\tvrFilter: %s\\n\",\n\t\tfstr.bv_len ? fstr.bv_val : \"empty\", 0, 0 );\n\top->o_tmpfree( fstr.bv_val, op->o_tmpmemctx );\n#endif\n\n\top->o_valuesreturnfilter = ctrl->ldctl_iscritical\n\t\t? SLAP_CONTROL_CRITICAL\n\t\t: SLAP_CONTROL_NONCRITICAL;\n\n\trs->sr_err = LDAP_SUCCESS;\n\treturn LDAP_SUCCESS;\n}",
        "commit_message": "ITS#9408 fix vrfilter double-free",
        "cve_desc": "A flaw was discovered in OpenLDAP before 2.4.57 leading to a slapd crash in the Values Return Filter control handling, resulting in denial of service (double free and out-of-bounds read).",
        "target": 0
      },
      {
        "idx": 342672,
        "reasoning": "This code snippet is safe and does not exhibit any obvious vulnerabilities. It simply parses an LDAP control (`relax`) and sets a flag within the operation context (`op->o_relax`) based on the control's criticality, with checks to ensure the control is used correctly\u2014only once and with an absent value\u2014preventing any memory corruption or logic errors.",
        "func": "static int parseRelax (\n\tOperation *op,\n\tSlapReply *rs,\n\tLDAPControl *ctrl )\n{\n\tif ( op->o_relax != SLAP_CONTROL_NONE ) {\n\t\trs->sr_text = \"relax control specified multiple times\";\n\t\treturn LDAP_PROTOCOL_ERROR;\n\t}\n\n\tif ( !BER_BVISNULL( &ctrl->ldctl_value )) {\n\t\trs->sr_text = \"relax control value not absent\";\n\t\treturn LDAP_PROTOCOL_ERROR;\n\t}\n\n\top->o_relax = ctrl->ldctl_iscritical\n\t\t? SLAP_CONTROL_CRITICAL\n\t\t: SLAP_CONTROL_NONCRITICAL;\n\n\treturn LDAP_SUCCESS;\n}",
        "commit_message": "ITS#9408 fix vrfilter double-free",
        "cve_desc": "A flaw was discovered in OpenLDAP before 2.4.57 leading to a slapd crash in the Values Return Filter control handling, resulting in denial of service (double free and out-of-bounds read).",
        "target": 0
      }
    ],
    "1": []
  },
  "openmpt": {
    "0": [],
    "1": []
  },
  "openssh-portable": {
    "0": [],
    "1": [
      {
        "idx": 1712,
        "reasoning": "This code is vulnerable to a denial of service because it doesn't unregister the `KEXINIT` handler after processing the initial message, allowing an unauthenticated attacker to repeatedly send `KEXINIT` packets. Each repeated `KEXINIT` triggers memory allocation, potentially consuming up to 128MB of memory until the connection is closed, leading to resource exhaustion.",
        "func": "kex_input_kexinit(int type, u_int32_t seq, void *ctxt)\n{\n\tstruct ssh *ssh = ctxt;\n\tstruct kex *kex = ssh->kex;\n\tconst u_char *ptr;\n\tu_int i;\n\tsize_t dlen;\n\tint r;\n\n\tdebug(\"SSH2_MSG_KEXINIT received\");\n \tif (kex == NULL)\n \t\treturn SSH_ERR_INVALID_ARGUMENT;\n \n \tptr = sshpkt_ptr(ssh, &dlen);\n \tif ((r = sshbuf_put(kex->peer, ptr, dlen)) != 0)\n \t\treturn r;\n\n\t/* discard packet */\n\tfor (i = 0; i < KEX_COOKIE_LEN; i++)\n\t\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0)\n\t\t\treturn r;\n\tfor (i = 0; i < PROPOSAL_MAX; i++)\n\t\tif ((r = sshpkt_get_string(ssh, NULL, NULL)) != 0)\n\t\t\treturn r;\n\t/*\n\t * XXX RFC4253 sec 7: \"each side MAY guess\" - currently no supported\n\t * KEX method has the server move first, but a server might be using\n\t * a custom method or one that we otherwise don't support. We should\n\t * be prepared to remember first_kex_follows here so we can eat a\n\t * packet later.\n\t * XXX2 - RFC4253 is kind of ambiguous on what first_kex_follows means\n\t * for cases where the server *doesn't* go first. I guess we should\n\t * ignore it when it is set for these cases, which is what we do now.\n\t */\n\tif ((r = sshpkt_get_u8(ssh, NULL)) != 0 ||\t/* first_kex_follows */\n\t    (r = sshpkt_get_u32(ssh, NULL)) != 0 ||\t/* reserved */\n\t    (r = sshpkt_get_end(ssh)) != 0)\n\t\t\treturn r;\n\n\tif (!(kex->flags & KEX_INIT_SENT))\n\t\tif ((r = kex_send_kexinit(ssh)) != 0)\n\t\t\treturn r;\n\tif ((r = kex_choose_conf(ssh)) != 0)\n\t\treturn r;\n\n\tif (kex->kex_type < KEX_MAX && kex->kex[kex->kex_type] != NULL)\n\t\treturn (kex->kex[kex->kex_type])(ssh);\n\n\treturn SSH_ERR_INTERNAL_ERROR;\n}\n",
        "commit_message": "upstream commit\n\nUnregister the KEXINIT handler after message has been\nreceived. Otherwise an unauthenticated peer can repeat the KEXINIT and cause\nallocation of up to 128MB -- until the connection is closed. Reported by\nshilei-c at 360.cn\n\nUpstream-ID: 43649ae12a27ef94290db16d1a98294588b75c05",
        "cve_desc": "The kex_input_kexinit function in kex.c in OpenSSH 6.x and 7.x through 7.3 allows remote attackers to cause a denial of service (memory consumption) by sending many duplicate KEXINIT requests.  NOTE: a third party reports that \"OpenSSH upstream does not consider this as a security issue.\"",
        "target": 1
      },
      {
        "idx": 1791,
        "reasoning": "This code is vulnerable to a denial-of-service attack because it doesn't limit the length of the `password` string passed to `sys_auth_passwd`. An attacker can send a password exceeding 1000 characters, causing `sshd` to spend excessive CPU time hashing it, leading to resource exhaustion and potentially crashing the service \u2013 a vulnerability directly addressed by this commit.",
        "func": "auth_password(Authctxt *authctxt, const char *password)\n{\n\tstruct passwd * pw = authctxt->pw;\n\tint result, ok = authctxt->valid;\n#if defined(USE_SHADOW) && defined(HAS_SHADOW_EXPIRE)\n \tstatic int expire_checked = 0;\n #endif\n \n #ifndef HAVE_CYGWIN\n \tif (pw->pw_uid == 0 && options.permit_root_login != PERMIT_YES)\n \t\tok = 0;\n#endif\n\tif (*password == '\\0' && options.permit_empty_passwd == 0)\n\t\treturn 0;\n\n#ifdef KRB5\n\tif (options.kerberos_authentication == 1) {\n\t\tint ret = auth_krb5_password(authctxt, password);\n\t\tif (ret == 1 || ret == 0)\n\t\t\treturn ret && ok;\n\t\t/* Fall back to ordinary passwd authentication. */\n\t}\n#endif\n#ifdef HAVE_CYGWIN\n\t{\n\t\tHANDLE hToken = cygwin_logon_user(pw, password);\n\n\t\tif (hToken == INVALID_HANDLE_VALUE)\n\t\t\treturn 0;\n\t\tcygwin_set_impersonation_token(hToken);\n\t\treturn ok;\n\t}\n#endif\n#ifdef USE_PAM\n\tif (options.use_pam)\n\t\treturn (sshpam_auth_passwd(authctxt, password) && ok);\n#endif\n#if defined(USE_SHADOW) && defined(HAS_SHADOW_EXPIRE)\n\tif (!expire_checked) {\n\t\texpire_checked = 1;\n\t\tif (auth_shadow_pwexpired(authctxt))\n\t\t\tauthctxt->force_pwchange = 1;\n\t}\n#endif\n\tresult = sys_auth_passwd(authctxt, password);\n\tif (authctxt->force_pwchange)\n\t\tdisable_forwarding();\n\treturn (result && ok);\n}\n",
        "commit_message": "upstream commit\n\nSkip passwords longer than 1k in length so clients can't\neasily DoS sshd by sending very long passwords, causing it to spend CPU\nhashing them. feedback djm@, ok markus@.\n\nBrought to our attention by tomas.kuthan at oracle.com, shilei-c at\n360.cn and coredump at autistici.org\n\nUpstream-ID: d0af7d4a2190b63ba1d38eec502bc4be0be9e333",
        "cve_desc": "The auth_password function in auth-passwd.c in sshd in OpenSSH before 7.3 does not limit password lengths for password authentication, which allows remote attackers to cause a denial of service (crypt CPU consumption) via a long string.",
        "target": 1
      }
    ]
  },
  "openssl": {
    "0": [
      {
        "idx": 10871,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message (CVE-2013-6449). The commit addresses an issue with selecting TLS PRF and record hash algorithms based on the SSL version, while the provided code deals with retrieving SRP+ password information and doesn't involve version negotiation or algorithm selection.\n\n\n\n",
        "func": "static char * MS_CALLBACK srp_password_from_info_cb(SSL *s, void *arg)\n\t{\n\treturn BUF_strdup(s->srp_ctx.info) ;\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 0
      },
      {
        "idx": 10872,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message (CVE-2013-6449). The commit addresses an issue with selecting TLS PRF and record hash algorithms based on the SSL version, while this code focuses on setting callback functions for temporary key generation and TLS extension debugging \u2013 it doesn\u2019t handle version negotiation or algorithm selection.\n\n\n\n",
        "func": "long ssl3_callback_ctrl(SSL *s, int cmd, void (*fp)(void))\n\t{\n\tint ret=0;\n\n#if !defined(OPENSSL_NO_DSA) || !defined(OPENSSL_NO_RSA)\n\tif (\n#ifndef OPENSSL_NO_RSA\n\t    cmd == SSL_CTRL_SET_TMP_RSA_CB ||\n#endif\n#ifndef OPENSSL_NO_DSA\n\t    cmd == SSL_CTRL_SET_TMP_DH_CB ||\n#endif\n\t\t0)\n\t\t{\n\t\tif (!ssl_cert_inst(&s->cert))\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_CALLBACK_CTRL, ERR_R_MALLOC_FAILURE);\n\t\t\treturn(0);\n\t\t\t}\n\t\t}\n#endif\n\n\tswitch (cmd)\n\t\t{\n#ifndef OPENSSL_NO_RSA\n\tcase SSL_CTRL_SET_TMP_RSA_CB:\n\t\t{\n\t\ts->cert->rsa_tmp_cb = (RSA *(*)(SSL *, int, int))fp;\n\t\t}\n\t\tbreak;\n#endif\n#ifndef OPENSSL_NO_DH\n\tcase SSL_CTRL_SET_TMP_DH_CB:\n\t\t{\n\t\ts->cert->dh_tmp_cb = (DH *(*)(SSL *, int, int))fp;\n\t\t}\n\t\tbreak;\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tcase SSL_CTRL_SET_TMP_ECDH_CB:\n\t\t{\n\t\ts->cert->ecdh_tmp_cb = (EC_KEY *(*)(SSL *, int, int))fp;\n\t\t}\n\t\tbreak;\n#endif\n#ifndef OPENSSL_NO_TLSEXT\n\tcase SSL_CTRL_SET_TLSEXT_DEBUG_CB:\n\t\ts->tlsext_debug_cb=(void (*)(SSL *,int ,int,\n\t\t\t\t\tunsigned char *, int, void *))fp;\n\t\tbreak;\n#endif\n\tdefault:\n\t\tbreak;\n\t\t}\n\treturn(ret);\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 0
      },
      {
        "idx": 10873,
        "reasoning": "This code was modified by the commit to use the `SSL_METHOD` version instead of the `SSL` structure version when determining TLS protocol support, addressing the vulnerability described in CVE-2013-6449.  The commit message explicitly states that OpenSSL 1.0.2 and later (which likely includes the codebase this snippet is from) *already* effectively implement this fix, meaning this specific code isn't directly vulnerable.\n\n\n\n",
        "func": "SSL_CIPHER *ssl3_choose_cipher(SSL *s, STACK_OF(SSL_CIPHER) *clnt,\n\t     STACK_OF(SSL_CIPHER) *srvr)\n\t{\n\tSSL_CIPHER *c,*ret=NULL;\n\tSTACK_OF(SSL_CIPHER) *prio, *allow;\n\tint i,ii,ok;\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_EC)\n\tunsigned int j;\n\tint ec_ok, ec_nid;\n\tunsigned char ec_search1 = 0, ec_search2 = 0;\n#endif\n\tCERT *cert;\n\tunsigned long alg_k,alg_a,mask_k,mask_a,emask_k,emask_a;\n\n\t/* Let's see which ciphers we can support */\n\tcert=s->cert;\n\n#if 0\n\t/* Do not set the compare functions, because this may lead to a\n\t * reordering by \"id\". We want to keep the original ordering.\n\t * We may pay a price in performance during sk_SSL_CIPHER_find(),\n\t * but would have to pay with the price of sk_SSL_CIPHER_dup().\n\t */\n\tsk_SSL_CIPHER_set_cmp_func(srvr, ssl_cipher_ptr_id_cmp);\n\tsk_SSL_CIPHER_set_cmp_func(clnt, ssl_cipher_ptr_id_cmp);\n#endif\n\n#ifdef CIPHER_DEBUG\n\tprintf(\"Server has %d from %p:\\n\", sk_SSL_CIPHER_num(srvr), (void *)srvr);\n\tfor(i=0 ; i < sk_SSL_CIPHER_num(srvr) ; ++i)\n\t\t{\n\t\tc=sk_SSL_CIPHER_value(srvr,i);\n\t\tprintf(\"%p:%s\\n\",(void *)c,c->name);\n\t\t}\n\tprintf(\"Client sent %d from %p:\\n\", sk_SSL_CIPHER_num(clnt), (void *)clnt);\n\tfor(i=0 ; i < sk_SSL_CIPHER_num(clnt) ; ++i)\n\t    {\n\t    c=sk_SSL_CIPHER_value(clnt,i);\n\t    printf(\"%p:%s\\n\",(void *)c,c->name);\n\t    }\n#endif\n\n\tif (s->options & SSL_OP_CIPHER_SERVER_PREFERENCE)\n\t\t{\n\t\tprio = srvr;\n\t\tallow = clnt;\n\t\t}\n\telse\n\t\t{\n\t\tprio = clnt;\n\t\tallow = srvr;\n\t\t}\n\n\tfor (i=0; i<sk_SSL_CIPHER_num(prio); i++)\n\t\t{\n\t\tc=sk_SSL_CIPHER_value(prio,i);\n\n\t\t/* Skip TLS v1.2 only ciphersuites if lower than v1.2 */\n\t\tif ((c->algorithm_ssl & SSL_TLSV1_2) && \n\t\t\t(TLS1_get_version(s) < TLS1_2_VERSION))\n\t\t\tcontinue;\n\n\t\tssl_set_cert_masks(cert,c);\n\t\tmask_k = cert->mask_k;\n\t\tmask_a = cert->mask_a;\n\t\temask_k = cert->export_mask_k;\n\t\temask_a = cert->export_mask_a;\n#ifndef OPENSSL_NO_SRP\n\t\tmask_k=cert->mask_k | s->srp_ctx.srp_Mask;\n\t\temask_k=cert->export_mask_k | s->srp_ctx.srp_Mask;\n#endif\n\t\t\t\n#ifdef KSSL_DEBUG\n/*\t\tprintf(\"ssl3_choose_cipher %d alg= %lx\\n\", i,c->algorithms);*/\n#endif    /* KSSL_DEBUG */\n\n\t\talg_k=c->algorithm_mkey;\n\t\talg_a=c->algorithm_auth;\n\n#ifndef OPENSSL_NO_KRB5\n\t\tif (alg_k & SSL_kKRB5)\n\t\t\t{\n\t\t\tif ( !kssl_keytab_is_available(s->kssl_ctx) )\n\t\t\t    continue;\n\t\t\t}\n#endif /* OPENSSL_NO_KRB5 */\n#ifndef OPENSSL_NO_PSK\n\t\t/* with PSK there must be server callback set */\n\t\tif ((alg_k & SSL_kPSK) && s->psk_server_callback == NULL)\n\t\t\tcontinue;\n#endif /* OPENSSL_NO_PSK */\n\n\t\tif (SSL_C_IS_EXPORT(c))\n\t\t\t{\n\t\t\tok = (alg_k & emask_k) && (alg_a & emask_a);\n#ifdef CIPHER_DEBUG\n\t\t\tprintf(\"%d:[%08lX:%08lX:%08lX:%08lX]%p:%s (export)\\n\",ok,alg_k,alg_a,emask_k,emask_a,\n\t\t\t       (void *)c,c->name);\n#endif\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\tok = (alg_k & mask_k) && (alg_a & mask_a);\n#ifdef CIPHER_DEBUG\n\t\t\tprintf(\"%d:[%08lX:%08lX:%08lX:%08lX]%p:%s\\n\",ok,alg_k,alg_a,mask_k,mask_a,(void *)c,\n\t\t\t       c->name);\n#endif\n\t\t\t}\n\n#ifndef OPENSSL_NO_TLSEXT\n#ifndef OPENSSL_NO_EC\n\t\tif (\n\t\t\t/* if we are considering an ECC cipher suite that uses our certificate */\n\t\t\t(alg_a & SSL_aECDSA || alg_a & SSL_aECDH)\n\t\t\t/* and we have an ECC certificate */\n\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].x509 != NULL)\n\t\t\t/* and the client specified a Supported Point Formats extension */\n\t\t\t&& ((s->session->tlsext_ecpointformatlist_length > 0) && (s->session->tlsext_ecpointformatlist != NULL))\n\t\t\t/* and our certificate's point is compressed */\n\t\t\t&& (\n\t\t\t\t(s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info->key != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info->key->public_key != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info->key->public_key->data != NULL)\n\t\t\t\t&& (\n\t\t\t\t\t(*(s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info->key->public_key->data) == POINT_CONVERSION_COMPRESSED)\n\t\t\t\t\t|| (*(s->cert->pkeys[SSL_PKEY_ECC].x509->cert_info->key->public_key->data) == POINT_CONVERSION_COMPRESSED + 1)\n\t\t\t\t\t)\n\t\t\t\t)\n\t\t)\n\t\t\t{\n\t\t\tec_ok = 0;\n\t\t\t/* if our certificate's curve is over a field type that the client does not support\n\t\t\t * then do not allow this cipher suite to be negotiated */\n\t\t\tif (\n\t\t\t\t(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth != NULL)\n\t\t\t\t&& (EC_METHOD_get_field_type(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth) == NID_X9_62_prime_field)\n\t\t\t)\n\t\t\t\t{\n\t\t\t\tfor (j = 0; j < s->session->tlsext_ecpointformatlist_length; j++)\n\t\t\t\t\t{\n\t\t\t\t\tif (s->session->tlsext_ecpointformatlist[j] == TLSEXT_ECPOINTFORMAT_ansiX962_compressed_prime)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_ok = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\telse if (EC_METHOD_get_field_type(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth) == NID_X9_62_characteristic_two_field)\n\t\t\t\t{\n\t\t\t\tfor (j = 0; j < s->session->tlsext_ecpointformatlist_length; j++)\n\t\t\t\t\t{\n\t\t\t\t\tif (s->session->tlsext_ecpointformatlist[j] == TLSEXT_ECPOINTFORMAT_ansiX962_compressed_char2)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_ok = 1;\n\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tok = ok && ec_ok;\n\t\t\t}\n\t\tif (\n\t\t\t/* if we are considering an ECC cipher suite that uses our certificate */\n\t\t\t(alg_a & SSL_aECDSA || alg_a & SSL_aECDH)\n\t\t\t/* and we have an ECC certificate */\n\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].x509 != NULL)\n\t\t\t/* and the client specified an EllipticCurves extension */\n\t\t\t&& ((s->session->tlsext_ellipticcurvelist_length > 0) && (s->session->tlsext_ellipticcurvelist != NULL))\n\t\t)\n\t\t\t{\n\t\t\tec_ok = 0;\n\t\t\tif (\n\t\t\t\t(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec != NULL)\n\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group != NULL)\n\t\t\t)\n\t\t\t\t{\n\t\t\t\tec_nid = EC_GROUP_get_curve_name(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group);\n\t\t\t\tif ((ec_nid == 0)\n\t\t\t\t\t&& (s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth != NULL)\n\t\t\t\t)\n\t\t\t\t\t{\n\t\t\t\t\tif (EC_METHOD_get_field_type(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth) == NID_X9_62_prime_field)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_search1 = 0xFF;\n\t\t\t\t\t\tec_search2 = 0x01;\n\t\t\t\t\t\t}\n\t\t\t\t\telse if (EC_METHOD_get_field_type(s->cert->pkeys[SSL_PKEY_ECC].privatekey->pkey.ec->group->meth) == NID_X9_62_characteristic_two_field)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_search1 = 0xFF;\n\t\t\t\t\t\tec_search2 = 0x02;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\tec_search1 = 0x00;\n\t\t\t\t\tec_search2 = tls1_ec_nid2curve_id(ec_nid);\n\t\t\t\t\t}\n\t\t\t\tif ((ec_search1 != 0) || (ec_search2 != 0))\n\t\t\t\t\t{\n\t\t\t\t\tfor (j = 0; j < s->session->tlsext_ellipticcurvelist_length / 2; j++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tif ((s->session->tlsext_ellipticcurvelist[2*j] == ec_search1) && (s->session->tlsext_ellipticcurvelist[2*j+1] == ec_search2))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tec_ok = 1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tok = ok && ec_ok;\n\t\t\t}\n\t\tif (\n\t\t\t/* if we are considering an ECC cipher suite that uses an ephemeral EC key */\n\t\t\t(alg_k & SSL_kEECDH)\n\t\t\t/* and we have an ephemeral EC key */\n\t\t\t&& (s->cert->ecdh_tmp != NULL)\n\t\t\t/* and the client specified an EllipticCurves extension */\n\t\t\t&& ((s->session->tlsext_ellipticcurvelist_length > 0) && (s->session->tlsext_ellipticcurvelist != NULL))\n\t\t)\n\t\t\t{\n\t\t\tec_ok = 0;\n\t\t\tif (s->cert->ecdh_tmp->group != NULL)\n\t\t\t\t{\n\t\t\t\tec_nid = EC_GROUP_get_curve_name(s->cert->ecdh_tmp->group);\n\t\t\t\tif ((ec_nid == 0)\n\t\t\t\t\t&& (s->cert->ecdh_tmp->group->meth != NULL)\n\t\t\t\t)\n\t\t\t\t\t{\n\t\t\t\t\tif (EC_METHOD_get_field_type(s->cert->ecdh_tmp->group->meth) == NID_X9_62_prime_field)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_search1 = 0xFF;\n\t\t\t\t\t\tec_search2 = 0x01;\n\t\t\t\t\t\t}\n\t\t\t\t\telse if (EC_METHOD_get_field_type(s->cert->ecdh_tmp->group->meth) == NID_X9_62_characteristic_two_field)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tec_search1 = 0xFF;\n\t\t\t\t\t\tec_search2 = 0x02;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\telse\n\t\t\t\t\t{\n\t\t\t\t\tec_search1 = 0x00;\n\t\t\t\t\tec_search2 = tls1_ec_nid2curve_id(ec_nid);\n\t\t\t\t\t}\n\t\t\t\tif ((ec_search1 != 0) || (ec_search2 != 0))\n\t\t\t\t\t{\n\t\t\t\t\tfor (j = 0; j < s->session->tlsext_ellipticcurvelist_length / 2; j++)\n\t\t\t\t\t\t{\n\t\t\t\t\t\tif ((s->session->tlsext_ellipticcurvelist[2*j] == ec_search1) && (s->session->tlsext_ellipticcurvelist[2*j+1] == ec_search2))\n\t\t\t\t\t\t\t{\n\t\t\t\t\t\t\tec_ok = 1;\n\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tok = ok && ec_ok;\n\t\t\t}\n#endif /* OPENSSL_NO_EC */\n#endif /* OPENSSL_NO_TLSEXT */\n\n\t\tif (!ok) continue;\n\t\tii=sk_SSL_CIPHER_find(allow,c);\n\t\tif (ii >= 0)\n\t\t\t{\n#if !defined(OPENSSL_NO_EC) && !defined(OPENSSL_NO_TLSEXT)\n\t\t\tif ((alg_k & SSL_kEECDH) && (alg_a & SSL_aECDSA) && s->s3->is_probably_safari)\n\t\t\t\t{\n\t\t\t\tif (!ret) ret=sk_SSL_CIPHER_value(allow,ii);\n\t\t\t\tcontinue;\n\t\t\t\t}\n#endif\n\t\t\tret=sk_SSL_CIPHER_value(allow,ii);\n\t\t\tbreak;\n\t\t\t}\n\t\t}\n\treturn(ret);\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 0
      },
      {
        "idx": 10874,
        "reasoning": "This code snippet, while part of the project addressing CVE-2013-6449, is not directly vulnerable itself. The commit message indicates the vulnerability stemmed from using an inaccurate SSL structure version for PRF and record hash algorithm selection, and this code primarily focuses on clearing SSL state\u2014it doesn't participate in the version negotiation or algorithm selection process where the flaw existed.\n\n\n\n",
        "func": "void ssl3_clear(SSL *s)\n\t{\n\tunsigned char *rp,*wp;\n\tsize_t rlen, wlen;\n\tint init_extra;\n\n#ifdef TLSEXT_TYPE_opaque_prf_input\n\tif (s->s3->client_opaque_prf_input != NULL)\n\t\tOPENSSL_free(s->s3->client_opaque_prf_input);\n\ts->s3->client_opaque_prf_input = NULL;\n\tif (s->s3->server_opaque_prf_input != NULL)\n\t\tOPENSSL_free(s->s3->server_opaque_prf_input);\n\ts->s3->server_opaque_prf_input = NULL;\n#endif\n\n\tssl3_cleanup_key_block(s);\n\tif (s->s3->tmp.ca_names != NULL)\n\t\tsk_X509_NAME_pop_free(s->s3->tmp.ca_names,X509_NAME_free);\n\n\tif (s->s3->rrec.comp != NULL)\n\t\t{\n\t\tOPENSSL_free(s->s3->rrec.comp);\n\t\ts->s3->rrec.comp=NULL;\n\t\t}\n#ifndef OPENSSL_NO_DH\n\tif (s->s3->tmp.dh != NULL)\n\t\t{\n\t\tDH_free(s->s3->tmp.dh);\n\t\ts->s3->tmp.dh = NULL;\n\t\t}\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tif (s->s3->tmp.ecdh != NULL)\n\t\t{\n\t\tEC_KEY_free(s->s3->tmp.ecdh);\n\t\ts->s3->tmp.ecdh = NULL;\n\t\t}\n#endif\n#ifndef OPENSSL_NO_TLSEXT\n#ifndef OPENSSL_NO_EC\n\ts->s3->is_probably_safari = 0;\n#endif /* !OPENSSL_NO_EC */\n#endif /* !OPENSSL_NO_TLSEXT */\n\n\trp = s->s3->rbuf.buf;\n\twp = s->s3->wbuf.buf;\n\trlen = s->s3->rbuf.len;\n \twlen = s->s3->wbuf.len;\n\tinit_extra = s->s3->init_extra;\n\tif (s->s3->handshake_buffer) {\n\t\tBIO_free(s->s3->handshake_buffer);\n\t\ts->s3->handshake_buffer = NULL;\n\t}\n\tif (s->s3->handshake_dgst) {\n\t\tssl3_free_digest_list(s);\n\t}\t\n\tmemset(s->s3,0,sizeof *s->s3);\n\ts->s3->rbuf.buf = rp;\n\ts->s3->wbuf.buf = wp;\n\ts->s3->rbuf.len = rlen;\n \ts->s3->wbuf.len = wlen;\n\ts->s3->init_extra = init_extra;\n\n\tssl_free_wbio_buffer(s);\n\n\ts->packet_length=0;\n\ts->s3->renegotiate=0;\n\ts->s3->total_renegotiations=0;\n\ts->s3->num_renegotiations=0;\n\ts->s3->in_read_app_data=0;\n\ts->version=SSL3_VERSION;\n\n#if !defined(OPENSSL_NO_TLSEXT) && !defined(OPENSSL_NO_NEXTPROTONEG)\n\tif (s->next_proto_negotiated)\n\t\t{\n\t\tOPENSSL_free(s->next_proto_negotiated);\n\t\ts->next_proto_negotiated = NULL;\n\t\ts->next_proto_negotiated_len = 0;\n\t\t}\n#endif\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 0
      },
      {
        "idx": 10875,
        "reasoning": "This code is not directly vulnerable to CVE-2013-6449 because the commit message states the fix was already effectively implemented in OpenSSL 1.0.2 and later, and this code snippet doesn't appear to be directly involved in the TLS version negotiation or PRF/record hash algorithm selection process where the vulnerability resided. The `ssl3_ctrl` function primarily handles various SSL control operations, but doesn't show the flawed logic of using the SSL structure's version instead of the SSL_METHOD structure's version.\n\n\n\n",
        "func": "long ssl3_ctrl(SSL *s, int cmd, long larg, void *parg)\n\t{\n\tint ret=0;\n\n#if !defined(OPENSSL_NO_DSA) || !defined(OPENSSL_NO_RSA)\n\tif (\n#ifndef OPENSSL_NO_RSA\n\t    cmd == SSL_CTRL_SET_TMP_RSA ||\n\t    cmd == SSL_CTRL_SET_TMP_RSA_CB ||\n#endif\n#ifndef OPENSSL_NO_DSA\n\t    cmd == SSL_CTRL_SET_TMP_DH ||\n\t    cmd == SSL_CTRL_SET_TMP_DH_CB ||\n#endif\n\t\t0)\n\t\t{\n\t\tif (!ssl_cert_inst(&s->cert))\n\t\t    \t{\n\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_MALLOC_FAILURE);\n\t\t\treturn(0);\n\t\t\t}\n\t\t}\n#endif\n\n\tswitch (cmd)\n\t\t{\n\tcase SSL_CTRL_GET_SESSION_REUSED:\n\t\tret=s->hit;\n\t\tbreak;\n\tcase SSL_CTRL_GET_CLIENT_CERT_REQUEST:\n\t\tbreak;\n\tcase SSL_CTRL_GET_NUM_RENEGOTIATIONS:\n\t\tret=s->s3->num_renegotiations;\n\t\tbreak;\n\tcase SSL_CTRL_CLEAR_NUM_RENEGOTIATIONS:\n\t\tret=s->s3->num_renegotiations;\n\t\ts->s3->num_renegotiations=0;\n\t\tbreak;\n\tcase SSL_CTRL_GET_TOTAL_RENEGOTIATIONS:\n\t\tret=s->s3->total_renegotiations;\n\t\tbreak;\n\tcase SSL_CTRL_GET_FLAGS:\n\t\tret=(int)(s->s3->flags);\n\t\tbreak;\n#ifndef OPENSSL_NO_RSA\n\tcase SSL_CTRL_NEED_TMP_RSA:\n\t\tif ((s->cert != NULL) && (s->cert->rsa_tmp == NULL) &&\n\t\t    ((s->cert->pkeys[SSL_PKEY_RSA_ENC].privatekey == NULL) ||\n\t\t     (EVP_PKEY_size(s->cert->pkeys[SSL_PKEY_RSA_ENC].privatekey) > (512/8))))\n\t\t\tret = 1;\n\t\tbreak;\n\tcase SSL_CTRL_SET_TMP_RSA:\n\t\t{\n\t\t\tRSA *rsa = (RSA *)parg;\n\t\t\tif (rsa == NULL)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_PASSED_NULL_PARAMETER);\n\t\t\t\treturn(ret);\n\t\t\t\t}\n\t\t\tif ((rsa = RSAPrivateKey_dup(rsa)) == NULL)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_RSA_LIB);\n\t\t\t\treturn(ret);\n\t\t\t\t}\n\t\t\tif (s->cert->rsa_tmp != NULL)\n\t\t\t\tRSA_free(s->cert->rsa_tmp);\n\t\t\ts->cert->rsa_tmp = rsa;\n\t\t\tret = 1;\n\t\t}\n\t\tbreak;\n\tcase SSL_CTRL_SET_TMP_RSA_CB:\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED);\n\t\treturn(ret);\n\t\t}\n\t\tbreak;\n#endif\n#ifndef OPENSSL_NO_DH\n\tcase SSL_CTRL_SET_TMP_DH:\n\t\t{\n\t\t\tDH *dh = (DH *)parg;\n\t\t\tif (dh == NULL)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_PASSED_NULL_PARAMETER);\n\t\t\t\treturn(ret);\n\t\t\t\t}\n\t\t\tif ((dh = DHparams_dup(dh)) == NULL)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_DH_LIB);\n\t\t\t\treturn(ret);\n\t\t\t\t}\n\t\t\tif (!(s->options & SSL_OP_SINGLE_DH_USE))\n\t\t\t\t{\n\t\t\t\tif (!DH_generate_key(dh))\n\t\t\t\t\t{\n\t\t\t\t\tDH_free(dh);\n\t\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_DH_LIB);\n\t\t\t\t\treturn(ret);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\tif (s->cert->dh_tmp != NULL)\n\t\t\t\tDH_free(s->cert->dh_tmp);\n\t\t\ts->cert->dh_tmp = dh;\n\t\t\tret = 1;\n\t\t}\n\t\tbreak;\n\tcase SSL_CTRL_SET_TMP_DH_CB:\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED);\n\t\treturn(ret);\n\t\t}\n\t\tbreak;\n#endif\n#ifndef OPENSSL_NO_ECDH\n\tcase SSL_CTRL_SET_TMP_ECDH:\n\t\t{\n\t\tEC_KEY *ecdh = NULL;\n \t\t\t\n\t\tif (parg == NULL)\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_PASSED_NULL_PARAMETER);\n\t\t\treturn(ret);\n\t\t\t}\n\t\tif (!EC_KEY_up_ref((EC_KEY *)parg))\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_CTRL,ERR_R_ECDH_LIB);\n\t\t\treturn(ret);\n\t\t\t}\n\t\tecdh = (EC_KEY *)parg;\n\t\tif (!(s->options & SSL_OP_SINGLE_ECDH_USE))\n\t\t\t{\n\t\t\tif (!EC_KEY_generate_key(ecdh))\n\t\t\t\t{\n\t\t\t\tEC_KEY_free(ecdh);\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL,ERR_R_ECDH_LIB);\n\t\t\t\treturn(ret);\n\t\t\t\t}\n\t\t\t}\n\t\tif (s->cert->ecdh_tmp != NULL)\n\t\t\tEC_KEY_free(s->cert->ecdh_tmp);\n\t\ts->cert->ecdh_tmp = ecdh;\n\t\tret = 1;\n\t\t}\n\t\tbreak;\n\tcase SSL_CTRL_SET_TMP_ECDH_CB:\n\t\t{\n\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_SHOULD_NOT_HAVE_BEEN_CALLED);\n\t\treturn(ret);\n\t\t}\n\t\tbreak;\n#endif /* !OPENSSL_NO_ECDH */\n#ifndef OPENSSL_NO_TLSEXT\n\tcase SSL_CTRL_SET_TLSEXT_HOSTNAME:\n \t\tif (larg == TLSEXT_NAMETYPE_host_name)\n\t\t\t{\n\t\t\tif (s->tlsext_hostname != NULL) \n\t\t\t\tOPENSSL_free(s->tlsext_hostname);\n\t\t\ts->tlsext_hostname = NULL;\n\n\t\t\tret = 1;\n\t\t\tif (parg == NULL) \n\t\t\t\tbreak;\n\t\t\tif (strlen((char *)parg) > TLSEXT_MAXLEN_host_name)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, SSL_R_SSL3_EXT_INVALID_SERVERNAME);\n\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\tif ((s->tlsext_hostname = BUF_strdup((char *)parg)) == NULL)\n\t\t\t\t{\n\t\t\t\tSSLerr(SSL_F_SSL3_CTRL, ERR_R_INTERNAL_ERROR);\n\t\t\t\treturn 0;\n\t\t\t\t}\n\t\t\t}\n\t\telse\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_CTRL, SSL_R_SSL3_EXT_INVALID_SERVERNAME_TYPE);\n\t\t\treturn 0;\n\t\t\t}\n \t\tbreak;\n\tcase SSL_CTRL_SET_TLSEXT_DEBUG_ARG:\n\t\ts->tlsext_debug_arg=parg;\n\t\tret = 1;\n\t\tbreak;\n\n#ifdef TLSEXT_TYPE_opaque_prf_input\n\tcase SSL_CTRL_SET_TLSEXT_OPAQUE_PRF_INPUT:\n\t\tif (larg > 12288) /* actual internal limit is 2^16 for the complete hello message\n\t\t                   * (including the cert chain and everything) */\n\t\t\t{\n\t\t\tSSLerr(SSL_F_SSL3_CTRL, SSL_R_OPAQUE_PRF_INPUT_TOO_LONG);\n\t\t\tbreak;\n\t\t\t}\n\t\tif (s->tlsext_opaque_prf_input != NULL)\n\t\t\tOPENSSL_free(s->tlsext_opaque_prf_input);\n\t\tif ((size_t)larg == 0)\n\t\t\ts->tlsext_opaque_prf_input = OPENSSL_malloc(1); /* dummy byte just to get non-NULL */\n\t\telse\n\t\t\ts->tlsext_opaque_prf_input = BUF_memdup(parg, (size_t)larg);\n\t\tif (s->tlsext_opaque_prf_input != NULL)\n\t\t\t{\n\t\t\ts->tlsext_opaque_prf_input_len = (size_t)larg;\n\t\t\tret = 1;\n\t\t\t}\n\t\telse\n\t\t\ts->tlsext_opaque_prf_input_len = 0;\n\t\tbreak;\n#endif\n\n\tcase SSL_CTRL_SET_TLSEXT_STATUS_REQ_TYPE:\n\t\ts->tlsext_status_type=larg;\n\t\tret = 1;\n\t\tbreak;\n\n\tcase SSL_CTRL_GET_TLSEXT_STATUS_REQ_EXTS:\n\t\t*(STACK_OF(X509_EXTENSION) **)parg = s->tlsext_ocsp_exts;\n\t\tret = 1;\n\t\tbreak;\n\n\tcase SSL_CTRL_SET_TLSEXT_STATUS_REQ_EXTS:\n\t\ts->tlsext_ocsp_exts = parg;\n\t\tret = 1;\n\t\tbreak;\n\n\tcase SSL_CTRL_GET_TLSEXT_STATUS_REQ_IDS:\n\t\t*(STACK_OF(OCSP_RESPID) **)parg = s->tlsext_ocsp_ids;\n\t\tret = 1;\n\t\tbreak;\n\n\tcase SSL_CTRL_SET_TLSEXT_STATUS_REQ_IDS:\n\t\ts->tlsext_ocsp_ids = parg;\n\t\tret = 1;\n\t\tbreak;\n\n\tcase SSL_CTRL_GET_TLSEXT_STATUS_REQ_OCSP_RESP:\n\t\t*(unsigned char **)parg = s->tlsext_ocsp_resp;\n\t\treturn s->tlsext_ocsp_resplen;\n\t\t\n\tcase SSL_CTRL_SET_TLSEXT_STATUS_REQ_OCSP_RESP:\n\t\tif (s->tlsext_ocsp_resp)\n\t\t\tOPENSSL_free(s->tlsext_ocsp_resp);\n\t\ts->tlsext_ocsp_resp = parg;\n\t\ts->tlsext_ocsp_resplen = larg;\n\t\tret = 1;\n\t\tbreak;\n\n#ifndef OPENSSL_NO_HEARTBEATS\n\tcase SSL_CTRL_TLS_EXT_SEND_HEARTBEAT:\n\t\tif (SSL_version(s) == DTLS1_VERSION || SSL_version(s) == DTLS1_BAD_VER)\n\t\t\tret = dtls1_heartbeat(s);\n\t\telse\n\t\t\tret = tls1_heartbeat(s);\n\t\tbreak;\n\n\tcase SSL_CTRL_GET_TLS_EXT_HEARTBEAT_PENDING:\n\t\tret = s->tlsext_hb_pending;\n\t\tbreak;\n\n\tcase SSL_CTRL_SET_TLS_EXT_HEARTBEAT_NO_REQUESTS:\n\t\tif (larg)\n\t\t\ts->tlsext_heartbeat |= SSL_TLSEXT_HB_DONT_RECV_REQUESTS;\n\t\telse\n\t\t\ts->tlsext_heartbeat &= ~SSL_TLSEXT_HB_DONT_RECV_REQUESTS;\n\t\tret = 1;\n\t\tbreak;\n#endif\n\n#endif /* !OPENSSL_NO_TLSEXT */\n\tdefault:\n\t\tbreak;\n\t\t}\n\treturn(ret);\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 0,
        "reasoning": "This code is vulnerable because it initially retrieves the TLS version from the `SSL` structure (`TLS1_get_version(s)`), which can be inaccurate, instead of the `SSL_METHOD` structure. This inaccuracy allows a malicious TLS 1.2 client to potentially negotiate algorithms incorrectly, leading to a denial of service as described in CVE-2013-6449.",
        "func": " long ssl_get_algorithm2(SSL *s)\n        {\n        long alg2 = s->s3->tmp.new_cipher->algorithm2;\n       if (TLS1_get_version(s) >= TLS1_2_VERSION &&\n            alg2 == (SSL_HANDSHAKE_MAC_DEFAULT|TLS1_PRF))\n                return SSL_HANDSHAKE_MAC_SHA256 | TLS1_PRF_SHA256;\n        return alg2;\n\t}\n",
        "commit_message": "Use version in SSL_METHOD not SSL structure.\n\nWhen deciding whether to use TLS 1.2 PRF and record hash algorithms\nuse the version number in the corresponding SSL_METHOD structure\ninstead of the SSL structure. The SSL structure version is sometimes\ninaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n(CVE-2013-6449)",
        "cve_desc": "The ssl_get_algorithm2 function in ssl/s3_lib.c in OpenSSL before 1.0.2 obtains a certain version number from an incorrect data structure, which allows remote attackers to cause a denial of service (daemon crash) via crafted traffic from a TLS 1.2 client.",
        "target": 1
      },
      {
        "idx": 108,
        "reasoning": "The vulnerability lies in how the code handles errors during the decoding of combined ASN.1 structures, specifically when a decoding failure occurs within a nested structure, the parent structure's pointer is incorrectly zeroed. This zeroing leaks memory containing sensitive information from the parent structure's components, potentially exposing data from PKCS#7 or CMS structures as described in CVE-2015-3195.",
        "func": "int ASN1_item_ex_d2i(ASN1_VALUE **pval, const unsigned char **in, long len,\n                     const ASN1_ITEM *it,\n                     int tag, int aclass, char opt, ASN1_TLC *ctx)\n{\n    const ASN1_TEMPLATE *tt, *errtt = NULL;\n    const ASN1_COMPAT_FUNCS *cf;\n    const ASN1_EXTERN_FUNCS *ef;\n    const ASN1_AUX *aux = it->funcs;\n    ASN1_aux_cb *asn1_cb;\n    const unsigned char *p = NULL, *q;\n    unsigned char *wp = NULL;   /* BIG FAT WARNING! BREAKS CONST WHERE USED */\n    unsigned char imphack = 0, oclass;\n    char seq_eoc, seq_nolen, cst, isopt;\n    long tmplen;\n    int i;\n     int otag;\n     int ret = 0;\n     ASN1_VALUE **pchptr, *ptmpval;\n     if (!pval)\n         return 0;\n     if (aux && aux->asn1_cb)\n        asn1_cb = 0;\n\n    switch (it->itype) {\n    case ASN1_ITYPE_PRIMITIVE:\n        if (it->templates) {\n            /*\n             * tagging or OPTIONAL is currently illegal on an item template\n             * because the flags can't get passed down. In practice this\n             * isn't a problem: we include the relevant flags from the item\n             * template in the template itself.\n             */\n            if ((tag != -1) || opt) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I,\n                        ASN1_R_ILLEGAL_OPTIONS_ON_ITEM_TEMPLATE);\n                goto err;\n            }\n            return asn1_template_ex_d2i(pval, in, len,\n                                        it->templates, opt, ctx);\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it,\n                                     tag, aclass, opt, ctx);\n        break;\n\n    case ASN1_ITYPE_MSTRING:\n        p = *in;\n        /* Just read in tag and class */\n        ret = asn1_check_tlen(NULL, &otag, &oclass, NULL, NULL,\n                              &p, len, -1, 0, 1, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Must be UNIVERSAL class */\n        if (oclass != V_ASN1_UNIVERSAL) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_NOT_UNIVERSAL);\n            goto err;\n        }\n        /* Check tag matches bit map */\n        if (!(ASN1_tag2bit(otag) & it->utype)) {\n            /* If OPTIONAL, assume this is OK */\n            if (opt)\n                return -1;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MSTRING_WRONG_TAG);\n            goto err;\n        }\n        return asn1_d2i_ex_primitive(pval, in, len, it, otag, 0, 0, ctx);\n\n    case ASN1_ITYPE_EXTERN:\n        /* Use new style d2i */\n        ef = it->funcs;\n        return ef->asn1_ex_d2i(pval, in, len, it, tag, aclass, opt, ctx);\n\n    case ASN1_ITYPE_COMPAT:\n        /* we must resort to old style evil hackery */\n        cf = it->funcs;\n\n        /* If OPTIONAL see if it is there */\n        if (opt) {\n            int exptag;\n            p = *in;\n            if (tag == -1)\n                exptag = it->utype;\n            else\n                exptag = tag;\n            /*\n             * Don't care about anything other than presence of expected tag\n             */\n\n            ret = asn1_check_tlen(NULL, NULL, NULL, NULL, NULL,\n                                  &p, len, exptag, aclass, 1, ctx);\n            if (!ret) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            if (ret == -1)\n                return -1;\n        }\n\n        /*\n         * This is the old style evil hack IMPLICIT handling: since the\n         * underlying code is expecting a tag and class other than the one\n         * present we change the buffer temporarily then change it back\n         * afterwards. This doesn't and never did work for tags > 30. Yes\n         * this is *horrible* but it is only needed for old style d2i which\n         * will hopefully not be around for much longer. FIXME: should copy\n         * the buffer then modify it so the input buffer can be const: we\n         * should *always* copy because the old style d2i might modify the\n         * buffer.\n         */\n\n        if (tag != -1) {\n            wp = *(unsigned char **)in;\n            imphack = *wp;\n            if (p == NULL) {\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n                goto err;\n            }\n            *wp = (unsigned char)((*p & V_ASN1_CONSTRUCTED)\n                                  | it->utype);\n        }\n\n        ptmpval = cf->asn1_d2i(pval, in, len);\n\n        if (tag != -1)\n            *wp = imphack;\n\n        if (ptmpval)\n            return 1;\n\n        ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n        goto err;\n\n    case ASN1_ITYPE_CHOICE:\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n        if (*pval) {\n            /* Free up and zero CHOICE value if initialised */\n            i = asn1_get_choice_selector(pval, it);\n            if ((i >= 0) && (i < it->tcount)) {\n                tt = it->templates + i;\n                pchptr = asn1_get_field_ptr(pval, tt);\n                ASN1_template_free(pchptr, tt);\n                asn1_set_choice_selector(pval, -1, it);\n            }\n        } else if (!ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n        /* CHOICE type, try each possibility in turn */\n        p = *in;\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            pchptr = asn1_get_field_ptr(pval, tt);\n            /*\n             * We mark field as OPTIONAL so its absence can be recognised.\n             */\n            ret = asn1_template_ex_d2i(pchptr, &p, len, tt, 1, ctx);\n            /* If field not present, try the next one */\n            if (ret == -1)\n                continue;\n            /* If positive return, read OK, break loop */\n            if (ret > 0)\n                break;\n            /* Otherwise must be an ASN1 parsing error */\n            errtt = tt;\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        /* Did we fall off the end without reading anything? */\n        if (i == it->tcount) {\n            /* If OPTIONAL, this is OK */\n            if (opt) {\n                /* Free and zero it */\n                ASN1_item_ex_free(pval, it);\n                return -1;\n            }\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_NO_MATCHING_CHOICE_TYPE);\n            goto err;\n        }\n\n        asn1_set_choice_selector(pval, i, it);\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        *in = p;\n        return 1;\n\n    case ASN1_ITYPE_NDEF_SEQUENCE:\n    case ASN1_ITYPE_SEQUENCE:\n        p = *in;\n        tmplen = len;\n\n        /* If no IMPLICIT tagging set to SEQUENCE, UNIVERSAL */\n        if (tag == -1) {\n            tag = V_ASN1_SEQUENCE;\n            aclass = V_ASN1_UNIVERSAL;\n        }\n        /* Get SEQUENCE length and update len, p */\n        ret = asn1_check_tlen(&len, NULL, NULL, &seq_eoc, &cst,\n                              &p, len, tag, aclass, opt, ctx);\n        if (!ret) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        } else if (ret == -1)\n            return -1;\n        if (aux && (aux->flags & ASN1_AFLG_BROKEN)) {\n            len = tmplen - (p - *in);\n            seq_nolen = 1;\n        }\n        /* If indefinite we don't do a length check */\n        else\n            seq_nolen = seq_eoc;\n        if (!cst) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_NOT_CONSTRUCTED);\n            goto err;\n        }\n\n        if (!*pval && !ASN1_item_ex_new(pval, it)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ERR_R_NESTED_ASN1_ERROR);\n            goto err;\n        }\n\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_PRE, pval, it, NULL))\n            goto auxerr;\n\n        /* Free up and zero any ADB found */\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            if (tt->flags & ASN1_TFLG_ADB_MASK) {\n                const ASN1_TEMPLATE *seqtt;\n                ASN1_VALUE **pseqval;\n                seqtt = asn1_do_adb(pval, tt, 1);\n                pseqval = asn1_get_field_ptr(pval, seqtt);\n                ASN1_template_free(pseqval, seqtt);\n            }\n        }\n\n        /* Get each field entry */\n        for (i = 0, tt = it->templates; i < it->tcount; i++, tt++) {\n            const ASN1_TEMPLATE *seqtt;\n            ASN1_VALUE **pseqval;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            pseqval = asn1_get_field_ptr(pval, seqtt);\n            /* Have we ran out of data? */\n            if (!len)\n                break;\n            q = p;\n            if (asn1_check_eoc(&p, len)) {\n                if (!seq_eoc) {\n                    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_UNEXPECTED_EOC);\n                    goto err;\n                }\n                len -= p - q;\n                seq_eoc = 0;\n                q = p;\n                break;\n            }\n            /*\n             * This determines the OPTIONAL flag value. The field cannot be\n             * omitted if it is the last of a SEQUENCE and there is still\n             * data to be read. This isn't strictly necessary but it\n             * increases efficiency in some cases.\n             */\n            if (i == (it->tcount - 1))\n                isopt = 0;\n            else\n                isopt = (char)(seqtt->flags & ASN1_TFLG_OPTIONAL);\n            /*\n             * attempt to read in field, allowing each to be OPTIONAL\n             */\n\n            ret = asn1_template_ex_d2i(pseqval, &p, len, seqtt, isopt, ctx);\n            if (!ret) {\n                errtt = seqtt;\n                goto err;\n            } else if (ret == -1) {\n                /*\n                 * OPTIONAL component absent. Free and zero the field.\n                 */\n                ASN1_template_free(pseqval, seqtt);\n                continue;\n            }\n            /* Update length */\n            len -= p - q;\n        }\n\n        /* Check for EOC if expecting one */\n        if (seq_eoc && !asn1_check_eoc(&p, len)) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_MISSING_EOC);\n            goto err;\n        }\n        /* Check all data read */\n        if (!seq_nolen && len) {\n            ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_SEQUENCE_LENGTH_MISMATCH);\n            goto err;\n        }\n\n        /*\n         * If we get here we've got no more data in the SEQUENCE, however we\n         * may not have read all fields so check all remaining are OPTIONAL\n         * and clear any that are.\n         */\n        for (; i < it->tcount; tt++, i++) {\n            const ASN1_TEMPLATE *seqtt;\n            seqtt = asn1_do_adb(pval, tt, 1);\n            if (!seqtt)\n                goto err;\n            if (seqtt->flags & ASN1_TFLG_OPTIONAL) {\n                ASN1_VALUE **pseqval;\n                pseqval = asn1_get_field_ptr(pval, seqtt);\n                ASN1_template_free(pseqval, seqtt);\n            } else {\n                errtt = seqtt;\n                ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_FIELD_MISSING);\n                goto err;\n            }\n        }\n        /* Save encoding */\n        if (!asn1_enc_save(pval, *in, p - *in, it))\n            goto auxerr;\n        if (asn1_cb && !asn1_cb(ASN1_OP_D2I_POST, pval, it, NULL))\n            goto auxerr;\n        *in = p;\n        return 1;\n\n    default:\n        return 0;\n    }\n auxerr:\n    ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_AUX_ERROR);\n  auxerr:\n     ASN1err(ASN1_F_ASN1_ITEM_EX_D2I, ASN1_R_AUX_ERROR);\n  err:\n    ASN1_item_ex_free(pval, it);\n     if (errtt)\n         ERR_add_error_data(4, \"Field=\", errtt->field_name,\n                            \", Type=\", it->sname);\n}\n",
        "commit_message": "Fix leak with ASN.1 combine.\n\nWhen parsing a combined structure pass a flag to the decode routine\nso on error a pointer to the parent structure is not zeroed as\nthis will leak any additional components in the parent.\n\nThis can leak memory in any application parsing PKCS#7 or CMS structures.\n\nCVE-2015-3195.\n\nThanks to Adam Langley (Google/BoringSSL) for discovering this bug using\nlibFuzzer.\n\nPR#4131\n\nReviewed-by: Richard Levitte <levitte@openssl.org>",
        "cve_desc": "The ASN1_TFLG_COMBINE implementation in crypto/asn1/tasn_dec.c in OpenSSL before 0.9.8zh, 1.0.0 before 1.0.0t, 1.0.1 before 1.0.1q, and 1.0.2 before 1.0.2e mishandles errors caused by malformed X509_ATTRIBUTE data, which allows remote attackers to obtain sensitive information from process memory by triggering a decoding failure in a PKCS#7 or CMS application.",
        "target": 1
      },
      {
        "idx": 109,
        "reasoning": "This code is vulnerable because it doesn't check if `pss->maskGenAlgorithm` is NULL before attempting to access its `parameter` member, leading to a NULL pointer dereference if the mask generation algorithm is missing as described in the CVE. This dereference can be triggered during certificate verification, resulting in a denial-of-service attack against clients or servers performing authentication.",
        "func": "static RSA_PSS_PARAMS *rsa_pss_decode(const X509_ALGOR *alg,\n                                      X509_ALGOR **pmaskHash)\n{\n    const unsigned char *p;\n    int plen;\n    RSA_PSS_PARAMS *pss;\n\n    *pmaskHash = NULL;\n\n    if (!alg->parameter || alg->parameter->type != V_ASN1_SEQUENCE)\n        return NULL;\n    p = alg->parameter->value.sequence->data;\n    plen = alg->parameter->value.sequence->length;\n    pss = d2i_RSA_PSS_PARAMS(NULL, &p, plen);\n\n    if (!pss)\n        return NULL;\n\n     if (pss->maskGenAlgorithm) {\n         ASN1_TYPE *param = pss->maskGenAlgorithm->parameter;\n         if (OBJ_obj2nid(pss->maskGenAlgorithm->algorithm) == NID_mgf1\n            && param->type == V_ASN1_SEQUENCE) {\n             p = param->value.sequence->data;\n             plen = param->value.sequence->length;\n             *pmaskHash = d2i_X509_ALGOR(NULL, &p, plen);\n        }\n    }\n\n    return pss;\n}\n",
        "commit_message": "Add PSS parameter check.\n\nAvoid seg fault by checking mgf1 parameter is not NULL. This can be\ntriggered during certificate verification so could be a DoS attack\nagainst a client or a server enabling client authentication.\n\nThanks to Lo\u00efc Jonas Etienne (Qnective AG) for discovering this bug.\n\nCVE-2015-3194\n\nReviewed-by: Matt Caswell <matt@openssl.org>",
        "cve_desc": "crypto/rsa/rsa_ameth.c in OpenSSL 1.0.1 before 1.0.1q and 1.0.2 before 1.0.2e allows remote attackers to cause a denial of service (NULL pointer dereference and application crash) via an RSA PSS ASN.1 signature that lacks a mask generation function parameter.",
        "target": 1
      }
    ]
  },
  "openthread": {
    "0": [],
    "1": []
  },
  "openvpn": {
    "0": [],
    "1": []
  },
  "ovs": {
    "0": [],
    "1": []
  },
  "p11-kit": {
    "0": [],
    "1": []
  },
  "patch": {
    "0": [],
    "1": [
      {
        "idx": 215920,
        "reasoning": "The provided code, despite adding integer overflow checks for line numbers, is vulnerable to a symlink attack as described in the CVE because it doesn't properly sanitize filenames within the patch file, allowing an attacker to include symlinks pointing to arbitrary files.  When `patch` applies the changes, it could overwrite these targeted files due to the lack of validation on the file paths specified in the patch.",
        "func": "another_hunk (enum diff difftype, bool rev)\n{\n    char *s;\n    lin context = 0;\n    size_t chars_read;\n    char numbuf0[LINENUM_LENGTH_BOUND + 1];\n    char numbuf1[LINENUM_LENGTH_BOUND + 1];\n    char numbuf2[LINENUM_LENGTH_BOUND + 1];\n    char numbuf3[LINENUM_LENGTH_BOUND + 1];\n\n    while (p_end >= 0) {\n\tif (p_end == p_efake)\n\t    p_end = p_bfake;\t\t/* don't free twice */\n\telse\n\t    free(p_line[p_end]);\n\tp_end--;\n    }\n    assert(p_end == -1);\n    p_efake = -1;\n\n    if (p_c_function)\n      {\n\tfree (p_c_function);\n\tp_c_function = NULL;\n      }\n\n    p_max = hunkmax;\t\t\t/* gets reduced when --- found */\n    if (difftype == CONTEXT_DIFF || difftype == NEW_CONTEXT_DIFF) {\n\tfile_offset line_beginning = file_tell (pfp);\n\t\t\t\t\t/* file pos of the current line */\n\tlin repl_beginning = 0;\t\t/* index of --- line */\n\tlin fillcnt = 0;\t/* #lines of missing ptrn or repl */\n\tlin fillsrc;\t\t/* index of first line to copy */\n\tlin filldst;\t\t/* index of first missing line */\n\tbool ptrn_spaces_eaten = false;\t/* ptrn was slightly misformed */\n\tbool some_context = false;\t/* (perhaps internal) context seen */\n\tbool repl_could_be_missing = true;\n\tbool ptrn_missing = false;\t/* The pattern was missing.  */\n\tbool repl_missing = false;\t/* Likewise for replacement.  */\n\tfile_offset repl_backtrack_position = 0;\n\t\t\t\t\t/* file pos of first repl line */\n\tlin repl_patch_line;\t\t/* input line number for same */\n\tlin repl_context;\t\t/* context for same */\n\tlin ptrn_prefix_context = -1;\t/* lines in pattern prefix context */\n\tlin ptrn_suffix_context = -1;\t/* lines in pattern suffix context */\n\tlin repl_prefix_context = -1;\t/* lines in replac. prefix context */\n\tlin ptrn_copiable = 0;\t\t/* # of copiable lines in ptrn */\n\tlin repl_copiable = 0;\t\t/* Likewise for replacement.  */\n\n\t/* Pacify 'gcc -Wall'.  */\n\tfillsrc = filldst = repl_patch_line = repl_context = 0;\n\n\tchars_read = get_line ();\n\tif (chars_read == (size_t) -1\n\t    || chars_read <= 8\n\t    || strncmp (buf, \"********\", 8) != 0) {\n\t    next_intuit_at(line_beginning,p_input_line);\n\t    return chars_read == (size_t) -1 ? -1 : 0;\n\t}\n\ts = buf;\n\twhile (*s == '*')\n\t    s++;\n\tif (*s == ' ')\n\t  {\n\t    p_c_function = s;\n\t    while (*s != '\\n')\n\t\ts++;\n\t    *s = '\\0';\n\t    p_c_function = savestr (p_c_function);\n\t    if (! p_c_function)\n\t      return -1;\n\t  }\n\tp_hunk_beg = p_input_line + 1;\n\twhile (p_end < p_max) {\n\t    chars_read = get_line ();\n\t    if (chars_read == (size_t) -1)\n\t      return -1;\n\t    if (!chars_read) {\n\t\tif (repl_beginning && repl_could_be_missing) {\n\t\t    repl_missing = true;\n\t\t    goto hunk_done;\n\t\t}\n\t\tif (p_max - p_end < 4) {\n\t\t    strcpy (buf, \"  \\n\");  /* assume blank lines got chopped */\n\t\t    chars_read = 3;\n\t\t} else {\n\t\t    fatal (\"unexpected end of file in patch\");\n\t\t}\n\t    }\n\t    p_end++;\n\t    if (p_end == hunkmax)\n\t      fatal (\"unterminated hunk starting at line %s; giving up at line %s: %s\",\n\t\t     format_linenum (numbuf0, pch_hunk_beg ()),\n\t\t     format_linenum (numbuf1, p_input_line), buf);\n\t    assert(p_end < hunkmax);\n\t    p_Char[p_end] = *buf;\n\t    p_len[p_end] = 0;\n\t    p_line[p_end] = 0;\n\t    switch (*buf) {\n\t    case '*':\n\t\tif (strnEQ(buf, \"********\", 8)) {\n\t\t    if (repl_beginning && repl_could_be_missing) {\n\t\t\trepl_missing = true;\n\t\t\tgoto hunk_done;\n\t\t    }\n\t\t    else\n\t\t      fatal (\"unexpected end of hunk at line %s\",\n\t\t\t     format_linenum (numbuf0, p_input_line));\n\t\t}\n\t\tif (p_end != 0) {\n\t\t    if (repl_beginning && repl_could_be_missing) {\n\t\t\trepl_missing = true;\n\t\t\tgoto hunk_done;\n\t\t    }\n\t\t    fatal (\"unexpected '***' at line %s: %s\",\n\t\t\t   format_linenum (numbuf0, p_input_line), buf);\n\t\t}\n\t\tcontext = 0;\n\t\tp_len[p_end] = strlen (buf);\n\t\tif (! (p_line[p_end] = savestr (buf))) {\n\t\t    p_end--;\n\t\t    return -1;\n\t\t}\n\t\tfor (s = buf;  *s && !ISDIGIT (*s);  s++)\n\t\t  /* do nothing */ ;\n\t\tif (strnEQ(s,\"0,0\",3))\n\t\t    remove_prefix (s, 2);\n\t\ts = scan_linenum (s, &p_first);\n\t\tif (*s == ',') {\n\t\t    while (*s && !ISDIGIT (*s))\n\t\t      s++;\n\t\t    scan_linenum (s, &p_ptrn_lines);\n\t\t    p_ptrn_lines += 1 - p_first;\n\t\t}\n\t\telse if (p_first)\n\t\t    p_ptrn_lines = 1;\n\t\telse {\n\t\t    p_ptrn_lines = 0;\n\t\t    p_first = 1;\n\t\t}\n\t\tp_max = p_ptrn_lines + 6;\t/* we need this much at least */\n\t\twhile (p_max + 1 >= hunkmax)\n\t\t    if (! grow_hunkmax ())\n\t\t\treturn -1;\n\t\tp_max = hunkmax;\n\t\tbreak;\n\t    case '-':\n\t\tif (buf[1] != '-')\n\t\t  goto change_line;\n\t\tif (ptrn_prefix_context == -1)\n\t\t  ptrn_prefix_context = context;\n\t\tptrn_suffix_context = context;\n\t\tif (repl_beginning\n\t\t    || (p_end\n\t\t\t!= p_ptrn_lines + 1 + (p_Char[p_end - 1] == '\\n')))\n\t\t  {\n\t\t    if (p_end == 1)\n\t\t      {\n\t\t\t/* 'Old' lines were omitted.  Set up to fill\n\t\t\t   them in from 'new' context lines.  */\n\t\t\tptrn_missing = true;\n\t\t\tp_end = p_ptrn_lines + 1;\n\t\t\tptrn_prefix_context = ptrn_suffix_context = -1;\n\t\t\tfillsrc = p_end + 1;\n\t\t\tfilldst = 1;\n\t\t\tfillcnt = p_ptrn_lines;\n\t\t      }\n\t\t    else if (! repl_beginning)\n\t\t      fatal (\"%s '---' at line %s; check line numbers at line %s\",\n\t\t\t     (p_end <= p_ptrn_lines\n\t\t\t      ? \"Premature\"\n\t\t\t      : \"Overdue\"),\n\t\t\t     format_linenum (numbuf0, p_input_line),\n\t\t\t     format_linenum (numbuf1, p_hunk_beg));\n\t\t    else if (! repl_could_be_missing)\n\t\t      fatal (\"duplicate '---' at line %s; check line numbers at line %s\",\n\t\t\t     format_linenum (numbuf0, p_input_line),\n\t\t\t     format_linenum (numbuf1,\n\t\t\t\t\t     p_hunk_beg + repl_beginning));\n\t\t    else\n\t\t      {\n\t\t\trepl_missing = true;\n\t\t\tgoto hunk_done;\n\t\t      }\n\t\t  }\n\t\trepl_beginning = p_end;\n\t\trepl_backtrack_position = file_tell (pfp);\n\t\trepl_patch_line = p_input_line;\n\t\trepl_context = context;\n\t\tp_len[p_end] = strlen (buf);\n\t\tif (! (p_line[p_end] = savestr (buf)))\n\t\t  {\n\t\t    p_end--;\n\t\t    return -1;\n\t\t  }\n\t\tp_Char[p_end] = '=';\n\t\tfor (s = buf;  *s && ! ISDIGIT (*s);  s++)\n\t\t  /* do nothing */ ;\n\t\ts = scan_linenum (s, &p_newfirst);\n\t\tif (*s == ',')\n\t\t  {\n\t\t    do\n\t\t      {\n\t\t\tif (!*++s)\n\t\t\t  malformed ();\n\t\t      }\n\t\t    while (! ISDIGIT (*s));\n\t\t    scan_linenum (s, &p_repl_lines);\n\t\t    p_repl_lines += 1 - p_newfirst;\n\t\t  }\n\t\telse if (p_newfirst)\n\t\t  p_repl_lines = 1;\n\t\telse\n\t\t  {\n\t\t    p_repl_lines = 0;\n\t\t    p_newfirst = 1;\n\t\t  }\n\t\tp_max = p_repl_lines + p_end;\n\t\twhile (p_max + 1 >= hunkmax)\n\t\t  if (! grow_hunkmax ())\n\t\t    return -1;\n\t\tif (p_repl_lines != ptrn_copiable\n\t\t    && (p_prefix_context != 0\n\t\t\t|| context != 0\n\t\t\t|| p_repl_lines != 1))\n\t\t  repl_could_be_missing = false;\n\t\tcontext = 0;\n\t\tbreak;\n\t    case '+':  case '!':\n\t\trepl_could_be_missing = false;\n\t      change_line:\n\t\ts = buf + 1;\n\t\tchars_read--;\n\t\tif (*s == '\\n' && canonicalize) {\n\t\t    strcpy (s, \" \\n\");\n\t\t    chars_read = 2;\n\t\t}\n\t\tif (*s == ' ' || *s == '\\t') {\n\t\t    s++;\n\t\t    chars_read--;\n\t\t} else if (repl_beginning && repl_could_be_missing) {\n\t\t    repl_missing = true;\n\t\t    goto hunk_done;\n\t\t}\n\t\tif (! repl_beginning)\n\t\t  {\n\t\t    if (ptrn_prefix_context == -1)\n\t\t      ptrn_prefix_context = context;\n\t\t  }\n\t\telse\n\t\t  {\n\t\t    if (repl_prefix_context == -1)\n\t\t      repl_prefix_context = context;\n\t\t  }\n\t\tchars_read -=\n\t\t  (1 < chars_read\n\t\t   && p_end == (repl_beginning ? p_max : p_ptrn_lines)\n\t\t   && incomplete_line ());\n\t\tp_len[p_end] = chars_read;\n\t\tp_line[p_end] = savebuf (s, chars_read);\n\t\tif (chars_read && ! p_line[p_end]) {\n\t\t    p_end--;\n\t\t    return -1;\n\t        }\n\t\tcontext = 0;\n\t\tbreak;\n\t    case '\\t': case '\\n':\t/* assume spaces got eaten */\n\t\ts = buf;\n\t\tif (*buf == '\\t') {\n\t\t    s++;\n\t\t    chars_read--;\n\t\t}\n\t\tif (repl_beginning && repl_could_be_missing &&\n\t\t    (!ptrn_spaces_eaten || difftype == NEW_CONTEXT_DIFF) ) {\n\t\t    repl_missing = true;\n\t\t    goto hunk_done;\n\t\t}\n\t\tchars_read -=\n\t\t  (1 < chars_read\n\t\t   && p_end == (repl_beginning ? p_max : p_ptrn_lines)\n\t\t   && incomplete_line ());\n\t\tp_len[p_end] = chars_read;\n\t\tp_line[p_end] = savebuf (buf, chars_read);\n\t\tif (chars_read && ! p_line[p_end]) {\n\t\t    p_end--;\n\t\t    return -1;\n\t\t}\n\t\tif (p_end != p_ptrn_lines + 1) {\n\t\t    ptrn_spaces_eaten |= (repl_beginning != 0);\n\t\t    some_context = true;\n\t\t    context++;\n\t\t    if (repl_beginning)\n\t\t\trepl_copiable++;\n\t\t    else\n\t\t\tptrn_copiable++;\n\t\t    p_Char[p_end] = ' ';\n\t\t}\n\t\tbreak;\n\t    case ' ':\n\t\ts = buf + 1;\n\t\tchars_read--;\n\t\tif (*s == '\\n' && canonicalize) {\n\t\t    strcpy (s, \"\\n\");\n\t\t    chars_read = 2;\n\t\t}\n\t\tif (*s == ' ' || *s == '\\t') {\n\t\t    s++;\n\t\t    chars_read--;\n\t\t} else if (repl_beginning && repl_could_be_missing) {\n\t\t    repl_missing = true;\n\t\t    goto hunk_done;\n\t\t}\n\t\tsome_context = true;\n\t\tcontext++;\n\t\tif (repl_beginning)\n\t\t    repl_copiable++;\n\t\telse\n\t\t    ptrn_copiable++;\n\t\tchars_read -=\n\t\t  (1 < chars_read\n\t\t   && p_end == (repl_beginning ? p_max : p_ptrn_lines)\n\t\t   && incomplete_line ());\n\t\tp_len[p_end] = chars_read;\n\t\tp_line[p_end] = savebuf (s, chars_read);\n\t\tif (chars_read && ! p_line[p_end]) {\n\t\t    p_end--;\n\t\t    return -1;\n\t\t}\n\t\tbreak;\n\t    default:\n\t\tif (repl_beginning && repl_could_be_missing) {\n\t\t    repl_missing = true;\n\t\t    goto hunk_done;\n\t\t}\n\t\tmalformed ();\n\t    }\n\t}\n\n    hunk_done:\n\tif (p_end >=0 && !repl_beginning)\n\t  fatal (\"no '---' found in patch at line %s\",\n\t\t format_linenum (numbuf0, pch_hunk_beg ()));\n\n\tif (repl_missing) {\n\n\t    /* reset state back to just after --- */\n\t    p_input_line = repl_patch_line;\n\t    context = repl_context;\n\t    for (p_end--; p_end > repl_beginning; p_end--)\n\t\tfree(p_line[p_end]);\n\t    Fseek (pfp, repl_backtrack_position, SEEK_SET);\n\n\t    /* redundant 'new' context lines were omitted - set */\n\t    /* up to fill them in from the old file context */\n\t    fillsrc = 1;\n\t    filldst = repl_beginning+1;\n\t    fillcnt = p_repl_lines;\n\t    p_end = p_max;\n\t}\n\telse if (! ptrn_missing && ptrn_copiable != repl_copiable)\n\t  fatal (\"context mangled in hunk at line %s\",\n\t\t format_linenum (numbuf0, p_hunk_beg));\n\telse if (!some_context && fillcnt == 1) {\n\t    /* the first hunk was a null hunk with no context */\n\t    /* and we were expecting one line -- fix it up. */\n\t    while (filldst < p_end) {\n\t\tp_line[filldst] = p_line[filldst+1];\n\t\tp_Char[filldst] = p_Char[filldst+1];\n\t\tp_len[filldst] = p_len[filldst+1];\n\t\tfilldst++;\n\t    }\n#if 0\n\t    repl_beginning--;\t\t/* this doesn't need to be fixed */\n#endif\n\t    p_end--;\n\t    p_first++;\t\t\t/* do append rather than insert */\n\t    fillcnt = 0;\n\t    p_ptrn_lines = 0;\n\t}\n\n\tp_prefix_context = ((repl_prefix_context == -1\n\t\t\t     || (ptrn_prefix_context != -1\n\t\t\t\t && ptrn_prefix_context < repl_prefix_context))\n\t\t\t    ? ptrn_prefix_context : repl_prefix_context);\n\tp_suffix_context = ((ptrn_suffix_context != -1\n\t\t\t     && ptrn_suffix_context < context)\n\t\t\t    ? ptrn_suffix_context : context);\n\tif (p_prefix_context == -1 || p_suffix_context == -1)\n\t    fatal (\"replacement text or line numbers mangled in hunk at line %s\",\n\t\t   format_linenum (numbuf0, p_hunk_beg));\n\n\tif (difftype == CONTEXT_DIFF\n\t    && (fillcnt\n\t\t|| (p_first > 1\n\t\t    && p_prefix_context + p_suffix_context < ptrn_copiable))) {\n\t    if (verbosity == VERBOSE)\n\t\tsay (\"%s\\n%s\\n%s\\n\",\n\"(Fascinating -- this is really a new-style context diff but without\",\n\"the telltale extra asterisks on the *** line that usually indicate\",\n\"the new style...)\");\n\t    diff_type = difftype = NEW_CONTEXT_DIFF;\n\t}\n\n\t/* if there were omitted context lines, fill them in now */\n\tif (fillcnt) {\n\t    p_bfake = filldst;\t\t/* remember where not to free() */\n\t    p_efake = filldst + fillcnt - 1;\n\t    while (fillcnt-- > 0) {\n\t\twhile (fillsrc <= p_end && fillsrc != repl_beginning\n\t\t       && p_Char[fillsrc] != ' ')\n\t\t    fillsrc++;\n\t\tif (p_end < fillsrc || fillsrc == repl_beginning)\n\t\t  {\n\t\t    fatal (\"replacement text or line numbers mangled in hunk at line %s\",\n\t\t\t   format_linenum (numbuf0, p_hunk_beg));\n\t\t  }\n\t\tp_line[filldst] = p_line[fillsrc];\n\t\tp_Char[filldst] = p_Char[fillsrc];\n\t\tp_len[filldst] = p_len[fillsrc];\n\t\tfillsrc++; filldst++;\n\t    }\n\t    while (fillsrc <= p_end && fillsrc != repl_beginning)\n\t      {\n\t\tif (p_Char[fillsrc] == ' ')\n\t\t  fatal (\"replacement text or line numbers mangled in hunk at line %s\",\n\t\t\t format_linenum (numbuf0, p_hunk_beg));\n\t\tfillsrc++;\n\t      }\n\t    if (debug & 64)\n\t      printf (\"fillsrc %s, filldst %s, rb %s, e+1 %s\\n\",\n\t\t      format_linenum (numbuf0, fillsrc),\n\t\t      format_linenum (numbuf1, filldst),\n\t\t      format_linenum (numbuf2, repl_beginning),\n\t\t      format_linenum (numbuf3, p_end + 1));\n\t    assert(fillsrc==p_end+1 || fillsrc==repl_beginning);\n\t    assert(filldst==p_end+1 || filldst==repl_beginning);\n\t}\n    }\n    else if (difftype == UNI_DIFF) {\n\tfile_offset line_beginning = file_tell (pfp);  /* file pos of the current line */\n\tlin fillsrc;  /* index of old lines */\n\tlin filldst;  /* index of new lines */\n\tchar ch = '\\0';\n\n\tchars_read = get_line ();\n\tif (chars_read == (size_t) -1\n\t    || chars_read <= 4\n\t    || strncmp (buf, \"@@ -\", 4) != 0) {\n\t    next_intuit_at(line_beginning,p_input_line);\n\t    return chars_read == (size_t) -1 ? -1 : 0;\n\t}\n\ts = scan_linenum (buf + 4, &p_first);\n\tif (*s == ',')\n\t    s = scan_linenum (s + 1, &p_ptrn_lines);\n\telse\n\t    p_ptrn_lines = 1;\n\tif (*s == ' ') s++;\n\tif (*s != '+')\n\t    malformed ();\n\ts = scan_linenum (s + 1, &p_newfirst);\n\tif (*s == ',')\n\t    s = scan_linenum (s + 1, &p_repl_lines);\n\telse\n\t    p_repl_lines = 1;\n\tif (*s == ' ') s++;\n\tif (*s++ != '@')\n\t    malformed ();\n\tif (*s++ == '@' && *s == ' ')\n\t  {\n\t    p_c_function = s;\n\t    while (*s != '\\n')\n\t\ts++;\n\t    *s = '\\0';\n\t    p_c_function = savestr (p_c_function);\n\t    if (! p_c_function)\n\t      return -1;\n\t  }\n\tif (!p_ptrn_lines)\n\t    p_first++;\t\t\t/* do append rather than insert */\n\tif (!p_repl_lines)\n\t    p_newfirst++;\n\tp_max = p_ptrn_lines + p_repl_lines + 1;\n\twhile (p_max + 1 >= hunkmax)\n\t    if (! grow_hunkmax ())\n\t\treturn -1;\n\tfillsrc = 1;\n\tfilldst = fillsrc + p_ptrn_lines;\n\tp_end = filldst + p_repl_lines;\n\tsprintf (buf, \"*** %s,%s ****\\n\",\n\t\t format_linenum (numbuf0, p_first),\n\t\t format_linenum (numbuf1, p_first + p_ptrn_lines - 1));\n\tp_len[0] = strlen (buf);\n\tif (! (p_line[0] = savestr (buf))) {\n\t    p_end = -1;\n\t    return -1;\n\t}\n\tp_Char[0] = '*';\n\tsprintf (buf, \"--- %s,%s ----\\n\",\n\t\t format_linenum (numbuf0, p_newfirst),\n\t\t format_linenum (numbuf1, p_newfirst + p_repl_lines - 1));\n\tp_len[filldst] = strlen (buf);\n\tif (! (p_line[filldst] = savestr (buf))) {\n\t    p_end = 0;\n\t    return -1;\n\t}\n\tp_Char[filldst++] = '=';\n\tp_prefix_context = -1;\n\tp_hunk_beg = p_input_line + 1;\n\twhile (fillsrc <= p_ptrn_lines || filldst <= p_end) {\n\t    chars_read = get_line ();\n\t    if (!chars_read) {\n\t\tif (p_max - filldst < 3) {\n\t\t    strcpy (buf, \" \\n\");  /* assume blank lines got chopped */\n\t\t    chars_read = 2;\n\t\t} else {\n\t\t    fatal (\"unexpected end of file in patch\");\n\t\t}\n\t    }\n\t    if (chars_read == (size_t) -1)\n\t\ts = 0;\n\t    else if (*buf == '\\t' || *buf == '\\n') {\n\t\tch = ' ';\t\t/* assume the space got eaten */\n\t\ts = savebuf (buf, chars_read);\n\t    }\n\t    else {\n\t\tch = *buf;\n\t\ts = savebuf (buf+1, --chars_read);\n\t    }\n\t    if (chars_read && ! s)\n\t      {\n\t\twhile (--filldst > p_ptrn_lines)\n\t\t    free(p_line[filldst]);\n\t\tp_end = fillsrc-1;\n\t\treturn -1;\n\t      }\n\t    switch (ch) {\n\t    case '-':\n\t\tif (fillsrc > p_ptrn_lines) {\n\t\t    free(s);\n\t\t    p_end = filldst-1;\n\t\t    malformed ();\n\t\t}\n\t\tchars_read -= fillsrc == p_ptrn_lines && incomplete_line ();\n\t\tp_Char[fillsrc] = ch;\n\t\tp_line[fillsrc] = s;\n\t\tp_len[fillsrc++] = chars_read;\n\t\tbreak;\n\t    case '=':\n\t\tch = ' ';\n\t\t/* FALL THROUGH */\n\t    case ' ':\n\t\tif (fillsrc > p_ptrn_lines) {\n\t\t    free(s);\n\t\t    while (--filldst > p_ptrn_lines)\n\t\t\tfree(p_line[filldst]);\n\t\t    p_end = fillsrc-1;\n\t\t    malformed ();\n\t\t}\n\t\tcontext++;\n\t\tchars_read -= fillsrc == p_ptrn_lines && incomplete_line ();\n\t\tp_Char[fillsrc] = ch;\n\t\tp_line[fillsrc] = s;\n\t\tp_len[fillsrc++] = chars_read;\n\t\ts = savebuf (s, chars_read);\n\t\tif (chars_read && ! s) {\n\t\t    while (--filldst > p_ptrn_lines)\n\t\t\tfree(p_line[filldst]);\n\t\t    p_end = fillsrc-1;\n\t\t    return -1;\n\t\t}\n\t\t/* FALL THROUGH */\n\t    case '+':\n\t\tif (filldst > p_end) {\n\t\t    free(s);\n\t\t    while (--filldst > p_ptrn_lines)\n\t\t\tfree(p_line[filldst]);\n\t\t    p_end = fillsrc-1;\n\t\t    malformed ();\n\t\t}\n\t\tchars_read -= filldst == p_end && incomplete_line ();\n\t\tp_Char[filldst] = ch;\n\t\tp_line[filldst] = s;\n\t\tp_len[filldst++] = chars_read;\n\t\tbreak;\n\t    default:\n\t\tp_end = filldst;\n\t\tmalformed ();\n\t    }\n\t    if (ch != ' ') {\n\t\tif (p_prefix_context == -1)\n\t\t    p_prefix_context = context;\n\t\tcontext = 0;\n\t    }\n\t}/* while */\n\tif (p_prefix_context == -1)\n\t  malformed ();\n\tp_suffix_context = context;\n    }\n    else {\t\t\t\t/* normal diff--fake it up */\n\tchar hunk_type;\n\tint i;\n\tlin min, max;\n\tfile_offset line_beginning = file_tell (pfp);\n\n\tp_prefix_context = p_suffix_context = 0;\n\tchars_read = get_line ();\n\tif (chars_read == (size_t) -1 || !chars_read || !ISDIGIT (*buf)) {\n\t    next_intuit_at(line_beginning,p_input_line);\n\t    return chars_read == (size_t) -1 ? -1 : 0;\n\t}\n\ts = scan_linenum (buf, &p_first);\n\tif (*s == ',') {\n\t    s = scan_linenum (s + 1, &p_ptrn_lines);\n\t    p_ptrn_lines += 1 - p_first;\n\t}\n\telse\n\t    p_ptrn_lines = (*s != 'a');\n\thunk_type = *s;\n\tif (hunk_type == 'a')\n\t    p_first++;\t\t\t/* do append rather than insert */\n\ts = scan_linenum (s + 1, &min);\n\tif (*s == ',')\n\t    scan_linenum (s + 1, &max);\n\telse\n\t    max = min;\n\tif (hunk_type == 'd')\n\t    min++;\n\tp_end = p_ptrn_lines + 1 + max - min + 1;\n\twhile (p_end + 1 >= hunkmax)\n\t  if (! grow_hunkmax ())\n\t    {\n\t      p_end = -1;\n\t      return -1;\n\t    }\n\tp_newfirst = min;\n\tp_repl_lines = max - min + 1;\n\tsprintf (buf, \"*** %s,%s\\n\",\n\t\t format_linenum (numbuf0, p_first),\n\t\t format_linenum (numbuf1, p_first + p_ptrn_lines - 1));\n\tp_len[0] = strlen (buf);\n\tif (! (p_line[0] = savestr (buf))) {\n\t    p_end = -1;\n\t    return -1;\n\t}\n\tp_Char[0] = '*';\n\tfor (i=1; i<=p_ptrn_lines; i++) {\n\t    chars_read = get_line ();\n\t    if (chars_read == (size_t) -1)\n\t      {\n\t\tp_end = i - 1;\n\t\treturn -1;\n\t      }\n\t    if (!chars_read)\n\t      fatal (\"unexpected end of file in patch at line %s\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t    if (buf[0] != '<' || (buf[1] != ' ' && buf[1] != '\\t'))\n\t      fatal (\"'<' expected at line %s of patch\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t    chars_read -= 2 + (i == p_ptrn_lines && incomplete_line ());\n\t    p_len[i] = chars_read;\n\t    p_line[i] = savebuf (buf + 2, chars_read);\n\t    if (chars_read && ! p_line[i]) {\n\t\tp_end = i-1;\n\t\treturn -1;\n\t    }\n\t    p_Char[i] = '-';\n\t}\n\tif (hunk_type == 'c') {\n\t    chars_read = get_line ();\n\t    if (chars_read == (size_t) -1)\n\t      {\n\t\tp_end = i - 1;\n\t\treturn -1;\n\t      }\n\t    if (! chars_read)\n\t      fatal (\"unexpected end of file in patch at line %s\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t    if (*buf != '-')\n\t      fatal (\"'---' expected at line %s of patch\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t}\n\tsprintf (buf, \"--- %s,%s\\n\",\n\t\t format_linenum (numbuf0, min),\n\t\t format_linenum (numbuf1, max));\n\tp_len[i] = strlen (buf);\n\tif (! (p_line[i] = savestr (buf))) {\n\t    p_end = i-1;\n\t    return -1;\n\t}\n\tp_Char[i] = '=';\n\tfor (i++; i<=p_end; i++) {\n\t    chars_read = get_line ();\n\t    if (chars_read == (size_t) -1)\n\t      {\n\t\tp_end = i - 1;\n\t\treturn -1;\n\t      }\n\t    if (!chars_read)\n\t      fatal (\"unexpected end of file in patch at line %s\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t    if (buf[0] != '>' || (buf[1] != ' ' && buf[1] != '\\t'))\n\t      fatal (\"'>' expected at line %s of patch\",\n\t\t     format_linenum (numbuf0, p_input_line));\n\t    chars_read -= 2 + (i == p_end && incomplete_line ());\n\t    p_len[i] = chars_read;\n\t    p_line[i] = savebuf (buf + 2, chars_read);\n\t    if (chars_read && ! p_line[i]) {\n\t\tp_end = i-1;\n\t\treturn -1;\n\t    }\n\t    p_Char[i] = '+';\n\t}\n    }\n    if (rev)\t\t\t\t/* backwards patch? */\n\tif (!pch_swap())\n\t    say (\"Not enough memory to swap next hunk!\\n\");\n    assert (p_end + 1 < hunkmax);\n    p_Char[p_end + 1] = '^';  /* add a stopper for apply_hunk */\n    if (debug & 2) {\n\tlin i;\n\n\tfor (i = 0; i <= p_end + 1; i++) {\n\t    fprintf (stderr, \"%s %c\",\n\t\t     format_linenum (numbuf0, i),\n\t\t     p_Char[i]);\n\t    if (p_Char[i] == '*')\n\t      fprintf (stderr, \" %s,%s\\n\",\n\t\t       format_linenum (numbuf0, p_first),\n\t\t       format_linenum (numbuf1, p_ptrn_lines));\n\t    else if (p_Char[i] == '=')\n\t      fprintf (stderr, \" %s,%s\\n\",\n\t\t       format_linenum (numbuf0, p_newfirst),\n\t\t       format_linenum (numbuf1, p_repl_lines));\n\t    else if (p_Char[i] != '^')\n\t      {\n\t\tfputs(\" |\", stderr);\n\t\tpch_write_line (i, stderr);\n\t      }\n\t    else\n\t      fputc('\\n', stderr);\n\t}\n\tfflush (stderr);\n    }\n    return 1;\n}",
        "commit_message": "Add line number overflow checking\n\n* bootstrap.conf: use intprops module.\n* src/common.h: Define LINENUM_MIN and LINENUM_MAX macros.\n* src/pch.c (another_hunk): Add line number overflow checking.  Based on Robert\nC. Seacord's INT32-C document for integer overflow checking and Tobias\nStoeckmann's \"integer overflows and oob memory access\" patch for FreeBSD.",
        "cve_desc": "GNU patch 2.7.1 allows remote attackers to write to arbitrary files via a symlink attack in a patch file.",
        "target": 1
      },
      {
        "idx": 216004,
        "reasoning": "This code is vulnerable to arbitrary command execution because it directly uses the `EDITOR_PROGRAM` variable in a `popen` call without proper sanitization, allowing an attacker to inject malicious commands into the `ed` script. While the patch attempts to mitigate this by writing to a temporary file, the initial `popen` call remains vulnerable if `EDITOR_PROGRAM` is controllable or contains malicious code, as it's still used to invoke the editor.",
        "func": "do_ed_script (char const *inname, char const *outname,\n\t      bool *outname_needs_removal, FILE *ofp)\n{\n    static char const editor_program[] = EDITOR_PROGRAM;\n\n    file_offset beginning_of_this_line;\n    FILE *pipefp = 0;\n    size_t chars_read;\n\n    if (! dry_run && ! skip_rest_of_patch) {\n\tint exclusive = *outname_needs_removal ? 0 : O_EXCL;\n\tif (inerrno != ENOENT)\n\t  {\n\t    *outname_needs_removal = true;\n\t    copy_file (inname, outname, 0, exclusive, instat.st_mode, true);\n\t  }\n\tsprintf (buf, \"%s %s%s\", editor_program,\n\t\t verbosity == VERBOSE ? \"\" : \"- \",\n\t\t outname);\n\tfflush (stdout);\n\tpipefp = popen(buf, binary_transput ? \"wb\" : \"w\");\n\tif (!pipefp)\n\t  pfatal (\"Can't open pipe to %s\", quotearg (buf));\n    }\n    for (;;) {\n\tchar ed_command_letter;\n\tbeginning_of_this_line = file_tell (pfp);\n\tchars_read = get_line ();\n\tif (! chars_read) {\n\t    next_intuit_at(beginning_of_this_line,p_input_line);\n\t    break;\n\t}\n\ted_command_letter = get_ed_command_letter (buf);\n\tif (ed_command_letter) {\n\t    if (pipefp)\n\t\tif (! fwrite (buf, sizeof *buf, chars_read, pipefp))\n\t\t    write_fatal ();\n\t    if (ed_command_letter != 'd' && ed_command_letter != 's') {\n\t        p_pass_comments_through = true;\n\t\twhile ((chars_read = get_line ()) != 0) {\n\t\t    if (pipefp)\n\t\t\tif (! fwrite (buf, sizeof *buf, chars_read, pipefp))\n\t\t\t    write_fatal ();\n\t\t    if (chars_read == 2  &&  strEQ (buf, \".\\n\"))\n\t\t\tbreak;\n\t\t}\n\t\tp_pass_comments_through = false;\n\t    }\n\t}\n\telse {\n\t    next_intuit_at(beginning_of_this_line,p_input_line);\n\t    break;\n\t}\n    }\n    if (!pipefp)\n      return;\n    if (fwrite (\"w\\nq\\n\", sizeof (char), (size_t) 4, pipefp) == 0\n\t|| fflush (pipefp) != 0)\n      write_fatal ();\n    if (pclose (pipefp) != 0)\n      fatal (\"%s FAILED\", editor_program);\n\n    if (ofp)\n      {\n\tFILE *ifp = fopen (outname, binary_transput ? \"rb\" : \"r\");\n\tint c;\n\tif (!ifp)\n\t  pfatal (\"can't open '%s'\", outname);\n\twhile ((c = getc (ifp)) != EOF)\n\t  if (putc (c, ofp) == EOF)\n\t    write_fatal ();\n\tif (ferror (ifp) || fclose (ifp) != 0)\n\t  read_fatal ();\n      }\n}",
        "commit_message": "Fix arbitrary command execution in ed-style patches (CVE-2018-1000156)\n\n* src/pch.c (do_ed_script): Write ed script to a temporary file instead\nof piping it to ed: this will cause ed to abort on invalid commands\ninstead of rejecting them and carrying on.\n* tests/ed-style: New test case.\n* tests/Makefile.am (TESTS): Add test case.",
        "cve_desc": "GNU Patch version 2.7.6 contains an input validation vulnerability when processing patch files, specifically the EDITOR_PROGRAM invocation (using ed) can result in code execution. This attack appear to be exploitable via a patch file processed via the patch utility. This is similar to FreeBSD's CVE-2015-1418 however although they share a common ancestry the code bases have diverged over time.",
        "target": 1
      }
    ]
  },
  "pdfresurrect": {
    "0": [
      {
        "idx": 80763,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message states the changes address memory issues (likely heap overflows or use-after-free) in other parts of the project related to dynamic allocation, and this `display_creator` function itself doesn't perform any dynamic memory allocation or manipulation that would introduce vulnerabilities\u2014it only *displays* data from a pre-existing `pdf_t` structure.",
        "func": "static void display_creator(FILE *fp, const pdf_t *pdf)\n{\n    int i;\n\n    printf(\"PDF Version: %d.%d\\n\",\n           pdf->pdf_major_version, pdf->pdf_minor_version);\n\n    for (i=0; i<pdf->n_xrefs; ++i)\n    {\n        if (!pdf->xrefs[i].version)\n          continue;\n      \n        if (pdf_display_creator(pdf, i))\n          printf(\"\\n\");\n    }\n}\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 0
      },
      {
        "idx": 80764,
        "reasoning": "This code snippet appears safe as the commit message explicitly states it addresses memory issues (likely related to allocation failures) by adding zero and sanity checks to dynamic allocations. The code also includes error handling\u2014specifically, `pdf_delete(pdf)` is called and `NULL` is returned if `pdf_load_xrefs` fails\u2014which prevents potential use-after-free scenarios stemming from allocation problems, aligning with the fix described in the commit message and addressing the issues in the test cases.",
        "func": "static pdf_t *init_pdf(FILE *fp, const char *name)\n{\n    pdf_t *pdf;\n\n    pdf = pdf_new(name);\n    pdf_get_version(fp, pdf);\n    if (pdf_load_xrefs(fp, pdf) == -1) {\n      pdf_delete(pdf);\n      return NULL;\n    }\n    pdf_load_pages_kids(fp, pdf);\n\n    return pdf;\n }\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 0
      },
      {
        "idx": 80765,
        "reasoning": "This code appears safe as the commit message explicitly states it addresses memory issues from previous tests (`calloc_some.pdf` and `malloc_some.pdf`) by adding zero and sanity checks to all dynamic allocations. The code also consistently `free()`s the allocated memory (`new_name`) and `fclose()`s the file pointers (`new_fp`), preventing memory leaks and file descriptor leaks.\n\n\n\n",
        "func": "static void scrub_document(FILE *fp, const pdf_t *pdf)\n{\n    FILE *new_fp;\n    int   ch, i, j, last_version ;\n    char *new_name, *c;\n    const char *suffix = \"-scrubbed.pdf\";\n\n    /* Create a new name */\n    if (!(new_name = malloc(strlen(pdf->name) + strlen(suffix) + 1)))\n    {\n        ERR(\"Insufficient memory to create scrubbed file name\\n\");\n        return;\n    }\n\n    strcpy(new_name, pdf->name);\n    if ((c = strrchr(new_name, '.')))\n      *c = '\\0';\n    strcat(new_name, suffix);\n\n    if ((new_fp = fopen(new_name, \"r\")))\n    {\n        ERR(\"File name already exists for saving scrubbed document\\n\");\n        free(new_name);\n        fclose(new_fp);\n        return;\n    }\n\n    if (!(new_fp = fopen(new_name, \"w+\")))\n    {\n        ERR(\"Could not create file for saving scrubbed document\\n\");\n        free(new_name);\n        fclose(new_fp);\n        return;\n    }\n\n    /* Copy */\n    fseek(fp, SEEK_SET, 0);\n    while ((ch = fgetc(fp)) != EOF)\n      fputc(ch, new_fp); \n\n    /* Find last version (dont zero these baddies) */\n    last_version = 0;\n    for (i=0; i<pdf->n_xrefs; i++)\n      if (pdf->xrefs[i].version)\n        last_version = pdf->xrefs[i].version;\n   \n    /* Zero mod objects from all but the most recent version\n     * Zero del objects from all versions\n     */\n    fseek(new_fp, 0, SEEK_SET);\n    for (i=0; i<pdf->n_xrefs; i++)\n    {\n        for (j=0; j<pdf->xrefs[i].n_entries; j++)\n          if (!pdf->xrefs[i].entries[j].obj_id)\n            continue;\n          else\n          {\n              switch (pdf_get_object_status(pdf, i, j))\n              {\n                  case 'M':\n                      if (pdf->xrefs[i].version != last_version)\n                        pdf_zero_object(new_fp, pdf, i, j);\n                      break;\n\n                  case 'D':\n                      pdf_zero_object(new_fp, pdf, i, j);\n                      break;\n\n                  default:\n                      break;\n              }\n          }\n    }\n\n    /* Clean */\n    free(new_name);\n    fclose(new_fp);\n}\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 0
      },
      {
        "idx": 80766,
        "reasoning": "This code snippet presents a `usage` function that simply prints help information and exits. It doesn't perform any memory allocation, file handling, or operations that could introduce vulnerabilities, and the commit message indicates fixes were applied elsewhere to address memory issues\u2014not within this function itself.",
        "func": "static void usage(void)\n{\n    printf(EXEC_NAME \" Copyright (C) 2008-2010, 2012, 2013, 2017, 2019\"\n           \"Matt Davis (enferex)\\n\"\n           \"Special thanks to all contributors and the 757 crew.\\n\"\n           \"This program comes with ABSOLUTELY NO WARRANTY\\n\"\n           \"This is free software, and you are welcome to redistribute it\\n\"\n           \"under certain conditions.  For details see the file 'LICENSE'\\n\"\n           \"that came with this software or visit:\\n\"\n           \"<http://www.gnu.org/licenses/gpl-3.0.txt>\\n\\n\");\n    \n    printf(\"-- \" EXEC_NAME \" v\" VER\" --\\n\"\n           \"Usage: ./\" EXEC_NAME \" <file.pdf> [-i] [-w] [-q] [-s]\\n\"\n           \"\\t -i Display PDF creator information\\n\"\n           \"\\t -w Write the PDF versions and summary to disk\\n\"\n           \"\\t -q Display only the number of versions contained in the PDF\\n\"\n           \"\\t -s Scrub the previous history data from the specified PDF\\n\");\n\n    exit(0);\n}\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 0
      },
      {
        "idx": 80767,
        "reasoning": "This code is likely safe, as the commit message explicitly states it addresses memory issues related to dynamic allocations and includes zeroing/sanity checks\u2014mitigating common vulnerabilities like heap overflows or use-after-free. The `realloc` call increases allocation size in increments, and while `realloc` can fail, a failure isn't directly exploitable here without further context on error handling (which isn't shown).",
        "func": "static void add_kid(int id, xref_t *xref)\n{\n    /* Make some space */\n    if (((xref->n_kids + 1) * KID_SIZE) > (xref->n_kids_allocs*KIDS_PER_ALLOC))\n      xref->kids = realloc(\n          xref->kids, (++xref->n_kids_allocs)*(KIDS_PER_ALLOC * KID_SIZE));\n\n    xref->kids[xref->n_kids++] = id;\n}\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3961,
        "reasoning": "The code is vulnerable because the `sz` value, calculated as `pdf->xrefs[i].end - ftell(fp)`, is used directly in a `malloc` call without validation, potentially leading to a very large allocation or an incorrect size. This can result in a denial-of-service via memory exhaustion or, as the CVE describes, an out-of-bounds write if `fread` reads beyond the intended buffer due to an inaccurate `sz` calculation.",
        "func": "void pdf_load_pages_kids(FILE *fp, pdf_t *pdf)\n{\n    int     i, id, dummy;\n    char   *buf, *c;\n    long    start, sz;\n\n    start = ftell(fp);\n\n    /* Load all kids for all xref tables (versions) */\n    for (i=0; i<pdf->n_xrefs; i++)\n    {\n        if (pdf->xrefs[i].version && (pdf->xrefs[i].end != 0))\n        {\n            fseek(fp, pdf->xrefs[i].start, SEEK_SET);\n            while (SAFE_F(fp, (fgetc(fp) != 't')))\n                ; /* Iterate to trailer */\n \n             /* Get root catalog */\n             sz = pdf->xrefs[i].end - ftell(fp);\n            buf = malloc(sz + 1);\n             SAFE_E(fread(buf, 1, sz, fp), sz, \"Failed to load /Root.\\n\");\n             buf[sz] = '\\0';\n             if (!(c = strstr(buf, \"/Root\")))\n            {\n                free(buf);\n                continue;\n            }\n\n            /* Jump to catalog (root) */\n            id = atoi(c + strlen(\"/Root\") + 1);\n            free(buf);\n            buf = get_object(fp, id, &pdf->xrefs[i], NULL, &dummy);\n            if (!buf || !(c = strstr(buf, \"/Pages\")))\n            {\n                free(buf);\n                continue;\n            }\n\n            /* Start at the first Pages obj and get kids */\n            id = atoi(c + strlen(\"/Pages\") + 1);\n            load_kids(fp, id, &pdf->xrefs[i]);\n            free(buf); \n        }\n    }\n            \n    fseek(fp, start, SEEK_SET);\n}\n",
        "commit_message": "Zero and sanity check all dynamic allocs.\n\nThis addresses the memory issues in Issue #6 expressed in\ncalloc_some.pdf and malloc_some.pdf",
        "cve_desc": "An issue was discovered in PDFResurrect before 0.18. pdf_load_pages_kids in pdf.c doesn't validate a certain size value, which leads to a malloc failure and out-of-bounds write.",
        "target": 1
      }
    ]
  },
  "perl5": {
    "0": [
      {
        "idx": 302316,
        "reasoning": "This code snippet is not directly vulnerable to the integer overflow described in the commit message (CVE-2020-10543). The commit message refers to a vulnerability in the `regcomp.c` file related to size calculations during regex compilation, while this code snippet focuses on *dumping* a pre-compiled regular expression for debugging purposes \u2013 it doesn't perform any calculations that could lead to the overflow.",
        "func": "void\nPerl_regdump(pTHX_ const regexp *r)\n{\n#ifdef DEBUGGING\n    int i;\n    SV * const sv = sv_newmortal();\n    SV *dsv= sv_newmortal();\n    RXi_GET_DECL(r, ri);\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_REGDUMP;\n\n    (void)dumpuntil(r, ri->program, ri->program + 1, NULL, NULL, sv, 0, 0);\n\n    /* Header fields of interest. */\n    for (i = 0; i < 2; i++) {\n        if (r->substrs->data[i].substr) {\n            RE_PV_QUOTED_DECL(s, 0, dsv,\n                            SvPVX_const(r->substrs->data[i].substr),\n                            RE_SV_DUMPLEN(r->substrs->data[i].substr),\n                            PL_dump_re_max_len);\n            Perl_re_printf( aTHX_\n                          \"%s %s%s at %\" IVdf \"..%\" UVuf \" \",\n                          i ? \"floating\" : \"anchored\",\n                          s,\n                          RE_SV_TAIL(r->substrs->data[i].substr),\n                          (IV)r->substrs->data[i].min_offset,\n                          (UV)r->substrs->data[i].max_offset);\n        }\n        else if (r->substrs->data[i].utf8_substr) {\n            RE_PV_QUOTED_DECL(s, 1, dsv,\n                            SvPVX_const(r->substrs->data[i].utf8_substr),\n                            RE_SV_DUMPLEN(r->substrs->data[i].utf8_substr),\n                            30);\n            Perl_re_printf( aTHX_\n                          \"%s utf8 %s%s at %\" IVdf \"..%\" UVuf \" \",\n                          i ? \"floating\" : \"anchored\",\n                          s,\n                          RE_SV_TAIL(r->substrs->data[i].utf8_substr),\n                          (IV)r->substrs->data[i].min_offset,\n                          (UV)r->substrs->data[i].max_offset);\n        }\n    }\n\n    if (r->check_substr || r->check_utf8)\n        Perl_re_printf( aTHX_\n\t\t      (const char *)\n\t\t      (   r->check_substr == r->substrs->data[1].substr\n\t\t       && r->check_utf8   == r->substrs->data[1].utf8_substr\n\t\t       ? \"(checking floating\" : \"(checking anchored\"));\n    if (r->intflags & PREGf_NOSCAN)\n        Perl_re_printf( aTHX_  \" noscan\");\n    if (r->extflags & RXf_CHECK_ALL)\n        Perl_re_printf( aTHX_  \" isall\");\n    if (r->check_substr || r->check_utf8)\n        Perl_re_printf( aTHX_  \") \");\n\n    if (ri->regstclass) {\n        regprop(r, sv, ri->regstclass, NULL, NULL);\n        Perl_re_printf( aTHX_  \"stclass %s \", SvPVX_const(sv));\n    }\n    if (r->intflags & PREGf_ANCH) {\n        Perl_re_printf( aTHX_  \"anchored\");\n        if (r->intflags & PREGf_ANCH_MBOL)\n            Perl_re_printf( aTHX_  \"(MBOL)\");\n        if (r->intflags & PREGf_ANCH_SBOL)\n            Perl_re_printf( aTHX_  \"(SBOL)\");\n        if (r->intflags & PREGf_ANCH_GPOS)\n            Perl_re_printf( aTHX_  \"(GPOS)\");\n        Perl_re_printf( aTHX_ \" \");\n    }\n    if (r->intflags & PREGf_GPOS_SEEN)\n        Perl_re_printf( aTHX_  \"GPOS:%\" UVuf \" \", (UV)r->gofs);\n    if (r->intflags & PREGf_SKIP)\n        Perl_re_printf( aTHX_  \"plus \");\n    if (r->intflags & PREGf_IMPLICIT)\n        Perl_re_printf( aTHX_  \"implicit \");\n    Perl_re_printf( aTHX_  \"minlen %\" IVdf \" \", (IV)r->minlen);\n    if (r->extflags & RXf_EVAL_SEEN)\n        Perl_re_printf( aTHX_  \"with eval \");\n    Perl_re_printf( aTHX_  \"\\n\");\n    DEBUG_FLAGS_r({\n        regdump_extflags(\"r->extflags: \", r->extflags);\n        regdump_intflags(\"r->intflags: \", r->intflags);\n    });\n#else\n    PERL_ARGS_ASSERT_REGDUMP;\n    PERL_UNUSED_CONTEXT;\n    PERL_UNUSED_ARG(r);\n#endif\t/* DEBUGGING */",
        "commit_message": "regcomp.c: Prevent integer overflow from nested regex quantifiers.\n\n(CVE-2020-10543) On 32bit systems the size calculations for nested regular\nexpression quantifiers could overflow causing heap memory corruption.\n\nFixes: Perl/perl5-security#125\n(cherry picked from commit bfd31397db5dc1a5c5d3e0a1f753a4f89a736e71)",
        "cve_desc": "Perl before 5.30.3 on 32-bit platforms allows a heap-based buffer overflow because nested regular expression quantifiers have an integer overflow.",
        "target": 0
      },
      {
        "idx": 302317,
        "reasoning": "This code snippet is **not directly vulnerable** to the described integer overflow (CVE-2020-10543). The commit message indicates the vulnerability resided in size calculations for *nested regex quantifiers*, while this code focuses on emitting a single regex node and filling its argument \u2013 it doesn\u2019t appear to be involved in the complex quantifier calculations where the overflow occurred. \n\n\n\n",
        "func": "STATIC regnode_offset /* Location. */\nS_reganode(pTHX_ RExC_state_t *pRExC_state, U8 op, U32 arg)\n{\n    const regnode_offset ret = regnode_guts(pRExC_state, op, regarglen[op], \"reganode\");\n    regnode_offset ptr = ret;\n\n    PERL_ARGS_ASSERT_REGANODE;\n\n    /* ANYOF are special cased to allow non-length 1 args */\n    assert(regarglen[op] == 1);\n\n    FILL_ADVANCE_NODE_ARG(ptr, op, arg);\n    RExC_emit = ptr;\n    return(ret);",
        "commit_message": "regcomp.c: Prevent integer overflow from nested regex quantifiers.\n\n(CVE-2020-10543) On 32bit systems the size calculations for nested regular\nexpression quantifiers could overflow causing heap memory corruption.\n\nFixes: Perl/perl5-security#125\n(cherry picked from commit bfd31397db5dc1a5c5d3e0a1f753a4f89a736e71)",
        "cve_desc": "Perl before 5.30.3 on 32-bit platforms allows a heap-based buffer overflow because nested regular expression quantifiers have an integer overflow.",
        "target": 0
      },
      {
        "idx": 302318,
        "reasoning": "This code snippet focuses on constructing fully qualified names for Perl symbols and is unrelated to the regular expression compilation vulnerability described in the commit message (CVE-2020-10543). The vulnerability lies within `regcomp.c` concerning nested regex quantifiers and heap memory corruption, while this code handles string manipulation for names and doesn't involve regex processing or size calculations prone to integer overflows.\n\n\n\n",
        "func": "STATIC SV *\nS_get_fq_name(pTHX_\n              const char * const name,    /* The first non-blank in the \\p{}, \\P{} */\n              const Size_t name_len,      /* Its length in bytes, not including any trailing space */\n              const bool is_utf8,         /* ? Is 'name' encoded in UTF-8 */\n              const bool has_colon_colon\n             )\n{\n    /* Returns a mortal SV containing the fully qualified version of the input\n     * name */\n\n    SV * fq_name;\n\n    fq_name = newSVpvs_flags(\"\", SVs_TEMP);\n\n    /* Use the current package if it wasn't included in our input */\n    if (! has_colon_colon) {\n        const HV * pkg = (IN_PERL_COMPILETIME)\n                         ? PL_curstash\n                         : CopSTASH(PL_curcop);\n        const char* pkgname = HvNAME(pkg);\n\n        Perl_sv_catpvf(aTHX_ fq_name, \"%\" UTF8f,\n                      UTF8fARG(is_utf8, strlen(pkgname), pkgname));\n        sv_catpvs(fq_name, \"::\");\n    }\n\n    Perl_sv_catpvf(aTHX_ fq_name, \"%\" UTF8f,\n                         UTF8fARG(is_utf8, name_len, name));\n    return fq_name;",
        "commit_message": "regcomp.c: Prevent integer overflow from nested regex quantifiers.\n\n(CVE-2020-10543) On 32bit systems the size calculations for nested regular\nexpression quantifiers could overflow causing heap memory corruption.\n\nFixes: Perl/perl5-security#125\n(cherry picked from commit bfd31397db5dc1a5c5d3e0a1f753a4f89a736e71)",
        "cve_desc": "Perl before 5.30.3 on 32-bit platforms allows a heap-based buffer overflow because nested regular expression quantifiers have an integer overflow.",
        "target": 0
      },
      {
        "idx": 302319,
        "reasoning": "This code snippet focuses on handling named backreferences within regular expressions and doesn't directly involve the size calculations for nested quantifiers mentioned in the commit message and CVE. The vulnerability (CVE-2020-10543) resided in the regex compilation process where nested quantifiers could lead to integer overflows during size calculations, a process not represented in this specific function dealing with backreference handling.\n\n\n\n",
        "func": "PERL_STATIC_INLINE regnode_offset\nS_handle_named_backref(pTHX_ RExC_state_t *pRExC_state,\n                             I32 *flagp,\n                             char * parse_start,\n                             char ch\n                      )\n{\n    regnode_offset ret;\n    char* name_start = RExC_parse;\n    U32 num = 0;\n    SV *sv_dat = reg_scan_name(pRExC_state, REG_RSN_RETURN_DATA);\n    GET_RE_DEBUG_FLAGS_DECL;\n\n    PERL_ARGS_ASSERT_HANDLE_NAMED_BACKREF;\n\n    if (RExC_parse == name_start || *RExC_parse != ch) {\n        /* diag_listed_as: Sequence \\%s... not terminated in regex; marked by <-- HERE in m/%s/ */\n        vFAIL2(\"Sequence %.3s... not terminated\", parse_start);\n    }\n\n    if (sv_dat) {\n        num = add_data( pRExC_state, STR_WITH_LEN(\"S\"));\n        RExC_rxi->data->data[num]=(void*)sv_dat;\n        SvREFCNT_inc_simple_void_NN(sv_dat);\n    }\n    RExC_sawback = 1;\n    ret = reganode(pRExC_state,\n                   ((! FOLD)\n                     ? NREF\n                     : (ASCII_FOLD_RESTRICTED)\n                       ? NREFFA\n                       : (AT_LEAST_UNI_SEMANTICS)\n                         ? NREFFU\n                         : (LOC)\n                           ? NREFFL\n                           : NREFF),\n                    num);\n    *flagp |= HASWIDTH;\n\n    Set_Node_Offset(REGNODE_p(ret), parse_start+1);\n    Set_Node_Cur_Length(REGNODE_p(ret), parse_start);\n\n    nextchar(pRExC_state);\n    return ret;",
        "commit_message": "regcomp.c: Prevent integer overflow from nested regex quantifiers.\n\n(CVE-2020-10543) On 32bit systems the size calculations for nested regular\nexpression quantifiers could overflow causing heap memory corruption.\n\nFixes: Perl/perl5-security#125\n(cherry picked from commit bfd31397db5dc1a5c5d3e0a1f753a4f89a736e71)",
        "cve_desc": "Perl before 5.30.3 on 32-bit platforms allows a heap-based buffer overflow because nested regular expression quantifiers have an integer overflow.",
        "target": 0
      }
    ],
    "1": []
  },
  "phosphor-host-ipmid": {
    "0": [],
    "1": []
  },
  "php-src": {
    "0": [],
    "1": []
  },
  "pigeonhole": {
    "0": [
      {
        "idx": 285190,
        "reasoning": "This code snippet is not directly vulnerable to the issue described in the commit message (buffer overflow in `str_unescape()`). The commit focuses on ensuring `str_unescape()` doesn't write past allocated memory, but this code snippet deals with managing the `parser->root_list` array and appending arguments \u2013 it doesn't directly call or interact with the `str_unescape()` function itself.\n\n\n\n",
        "func": "static int finish_line\n(struct managesieve_parser *parser, unsigned int count,\n\tconst struct managesieve_arg **args_r)\n{\n\tstruct managesieve_arg *arg;\n\tint ret = array_count(&parser->root_list);\n\n\tparser->line_size += parser->cur_pos;\n\ti_stream_skip(parser->input, parser->cur_pos);\n\tparser->cur_pos = 0;\n\n\t/* fill the missing parameters with NILs */\n\twhile (count > array_count(&parser->root_list)) {\n\t\targ = array_append_space(&parser->root_list);\n\t\targ->type = MANAGESIEVE_ARG_NONE;\n\t}\n\targ = array_append_space(&parser->root_list);\n\targ->type = MANAGESIEVE_ARG_EOL;\n\n\t*args_r = array_get(&parser->root_list, &count);\n\treturn ret;\n}",
        "commit_message": "lib-managesieve: Make sure str_unescape() won't be writing past allocated memory\n\nThe previous commit should already prevent this, but this makes sure it\ncan't become broken in the future either. It makes the performance a tiny\nbit worse, but that's not practically noticeable.",
        "cve_desc": "In Dovecot before 2.2.36.4 and 2.3.x before 2.3.7.2 (and Pigeonhole before 0.5.7.2), protocol processing can fail for quoted strings. This occurs because '\\0' characters are mishandled, and can lead to out-of-bounds writes and remote code execution.",
        "target": 0
      },
      {
        "idx": 285191,
        "reasoning": "This code addresses a potential buffer overflow in the `str_unescape()` function by explicitly ensuring it doesn't write past allocated memory, even if a previous fix were to be broken. The commit message states the performance impact is negligible, indicating the added safety check doesn't introduce significant drawbacks, and the use of `p_strndup` further mitigates risks by limiting the copied string length.\n\n\n\n",
        "func": "static void managesieve_parser_save_arg(struct managesieve_parser *parser,\n\t\t\t\t const unsigned char *data, size_t size)\n{\n\tstruct managesieve_arg *arg;\n\tchar *str;\n\n\targ = managesieve_arg_create(parser);\n\n\tswitch (parser->cur_type) {\n\tcase ARG_PARSE_ATOM:\n\t\t/* simply save the string */\n\t\targ->type = MANAGESIEVE_ARG_ATOM;\n\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\targ->str_len = size;\n\t\tbreak;\n\tcase ARG_PARSE_STRING:\n\t\t/* data is quoted and may contain escapes. */\n\t\tif ((parser->flags & MANAGESIEVE_PARSE_FLAG_STRING_STREAM) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING_STREAM;\n\t\t\targ->_data.str_stream = parser->str_stream;\n\t\t} else {\n\t\t\ti_assert(size > 0);\n\n\t\t\targ->type = MANAGESIEVE_ARG_STRING;\n\t\t\tstr = p_strndup(parser->pool, data+1, size-1);\n\n\t\t\t/* remove the escapes */\n\t\t\tif (parser->str_first_escape >= 0 &&\n\t\t\t\t  (parser->flags & MANAGESIEVE_PARSE_FLAG_NO_UNESCAPE) == 0)\n\t\t\t\t(void)str_unescape(str);\n\n\t\t\targ->_data.str = str;\n\t\t\targ->str_len = strlen(str);\n\t\t}\n\t\tbreak;\n\tcase ARG_PARSE_LITERAL_DATA:\n\t\tif ((parser->flags & MANAGESIEVE_PARSE_FLAG_STRING_STREAM) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING_STREAM;\n\t\t\targ->_data.str_stream = parser->str_stream;\n\t\t} else if ((parser->flags & MANAGESIEVE_PARSE_FLAG_LITERAL_TYPE) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_LITERAL;\n\t\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\t\targ->str_len = size;\n\t\t} else {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING;\n\t\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\t\targ->str_len = size;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\ti_unreached();\n\t}\n\n\tparser->cur_type = ARG_PARSE_NONE;\n}",
        "commit_message": "lib-managesieve: Make sure str_unescape() won't be writing past allocated memory\n\nThe previous commit should already prevent this, but this makes sure it\ncan't become broken in the future either. It makes the performance a tiny\nbit worse, but that's not practically noticeable.",
        "cve_desc": "In Dovecot before 2.2.36.4 and 2.3.x before 2.3.7.2 (and Pigeonhole before 0.5.7.2), protocol processing can fail for quoted strings. This occurs because '\\0' characters are mishandled, and can lead to out-of-bounds writes and remote code execution.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 198929,
        "reasoning": "The code is vulnerable because the `str_unescape` function, called to remove escapes from strings, doesn't properly handle null bytes (`\\0`) within the input string. This mishandling of null bytes can lead to `str_unescape` writing past the allocated memory buffer, resulting in an out-of-bounds write and potentially remote code execution as described in the CVE.",
        "func": "static void managesieve_parser_save_arg(struct managesieve_parser *parser,\n\t\t\t\t const unsigned char *data, size_t size)\n{\n\tstruct managesieve_arg *arg;\n\tchar *str;\n\n\targ = managesieve_arg_create(parser);\n\n\tswitch (parser->cur_type) {\n\tcase ARG_PARSE_ATOM:\n\t\t/* simply save the string */\n\t\targ->type = MANAGESIEVE_ARG_ATOM;\n\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\targ->str_len = size;\n\t\tbreak;\n\tcase ARG_PARSE_STRING:\n\t\t/* data is quoted and may contain escapes. */\n\t\tif ((parser->flags & MANAGESIEVE_PARSE_FLAG_STRING_STREAM) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING_STREAM;\n\t\t\targ->_data.str_stream = parser->str_stream;\n\t\t} else {\n\t\t\ti_assert(size > 0);\n\n\t\t\targ->type = MANAGESIEVE_ARG_STRING;\n\t\t\tstr = p_strndup(parser->pool, data+1, size-1);\n\n\t\t\t/* remove the escapes */\n\t\t\tif (parser->str_first_escape >= 0 &&\n\t\t\t\t  (parser->flags & MANAGESIEVE_PARSE_FLAG_NO_UNESCAPE) == 0) {\n\t\t\t\t/* -1 because we skipped the '\"' prefix */\n\t\t\t\tstr_unescape(str + parser->str_first_escape-1);\n\t\t\t}\n\n\t\t\targ->_data.str = str;\n\t\t\targ->str_len = strlen(str);\n\t\t}\n\t\tbreak;\n\tcase ARG_PARSE_LITERAL_DATA:\n\t\tif ((parser->flags & MANAGESIEVE_PARSE_FLAG_STRING_STREAM) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING_STREAM;\n\t\t\targ->_data.str_stream = parser->str_stream;\n\t\t} else if ((parser->flags & MANAGESIEVE_PARSE_FLAG_LITERAL_TYPE) != 0) {\n\t\t\targ->type = MANAGESIEVE_ARG_LITERAL;\n\t\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\t\targ->str_len = size;\n\t\t} else {\n\t\t\targ->type = MANAGESIEVE_ARG_STRING;\n\t\t\targ->_data.str = p_strndup(parser->pool, data, size);\n\t\t\targ->str_len = size;\n\t\t}\n\t\tbreak;\n\tdefault:\n\t\ti_unreached();\n\t}\n\n\tparser->cur_type = ARG_PARSE_NONE;\n}",
        "commit_message": "lib-managesieve: Make sure str_unescape() won't be writing past allocated memory\n\nThe previous commit should already prevent this, but this makes sure it\ncan't become broken in the future either. It makes the performance a tiny\nbit worse, but that's not practically noticeable.",
        "cve_desc": "In Dovecot before 2.2.36.4 and 2.3.x before 2.3.7.2 (and Pigeonhole before 0.5.7.2), protocol processing can fail for quoted strings. This occurs because '\\0' characters are mishandled, and can lead to out-of-bounds writes and remote code execution.",
        "target": 1
      }
    ]
  },
  "pjproject": {
    "0": [],
    "1": []
  },
  "poppler": {
    "0": [
      {
        "idx": 11373,
        "reasoning": "This code snippet is not directly vulnerable to CVE-2009-3607, as it simply constructs a `PopplerPage` object and initializes its members. The vulnerability likely resided in how the `PopplerDocument` or `Page` structures were handled *before* this function was called, and this code appears to be a safe consumer of those objects, performing standard object creation and referencing.\n\n\n\n",
        "func": "_poppler_page_new (PopplerDocument *document, Page *page, int index)\n{\n  PopplerPage *poppler_page;\n\n  g_return_val_if_fail (POPPLER_IS_DOCUMENT (document), NULL);\n\n  poppler_page = (PopplerPage *) g_object_new (POPPLER_TYPE_PAGE, NULL, NULL);\n  poppler_page->document = (PopplerDocument *) g_object_ref (document);\n  poppler_page->page = page;\n  poppler_page->index = index;\n\n  return poppler_page;\n}\n",
        "commit_message": "[glib] Fix CVE-2009-3607",
        "cve_desc": "Integer overflow in the create_surface_from_thumbnail_data function in glib/poppler-page.cc in Poppler 0.x allows remote attackers to cause a denial of service (memory corruption) or possibly execute arbitrary code via a crafted PDF document that triggers a heap-based buffer overflow.  NOTE: some of these details are obtained from third party information.",
        "target": 0
      },
      {
        "idx": 11374,
        "reasoning": "This code snippet addresses CVE-2009-3607, indicating a *fix* for a previously identified vulnerability\u2014it doesn't *introduce* one. The commit message explicitly states it's a fix, and without further context suggesting new issues within this specific code, it's considered safe based on the information provided.\n\n\n\n",
        "func": "_poppler_page_render_to_pixbuf (PopplerPage *page,\n\t\t\t\tint src_x, int src_y,\n\t\t\t\tint src_width, int src_height,\n\t\t\t\tdouble scale,\n\t\t\t\tint rotation,\n\t\t\t\tGBool printing,\n\t\t\t\tGdkPixbuf *pixbuf)\n{\n  OutputDevData data;\n  \n  poppler_page_prepare_output_dev (page, scale, rotation, FALSE, &data);\n\n  page->page->displaySlice(page->document->output_dev,\n\t\t\t   72.0 * scale, 72.0 * scale,\n\t\t\t   rotation,\n\t\t\t   gFalse, /* useMediaBox */\n\t\t\t   gTrue, /* Crop */\n\t\t\t   src_x, src_y,\n\t\t\t   src_width, src_height,\n\t\t\t   printing,\n\t\t\t   page->document->doc->getCatalog (),\n\t\t\t   NULL, NULL,\n\t\t\t   printing ? poppler_print_annot_cb : NULL, NULL);\n  \n  poppler_page_copy_to_pixbuf (page, pixbuf, &data);\n}\n",
        "commit_message": "[glib] Fix CVE-2009-3607",
        "cve_desc": "Integer overflow in the create_surface_from_thumbnail_data function in glib/poppler-page.cc in Poppler 0.x allows remote attackers to cause a denial of service (memory corruption) or possibly execute arbitrary code via a crafted PDF document that triggers a heap-based buffer overflow.  NOTE: some of these details are obtained from third party information.",
        "target": 0
      },
      {
        "idx": 11375,
        "reasoning": "This code snippet addresses CVE-2009-3607, which was a vulnerability related to integer overflows when handling image dimensions, and the provided code includes checks to limit `cairo_width` and `cairo_height` to the dimensions of the `pixbuf`, preventing potential overflows. Therefore, the fix implemented appears to mitigate the vulnerability and the code is not flagged as vulnerable based on this snippet.\n\n\n\n",
        "func": "copy_cairo_surface_to_pixbuf (cairo_surface_t *surface,\n\t\t\t      unsigned char   *data,\n\t\t\t      GdkPixbuf       *pixbuf)\n{\n  int cairo_width, cairo_height, cairo_rowstride;\n  unsigned char *pixbuf_data, *dst, *cairo_data;\n  int pixbuf_rowstride, pixbuf_n_channels;\n  unsigned int *src;\n  int x, y;\n\n  cairo_width = cairo_image_surface_get_width (surface);\n  cairo_height = cairo_image_surface_get_height (surface);\n  cairo_rowstride = cairo_width * 4;\n  cairo_data = data;\n\n  pixbuf_data = gdk_pixbuf_get_pixels (pixbuf);\n  pixbuf_rowstride = gdk_pixbuf_get_rowstride (pixbuf);\n  pixbuf_n_channels = gdk_pixbuf_get_n_channels (pixbuf);\n\n  if (cairo_width > gdk_pixbuf_get_width (pixbuf))\n    cairo_width = gdk_pixbuf_get_width (pixbuf);\n  if (cairo_height > gdk_pixbuf_get_height (pixbuf))\n    cairo_height = gdk_pixbuf_get_height (pixbuf);\n  for (y = 0; y < cairo_height; y++)\n    {\n      src = (unsigned int *) (cairo_data + y * cairo_rowstride);\n      dst = pixbuf_data + y * pixbuf_rowstride;\n      for (x = 0; x < cairo_width; x++) \n\t{\n\t  dst[0] = (*src >> 16) & 0xff;\n\t  dst[1] = (*src >> 8) & 0xff; \n\t  dst[2] = (*src >> 0) & 0xff;\n\t  if (pixbuf_n_channels == 4)\n\t      dst[3] = (*src >> 24) & 0xff;\n\t  dst += pixbuf_n_channels;\n\t  src++;\n\t}\n    }\n}\t\n",
        "commit_message": "[glib] Fix CVE-2009-3607",
        "cve_desc": "Integer overflow in the create_surface_from_thumbnail_data function in glib/poppler-page.cc in Poppler 0.x allows remote attackers to cause a denial of service (memory corruption) or possibly execute arbitrary code via a crafted PDF document that triggers a heap-based buffer overflow.  NOTE: some of these details are obtained from third party information.",
        "target": 0
      },
      {
        "idx": 11376,
        "reasoning": "This code snippet is safe and doesn't introduce a vulnerability. The commit message explicitly states it *fixes* CVE-2009-3607, implying the previous code *was* vulnerable, but this specific snippet itself is a simple comparison function and doesn't exhibit any immediately obvious security flaws like buffer overflows or improper input handling. \n\n\n\n",
        "func": "image_draw_decide_cb (int image_id, void *data)\n{\n  return (image_id == GPOINTER_TO_INT (data));\n}\n",
        "commit_message": "[glib] Fix CVE-2009-3607",
        "cve_desc": "Integer overflow in the create_surface_from_thumbnail_data function in glib/poppler-page.cc in Poppler 0.x allows remote attackers to cause a denial of service (memory corruption) or possibly execute arbitrary code via a crafted PDF document that triggers a heap-based buffer overflow.  NOTE: some of these details are obtained from third party information.",
        "target": 0
      },
      {
        "idx": 11377,
        "reasoning": "This code addresses CVE-2009-3607 by ensuring proper reference counting of the `PopplerAnnot` object when copying an annotation mapping. The `g_object_ref` call increments the reference count of the annotation, preventing a use-after-free if the original annotation is destroyed elsewhere, thus fixing the vulnerability and making the code safe.\n\n\n\n",
        "func": "poppler_annot_mapping_copy (PopplerAnnotMapping *mapping)\n{\n  PopplerAnnotMapping *new_mapping;\n\n  new_mapping = poppler_annot_mapping_new ();\n\n  *new_mapping = *mapping;\n  if (mapping->annot)\n    new_mapping->annot = (PopplerAnnot *) g_object_ref (mapping->annot);\n\n  return new_mapping;\n}\n",
        "commit_message": "[glib] Fix CVE-2009-3607",
        "cve_desc": "Integer overflow in the create_surface_from_thumbnail_data function in glib/poppler-page.cc in Poppler 0.x allows remote attackers to cause a denial of service (memory corruption) or possibly execute arbitrary code via a crafted PDF document that triggers a heap-based buffer overflow.  NOTE: some of these details are obtained from third party information.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 27,
        "reasoning": "The code is vulnerable due to a potential integer overflow in the `gmallocn` calls within the `splashModeRGB8` and `splashModeXBGR8` cases, as well as the `splashModeCMYK8` case, where the size calculation `n * 3` or `n * 4` could exceed the maximum allocatable size. This overflow can lead to a heap buffer overflow, potentially causing a denial of service or even arbitrary code execution, aligning with the described CVE involving multiple integer overflows in Poppler.",
        "func": "void SplashOutputDev::drawImage(GfxState *state, Object *ref, Stream *str,\n\t\t\t\tint width, int height,\n\t\t\t\tGfxImageColorMap *colorMap,\n\t\t\t\tint *maskColors, GBool inlineImg) {\n  double *ctm;\n  SplashCoord mat[6];\n  SplashOutImageData imgData;\n  SplashColorMode srcMode;\n  SplashImageSource src;\n  GfxGray gray;\n  GfxRGB rgb;\n#if SPLASH_CMYK\n  GfxCMYK cmyk;\n#endif\n  Guchar pix;\n  int n, i;\n\n  ctm = state->getCTM();\n  mat[0] = ctm[0];\n  mat[1] = ctm[1];\n  mat[2] = -ctm[2];\n  mat[3] = -ctm[3];\n  mat[4] = ctm[2] + ctm[4];\n  mat[5] = ctm[3] + ctm[5];\n\n  imgData.imgStr = new ImageStream(str, width,\n\t\t\t\t   colorMap->getNumPixelComps(),\n\t\t\t\t   colorMap->getBits());\n  imgData.imgStr->reset();\n  imgData.colorMap = colorMap;\n  imgData.maskColors = maskColors;\n  imgData.colorMode = colorMode;\n  imgData.width = width;\n  imgData.height = height;\n  imgData.y = 0;\n\n  imgData.lookup = NULL;\n  if (colorMap->getNumPixelComps() == 1) {\n    n = 1 << colorMap->getBits();\n    switch (colorMode) {\n    case splashModeMono1:\n    case splashModeMono8:\n      imgData.lookup = (SplashColorPtr)gmalloc(n);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getGray(&pix, &gray);\n\timgData.lookup[i] = colToByte(gray);\n      }\n      break;\n    case splashModeRGB8:\n    case splashModeBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[3*i] = colToByte(rgb.r);\n\timgData.lookup[3*i+1] = colToByte(rgb.g);\n\timgData.lookup[3*i+2] = colToByte(rgb.b);\n       }\n       break;\n     case splashModeXBGR8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 3);\n       for (i = 0; i < n; ++i) {\n \tpix = (Guchar)i;\n \tcolorMap->getRGB(&pix, &rgb);\n\timgData.lookup[4*i] = colToByte(rgb.r);\n\timgData.lookup[4*i+1] = colToByte(rgb.g);\n\timgData.lookup[4*i+2] = colToByte(rgb.b);\n\timgData.lookup[4*i+3] = 255;\n      }\n      break;\n#if SPLASH_CMYK\n    case splashModeCMYK8:\n      imgData.lookup = (SplashColorPtr)gmallocn(n, 4);\n      for (i = 0; i < n; ++i) {\n\tpix = (Guchar)i;\n\tcolorMap->getCMYK(&pix, &cmyk);\n\timgData.lookup[4*i] = colToByte(cmyk.c);\n\timgData.lookup[4*i+1] = colToByte(cmyk.m);\n\timgData.lookup[4*i+2] = colToByte(cmyk.y);\n\timgData.lookup[4*i+3] = colToByte(cmyk.k);\n      }\n      break;\n#endif\n      break;\n    }\n  }\n\n  if (colorMode == splashModeMono1) {\n    srcMode = splashModeMono8;\n  } else {\n    srcMode = colorMode;\n  }\n  src = maskColors ? &alphaImageSrc : &imageSrc;\n  splash->drawImage(src, &imgData, srcMode, maskColors ? gTrue : gFalse,\n\t\t    width, height, mat);\n  if (inlineImg) {\n    while (imgData.y < height) {\n      imgData.imgStr->getLine();\n      ++imgData.y;\n    }\n  }\n\n  gfree(imgData.lookup);\n  delete imgData.imgStr;\n  str->close();\n}\n",
        "commit_message": "Did a mistake in the gmalloc -> gmallocn commit, it's a 4 here not a 3",
        "cve_desc": "Multiple integer overflows in Poppler 0.10.5 and earlier allow remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF file, related to (1) glib/poppler-page.cc; (2) ArthurOutputDev.cc, (3) CairoOutputDev.cc, (4) GfxState.cc, (5) JBIG2Stream.cc, (6) PSOutputDev.cc, and (7) SplashOutputDev.cc in poppler/; and (8) SplashBitmap.cc, (9) Splash.cc, and (10) SplashFTFont.cc in splash/.  NOTE: this may overlap CVE-2009-0791.",
        "target": 1
      },
      {
        "idx": 28,
        "reasoning": "The code is vulnerable due to a potential integer overflow in the calculation `width * height * 4` within the `gmalloc` call, as a crafted PDF could provide large values for `width` and `height` leading to an excessively large allocation size that overflows an integer. This overflow can lead to a smaller-than-expected buffer being allocated, resulting in a buffer overflow when writing image data, potentially causing a denial of service or arbitrary code execution as described in the CVE.",
        "func": "void ArthurOutputDev::drawImage(GfxState *state, Object *ref, Stream *str,\n\t\t\t\tint width, int height,\n\t\t\t\tGfxImageColorMap *colorMap,\n\t\t\t\tint *maskColors, GBool inlineImg)\n{\n  unsigned char *buffer;\n  unsigned int *dest;\n  int x, y;\n  ImageStream *imgStr;\n  Guchar *pix;\n  int i;\n  double *ctm;\n   QMatrix matrix;\n   int is_identity_transform;\n   \n  buffer = (unsigned char *)gmalloc (width * height * 4);\n \n   /* TODO: Do we want to cache these? */\n   imgStr = new ImageStream(str, width,\n\t\t\t   colorMap->getNumPixelComps(),\n\t\t\t   colorMap->getBits());\n  imgStr->reset();\n  \n  /* ICCBased color space doesn't do any color correction\n   * so check its underlying color space as well */\n  is_identity_transform = colorMap->getColorSpace()->getMode() == csDeviceRGB ||\n\t\t  (colorMap->getColorSpace()->getMode() == csICCBased && \n\t\t  ((GfxICCBasedColorSpace*)colorMap->getColorSpace())->getAlt()->getMode() == csDeviceRGB);\n\n  if (maskColors) {\n    for (y = 0; y < height; y++) {\n      dest = (unsigned int *) (buffer + y * 4 * width);\n      pix = imgStr->getLine();\n      colorMap->getRGBLine (pix, dest, width);\n\n      for (x = 0; x < width; x++) {\n\tfor (i = 0; i < colorMap->getNumPixelComps(); ++i) {\n\t  \n\t  if (pix[i] < maskColors[2*i] * 255||\n\t      pix[i] > maskColors[2*i+1] * 255) {\n\t    *dest = *dest | 0xff000000;\n\t    break;\n\t  }\n\t}\n\tpix += colorMap->getNumPixelComps();\n\tdest++;\n      }\n    }\n\n    m_image = new QImage(buffer, width, height, QImage::Format_ARGB32);\n  }\n  else {\n    for (y = 0; y < height; y++) {\n      dest = (unsigned int *) (buffer + y * 4 * width);\n      pix = imgStr->getLine();\n      colorMap->getRGBLine (pix, dest, width);\n    }\n\n    m_image = new QImage(buffer, width, height, QImage::Format_RGB32);\n  }\n\n  if (m_image == NULL || m_image->isNull()) {\n    qDebug() << \"Null image\";\n    delete imgStr;\n    return;\n  }\n  ctm = state->getCTM();\n  matrix.setMatrix(ctm[0] / width, ctm[1] / width, -ctm[2] / height, -ctm[3] / height, ctm[2] + ctm[4], ctm[3] + ctm[5]);\n\n  m_painter->setMatrix(matrix, true);\n  m_painter->drawImage( QPoint(0,0), *m_image );\n  delete m_image;\n  m_image = 0;\n  free (buffer);\n  delete imgStr;\n\n}\n",
        "commit_message": "Be paranoid, use gmallocn or gmallocn3 in all gmalloc with *",
        "cve_desc": "Multiple integer overflows in Poppler 0.10.5 and earlier allow remote attackers to cause a denial of service (application crash) or possibly execute arbitrary code via a crafted PDF file, related to (1) glib/poppler-page.cc; (2) ArthurOutputDev.cc, (3) CairoOutputDev.cc, (4) GfxState.cc, (5) JBIG2Stream.cc, (6) PSOutputDev.cc, and (7) SplashOutputDev.cc in poppler/; and (8) SplashBitmap.cc, (9) Splash.cc, and (10) SplashFTFont.cc in splash/.  NOTE: this may overlap CVE-2009-0791.",
        "target": 1
      },
      {
        "idx": 65,
        "reasoning": "This code is vulnerable to a format string vulnerability because the `destFileName` provided by the user is directly used in `snprintf` without proper sanitization. An attacker can supply a malicious `destFileName` containing format string specifiers (like `%s`, `%x`, `%n`) which `snprintf` will interpret, potentially leading to a crash or even arbitrary code execution.",
        "func": "bool extractPages (const char *srcFileName, const char *destFileName) {\n  char pathName[4096];\n  GooString *gfileName = new GooString (srcFileName);\n  PDFDoc *doc = new PDFDoc (gfileName, NULL, NULL, NULL);\n\n  if (!doc->isOk()) {\n    error(errSyntaxError, -1, \"Could not extract page(s) from damaged file ('{0:s}')\", srcFileName);\n    return false;\n  }\n\n  if (firstPage == 0 && lastPage == 0) {\n    firstPage = 1;\n    lastPage = doc->getNumPages();\n  }\n  if (lastPage == 0)\n    lastPage = doc->getNumPages();\n  if (firstPage == 0)\n   if (firstPage == 0)\n     firstPage = 1;\n   if (firstPage != lastPage && strstr(destFileName, \"%d\") == NULL) {\n    error(errSyntaxError, -1, \"'{0:s}' must contain '%%d' if more than one page should be extracted\", destFileName);\n     return false;\n   }\n   for (int pageNo = firstPage; pageNo <= lastPage; pageNo++) {\n     snprintf (pathName, sizeof (pathName) - 1, destFileName, pageNo);\n     GooString *gpageName = new GooString (pathName);\n\t{\n\t  printUsage (\"pdfseparate\", \"<PDF-sourcefile> <PDF-pattern-destfile>\",\n\t\t      argDesc);\n\t}\n      if (printVersion || printHelp)\n\texitCode = 0;\n      goto err0;\n    }\n  globalParams = new GlobalParams();\n  ok = extractPages (argv[1], argv[2]);\n  if (ok) {\n    exitCode = 0;\n  }\n  delete globalParams;\n\nerr0:\n\n  return exitCode;\n}\n",
        "commit_message": "Allow only one %d in the filename\n\nFixes crashes if you had %s and similar in the filename\n\nInspired from patch by Pedro Ribeiro <pedrib@gmail.com>\n\nBug #69434",
        "cve_desc": "Format string vulnerability in the extractPages function in utils/pdfseparate.cc in poppler before 0.24.3 allows remote attackers to cause a denial of service (crash) via format string specifiers in a destination filename.",
        "target": 1
      },
      {
        "idx": 66,
        "reasoning": "The code is vulnerable to a stack-based buffer overflow because it uses `sprintf` to format the `destFileName` into the `pathName` buffer without sufficient bounds checking, potentially writing beyond the 1024-byte limit of `pathName`. This allows a malicious actor to craft a `destFileName` that, when combined with the page number, results in a string longer than `pathName` can hold, overwriting adjacent memory on the stack and potentially leading to a crash or arbitrary code execution as described in the CVE.",
        "func": " bool extractPages (const char *srcFileName, const char *destFileName) {\n  char pathName[1024];\n   GooString *gfileName = new GooString (srcFileName);\n   PDFDoc *doc = new PDFDoc (gfileName, NULL, NULL, NULL);\n \n  if (!doc->isOk()) {\n    error(errSyntaxError, -1, \"Could not extract page(s) from damaged file ('{0:s}')\", srcFileName);\n    return false;\n  }\n\n  if (firstPage == 0 && lastPage == 0) {\n    firstPage = 1;\n    lastPage = doc->getNumPages();\n  }\n  if (lastPage == 0)\n    lastPage = doc->getNumPages();\n  if (firstPage == 0)\n    firstPage = 1;\n  if (firstPage != lastPage && strstr(destFileName, \"%d\") == NULL) {\n    error(errSyntaxError, -1, \"'{0:s}' must contain '%%d' if more than one page should be extracted\", destFileName);\n     return false;\n   }\n   for (int pageNo = firstPage; pageNo <= lastPage; pageNo++) {\n    sprintf (pathName, destFileName, pageNo);\n     GooString *gpageName = new GooString (pathName);\n     int errCode = doc->savePageAs(gpageName, pageNo);\n     if ( errCode != errNone) {\n      delete gpageName;\n      delete gfileName;\n      return false;\n    }\n    delete gpageName;\n  }\n  delete gfileName;\n  return true;\n}\n",
        "commit_message": "pdfseparate: improve the path building\n\nMake use of snprintf to limit the output to the pathName buffer;\nwhile I'm there, expand its size to 4096 (might help longer paths),\nalthough a better fix would be dynamically allocate its length\n(and/or using GooString, maybe).",
        "cve_desc": "Stack-based buffer overflow in the extractPages function in utils/pdfseparate.cc in poppler before 0.24.2 allows remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via a source filename.",
        "target": 1
      },
      {
        "idx": 215,
        "reasoning": "The code is vulnerable to a NULL pointer dereference because it doesn't adequately check if `docs[i]->getCatalog()` returns a valid catalog before attempting to access its members like `getPage` or `getResourceDict`. This can occur with broken or maliciously crafted PDF documents, leading to a crash as described in the CVE, because accessing members of a null pointer results in undefined behavior.",
        "func": "int main (int argc, char *argv[])\n{\n  int objectsCount = 0;\n  Guint numOffset = 0;\n  std::vector<Object> pages;\n  std::vector<Guint> offsets;\n  XRef *yRef, *countRef;\n  FILE *f;\n  OutStream *outStr;\n  int i;\n  int j, rootNum;\n  std::vector<PDFDoc *>docs;\n  int majorVersion = 0;\n  int minorVersion = 0;\n  char *fileName = argv[argc - 1];\n  int exitCode;\n\n  exitCode = 99;\n  const GBool ok = parseArgs (argDesc, &argc, argv);\n  if (!ok || argc < 3 || printVersion || printHelp) {\n    fprintf(stderr, \"pdfunite version %s\\n\", PACKAGE_VERSION);\n    fprintf(stderr, \"%s\\n\", popplerCopyright);\n    fprintf(stderr, \"%s\\n\", xpdfCopyright);\n    if (!printVersion) {\n      printUsage(\"pdfunite\", \"<PDF-sourcefile-1>..<PDF-sourcefile-n> <PDF-destfile>\",\n\targDesc);\n    }\n    if (printVersion || printHelp)\n      exitCode = 0;\n    return exitCode;\n  }\n  exitCode = 0;\n  globalParams = new GlobalParams();\n\n  for (i = 1; i < argc - 1; i++) {\n    GooString *gfileName = new GooString(argv[i]);\n    PDFDoc *doc = new PDFDoc(gfileName, NULL, NULL, NULL);\n    if (doc->isOk() && !doc->isEncrypted()) {\n      docs.push_back(doc);\n      if (doc->getPDFMajorVersion() > majorVersion) {\n        majorVersion = doc->getPDFMajorVersion();\n        minorVersion = doc->getPDFMinorVersion();\n      } else if (doc->getPDFMajorVersion() == majorVersion) {\n        if (doc->getPDFMinorVersion() > minorVersion) {\n          minorVersion = doc->getPDFMinorVersion();\n        }\n      }\n    } else if (doc->isOk()) {\n      error(errUnimplemented, -1, \"Could not merge encrypted files ('{0:s}')\", argv[i]);\n      return -1;\n    } else {\n      error(errSyntaxError, -1, \"Could not merge damaged documents ('{0:s}')\", argv[i]);\n      return -1;\n    }\n  }\n\n  if (!(f = fopen(fileName, \"wb\"))) {\n    error(errIO, -1, \"Could not open file '{0:s}'\", fileName);\n    return -1;\n  }\n  outStr = new FileOutStream(f, 0);\n\n  yRef = new XRef();\n  countRef = new XRef();\n  yRef->add(0, 65535, 0, gFalse);\n  PDFDoc::writeHeader(outStr, majorVersion, minorVersion);\n\n  Object intents;\n  Object afObj;\n  Object ocObj;\n  Object names;\n  if (docs.size() >= 1) {\n    Object catObj;\n    docs[0]->getXRef()->getCatalog(&catObj);\n    Dict *catDict = catObj.getDict();\n     catDict->lookup(\"OutputIntents\", &intents);\n     catDict->lookupNF(\"AcroForm\", &afObj);\n     Ref *refPage = docs[0]->getCatalog()->getPageRef(1);\n    if (!afObj.isNull()) {\n       docs[0]->markAcroForm(&afObj, yRef, countRef, 0, refPage->num, refPage->num);\n     }\n     catDict->lookupNF(\"OCProperties\", &ocObj);\n    if (!ocObj.isNull() && ocObj.isDict()) {\n       docs[0]->markPageObjects(ocObj.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n     }\n     catDict->lookup(\"Names\", &names);\n    if (!names.isNull() && names.isDict()) {\n       docs[0]->markPageObjects(names.getDict(), yRef, countRef, 0, refPage->num, refPage->num);\n     }\n     if (intents.isArray() && intents.arrayGetLength() > 0) {\n      for (i = 1; i < (int) docs.size(); i++) {\n        Object pagecatObj, pageintents;\n        docs[i]->getXRef()->getCatalog(&pagecatObj);\n        Dict *pagecatDict = pagecatObj.getDict();\n        pagecatDict->lookup(\"OutputIntents\", &pageintents);\n        if (pageintents.isArray() && pageintents.arrayGetLength() > 0) {\n          for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n            Object intent;\n            intents.arrayGet(j, &intent, 0);\n            if (intent.isDict()) {\n              Object idf;\n              intent.dictLookup(\"OutputConditionIdentifier\", &idf);\n              if (idf.isString()) {\n                GooString *gidf = idf.getString();\n                GBool removeIntent = gTrue;\n                for (int k = 0; k < pageintents.arrayGetLength(); k++) {\n                  Object pgintent;\n                  pageintents.arrayGet(k, &pgintent, 0);\n                  if (pgintent.isDict()) {\n                    Object pgidf;\n                    pgintent.dictLookup(\"OutputConditionIdentifier\", &pgidf);\n                    if (pgidf.isString()) {\n                      GooString *gpgidf = pgidf.getString();\n                      if (gpgidf->cmp(gidf) == 0) {\n                        pgidf.free();\n                        removeIntent = gFalse;\n                        break;\n                      }\n                    }\n                    pgidf.free();\n                  }\n                }\n                if (removeIntent) {\n                  intents.arrayRemove(j);\n                  error(errSyntaxWarning, -1, \"Output intent {0:s} missing in pdf {1:s}, removed\",\n                   gidf->getCString(), docs[i]->getFileName()->getCString());\n                }\n              } else {\n                intents.arrayRemove(j);\n                error(errSyntaxWarning, -1, \"Invalid output intent dict, missing required OutputConditionIdentifier\");\n              }\n              idf.free();\n            } else {\n              intents.arrayRemove(j);\n            }\n            intent.free();\n          }\n        } else {\n          error(errSyntaxWarning, -1, \"Output intents differs, remove them all\");\n          intents.free();\n          break;\n        }\n        pagecatObj.free();\n        pageintents.free();\n      }\n    }\n    if (intents.isArray() && intents.arrayGetLength() > 0) {\n      for (j = intents.arrayGetLength() - 1; j >= 0; j--) {\n        Object intent;\n        intents.arrayGet(j, &intent, 0);\n        if (intent.isDict()) {\n          docs[0]->markPageObjects(intent.getDict(), yRef, countRef, numOffset, 0, 0);\n        } else {\n          intents.arrayRemove(j);\n        }\n        intent.free();\n      }\n    }\n    catObj.free();\n  }\n \n   for (i = 0; i < (int) docs.size(); i++) {\n     for (j = 1; j <= docs[i]->getNumPages(); j++) {\n       PDFRectangle *cropBox = NULL;\n       if (docs[i]->getCatalog()->getPage(j)->isCropped())\n         cropBox = docs[i]->getCatalog()->getPage(j)->getCropBox();\n      Object page;\n      docs[i]->getXRef()->fetch(refPage->num, refPage->gen, &page);\n      Dict *pageDict = page.getDict();\n      Dict *resDict = docs[i]->getCatalog()->getPage(j)->getResourceDict();\n      if (resDict) {\n        Object *newResource = new Object();\n        newResource->initDict(resDict);\n        pageDict->set(\"Resources\", newResource);\n        delete newResource;\n      }\n      pages.push_back(page);\n      offsets.push_back(numOffset);\n      docs[i]->markPageObjects(pageDict, yRef, countRef, numOffset, refPage->num, refPage->num);\n      Object annotsObj;\n      pageDict->lookupNF(\"Annots\", &annotsObj);\n      if (!annotsObj.isNull()) {\n        docs[i]->markAnnotations(&annotsObj, yRef, countRef, numOffset, refPage->num, refPage->num);\n        annotsObj.free();\n      }\n    }\n    Object pageCatObj, pageNames, pageForm;\n    docs[i]->getXRef()->getCatalog(&pageCatObj);\n    Dict *pageCatDict = pageCatObj.getDict();\n    pageCatDict->lookup(\"Names\", &pageNames);\n    if (!pageNames.isNull() && pageNames.isDict()) {\n      if (!names.isDict()) {\n        names.free();\n        names.initDict(yRef);\n      }\n      doMergeNameDict(docs[i], yRef, countRef, 0, 0, names.getDict(), pageNames.getDict(), numOffset);\n    }\n    pageCatDict->lookup(\"AcroForm\", &pageForm);\n    if (i > 0 && !pageForm.isNull() && pageForm.isDict()) {\n      if (afObj.isNull()) {\n        pageCatDict->lookupNF(\"AcroForm\", &afObj);\n      } else if (afObj.isDict()) {\n        doMergeFormDict(afObj.getDict(), pageForm.getDict(), numOffset);\n      }\n    }\n    pageForm.free();\n    pageNames.free();\n    pageCatObj.free();\n    objectsCount += docs[i]->writePageObjects(outStr, yRef, numOffset, gTrue);\n    numOffset = yRef->getNumObjects() + 1;\n  }\n\n  rootNum = yRef->getNumObjects() + 1;\n  yRef->add(rootNum, 0, outStr->getPos(), gTrue);\n  outStr->printf(\"%d 0 obj\\n\", rootNum);\n  outStr->printf(\"<< /Type /Catalog /Pages %d 0 R\", rootNum + 1);\n  if (intents.isArray() && intents.arrayGetLength() > 0) {\n    outStr->printf(\" /OutputIntents [\");\n    for (j = 0; j < intents.arrayGetLength(); j++) {\n      Object intent;\n      intents.arrayGet(j, &intent, 0);\n      if (intent.isDict()) {\n        PDFDoc::writeObject(&intent, outStr, yRef, 0, NULL, cryptRC4, 0, 0, 0);\n      }\n      intent.free();\n    }\n    outStr->printf(\"]\");\n  }\n  intents.free();\n  if (!afObj.isNull()) {\n    outStr->printf(\" /AcroForm \");\n    PDFDoc::writeObject(&afObj, outStr, yRef, 0, NULL, cryptRC4, 0, 0, 0);\n    afObj.free();\n  }\n  if (!ocObj.isNull() && ocObj.isDict()) {\n    outStr->printf(\" /OCProperties \");\n    PDFDoc::writeObject(&ocObj, outStr, yRef, 0, NULL, cryptRC4, 0, 0, 0);\n    ocObj.free();\n  }\n  if (!names.isNull() && names.isDict()) {\n    outStr->printf(\" /Names \");\n    PDFDoc::writeObject(&names, outStr, yRef, 0, NULL, cryptRC4, 0, 0, 0);\n    names.free();\n  }\n  outStr->printf(\">>\\nendobj\\n\");\n  objectsCount++;\n\n  yRef->add(rootNum + 1, 0, outStr->getPos(), gTrue);\n  outStr->printf(\"%d 0 obj\\n\", rootNum + 1);\n  outStr->printf(\"<< /Type /Pages /Kids [\");\n  for (j = 0; j < (int) pages.size(); j++)\n    outStr->printf(\" %d 0 R\", rootNum + j + 2);\n  outStr->printf(\" ] /Count %zd >>\\nendobj\\n\", pages.size());\n  objectsCount++;\n\n  for (i = 0; i < (int) pages.size(); i++) {\n    yRef->add(rootNum + i + 2, 0, outStr->getPos(), gTrue);\n    outStr->printf(\"%d 0 obj\\n\", rootNum + i + 2);\n    outStr->printf(\"<< \");\n    Dict *pageDict = pages[i].getDict();\n    for (j = 0; j < pageDict->getLength(); j++) {\n      if (j > 0)\n\toutStr->printf(\" \");\n      const char *key = pageDict->getKey(j);\n      Object value;\n      pageDict->getValNF(j, &value);\n      if (strcmp(key, \"Parent\") == 0) {\n        outStr->printf(\"/Parent %d 0 R\", rootNum + 1);\n      } else {\n        outStr->printf(\"/%s \", key);\n        PDFDoc::writeObject(&value, outStr, yRef, offsets[i], NULL, cryptRC4, 0, 0, 0);\n      }\n      value.free();\n    }\n    outStr->printf(\" >>\\nendobj\\n\");\n    objectsCount++;\n  }\n  Goffset uxrefOffset = outStr->getPos();\n  Ref ref;\n  ref.num = rootNum;\n  ref.gen = 0;\n  Dict *trailerDict = PDFDoc::createTrailerDict(objectsCount, gFalse, 0, &ref, yRef,\n                                                fileName, outStr->getPos());\n  PDFDoc::writeXRefTableTrailer(trailerDict, yRef, gTrue, // write all entries according to ISO 32000-1, 7.5.4 Cross-Reference Table: \"For a file that has never been incrementally updated, the cross-reference section shall contain only one subsection, whose object numbering begins at 0.\"\n                                uxrefOffset, outStr, yRef);\n  delete trailerDict;\n\n  outStr->close();\n  delete outStr;\n  fclose(f);\n  delete yRef;\n  delete countRef;\n  for (j = 0; j < (int) pages.size (); j++) pages[j].free();\n  for (i = 0; i < (int) docs.size (); i++) delete docs[i];\n  delete globalParams;\n  return exitCode;\n}\n",
        "commit_message": "pdfunite: Fix crash with broken documents\n\nSometimes we can't parse pages so check before accessing them\n\nThanks to Jiaqi Peng for the report\n\nFixes bugs #101153 and #101149",
        "cve_desc": "poppler since version 0.17.3 has been vulnerable to NULL pointer dereference in pdfunite triggered by specially crafted documents.",
        "target": 1
      }
    ]
  },
  "postgres": {
    "0": [
      {
        "idx": 191555,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message, which concerns integer overflows leading to buffer overruns in *input functions* and stack overflows. The `comparePairs` function deals with comparing existing data structures (`Pairs`) and doesn't perform any memory allocation or calculations that could be susceptible to the identified integer overflow issue; therefore, it wasn't flagged as vulnerable.\n\n\n\n",
        "func": "comparePairs(const void *a, const void *b)\n{\n\tconst Pairs *pa = a;\n\tconst Pairs *pb = b;\n\n\tif (pa->keylen == pb->keylen)\n\t{\n\t\tint\t\t\tres = memcmp(pa->key, pb->key, pa->keylen);\n\n\t\tif (res)\n\t\t\treturn res;\n\n\t\t/* guarantee that needfree will be later */\n\t\tif (pb->needfree == pa->needfree)\n\t\t\treturn 0;\n\t\telse if (pa->needfree)\n\t\t\treturn 1;\n\t\telse\n\t\t\treturn -1;\n\t}\n\treturn (pa->keylen > pb->keylen) ? 1 : -1;\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 0
      },
      {
        "idx": 191556,
        "reasoning": "The provided commit message describes vulnerabilities related to integer overflows leading to buffer overruns in *input functions* and stack overflows\u2014none of which are present in the `cpw` code snippet. The `cpw` function performs a straightforward character copy with escaping, and the commit specifically addresses allocation size calculations in other parts of the codebase, not this copy function.\n\n\n\n",
        "func": "cpw(char *dst, char *src, int len)\n{\n\tchar\t   *ptr = src;\n\n\twhile (ptr - src < len)\n\t{\n\t\tif (*ptr == '\"' || *ptr == '\\\\')\n\t\t\t*dst++ = '\\\\';\n\t\t*dst++ = *ptr++;\n\t}\n\treturn dst;\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 0
      },
      {
        "idx": 191557,
        "reasoning": "This code snippet, while containing a `RESIZEPRSBUF` macro, is not directly flagged as vulnerable in the provided commit message or CVE details. The commit addresses integer overflow issues in allocation sizes *before* data is written, and the `RESIZEPRSBUF` macro likely handles dynamic resizing to prevent buffer overflows during the parsing process, mitigating the risk of writing past the allocated memory.\n\n\n\n",
        "func": "get_val(HSParser *state, bool ignoreeq, bool *escaped)\n{\n\tint\t\t\tst = GV_WAITVAL;\n\n\tstate->wordlen = 32;\n\tstate->cur = state->word = palloc(state->wordlen);\n\t*escaped = false;\n\n\twhile (1)\n\t{\n\t\tif (st == GV_WAITVAL)\n\t\t{\n\t\t\tif (*(state->ptr) == '\"')\n\t\t\t{\n\t\t\t\t*escaped = true;\n\t\t\t\tst = GV_INESCVAL;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '\\0')\n\t\t\t{\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '=' && !ignoreeq)\n\t\t\t{\n\t\t\t\telog(ERROR, \"Syntax error near '%c' at position %d\", *(state->ptr), (int32) (state->ptr - state->begin));\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '\\\\')\n\t\t\t{\n\t\t\t\tst = GV_WAITESCIN;\n\t\t\t}\n\t\t\telse if (!isspace((unsigned char) *(state->ptr)))\n\t\t\t{\n\t\t\t\t*(state->cur) = *(state->ptr);\n\t\t\t\tstate->cur++;\n\t\t\t\tst = GV_INVAL;\n\t\t\t}\n\t\t}\n\t\telse if (st == GV_INVAL)\n\t\t{\n\t\t\tif (*(state->ptr) == '\\\\')\n\t\t\t{\n\t\t\t\tst = GV_WAITESCIN;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '=' && !ignoreeq)\n\t\t\t{\n\t\t\t\tstate->ptr--;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == ',' && ignoreeq)\n\t\t\t{\n\t\t\t\tstate->ptr--;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse if (isspace((unsigned char) *(state->ptr)))\n\t\t\t{\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '\\0')\n\t\t\t{\n\t\t\t\tstate->ptr--;\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tRESIZEPRSBUF;\n\t\t\t\t*(state->cur) = *(state->ptr);\n\t\t\t\tstate->cur++;\n\t\t\t}\n\t\t}\n\t\telse if (st == GV_INESCVAL)\n\t\t{\n\t\t\tif (*(state->ptr) == '\\\\')\n\t\t\t{\n\t\t\t\tst = GV_WAITESCESCIN;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '\"')\n\t\t\t{\n\t\t\t\treturn true;\n\t\t\t}\n\t\t\telse if (*(state->ptr) == '\\0')\n\t\t\t{\n\t\t\t\telog(ERROR, \"Unexpected end of string\");\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tRESIZEPRSBUF;\n\t\t\t\t*(state->cur) = *(state->ptr);\n\t\t\t\tstate->cur++;\n\t\t\t}\n\t\t}\n\t\telse if (st == GV_WAITESCIN)\n\t\t{\n\t\t\tif (*(state->ptr) == '\\0')\n\t\t\t\telog(ERROR, \"Unexpected end of string\");\n\t\t\tRESIZEPRSBUF;\n\t\t\t*(state->cur) = *(state->ptr);\n\t\t\tstate->cur++;\n\t\t\tst = GV_INVAL;\n\t\t}\n\t\telse if (st == GV_WAITESCESCIN)\n\t\t{\n\t\t\tif (*(state->ptr) == '\\0')\n\t\t\t\telog(ERROR, \"Unexpected end of string\");\n\t\t\tRESIZEPRSBUF;\n\t\t\t*(state->cur) = *(state->ptr);\n\t\t\tstate->cur++;\n\t\t\tst = GV_INESCVAL;\n\t\t}\n\t\telse\n\t\t\telog(ERROR, \"Unknown state %d at position line %d in file '%s'\", st, __LINE__, __FILE__);\n\n\t\tstate->ptr++;\n\t}\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 0
      },
      {
        "idx": 191558,
        "reasoning": "This code snippet is **not vulnerable** to the integer overflow issue described in the commit message. The commit addresses vulnerabilities in *allocation size calculations* within type input functions, while this `hstoreCheckKeyLen` function simply *checks* a length against a maximum and returns it \u2013 it doesn't perform any allocation or size calculation that could wrap around and lead to a buffer overrun.\n\n\n\n",
        "func": "hstoreCheckKeyLen(size_t len)\n{\n\tif (len > HSTORE_MAX_KEY_LEN)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_STRING_DATA_RIGHT_TRUNCATION),\n\t\t\t\t errmsg(\"string too long for hstore key\")));\n\treturn len;\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 0
      },
      {
        "idx": 191559,
        "reasoning": "This code snippet is **not vulnerable** to the integer overflow issue described in the commit message. The commit addresses overflows in *allocation size calculations* within input functions, while this `hstoreCheckValLen` function simply *checks* a length against a maximum value *after* it's presumably already been calculated, preventing excessively long strings from being processed\u2014it doesn't perform any size calculations itself.\n\n\n\n",
        "func": "hstoreCheckValLen(size_t len)\n{\n\tif (len > HSTORE_MAX_VALUE_LEN)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_STRING_DATA_RIGHT_TRUNCATION),\n\t\t\t\t errmsg(\"string too long for hstore value\")));\n\treturn len;\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 10520,
        "reasoning": "This code is vulnerable to an integer overflow when calculating `buflen` in `hstoreUniquePairs`, potentially leading to a small allocation size. Subsequently, writing to the `hstorePairs` structure with data exceeding this small size results in a buffer overflow, as highlighted by the CVE description.",
        "func": "hstore_from_array(PG_FUNCTION_ARGS)\n{\n\tArrayType  *in_array = PG_GETARG_ARRAYTYPE_P(0);\n\tint\t\t\tndims = ARR_NDIM(in_array);\n\tint\t\t\tcount;\n\tint32\t\tbuflen;\n\tHStore\t   *out;\n\tPairs\t   *pairs;\n\tDatum\t   *in_datums;\n\tbool\t   *in_nulls;\n\tint\t\t\tin_count;\n\tint\t\t\ti;\n\n\tAssert(ARR_ELEMTYPE(in_array) == TEXTOID);\n\n\tswitch (ndims)\n\t{\n\t\tcase 0:\n\t\t\tout = hstorePairs(NULL, 0, 0);\n\t\t\tPG_RETURN_POINTER(out);\n\n\t\tcase 1:\n\t\t\tif ((ARR_DIMS(in_array)[0]) % 2)\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t\t errmsg(\"array must have even number of elements\")));\n\t\t\tbreak;\n\n\t\tcase 2:\n\t\t\tif ((ARR_DIMS(in_array)[1]) != 2)\n\t\t\t\tereport(ERROR,\n\t\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t\t errmsg(\"array must have two columns\")));\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t errmsg(\"wrong number of array subscripts\")));\n\t}\n\n\tdeconstruct_array(in_array,\n\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &in_datums, &in_nulls, &in_count);\n \n \tcount = in_count / 2;\n \n \tpairs = palloc(count * sizeof(Pairs));\n \n \tfor (i = 0; i < count; ++i)\n\t{\n\t\tif (in_nulls[i * 2])\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_NULL_VALUE_NOT_ALLOWED),\n\t\t\t\t\t errmsg(\"null value not allowed for hstore key\")));\n\n\t\tif (in_nulls[i * 2 + 1])\n\t\t{\n\t\t\tpairs[i].key = VARDATA_ANY(in_datums[i * 2]);\n\t\t\tpairs[i].val = NULL;\n\t\t\tpairs[i].keylen = hstoreCheckKeyLen(VARSIZE_ANY_EXHDR(in_datums[i * 2]));\n\t\t\tpairs[i].vallen = 4;\n\t\t\tpairs[i].isnull = true;\n\t\t\tpairs[i].needfree = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpairs[i].key = VARDATA_ANY(in_datums[i * 2]);\n\t\t\tpairs[i].val = VARDATA_ANY(in_datums[i * 2 + 1]);\n\t\t\tpairs[i].keylen = hstoreCheckKeyLen(VARSIZE_ANY_EXHDR(in_datums[i * 2]));\n\t\t\tpairs[i].vallen = hstoreCheckValLen(VARSIZE_ANY_EXHDR(in_datums[i * 2 + 1]));\n\t\t\tpairs[i].isnull = false;\n\t\t\tpairs[i].needfree = false;\n\t\t}\n\t}\n\n\tcount = hstoreUniquePairs(pairs, count, &buflen);\n\n\tout = hstorePairs(pairs, count, buflen);\n\n\tPG_RETURN_POINTER(out);\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 1
      },
      {
        "idx": 10521,
        "reasoning": "This code is vulnerable to an integer overflow when calculating `buflen` in `hstoreUniquePairs` and subsequently allocating memory for the `hstore` structure in `hstorePairs`. If the input arrays are crafted such that the calculation of `buflen` wraps around to a small positive value, a buffer overflow will occur when writing data into the allocated memory.",
        "func": "hstore_from_arrays(PG_FUNCTION_ARGS)\n{\n\tint32\t\tbuflen;\n\tHStore\t   *out;\n\tPairs\t   *pairs;\n\tDatum\t   *key_datums;\n\tbool\t   *key_nulls;\n\tint\t\t\tkey_count;\n\tDatum\t   *value_datums;\n\tbool\t   *value_nulls;\n\tint\t\t\tvalue_count;\n\tArrayType  *key_array;\n\tArrayType  *value_array;\n\tint\t\t\ti;\n\n\tif (PG_ARGISNULL(0))\n\t\tPG_RETURN_NULL();\n\n\tkey_array = PG_GETARG_ARRAYTYPE_P(0);\n\n\tAssert(ARR_ELEMTYPE(key_array) == TEXTOID);\n\n\t/*\n\t * must check >1 rather than != 1 because empty arrays have 0 dimensions,\n\t * not 1\n\t */\n\n\tif (ARR_NDIM(key_array) > 1)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t errmsg(\"wrong number of array subscripts\")));\n\n\tdeconstruct_array(key_array,\n \t\t\t\t\t  TEXTOID, -1, false, 'i',\n \t\t\t\t\t  &key_datums, &key_nulls, &key_count);\n \n \t/* value_array might be NULL */\n \n \tif (PG_ARGISNULL(1))\n\t{\n\t\tvalue_array = NULL;\n\t\tvalue_count = key_count;\n\t\tvalue_datums = NULL;\n\t\tvalue_nulls = NULL;\n\t}\n\telse\n\t{\n\t\tvalue_array = PG_GETARG_ARRAYTYPE_P(1);\n\n\t\tAssert(ARR_ELEMTYPE(value_array) == TEXTOID);\n\n\t\tif (ARR_NDIM(value_array) > 1)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t errmsg(\"wrong number of array subscripts\")));\n\n\t\tif ((ARR_NDIM(key_array) > 0 || ARR_NDIM(value_array) > 0) &&\n\t\t\t(ARR_NDIM(key_array) != ARR_NDIM(value_array) ||\n\t\t\t ARR_DIMS(key_array)[0] != ARR_DIMS(value_array)[0] ||\n\t\t\t ARR_LBOUND(key_array)[0] != ARR_LBOUND(value_array)[0]))\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_ARRAY_SUBSCRIPT_ERROR),\n\t\t\t\t\t errmsg(\"arrays must have same bounds\")));\n\n\t\tdeconstruct_array(value_array,\n\t\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t\t  &value_datums, &value_nulls, &value_count);\n\n\t\tAssert(key_count == value_count);\n\t}\n\n\tpairs = palloc(key_count * sizeof(Pairs));\n\n\tfor (i = 0; i < key_count; ++i)\n\t{\n\t\tif (key_nulls[i])\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_NULL_VALUE_NOT_ALLOWED),\n\t\t\t\t\t errmsg(\"null value not allowed for hstore key\")));\n\n\t\tif (!value_nulls || value_nulls[i])\n\t\t{\n\t\t\tpairs[i].key = VARDATA_ANY(key_datums[i]);\n\t\t\tpairs[i].val = NULL;\n\t\t\tpairs[i].keylen = hstoreCheckKeyLen(VARSIZE_ANY_EXHDR(key_datums[i]));\n\t\t\tpairs[i].vallen = 4;\n\t\t\tpairs[i].isnull = true;\n\t\t\tpairs[i].needfree = false;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpairs[i].key = VARDATA_ANY(key_datums[i]);\n\t\t\tpairs[i].val = VARDATA_ANY(value_datums[i]);\n\t\t\tpairs[i].keylen = hstoreCheckKeyLen(VARSIZE_ANY_EXHDR(key_datums[i]));\n\t\t\tpairs[i].vallen = hstoreCheckValLen(VARSIZE_ANY_EXHDR(value_datums[i]));\n\t\t\tpairs[i].isnull = false;\n\t\t\tpairs[i].needfree = false;\n\t\t}\n\t}\n\n\tkey_count = hstoreUniquePairs(pairs, key_count, &buflen);\n\n\tout = hstorePairs(pairs, key_count, buflen);\n\n\tPG_RETURN_POINTER(out);\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 1
      },
      {
        "idx": 10523,
        "reasoning": "This code is vulnerable to an integer overflow when calculating the allocation size for the `pairs` array using `pcount * sizeof(Pairs)`, potentially leading to a small allocation followed by a buffer overrun in the subsequent loop. The `pq_getmsgint` function reads the number of pairs (`pcount`) from the input buffer, and a maliciously crafted input could cause `pcount` to be a large value, resulting in an integer overflow and a smaller-than-expected allocation size for `pairs`.",
        "func": "hstore_recv(PG_FUNCTION_ARGS)\n{\n\tint32\t\tbuflen;\n\tHStore\t   *out;\n\tPairs\t   *pairs;\n\tint32\t\ti;\n\tint32\t\tpcount;\n\tStringInfo\tbuf = (StringInfo) PG_GETARG_POINTER(0);\n\n\tpcount = pq_getmsgint(buf, 4);\n\n\tif (pcount == 0)\n\t{\n\t\tout = hstorePairs(NULL, 0, 0);\n \t\tPG_RETURN_POINTER(out);\n \t}\n \n \tpairs = palloc(pcount * sizeof(Pairs));\n \n \tfor (i = 0; i < pcount; ++i)\n\t{\n\t\tint\t\t\trawlen = pq_getmsgint(buf, 4);\n\t\tint\t\t\tlen;\n\n\t\tif (rawlen < 0)\n\t\t\tereport(ERROR,\n\t\t\t\t\t(errcode(ERRCODE_NULL_VALUE_NOT_ALLOWED),\n\t\t\t\t\t errmsg(\"null value not allowed for hstore key\")));\n\n\t\tpairs[i].key = pq_getmsgtext(buf, rawlen, &len);\n\t\tpairs[i].keylen = hstoreCheckKeyLen(len);\n\t\tpairs[i].needfree = true;\n\n\t\trawlen = pq_getmsgint(buf, 4);\n\t\tif (rawlen < 0)\n\t\t{\n\t\t\tpairs[i].val = NULL;\n\t\t\tpairs[i].vallen = 0;\n\t\t\tpairs[i].isnull = true;\n\t\t}\n\t\telse\n\t\t{\n\t\t\tpairs[i].val = pq_getmsgtext(buf, rawlen, &len);\n\t\t\tpairs[i].vallen = hstoreCheckValLen(len);\n\t\t\tpairs[i].isnull = false;\n\t\t}\n\t}\n\n\tpcount = hstoreUniquePairs(pairs, pcount, &buflen);\n\n\tout = hstorePairs(pairs, pcount, buflen);\n\n\tPG_RETURN_POINTER(out);\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 1
      },
      {
        "idx": 10524,
        "reasoning": "This code is vulnerable to an integer overflow when calculating the allocation size for `key_pairs` using `sizeof(Pairs) * key_count`. If `key_count` is sufficiently large, this multiplication can wrap around to a small positive value, leading to a smaller-than-expected allocation and a subsequent buffer overflow when writing data into `key_pairs`.",
        "func": "hstoreArrayToPairs(ArrayType *a, int *npairs)\n{\n\tDatum\t   *key_datums;\n\tbool\t   *key_nulls;\n\tint\t\t\tkey_count;\n\tPairs\t   *key_pairs;\n\tint\t\t\tbufsiz;\n\tint\t\t\ti,\n\t\t\t\tj;\n\n\tdeconstruct_array(a,\n\t\t\t\t\t  TEXTOID, -1, false, 'i',\n\t\t\t\t\t  &key_datums, &key_nulls, &key_count);\n\n\tif (key_count == 0)\n\t{\n\t\t*npairs = 0;\n \t\treturn NULL;\n \t}\n \n \tkey_pairs = palloc(sizeof(Pairs) * key_count);\n \n \tfor (i = 0, j = 0; i < key_count; i++)\n\t{\n\t\tif (!key_nulls[i])\n\t\t{\n\t\t\tkey_pairs[j].key = VARDATA(key_datums[i]);\n\t\t\tkey_pairs[j].keylen = VARSIZE(key_datums[i]) - VARHDRSZ;\n\t\t\tkey_pairs[j].val = NULL;\n\t\t\tkey_pairs[j].vallen = 0;\n\t\t\tkey_pairs[j].needfree = 0;\n\t\t\tkey_pairs[j].isnull = 1;\n\t\t\tj++;\n\t\t}\n\t}\n\n\t*npairs = hstoreUniquePairs(key_pairs, j, &bufsiz);\n\n\treturn key_pairs;\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 1
      },
      {
        "idx": 10533,
        "reasoning": "The `path_in` function is vulnerable to an integer overflow when calculating the allocation size for the `PATH` structure, specifically in the `size = offsetof(PATH, p[0]) + sizeof(path->p[0]) * npts;` line. If `npts` is sufficiently large, this multiplication can wrap around to a small positive value, leading to a small allocation followed by a buffer overrun when `path->p[0]` is written to.",
        "func": "path_in(PG_FUNCTION_ARGS)\n{\n\tchar\t   *str = PG_GETARG_CSTRING(0);\n\tPATH\t   *path;\n\tint\t\t\tisopen;\n \tchar\t   *s;\n \tint\t\t\tnpts;\n \tint\t\t\tsize;\n \tint\t\t\tdepth = 0;\n \n \tif ((npts = pair_count(str, ',')) <= 0)\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_TEXT_REPRESENTATION),\n\t\t\t\t errmsg(\"invalid input syntax for type path: \\\"%s\\\"\", str)));\n\n\ts = str;\n\twhile (isspace((unsigned char) *s))\n\t\ts++;\n\n\t/* skip single leading paren */\n\tif ((*s == LDELIM) && (strrchr(s, LDELIM) == s))\n\t{\n\t\ts++;\n \t\tdepth++;\n \t}\n \n\tsize = offsetof(PATH, p[0]) +sizeof(path->p[0]) * npts;\n \tpath = (PATH *) palloc(size);\n \n \tSET_VARSIZE(path, size);\n\tpath->npts = npts;\n\n\tif ((!path_decode(TRUE, npts, s, &isopen, &s, &(path->p[0])))\n\t&& (!((depth == 0) && (*s == '\\0'))) && !((depth >= 1) && (*s == RDELIM)))\n\t\tereport(ERROR,\n\t\t\t\t(errcode(ERRCODE_INVALID_TEXT_REPRESENTATION),\n\t\t\t\t errmsg(\"invalid input syntax for type path: \\\"%s\\\"\", str)));\n\n\tpath->closed = (!isopen);\n\t/* prevent instability in unused pad bytes */\n\tpath->dummy = 0;\n\n\tPG_RETURN_PATH_P(path);\n}\n",
        "commit_message": "Predict integer overflow to avoid buffer overruns.\n\nSeveral functions, mostly type input functions, calculated an allocation\nsize such that the calculation wrapped to a small positive value when\narguments implied a sufficiently-large requirement.  Writes past the end\nof the inadvertent small allocation followed shortly thereafter.\nCoverity identified the path_in() vulnerability; code inspection led to\nthe rest.  In passing, add check_stack_depth() to prevent stack overflow\nin related functions.\n\nBack-patch to 8.4 (all supported versions).  The non-comment hstore\nchanges touch code that did not exist in 8.4, so that part stops at 9.0.\n\nNoah Misch and Heikki Linnakangas, reviewed by Tom Lane.\n\nSecurity: CVE-2014-0064",
        "cve_desc": "Multiple integer overflows in the path_in and other unspecified functions in PostgreSQL before 8.4.20, 9.0.x before 9.0.16, 9.1.x before 9.1.12, 9.2.x before 9.2.7, and 9.3.x before 9.3.3 allow remote authenticated users to have unspecified impact and attack vectors, which trigger a buffer overflow.  NOTE: this identifier has been SPLIT due to different affected versions; use CVE-2014-2669 for the hstore vector.",
        "target": 1
      }
    ]
  },
  "postsrsd": {
    "0": [
      {
        "idx": 319976,
        "reasoning": "This code snippet for `is_hexdigit` is not directly vulnerable. The commit message describes a denial-of-service vulnerability related to input handling with `fread`/`fwrite` in a subprocess, not a flaw within this specific hexadecimal digit checking function.\n\n\n\n",
        "func": "static int is_hexdigit(char c)\n{\n    return (c >= '0' && c <= '9') || (c >= 'a' && c <= 'f')\n           || (c >= 'A' && c <= 'F');\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 0
      },
      {
        "idx": 319977,
        "reasoning": "This code snippet, `url_decode`, is **not directly vulnerable** to the described DoS issue. The commit message details a problem with `fread()/fwrite()` in a *subprocess* handling overly long requests, not within this specific URL decoding function itself; this function simply decodes a URL and has a length check (`--len`) to prevent buffer overflows during decoding.\n\n\n\n",
        "func": "static char *url_decode(char *buf, size_t len, const char *input)\n{\n    char *output = buf;\n    if (!input || !output || len == 0)\n        return NULL;\n\n    while (*input && --len)\n    {\n        if (*input == '%')\n        {\n            if (is_hexdigit(input[1]) && is_hexdigit(input[2]))\n            {\n                *output++ = hex2char(++input);\n                input += 2;\n            }\n            else\n            {\n                return 0;\n            }\n        }\n        else\n        {\n            *output++ = *input++;\n        }\n    }\n    *output = 0;\n    return buf;\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 0
      },
      {
        "idx": 319978,
        "reasoning": "This code snippet is not vulnerable. The commit message details a denial-of-service vulnerability in the `fread()/fwrite()` logic of a *subprocess* within PostSRSd, not within this specific `num2hex` function which simply converts a number to its hexadecimal representation \u2013 a safe operation in itself.\n\n\n\n",
        "func": "static char num2hex(char c)\n{\n    if (c < 10)\n        return '0' + c;\n    return 'a' + c - 10;\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 0
      },
      {
        "idx": 319979,
        "reasoning": "This code snippet is not flagged as vulnerable because the commit message details a denial-of-service vulnerability in the `fread()/fwrite()` logic of a *subprocess*, not within the `hex2char` function itself. The provided code simply converts hexadecimal characters to their numerical representation and doesn't handle external input or file operations directly, thus posing no immediate risk related to the described DoS issue.\n\n\n\n",
        "func": "static char hex2char(const char *s)\n{\n    return 16 * hex2num(s[0]) + hex2num(s[1]);\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 0
      },
      {
        "idx": 319980,
        "reasoning": "This code snippet focuses on socket creation and binding, and is not directly related to the described vulnerability of a denial-of-service caused by overly long input during request processing (specifically `fread`/`fwrite` in a subprocess). The commit message details a bug in how PostSRSd handles input *after* a connection is established\u2014something this code doesn\u2019t address, as it only handles the connection setup phase.\n\n\n\n",
        "func": "static size_t bind_service(const char *listen_addr, const char *service,\n                           int family, int *socks, size_t max_socks)\n{\n    struct addrinfo *addr, *it;\n    struct addrinfo hints;\n    int err, sock, flags;\n    size_t count = 0;\n    static const int one = 1;\n\n    memset(&hints, 0, sizeof(hints));\n    hints.ai_family = family;\n    hints.ai_socktype = SOCK_STREAM;\n\n    err = getaddrinfo(listen_addr, service, &hints, &addr);\n    if (err != 0)\n    {\n        fprintf(stderr, \"%s: bind_service(%s): %s\\n\", self, service,\n                gai_strerror(err));\n        return count;\n    }\n    sock = -1;\n    for (it = addr; it; it = it->ai_next)\n    {\n        if (max_socks == 0)\n            break;\n        sock = socket(it->ai_family, it->ai_socktype, it->ai_protocol);\n        if (sock < 0)\n            goto fail;\n        if (setsockopt(sock, SOL_SOCKET, SO_REUSEADDR, &one, sizeof(one)) < 0)\n            goto fail;\n        if (bind(sock, it->ai_addr, it->ai_addrlen) < 0)\n            goto fail;\n        if (listen(sock, 10) < 0)\n            goto fail;\n        flags = fcntl(sock, F_GETFL, 0);\n        if (flags < 0)\n            goto fail;\n        if (fcntl(sock, F_SETFL, flags | O_NONBLOCK) < 0)\n            goto fail;\n        *socks++ = sock;\n        ++count;\n        --max_socks;\n        continue;\n    fail:\n        err = errno;\n        if (sock >= 0)\n            close(sock);\n    }\n    freeaddrinfo(addr);\n    if (count == 0)\n        fprintf(stderr, \"%s: bind_service(%s): %s\\n\", self, service,\n                strerror(err));\n    return count;\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 201481,
        "reasoning": "The code is vulnerable to a denial-of-service (DoS) attack because it can hang when processing overly long GET requests, specifically due to issues with `fread()/fwrite()` in a subprocess when handling unexpectedly large input lines. While the issue *should* be prevented by Postfix's expected behavior, malformed requests with concatenated email addresses can trigger this vulnerability, leading to a hang.",
        "func": "int main(int argc, char **argv)\n{\n    int opt, timeout = 1800, family = AF_UNSPEC, hashlength = 0, hashmin = 0;\n    int daemonize = FALSE, always_rewrite = FALSE;\n    char *listen_addr = NULL, *forward_service = NULL, *reverse_service = NULL,\n         *user = NULL, *domain = NULL, *chroot_dir = NULL;\n    char separator = '=';\n    char *secret_file = NULL, *pid_file = NULL;\n    FILE *pf = NULL, *sf = NULL;\n    struct passwd *pwd = NULL;\n    char secretbuf[1024], *secret = NULL;\n    char *tmp;\n    time_t now;\n    srs_t *srs;\n    const char **excludes;\n    size_t s1 = 0, s2 = 1;\n    struct pollfd fds[4];\n    size_t socket_count = 0, sc;\n    int sockets[4] = {-1, -1, -1, -1};\n    handle_t handler[4] = {0, 0, 0, 0};\n    int fd, maxfd;\n\n    excludes = (const char **)calloc(1, sizeof(char *));\n    tmp = strrchr(argv[0], '/');\n    if (tmp)\n        self = strdup(tmp + 1);\n    else\n        self = strdup(argv[0]);\n\n    while ((opt = getopt(argc, argv, \"46d:a:l:f:r:s:n:N:u:t:p:c:X::ADhev\"))\n           != -1)\n    {\n        switch (opt)\n        {\n            case '?':\n                return EXIT_FAILURE;\n            case '4':\n                family = AF_INET;\n                break;\n            case '6':\n                family = AF_INET6;\n                break;\n            case 'd':\n                domain = strdup(optarg);\n                break;\n            case 'a':\n                separator = *optarg;\n                break;\n            case 'l':\n                listen_addr = strdup(optarg);\n                break;\n            case 'f':\n                forward_service = strdup(optarg);\n                break;\n            case 'r':\n                reverse_service = strdup(optarg);\n                break;\n            case 't':\n                timeout = atoi(optarg);\n                break;\n            case 's':\n                secret_file = strdup(optarg);\n                break;\n            case 'n':\n                hashlength = atoi(optarg);\n                break;\n            case 'N':\n                hashmin = atoi(optarg);\n                break;\n            case 'p':\n                pid_file = strdup(optarg);\n                break;\n            case 'u':\n                user = strdup(optarg);\n                break;\n            case 'c':\n                chroot_dir = strdup(optarg);\n                break;\n            case 'D':\n                daemonize = TRUE;\n                break;\n            case 'A':\n                always_rewrite = TRUE;\n                break;\n            case 'h':\n                show_help();\n                return EXIT_SUCCESS;\n            case 'X':\n                if (optarg != NULL)\n                {\n                    tmp = strtok(optarg, \",; \\t\\r\\n\");\n                    while (tmp)\n                    {\n                        if (s1 + 1 >= s2)\n                        {\n                            s2 *= 2;\n                            excludes = (const char **)realloc(\n                                excludes, s2 * sizeof(char *));\n                            if (excludes == NULL)\n                            {\n                                fprintf(stderr, \"%s: Out of memory\\n\\n\", self);\n                                return EXIT_FAILURE;\n                            }\n                        }\n                        excludes[s1++] = strdup(tmp);\n                        tmp = strtok(NULL, \",; \\t\\r\\n\");\n                    }\n                    excludes[s1] = NULL;\n                }\n                break;\n            case 'e':\n                if (getenv(\"SRS_DOMAIN\") != NULL)\n                    domain = strdup(getenv(\"SRS_DOMAIN\"));\n                if (getenv(\"SRS_SEPARATOR\") != NULL)\n                    separator = *getenv(\"SRS_SEPARATOR\");\n                if (getenv(\"SRS_HASHLENGTH\") != NULL)\n                    hashlength = atoi(getenv(\"SRS_HASHLENGTH\"));\n                if (getenv(\"SRS_HASHMIN\") != NULL)\n                    hashmin = atoi(getenv(\"SRS_HASHMIN\"));\n                if (getenv(\"SRS_FORWARD_PORT\") != NULL)\n                    forward_service = strdup(getenv(\"SRS_FORWARD_PORT\"));\n                if (getenv(\"SRS_REVERSE_PORT\") != NULL)\n                    reverse_service = strdup(getenv(\"SRS_REVERSE_PORT\"));\n                if (getenv(\"SRS_TIMEOUT\") != NULL)\n                    timeout = atoi(getenv(\"SRS_TIMEOUT\"));\n                if (getenv(\"SRS_SECRET\") != NULL)\n                    secret_file = strdup(getenv(\"SRS_SECRET\"));\n                if (getenv(\"SRS_PID_FILE\") != NULL)\n                    pid_file = strdup(getenv(\"SRS_PID_FILE\"));\n                if (getenv(\"RUN_AS\") != NULL)\n                    user = strdup(getenv(\"RUN_AS\"));\n                if (getenv(\"CHROOT\") != NULL)\n                    chroot_dir = strdup(getenv(\"CHROOT\"));\n                if (getenv(\"SRS_EXCLUDE_DOMAINS\") != NULL)\n                {\n                    tmp = strtok(getenv(\"SRS_EXCLUDE_DOMAINS\"), \",; \\t\\r\\n\");\n                    while (tmp)\n                    {\n                        if (s1 + 1 >= s2)\n                        {\n                            s2 *= 2;\n                            excludes = (const char **)realloc(\n                                excludes, s2 * sizeof(char *));\n                            if (excludes == NULL)\n                            {\n                                fprintf(stderr, \"%s: Out of memory\\n\\n\", self);\n                                return EXIT_FAILURE;\n                            }\n                        }\n                        excludes[s1++] = strdup(tmp);\n                        tmp = strtok(NULL, \",; \\t\\r\\n\");\n                    }\n                    excludes[s1] = NULL;\n                }\n                break;\n            case 'v':\n                fprintf(stdout, \"%s\\n\", POSTSRSD_VERSION);\n                return EXIT_SUCCESS;\n        }\n    }\n    if (optind < argc)\n    {\n        fprintf(stderr, \"%s: extra argument on command line: %s\\n\", self,\n                argv[optind]);\n        return EXIT_FAILURE;\n    }\n    if (domain == NULL || *domain == 0)\n    {\n        fprintf(stderr, \"%s: You must set a home domain (-d)\\n\", self);\n        return EXIT_FAILURE;\n    }\n\n    if (separator != '=' && separator != '+' && separator != '-')\n    {\n        fprintf(stderr, \"%s: SRS separator character must be one of '=+-'\\n\",\n                self);\n        return EXIT_FAILURE;\n    }\n    if (forward_service == NULL)\n        forward_service = strdup(\"10001\");\n    if (reverse_service == NULL)\n        reverse_service = strdup(\"10002\");\n\n    /* Close all file descriptors (std ones will be closed later). */\n    maxfd = sysconf(_SC_OPEN_MAX);\n    for (fd = 3; fd < maxfd; fd++)\n        close(fd);\n\n    /* The stuff we do first may not be possible from within chroot or without\n     * privileges */\n\n    /* Open pid file for writing (the actual process ID is filled in later) */\n    if (pid_file)\n    {\n        pf = fopen(pid_file, \"w\");\n        if (pf == NULL)\n        {\n            fprintf(stderr, \"%s: Cannot write PID: %s\\n\\n\", self, pid_file);\n            return EXIT_FAILURE;\n        }\n    }\n    /* Read secret. The default installation makes this root accessible only. */\n    if (secret_file != NULL)\n    {\n        sf = fopen(secret_file, \"rb\");\n        if (sf == NULL)\n        {\n            fprintf(stderr, \"%s: Cannot open file with secret: %s\\n\", self,\n                    secret_file);\n            return EXIT_FAILURE;\n        }\n    }\n    else\n    {\n        fprintf(stderr, \"%s: You must set a secret (-s)\\n\", self);\n        return EXIT_FAILURE;\n    }\n    /* Bind ports. May require privileges if the config specifies ports below\n     * 1024 */\n    sc = bind_service(listen_addr, forward_service, family,\n                      &sockets[socket_count], 4 - socket_count);\n    if (sc == 0)\n        return EXIT_FAILURE;\n    while (sc-- > 0)\n        handler[socket_count++] = handle_forward;\n    free(forward_service);\n    sc = bind_service(listen_addr, reverse_service, family,\n                      &sockets[socket_count], 4 - socket_count);\n    if (sc == 0)\n        return EXIT_FAILURE;\n    while (sc-- > 0)\n        handler[socket_count++] = handle_reverse;\n    free(reverse_service);\n    /* Open syslog now (NDELAY), because it may no longer be reachable from\n     * chroot */\n    openlog(self, LOG_PID | LOG_NDELAY, LOG_MAIL);\n    /* Force loading of timezone info (suggested by patrickdk77) */\n    now = time(NULL);\n    localtime(&now);\n    /* We also have to lookup the uid of the unprivileged user before the\n     * chroot. */\n    if (user)\n    {\n        errno = 0;\n        pwd = getpwnam(user);\n        if (pwd == NULL)\n        {\n            if (errno != 0)\n                fprintf(stderr, \"%s: Failed to lookup user: %s\\n\", self,\n                        strerror(errno));\n            else\n                fprintf(stderr, \"%s: No such user: %s\\n\", self, user);\n            return EXIT_FAILURE;\n        }\n    }\n    /* Now we can chroot, which again requires root privileges */\n    if (chroot_dir)\n    {\n        if (chdir(chroot_dir) < 0)\n        {\n            fprintf(stderr, \"%s: Cannot change to chroot: %s\\n\", self,\n                    strerror(errno));\n            return EXIT_FAILURE;\n        }\n        if (chroot(chroot_dir) < 0)\n        {\n            fprintf(stderr, \"%s: Failed to enable chroot: %s\\n\", self,\n                    strerror(errno));\n            return EXIT_FAILURE;\n        }\n    }\n    /* Finally, we revert to the unprivileged user */\n    if (pwd)\n    {\n        if (setgid(pwd->pw_gid) < 0)\n        {\n            fprintf(stderr, \"%s: Failed to switch group id: %s\\n\", self,\n                    strerror(errno));\n            return EXIT_FAILURE;\n        }\n        if (setuid(pwd->pw_uid) < 0)\n        {\n            fprintf(stderr, \"%s: Failed to switch user id: %s\\n\", self,\n                    strerror(errno));\n            return EXIT_FAILURE;\n        }\n    }\n    /* Standard double fork technique to disavow all knowledge about the\n     * controlling terminal */\n    if (daemonize)\n    {\n        close(0);\n        close(1);\n        close(2);\n        if (fork() != 0)\n            return EXIT_SUCCESS;\n        setsid();\n        if (fork() != 0)\n            return EXIT_SUCCESS;\n    }\n    /* Make note of our actual process ID */\n    if (pf)\n    {\n        fprintf(pf, \"%d\", (int)getpid());\n        fclose(pf);\n    }\n\n    srs = srs_new();\n    while ((secret = fgets(secretbuf, sizeof(secretbuf), sf)))\n    {\n        secret = strtok(secret, \"\\r\\n\");\n        if (secret)\n            srs_add_secret(srs, secret);\n    }\n    fclose(sf);\n\n    srs_set_alwaysrewrite(srs, always_rewrite);\n    srs_set_separator(srs, separator);\n    if (hashlength)\n        srs_set_hashlength(srs, hashlength);\n    if (hashmin)\n        srs_set_hashmin(srs, hashmin);\n\n    for (sc = 0; sc < socket_count; ++sc)\n    {\n        fds[sc].fd = sockets[sc];\n        fds[sc].events = POLLIN;\n    }\n    while (TRUE)\n    {\n        int conn;\n        FILE *fp;\n        char linebuf[1024], *line;\n        char keybuf[1024], *key;\n\n        if (poll(fds, socket_count, 1000) < 0)\n        {\n            if (errno == EINTR)\n                continue;\n            if (daemonize)\n                syslog(LOG_MAIL | LOG_ERR, \"Poll failure: %s\", strerror(errno));\n            else\n                fprintf(stderr, \"%s: Poll failure: %s\\n\", self,\n                        strerror(errno));\n            return EXIT_FAILURE;\n        }\n        for (sc = 0; sc < socket_count; ++sc)\n        {\n            if (fds[sc].revents)\n            {\n                conn = accept(fds[sc].fd, NULL, NULL);\n                if (conn < 0)\n                    continue;\n                if (fork() == 0)\n                {\n                    int i;\n                    /* close listen sockets so that we don't stop the main\n                     * daemon process from restarting */\n                    for (i = 0; i < socket_count; ++i)\n                        close(sockets[i]);\n\n                    fp = fdopen(conn, \"r+\");\n                    if (fp == NULL)\n                        exit(EXIT_FAILURE);\n                    fds[0].fd = conn;\n                    fds[0].events = POLLIN;\n                    if (poll(fds, 1, timeout * 1000) <= 0)\n                        return EXIT_FAILURE;\n                    line = fgets(linebuf, sizeof(linebuf), fp);\n                    while (line)\n                    {\n                        fseek(fp, 0, SEEK_CUR); /* Workaround for Solaris */\n                        char *token;\n                        token = strtok(line, \" \\r\\n\");\n                        if (token == NULL || strcmp(token, \"get\") != 0)\n                        {\n                            fprintf(fp, \"500 Invalid request\\n\");\n                            fflush(fp);\n                            return EXIT_FAILURE;\n                        }\n                        token = strtok(NULL, \"\\r\\n\");\n                        if (!token)\n                        {\n                            fprintf(fp, \"500 Invalid request\\n\");\n                            fflush(fp);\n                            return EXIT_FAILURE;\n                        }\n                        key = url_decode(keybuf, sizeof(keybuf), token);\n                        if (!key)\n                        {\n                            fprintf(fp, \"500 Invalid request\\n\");\n                            fflush(fp);\n                            return EXIT_FAILURE;\n                        }\n                        handler[sc](srs, fp, key, domain, excludes);\n                        fflush(fp);\n                        if (poll(fds, 1, timeout * 1000) <= 0)\n                            break;\n                        line = fgets(linebuf, sizeof(linebuf), fp);\n                    }\n                    fclose(fp);\n                    return EXIT_SUCCESS;\n                }\n                close(conn);\n            }\n        }\n        waitpid(-1, NULL, WNOHANG);\n    }\n    return EXIT_SUCCESS;\n}",
        "commit_message": "SECURITY: Fix DoS on overly long input from Postfix\n\nThanks to Mateusz Jo\u0144czyk who reported this issue and gave valuable\nfeedback for its resolution.\n\nPostSRSd would hang on an overly long GET request, because the\nfread()/fwrite() logic in the subprocess would get confused by the\nremaining input line in its buffer.\n\nTheoretically, this error should never occur, as Postfix is supposed to\nsend valid email addresses only, which are shorter than the buffer, even\nassuming every single character is percent-encoded. However, Postfix\nsometimes does seem to send malformed request with multiple concatenated\nemail addresses. I'm not sure if there's a reliable way to trigger this\ncondition by an external attacker, but it is a security bug in PostSRSd\nnevertheless.",
        "cve_desc": "PostSRSd before 1.11 allows a denial of service (subprocess hang) if Postfix sends certain long data fields such as multiple concatenated email addresses. NOTE: the PostSRSd maintainer acknowledges \"theoretically, this error should never occur ... I'm not sure if there's a reliable way to trigger this condition by an external attacker, but it is a security bug in PostSRSd nevertheless.\"",
        "target": 1
      }
    ]
  },
  "pupnp": {
    "0": [],
    "1": []
  },
  "pure-ftpd": {
    "0": [
      {
        "idx": 258470,
        "reasoning": "This code is not vulnerable to the reported issue in `pure_strcmp()`\u2014which concerns differing string lengths\u2014because `pure_memcmp()` explicitly takes a `len` argument defining the comparison length, preventing out-of-bounds reads even if the input buffers have different sizes. The loop iterates only up to the provided `len`, ensuring it never accesses memory beyond the bounds of either input buffer.\n\n\n\n",
        "func": "int pure_memcmp(const void * const b1_, const void * const b2_, size_t len)\n{\n    const unsigned char *b1 = (const unsigned char *) b1_;\n    const unsigned char *b2 = (const unsigned char *) b2_;\n    size_t               i;\n    unsigned char        d = (unsigned char) 0U;\n\n    for (i = 0U; i < len; i++) {\n        d |= b1[i] ^ b2[i];\n    }\n    return (int) ((1 & ((d - 1) >> 8)) - 1);\n}",
        "commit_message": "pure_strcmp(): len(s2) can be > len(s1)\n\nReported by Antonio Morales from GitHub Security Labs, thanks!",
        "cve_desc": "An issue was discovered in Pure-FTPd 1.0.49. An out-of-bounds (OOB) read has been detected in the pure_strcmp function in utils.c.",
        "target": 0
      },
      {
        "idx": 258471,
        "reasoning": "This code is **not vulnerable** despite the commit message highlighting a potential issue. The code explicitly calculates the minimum length between the two strings (`len`) and then uses `pure_memcmp` to compare only up to `len + 1` bytes, preventing a read beyond the bounds of either string even if `s2` is longer than `s1`. \n\n\n\n",
        "func": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    const size_t s1_len = strlen(s1);\n    const size_t s2_len = strlen(s2);\n    const size_t len = (s1_len < s2_len) ? s1_len : s2_len;\n\n    return pure_memcmp(s1, s2, len + 1);\n}",
        "commit_message": "pure_strcmp(): len(s2) can be > len(s1)\n\nReported by Antonio Morales from GitHub Security Labs, thanks!",
        "cve_desc": "An issue was discovered in Pure-FTPd 1.0.49. An out-of-bounds (OOB) read has been detected in the pure_strcmp function in utils.c.",
        "target": 0
      },
      {
        "idx": 258472,
        "reasoning": "This code snippet implements a memory zeroing function and is not directly related to the reported vulnerability in `pure_strcmp()`. The commit message specifically addresses a potential issue with string comparison where the length of the second string (`s2`) could exceed the length of the first string (`s1`), a problem this memory zeroing function doesn't contribute to.\n\n\n\n",
        "func": "void pure_memzero(void * const pnt, const size_t len)\n{\n# ifdef HAVE_EXPLICIT_BZERO\n    explicit_bzero(pnt, len);\n# else\n    volatile unsigned char *pnt_ = (volatile unsigned char *) pnt;\n    size_t                     i = (size_t) 0U;\n\n    while (i < len) {\n        pnt_[i++] = 0U;\n    }\n# endif\n}",
        "commit_message": "pure_strcmp(): len(s2) can be > len(s1)\n\nReported by Antonio Morales from GitHub Security Labs, thanks!",
        "cve_desc": "An issue was discovered in Pure-FTPd 1.0.49. An out-of-bounds (OOB) read has been detected in the pure_strcmp function in utils.c.",
        "target": 0
      },
      {
        "idx": 382849,
        "reasoning": "This code was proactively patched to *prevent* a stack exhaustion vulnerability by reusing a single buffer instead of allocating one for each filename. The commit message explicitly states the fix addresses a potential stack overflow reported by a security researcher, meaning the original code *was* vulnerable, but this version is not.",
        "func": "void dolist(char *arg, const int on_ctrl_conn)\n{\n    int c;\n    void *tls_fd = NULL;\n\n    matches = 0U;\n\n    opt_a = opt_C = opt_d = opt_F = opt_R = opt_r = opt_t = opt_S = 0;\n    opt_l = 1;\n    if (force_ls_a != 0) {\n        opt_a = 1;\n    }\n    if (arg != NULL) {\n        while (isspace((unsigned char) *arg)) {\n            arg++;\n        }\n        while (*arg == '-') {\n            while (arg++ && isalnum((unsigned char) *arg)) {\n                switch (*arg) {\n                case 'a':\n                    opt_a = 1;\n                    break;\n                case 'l':\n                    opt_l = 1;\n                    opt_C = 0;\n                    break;\n                case '1':\n                    opt_l = opt_C = 0;\n                    break;\n                case 'C':\n                    opt_l = 0;\n                    opt_C = 1;\n                    break;\n                case 'F':\n                    opt_F = 1;\n                    break;\n                case 'R':\n                    opt_R = 1;\n                    break;\n                case 'd':\n                    opt_d = 1;\n                    break;\n                case 'r':\n                    opt_r = 1;\n                    break;\n                case 't':\n                    opt_t = 1;\n                    opt_S = 0;\n                    break;\n                case 'S':\n                    opt_S = 1;\n                    opt_t = 0;\n                    break;\n                }\n            }\n            while (isspace((unsigned char) *arg)) {\n                arg++;\n            }\n        }\n    }\n    if (on_ctrl_conn == 0) {\n        opendata();\n        if ((c = xferfd) == -1) {\n            return;\n        }\n        doreply();\n#ifdef WITH_TLS\n        if (data_protection_level == CPL_PRIVATE) {\n            tls_init_data_session(xferfd, passive);\n            tls_fd = tls_data_cnx;\n        }\n#endif\n    } else {                           /* STAT command */\n        c = clientfd;\n#ifdef WITH_TLS\n        if (tls_cnx != NULL) {\n            secure_safe_write(tls_cnx, \"213-STAT\" CRLF,\n                              sizeof \"213-STAT\" CRLF - 1U);\n            tls_fd = tls_cnx;\n        }\n        else\n#endif\n        {\n            safe_write(c, \"213-STAT\" CRLF, sizeof \"213-STAT\" CRLF - 1U, -1);\n        }\n    }\n    if (arg != NULL && *arg != 0) {\n        int justone;\n\n        justone = 1;            /* just one argument, so don't print dir name */\n\n        do {\n            glob_t g;\n            int a;\n            char *endarg;\n\n            if ((endarg = unescape_and_return_next_file(arg)) != NULL) {\n                justone = 0;\n            }\n\n            /* Expand ~ here if needed */\n\n            alarm(GLOB_TIMEOUT);\n            memset(&g, 0, sizeof g);\n            a = sglob(arg,\n                      opt_a ? (GLOB_PERIOD | GLOB_LIMIT) : GLOB_LIMIT,\n                      NULL, &g, max_ls_files + 2, max_ls_depth * 2);\n            alarm(0);\n            if (a == 0) {\n                char **path;\n\n                if (g.gl_pathc <= 0) {\n                    path = NULL;\n                } else {\n                    path = g.gl_pathv;\n                }\n                if (path != NULL && path[0] != NULL && path[1] != NULL) {\n                    justone = 0;\n                }\n                while (path != NULL && *path != NULL) {\n                    struct stat st;\n\n                    if (stat(*path, &st) == 0) {\n                        if (opt_d || !(S_ISDIR(st.st_mode))) {\n                            listfile(NULL, *path);\n                            **path = 0;\n                        }\n                    } else {\n                        **path = 0;\n                    }\n                    path++;\n                }\n                outputfiles(c, tls_fd);    /* in case of opt_C */\n                path = g.gl_pathv;\n                while (path != NULL && *path != NULL) {\n                    if (matches >= max_ls_files) {\n                        break;\n                    }\n                    if (**path != 0) {\n                        if (!justone) {\n                            wrstr(c, tls_fd, \"\\r\\n\\r\\n\");\n                            wrstr(c, tls_fd, *path);\n                            wrstr(c, tls_fd, \":\\r\\n\\r\\n\");\n                        }\n                        if (!chdir(*path)) {\n                            listdir(0U, c, tls_fd, *path);\n                            if (chdir(wd)) {\n                                die(421, LOG_ERR, \"chdir: %s\", strerror(errno));\n                            }\n                        }\n                    }\n                    path++;\n                }\n            } else {\n                if (a == GLOB_NOSPACE) {\n                    addreply(226, MSG_GLOB_NO_MEMORY, arg);\n                    addreply_noformat(0, MSG_PROBABLY_DENIED);\n                } else if (a == GLOB_ABEND) {\n                    addreply(226, MSG_GLOB_READ_ERROR, arg);\n                } else if (a != GLOB_NOMATCH) {\n                    addreply(226, MSG_GLOB_READ_ERROR, arg);\n                    addreply_noformat(0, MSG_PROBABLY_DENIED);\n                }\n            }\n            globfree(&g);\n            arg = endarg;\n        } while (arg != NULL);\n    } else {\n        if (opt_d) {\n            listfile(NULL, \".\");\n        } else {\n            listdir(0U, c, tls_fd, \".\");\n        }\n        outputfiles(c, tls_fd);\n    }\n    wrstr(c, tls_fd, NULL);\n    if (on_ctrl_conn == 0) {\n#ifdef WITH_TLS\n        closedata();\n#endif\n        close(c);\n    } else {\n        addreply_noformat(213, \"End.\");\n        goto end;\n    }\n    if (opt_a || opt_C || opt_d || opt_F || opt_l || opt_r || opt_R ||\n        opt_t || opt_S)\n        addreply(0, \"Options: %s%s%s%s%s%s%s%s%s\",\n                 opt_a ? \"-a \" : \"\",\n                 opt_C ? \"-C \" : \"\",\n                 opt_d ? \"-d \" : \"\",\n                 opt_F ? \"-F \" : \"\",\n                 opt_l ? \"-l \" : \"\",\n                 opt_r ? \"-r \" : \"\",\n                 opt_R ? \"-R \" : \"\", opt_S ? \"-S \" : \"\",\n                 opt_t ? \"-t\" : \"\");\n    if (matches >= max_ls_files) {\n        addreply(226, MSG_LS_TRUNCATED, matches);\n    } else {\n        addreply(226, MSG_LS_SUCCESS, matches);\n    }\nend:\n    if (chdir(wd)) {\n        die(421, LOG_ERR, \"chdir: %s\", strerror(errno));\n    }\n}",
        "commit_message": "listdir(): reuse a single buffer to store every file name to display\n\nAllocating a new buffer for each entry is useless.\n\nAnd as these buffers are allocated on the stack, on systems with a\nsmall stack size, with many entries, the limit can easily be reached,\ncausing a stack exhaustion and aborting the user session.\n\nReported by Antonio Morales from the GitHub Security Lab team, thanks!",
        "cve_desc": "In Pure-FTPd 1.0.49, a stack exhaustion issue was discovered in the listdir function in ls.c.",
        "target": 0
      },
      {
        "idx": 382850,
        "reasoning": "This code addresses a potential stack exhaustion vulnerability by reusing a single buffer instead of allocating one per filename, mitigating the risk of exceeding stack limits with a large number of files. The commit message explicitly states the fix resolves a reported issue from the GitHub Security Lab, confirming the vulnerability was addressed and the code is now safe from that specific stack exhaustion concern.\n\n\n\n",
        "func": "static void outputfiles(int f, void * const tls_fd)\n{\n    unsigned int n;\n    struct filename *p;\n    struct filename *q;\n\n    if (!head) {\n        return;\n    }\n    tail->down = NULL;\n    tail = NULL;\n    colwidth = (colwidth | 7U) + 1U;\n    if (opt_l != 0 || opt_C == 0) {\n        colwidth = 75U;\n    }\n    /* set up first column */\n    p = head;\n    p->top = 1;\n    if (colwidth > 75U) {\n        n = filenames;\n    } else {\n        n = (filenames + (75U / colwidth) - 1U) / (75U / colwidth);\n    }\n    while (n && p) {\n        p = p->down;\n        if (p != NULL) {\n            p->top = 0;\n        }\n        n--;\n    }\n\n    /* while there's a neighbour to the right, point at it */\n    q = head;\n    while (p) {\n        p->top = q->top;\n        q->right = p;\n        q = q->down;\n        p = p->down;\n    }\n\n    /* some are at the right end */\n    while (q) {\n        q->right = NULL;\n        q = q->down;\n    }\n\n    /* don't want wraparound, do we? */\n    p = head;\n    while (p && p->down && !p->down->top) {\n        p = p->down;\n    }\n    if (p && p->down) {\n        p->down = NULL;\n    }\n\n    /* print each line, which consists of each column */\n    p = head;\n    while (p) {\n        q = p;\n        p = p->down;\n        while (q) {\n            char pad[6];\n            char *tmp = (char *) q;\n\n            if (q->right) {\n                memset(pad, '\\t', sizeof pad - 1U);\n                pad[(sizeof pad) - 1] = 0;\n                pad[(colwidth + 7U - strlen(q->line)) / 8] = 0;\n            } else {\n                pad[0] = '\\r';\n                pad[1] = '\\n';\n                pad[2] = 0;\n            }\n            wrstr(f, tls_fd, q->line);\n            wrstr(f, tls_fd, pad);\n            q = q->right;\n            free(tmp);\n            tmp = NULL;\n        }\n    }\n\n    /* reset variables for next time */\n    head = tail = NULL;\n    colwidth = 0U;\n    filenames = 0U;\n}",
        "commit_message": "listdir(): reuse a single buffer to store every file name to display\n\nAllocating a new buffer for each entry is useless.\n\nAnd as these buffers are allocated on the stack, on systems with a\nsmall stack size, with many entries, the limit can easily be reached,\ncausing a stack exhaustion and aborting the user session.\n\nReported by Antonio Morales from the GitHub Security Lab team, thanks!",
        "cve_desc": "In Pure-FTPd 1.0.49, a stack exhaustion issue was discovered in the listdir function in ls.c.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 197420,
        "reasoning": "The `pure_strcmp` function uses `strlen(s1) + 1U` as the length argument for `pure_memcmp`, potentially causing a read beyond the bounds of `s1` if `s2` is longer than `s1`. This is because `pure_memcmp` will attempt to compare up to `strlen(s1) + 1` bytes, leading to an out-of-bounds read when `s2` exceeds the length of `s1`.\n\n\n\n",
        "func": "int pure_strcmp(const char * const s1, const char * const s2)\n{\n    return pure_memcmp(s1, s2, strlen(s1) + 1U);\n}",
        "commit_message": "pure_strcmp(): len(s2) can be > len(s1)\n\nReported by Antonio Morales from GitHub Security Labs, thanks!",
        "cve_desc": "An issue was discovered in Pure-FTPd 1.0.49. An out-of-bounds (OOB) read has been detected in the pure_strcmp function in utils.c.",
        "target": 1
      },
      {
        "idx": 206558,
        "reasoning": "This code is vulnerable to a stack exhaustion attack because it previously allocated a new buffer on the stack for each filename during directory listing, potentially exceeding the stack's capacity with a large number of files. The commit aims to fix this by reusing a single buffer, but the recursive calls to `listdir` with `ALLOCA` for subdirectory paths can *still* lead to stack exhaustion if the directory structure is deep and contains many files, as `ALLOCA` allocates memory on the stack.",
        "func": "static void listdir(unsigned int depth, int f, void * const tls_fd,\n                    const char *name)\n{\n    PureFileInfo *dir;\n    char *names;\n    PureFileInfo *s;\n    PureFileInfo *r;\n    int d;\n\n    if (depth >= max_ls_depth || matches >= max_ls_files) {\n        return;\n    }\n    if ((dir = sreaddir(&names)) == NULL) {\n        addreply(226, MSG_CANT_READ_FILE, name);\n        return;\n    }\n    s = dir;\n    while (s->name_offset != (size_t) -1) {\n        d = 0;\n        if (FI_NAME(s)[0] != '.') {\n            d = listfile(s, NULL);\n        } else if (opt_a) {\n            if (FI_NAME(s)[1] == 0 ||\n                (FI_NAME(s)[1] == '.' && FI_NAME(s)[2] == 0)) {\n                listfile(s, NULL);\n            } else {\n                d = listfile(s, NULL);\n            }\n        }\n        if (!d) {\n            s->name_offset = (size_t) -1;\n        }\n        s++;\n    }\n    outputfiles(f, tls_fd);\n    r = dir;\n    while (opt_R && r != s) {\n        if (r->name_offset != (size_t) -1 && !chdir(FI_NAME(r))) {\n            char *alloca_subdir;\n            const size_t sizeof_subdir = PATH_MAX + 1U;\n\n            if ((alloca_subdir = ALLOCA(sizeof_subdir)) == NULL) {\n                goto toomany;\n            }\n            if (SNCHECK(snprintf(alloca_subdir, sizeof_subdir, \"%s/%s\",\n                                 name, FI_NAME(r)), sizeof_subdir)) {\n                goto nolist;\n            }\n            wrstr(f, tls_fd, \"\\r\\n\\r\\n\");\n            wrstr(f, tls_fd, alloca_subdir);\n            wrstr(f, tls_fd, \":\\r\\n\\r\\n\");\n            listdir(depth + 1U, f, tls_fd, alloca_subdir);\n            nolist:\n            ALLOCA_FREE(alloca_subdir);\n            if (matches >= max_ls_files) {\n                goto toomany;\n            }\n            if (chdir(\"..\")) {    /* defensive in the extreme... */\n                if (chdir(wd) || chdir(name)) {    /* someone rmdir()'d it? */\n                    die(421, LOG_ERR, \"chdir: %s\", strerror(errno));\n                }\n            }\n        }\n        r++;\n    }\n    toomany:\n    free(names);\n    free(dir);\n    names = NULL;\n}",
        "commit_message": "listdir(): reuse a single buffer to store every file name to display\n\nAllocating a new buffer for each entry is useless.\n\nAnd as these buffers are allocated on the stack, on systems with a\nsmall stack size, with many entries, the limit can easily be reached,\ncausing a stack exhaustion and aborting the user session.\n\nReported by Antonio Morales from the GitHub Security Lab team, thanks!",
        "cve_desc": "In Pure-FTPd 1.0.49, a stack exhaustion issue was discovered in the listdir function in ls.c.",
        "target": 1
      }
    ]
  },
  "qemu": {
    "0": [],
    "1": [
      {
        "idx": 10264,
        "reasoning": "The `v9fs_wstat` function, triggered by file renaming operations using the 9P2000.u protocol, is vulnerable to a race condition because it doesn't acquire a path write lock before calling functions like `v9fs_complete_rename` and `v9fs_path_copy`. This lack of locking allows concurrent access to the file system metadata, leading to a segmentation fault and ultimately a QEMU crash, as demonstrated by the provided reproduction steps.",
        "func": "static void coroutine_fn v9fs_wstat(void *opaque)\n{\n    int32_t fid;\n    int err = 0;\n    int16_t unused;\n    V9fsStat v9stat;\n    size_t offset = 7;\n     struct stat stbuf;\n     V9fsFidState *fidp;\n     V9fsPDU *pdu = opaque;\n \n     v9fs_stat_init(&v9stat);\n     err = pdu_unmarshal(pdu, offset, \"dwS\", &fid, &unused, &v9stat);\n        goto out_nofid;\n    }\n",
        "commit_message": "9p: fix QEMU crash when renaming files\n\nWhen using the 9P2000.u version of the protocol, the following shell\ncommand line in the guest can cause QEMU to crash:\n\n    while true; do rm -rf aa; mkdir -p a/b & touch a/b/c & mv a aa; done\n\nWith 9P2000.u, file renaming is handled by the WSTAT command. The\nv9fs_wstat() function calls v9fs_complete_rename(), which calls\nv9fs_fix_path() for every fid whose path is affected by the change.\nThe involved calls to v9fs_path_copy() may race with any other access\nto the fid path performed by some worker thread, causing a crash like\nshown below:\n\nThread 12 \"qemu-system-x86\" received signal SIGSEGV, Segmentation fault.\n0x0000555555a25da2 in local_open_nofollow (fs_ctx=0x555557d958b8, path=0x0,\n flags=65536, mode=0) at hw/9pfs/9p-local.c:59\n59          while (*path && fd != -1) {\n(gdb) bt\n#0  0x0000555555a25da2 in local_open_nofollow (fs_ctx=0x555557d958b8,\n path=0x0, flags=65536, mode=0) at hw/9pfs/9p-local.c:59\n#1  0x0000555555a25e0c in local_opendir_nofollow (fs_ctx=0x555557d958b8,\n path=0x0) at hw/9pfs/9p-local.c:92\n#2  0x0000555555a261b8 in local_lstat (fs_ctx=0x555557d958b8,\n fs_path=0x555556b56858, stbuf=0x7fff84830ef0) at hw/9pfs/9p-local.c:185\n#3  0x0000555555a2b367 in v9fs_co_lstat (pdu=0x555557d97498,\n path=0x555556b56858, stbuf=0x7fff84830ef0) at hw/9pfs/cofile.c:53\n#4  0x0000555555a1e9e2 in v9fs_stat (opaque=0x555557d97498)\n at hw/9pfs/9p.c:1083\n#5  0x0000555555e060a2 in coroutine_trampoline (i0=-669165424, i1=32767)\n at util/coroutine-ucontext.c:116\n#6  0x00007fffef4f5600 in __start_context () at /lib64/libc.so.6\n#7  0x0000000000000000 in  ()\n(gdb)\n\nThe fix is to take the path write lock when calling v9fs_complete_rename(),\nlike in v9fs_rename().\n\nImpact:  DoS triggered by unprivileged guest users.\n\nFixes: CVE-2018-19489\nCc: P J P <ppandit@redhat.com>\nReported-by: zhibin hu <noirfate@gmail.com>\nReviewed-by: Prasad J Pandit <pjp@fedoraproject.org>\nSigned-off-by: Greg Kurz <groug@kaod.org>",
        "cve_desc": "v9fs_wstat in hw/9pfs/9p.c in QEMU allows guest OS users to cause a denial of service (crash) because of a race condition during file renaming.",
        "target": 1
      },
      {
        "idx": 10269,
        "reasoning": "The code is vulnerable because the `vga_draw_graphic` function incorrectly calculates the region for the dirty bitmap when scanlines are padded, leading to an out-of-bounds read in `cpu_physical_memory_snapshot_get_dirty`. This miscalculation, particularly in split-screen mode, triggers an assertion failure and can result in a denial of service.",
        "func": "static void vga_draw_graphic(VGACommonState *s, int full_update)\n{\n    DisplaySurface *surface = qemu_console_surface(s->con);\n    int y1, y, update, linesize, y_start, double_scan, mask, depth;\n    int width, height, shift_control, line_offset, bwidth, bits;\n    ram_addr_t page0, page1;\n    DirtyBitmapSnapshot *snap = NULL;\n    int disp_width, multi_scan, multi_run;\n    uint8_t *d;\n    uint32_t v, addr1, addr;\n    vga_draw_line_func *vga_draw_line = NULL;\n    bool share_surface;\n    pixman_format_code_t format;\n#ifdef HOST_WORDS_BIGENDIAN\n    bool byteswap = !s->big_endian_fb;\n#else\n    bool byteswap = s->big_endian_fb;\n#endif\n\n    full_update |= update_basic_params(s);\n\n    s->get_resolution(s, &width, &height);\n    disp_width = width;\n\n    shift_control = (s->gr[VGA_GFX_MODE] >> 5) & 3;\n    double_scan = (s->cr[VGA_CRTC_MAX_SCAN] >> 7);\n    if (shift_control != 1) {\n        multi_scan = (((s->cr[VGA_CRTC_MAX_SCAN] & 0x1f) + 1) << double_scan)\n            - 1;\n    } else {\n        /* in CGA modes, multi_scan is ignored */\n        /* XXX: is it correct ? */\n        multi_scan = double_scan;\n    }\n    multi_run = multi_scan;\n    if (shift_control != s->shift_control ||\n        double_scan != s->double_scan) {\n        full_update = 1;\n        s->shift_control = shift_control;\n        s->double_scan = double_scan;\n    }\n\n    if (shift_control == 0) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    } else if (shift_control == 1) {\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            disp_width <<= 1;\n        }\n    }\n\n    depth = s->get_bpp(s);\n\n    /*\n     * Check whether we can share the surface with the backend\n     * or whether we need a shadow surface. We share native\n     * endian surfaces for 15bpp and above and byteswapped\n     * surfaces for 24bpp and above.\n     */\n    format = qemu_default_pixman_format(depth, !byteswap);\n    if (format) {\n        share_surface = dpy_gfx_check_format(s->con, format)\n            && !s->force_shadow;\n    } else {\n        share_surface = false;\n    }\n    if (s->line_offset != s->last_line_offset ||\n        disp_width != s->last_width ||\n        height != s->last_height ||\n        s->last_depth != depth ||\n        s->last_byteswap != byteswap ||\n        share_surface != is_buffer_shared(surface)) {\n        if (share_surface) {\n            surface = qemu_create_displaysurface_from(disp_width,\n                    height, format, s->line_offset,\n                    s->vram_ptr + (s->start_addr * 4));\n            dpy_gfx_replace_surface(s->con, surface);\n        } else {\n            qemu_console_resize(s->con, disp_width, height);\n            surface = qemu_console_surface(s->con);\n        }\n        s->last_scr_width = disp_width;\n        s->last_scr_height = height;\n        s->last_width = disp_width;\n        s->last_height = height;\n        s->last_line_offset = s->line_offset;\n        s->last_depth = depth;\n        s->last_byteswap = byteswap;\n        full_update = 1;\n    } else if (is_buffer_shared(surface) &&\n               (full_update || surface_data(surface) != s->vram_ptr\n                + (s->start_addr * 4))) {\n        pixman_format_code_t format =\n            qemu_default_pixman_format(depth, !byteswap);\n        surface = qemu_create_displaysurface_from(disp_width,\n                height, format, s->line_offset,\n                s->vram_ptr + (s->start_addr * 4));\n        dpy_gfx_replace_surface(s->con, surface);\n    }\n\n    if (shift_control == 0) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE4D2;\n        } else {\n            v = VGA_DRAW_LINE4;\n        }\n        bits = 4;\n    } else if (shift_control == 1) {\n        full_update |= update_palette16(s);\n        if (sr(s, VGA_SEQ_CLOCK_MODE) & 8) {\n            v = VGA_DRAW_LINE2D2;\n        } else {\n            v = VGA_DRAW_LINE2;\n        }\n        bits = 4;\n    } else {\n        switch(s->get_bpp(s)) {\n        default:\n        case 0:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8D2;\n            bits = 4;\n            break;\n        case 8:\n            full_update |= update_palette256(s);\n            v = VGA_DRAW_LINE8;\n            bits = 8;\n            break;\n        case 15:\n            v = s->big_endian_fb ? VGA_DRAW_LINE15_BE : VGA_DRAW_LINE15_LE;\n            bits = 16;\n            break;\n        case 16:\n            v = s->big_endian_fb ? VGA_DRAW_LINE16_BE : VGA_DRAW_LINE16_LE;\n            bits = 16;\n            break;\n        case 24:\n            v = s->big_endian_fb ? VGA_DRAW_LINE24_BE : VGA_DRAW_LINE24_LE;\n            bits = 24;\n            break;\n        case 32:\n            v = s->big_endian_fb ? VGA_DRAW_LINE32_BE : VGA_DRAW_LINE32_LE;\n            bits = 32;\n            break;\n        }\n    }\n    vga_draw_line = vga_draw_line_table[v];\n\n    if (!is_buffer_shared(surface) && s->cursor_invalidate) {\n        s->cursor_invalidate(s);\n    }\n\n    line_offset = s->line_offset;\n#if 0\n    printf(\"w=%d h=%d v=%d line_offset=%d cr[0x09]=0x%02x cr[0x17]=0x%02x linecmp=%d sr[0x01]=0x%02x\\n\",\n           width, height, v, line_offset, s->cr[9], s->cr[VGA_CRTC_MODE],\n           s->line_compare, sr(s, VGA_SEQ_CLOCK_MODE));\n#endif\n    addr1 = (s->start_addr * 4);\n    bwidth = (width * bits + 7) / 8;\n    y_start = -1;\n    d = surface_data(surface);\n    linesize = surface_stride(surface);\n    y1 = 0;\n\n     if (!full_update) {\n         vga_sync_dirty_bitmap(s);\n         snap = memory_region_snapshot_and_clear_dirty(&s->vram, addr1,\n                                                      bwidth * height,\n                                                       DIRTY_MEMORY_VGA);\n     }\n    for(y = 0; y < height; y++) {\n        addr = addr1;\n        if (!(s->cr[VGA_CRTC_MODE] & 1)) {\n            int shift;\n            /* CGA compatibility handling */\n            shift = 14 + ((s->cr[VGA_CRTC_MODE] >> 6) & 1);\n            addr = (addr & ~(1 << shift)) | ((y1 & 1) << shift);\n        }\n        if (!(s->cr[VGA_CRTC_MODE] & 2)) {\n            addr = (addr & ~0x8000) | ((y1 & 2) << 14);\n        }\n        update = full_update;\n        page0 = addr;\n        page1 = addr + bwidth - 1;\n        if (full_update) {\n            update = 1;\n        } else {\n            update = memory_region_snapshot_get_dirty(&s->vram, snap,\n                                                      page0, page1 - page0);\n        }\n        /* explicit invalidation for the hardware cursor (cirrus only) */\n        update |= vga_scanline_invalidated(s, y);\n        if (update) {\n            if (y_start < 0)\n                y_start = y;\n            if (!(is_buffer_shared(surface))) {\n                vga_draw_line(s, d, s->vram_ptr + addr, width);\n                if (s->cursor_draw_line)\n                    s->cursor_draw_line(s, d, y);\n            }\n        } else {\n            if (y_start >= 0) {\n                /* flush to display */\n                dpy_gfx_update(s->con, 0, y_start,\n                               disp_width, y - y_start);\n                y_start = -1;\n            }\n        }\n        if (!multi_run) {\n            mask = (s->cr[VGA_CRTC_MODE] & 3) ^ 3;\n            if ((y1 & mask) == mask)\n                addr1 += line_offset;\n            y1++;\n            multi_run = multi_scan;\n        } else {\n            multi_run--;\n        }\n        /* line compare acts on the displayed lines */\n        if (y == s->line_compare)\n            addr1 = 0;\n        d += linesize;\n    }\n    if (y_start >= 0) {\n        /* flush to display */\n        dpy_gfx_update(s->con, 0, y_start,\n                       disp_width, y - y_start);\n    }\n    g_free(snap);\n    memset(s->invalidated_y_table, 0, sizeof(s->invalidated_y_table));\n}\n",
        "commit_message": "vga: fix display update region calculation\n\nvga display update mis-calculated the region for the dirty bitmap\nsnapshot in case the scanlines are padded.  This can triggere an\nassert in cpu_physical_memory_snapshot_get_dirty().\n\nFixes: fec5e8c92becad223df9d972770522f64aafdb72\nReported-by: Kevin Wolf <kwolf@redhat.com>\nReported-by: \u674e\u5f3a <liqiang6-s@360.cn>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>\nMessage-id: 20170509104839.19415-1-kraxel@redhat.com",
        "cve_desc": "The vga display update in mis-calculated the region for the dirty bitmap snapshot in case split screen mode is used causing a denial of service (assertion failure) in the cpu_physical_memory_snapshot_get_dirty function.",
        "target": 1
      },
      {
        "idx": 10273,
        "reasoning": "The code is vulnerable to an infinite loop within the `lsi_execute_script` function when encountering empty opcodes, as the `s->dsp` index continues to advance even without processing valid instructions. While a loop exit condition was added after 10,000 iterations to mitigate this, it's a workaround rather than a true fix, and doesn't prevent the potential for prolonged resource consumption before triggering the interrupt.",
        "func": "static void lsi_execute_script(LSIState *s)\n{\n    PCIDevice *pci_dev = PCI_DEVICE(s);\n    uint32_t insn;\n    uint32_t addr, addr_high;\n    int opcode;\n    int insn_processed = 0;\n\n    s->istat1 |= LSI_ISTAT1_SRUN;\nagain:\n \n     s->istat1 |= LSI_ISTAT1_SRUN;\n again:\n    insn_processed++;\n     insn = read_dword(s, s->dsp);\n     if (!insn) {\n         /* If we receive an empty opcode increment the DSP by 4 bytes\n        s->dbc = insn & 0xffffff;\n        s->rbc = s->dbc;\n        /* ??? Set ESA.  */\n        s->ia = s->dsp - 8;\n        if (insn & (1 << 29)) {\n            /* Indirect addressing.  */\n            addr = read_dword(s, addr);\n        } else if (insn & (1 << 28)) {\n            uint32_t buf[2];\n            int32_t offset;\n            /* Table indirect addressing.  */\n\n            /* 32-bit Table indirect */\n            offset = sextract32(addr, 0, 24);\n            pci_dma_read(pci_dev, s->dsa + offset, buf, 8);\n            /* byte count is stored in bits 0:23 only */\n            s->dbc = cpu_to_le32(buf[0]) & 0xffffff;\n            s->rbc = s->dbc;\n            addr = cpu_to_le32(buf[1]);\n\n            /* 40-bit DMA, upper addr bits [39:32] stored in first DWORD of\n             * table, bits [31:24] */\n            if (lsi_dma_40bit(s))\n                addr_high = cpu_to_le32(buf[0]) >> 24;\n            else if (lsi_dma_ti64bit(s)) {\n                int selector = (cpu_to_le32(buf[0]) >> 24) & 0x1f;\n                switch (selector) {\n                case 0 ... 0x0f:\n                    /* offset index into scratch registers since\n                     * TI64 mode can use registers C to R */\n                    addr_high = s->scratch[2 + selector];\n                    break;\n                case 0x10:\n                    addr_high = s->mmrs;\n                    break;\n                case 0x11:\n                    addr_high = s->mmws;\n                    break;\n                case 0x12:\n                    addr_high = s->sfs;\n                    break;\n                case 0x13:\n                    addr_high = s->drs;\n                    break;\n                case 0x14:\n                    addr_high = s->sbms;\n                    break;\n                case 0x15:\n                    addr_high = s->dbms;\n                    break;\n                default:\n                    qemu_log_mask(LOG_GUEST_ERROR,\n                          \"lsi_scsi: Illegal selector specified (0x%x > 0x15) \"\n                          \"for 64-bit DMA block move\", selector);\n                    break;\n                }\n            }\n        } else if (lsi_dma_64bit(s)) {\n            /* fetch a 3rd dword if 64-bit direct move is enabled and\n               only if we're not doing table indirect or indirect addressing */\n            s->dbms = read_dword(s, s->dsp);\n            s->dsp += 4;\n            s->ia = s->dsp - 12;\n        }\n        if ((s->sstat1 & PHASE_MASK) != ((insn >> 24) & 7)) {\n            trace_lsi_execute_script_blockmove_badphase(\n                    scsi_phase_name(s->sstat1),\n                    scsi_phase_name(insn >> 24));\n            lsi_script_scsi_interrupt(s, LSI_SIST0_MA, 0);\n            break;\n        }\n        s->dnad = addr;\n        s->dnad64 = addr_high;\n        switch (s->sstat1 & 0x7) {\n        case PHASE_DO:\n            s->waiting = LSI_DMA_SCRIPTS;\n            lsi_do_dma(s, 1);\n            if (s->waiting)\n                s->waiting = LSI_DMA_IN_PROGRESS;\n            break;\n        case PHASE_DI:\n            s->waiting = LSI_DMA_SCRIPTS;\n            lsi_do_dma(s, 0);\n            if (s->waiting)\n                s->waiting = LSI_DMA_IN_PROGRESS;\n            break;\n        case PHASE_CMD:\n            lsi_do_command(s);\n            break;\n        case PHASE_ST:\n            lsi_do_status(s);\n            break;\n        case PHASE_MO:\n            lsi_do_msgout(s);\n            break;\n        case PHASE_MI:\n            lsi_do_msgin(s);\n            break;\n        default:\n            qemu_log_mask(LOG_UNIMP, \"lsi_scsi: Unimplemented phase %s\\n\",\n                          scsi_phase_name(s->sstat1));\n        }\n        s->dfifo = s->dbc & 0xff;\n        s->ctest5 = (s->ctest5 & 0xfc) | ((s->dbc >> 8) & 3);\n        s->sbc = s->dbc;\n        s->rbc -= s->dbc;\n        s->ua = addr + s->dbc;\n        break;\n\n    case 1: /* IO or Read/Write instruction.  */\n        opcode = (insn >> 27) & 7;\n        if (opcode < 5) {\n            uint32_t id;\n\n            if (insn & (1 << 25)) {\n                id = read_dword(s, s->dsa + sextract32(insn, 0, 24));\n            } else {\n                id = insn;\n            }\n            id = (id >> 16) & 0xf;\n            if (insn & (1 << 26)) {\n                addr = s->dsp + sextract32(addr, 0, 24);\n            }\n            s->dnad = addr;\n            switch (opcode) {\n            case 0: /* Select */\n                s->sdid = id;\n                if (s->scntl1 & LSI_SCNTL1_CON) {\n                    trace_lsi_execute_script_io_alreadyreselected();\n                    s->dsp = s->dnad;\n                    break;\n                }\n                s->sstat0 |= LSI_SSTAT0_WOA;\n                s->scntl1 &= ~LSI_SCNTL1_IARB;\n                if (!scsi_device_find(&s->bus, 0, id, 0)) {\n                    lsi_bad_selection(s, id);\n                    break;\n                }\n                trace_lsi_execute_script_io_selected(id,\n                                             insn & (1 << 3) ? \" ATN\" : \"\");\n                /* ??? Linux drivers compain when this is set.  Maybe\n                   it only applies in low-level mode (unimplemented).\n                lsi_script_scsi_interrupt(s, LSI_SIST0_CMP, 0); */\n                s->select_tag = id << 8;\n                s->scntl1 |= LSI_SCNTL1_CON;\n                if (insn & (1 << 3)) {\n                    s->socl |= LSI_SOCL_ATN;\n                    s->sbcl |= LSI_SBCL_ATN;\n                }\n                s->sbcl |= LSI_SBCL_BSY;\n                lsi_set_phase(s, PHASE_MO);\n                s->waiting = LSI_NOWAIT;\n                break;\n            case 1: /* Disconnect */\n                trace_lsi_execute_script_io_disconnect();\n                s->scntl1 &= ~LSI_SCNTL1_CON;\n                /* FIXME: this is not entirely correct; the target need not ask\n                 * for reselection until it has to send data, while here we force a\n                 * reselection as soon as the bus is free.  The correct flow would\n                 * reselect before lsi_transfer_data and disconnect as soon as\n                 * DMA ends.\n                 */\n                if (!s->current) {\n                    lsi_request *p = get_pending_req(s);\n                    if (p) {\n                        lsi_reselect(s, p);\n                    }\n                }\n                break;\n            case 2: /* Wait Reselect */\n                if (s->istat0 & LSI_ISTAT0_SIGP) {\n                    s->dsp = s->dnad;\n                } else if (!lsi_irq_on_rsl(s)) {\n                        lsi_wait_reselect(s);\n                }\n                break;\n            case 3: /* Set */\n                trace_lsi_execute_script_io_set(\n                        insn & (1 << 3) ? \" ATN\" : \"\",\n                        insn & (1 << 6) ? \" ACK\" : \"\",\n                        insn & (1 << 9) ? \" TM\" : \"\",\n                        insn & (1 << 10) ? \" CC\" : \"\");\n                if (insn & (1 << 3)) {\n                    s->socl |= LSI_SOCL_ATN;\n                    s->sbcl |= LSI_SBCL_ATN;\n                    lsi_set_phase(s, PHASE_MO);\n                }\n\n                if (insn & (1 << 6)) {\n                    s->sbcl |= LSI_SBCL_ACK;\n                }\n\n                if (insn & (1 << 9)) {\n                    qemu_log_mask(LOG_UNIMP,\n                        \"lsi_scsi: Target mode not implemented\\n\");\n                }\n                if (insn & (1 << 10))\n                    s->carry = 1;\n                break;\n            case 4: /* Clear */\n                trace_lsi_execute_script_io_clear(\n                        insn & (1 << 3) ? \" ATN\" : \"\",\n                        insn & (1 << 6) ? \" ACK\" : \"\",\n                        insn & (1 << 9) ? \" TM\" : \"\",\n                        insn & (1 << 10) ? \" CC\" : \"\");\n                if (insn & (1 << 3)) {\n                    s->socl &= ~LSI_SOCL_ATN;\n                    s->sbcl &= ~LSI_SBCL_ATN;\n                }\n\n                if (insn & (1 << 6)) {\n                    s->sbcl &= ~LSI_SBCL_ACK;\n                }\n\n                if (insn & (1 << 10))\n                    s->carry = 0;\n                break;\n            }\n        } else {\n            uint8_t op0;\n            uint8_t op1;\n            uint8_t data8;\n            int reg;\n            int operator;\n\n            static const char *opcode_names[3] =\n                {\"Write\", \"Read\", \"Read-Modify-Write\"};\n            static const char *operator_names[8] =\n                {\"MOV\", \"SHL\", \"OR\", \"XOR\", \"AND\", \"SHR\", \"ADD\", \"ADC\"};\n\n            reg = ((insn >> 16) & 0x7f) | (insn & 0x80);\n            data8 = (insn >> 8) & 0xff;\n            opcode = (insn >> 27) & 7;\n            operator = (insn >> 24) & 7;\n            trace_lsi_execute_script_io_opcode(\n                    opcode_names[opcode - 5], reg,\n                    operator_names[operator], data8, s->sfbr,\n                    (insn & (1 << 23)) ? \" SFBR\" : \"\");\n            op0 = op1 = 0;\n            switch (opcode) {\n            case 5: /* From SFBR */\n                op0 = s->sfbr;\n                op1 = data8;\n                break;\n            case 6: /* To SFBR */\n                if (operator)\n                    op0 = lsi_reg_readb(s, reg);\n                op1 = data8;\n                break;\n            case 7: /* Read-modify-write */\n                if (operator)\n                    op0 = lsi_reg_readb(s, reg);\n                if (insn & (1 << 23)) {\n                    op1 = s->sfbr;\n                } else {\n                    op1 = data8;\n                }\n                break;\n            }\n\n            switch (operator) {\n            case 0: /* move */\n                op0 = op1;\n                break;\n            case 1: /* Shift left */\n                op1 = op0 >> 7;\n                op0 = (op0 << 1) | s->carry;\n                s->carry = op1;\n                break;\n            case 2: /* OR */\n                op0 |= op1;\n                break;\n            case 3: /* XOR */\n                op0 ^= op1;\n                break;\n            case 4: /* AND */\n                op0 &= op1;\n                break;\n            case 5: /* SHR */\n                op1 = op0 & 1;\n                op0 = (op0 >> 1) | (s->carry << 7);\n                s->carry = op1;\n                break;\n            case 6: /* ADD */\n                op0 += op1;\n                s->carry = op0 < op1;\n                break;\n            case 7: /* ADC */\n                op0 += op1 + s->carry;\n                if (s->carry)\n                    s->carry = op0 <= op1;\n                else\n                    s->carry = op0 < op1;\n                break;\n            }\n\n            switch (opcode) {\n            case 5: /* From SFBR */\n            case 7: /* Read-modify-write */\n                lsi_reg_writeb(s, reg, op0);\n                break;\n            case 6: /* To SFBR */\n                s->sfbr = op0;\n                break;\n            }\n        }\n        break;\n\n    case 2: /* Transfer Control.  */\n        {\n            int cond;\n            int jmp;\n\n            if ((insn & 0x002e0000) == 0) {\n                trace_lsi_execute_script_tc_nop();\n                break;\n            }\n            if (s->sist1 & LSI_SIST1_STO) {\n                trace_lsi_execute_script_tc_delayedselect_timeout();\n                lsi_stop_script(s);\n                break;\n            }\n            cond = jmp = (insn & (1 << 19)) != 0;\n            if (cond == jmp && (insn & (1 << 21))) {\n                trace_lsi_execute_script_tc_compc(s->carry == jmp);\n                cond = s->carry != 0;\n            }\n            if (cond == jmp && (insn & (1 << 17))) {\n                trace_lsi_execute_script_tc_compp(scsi_phase_name(s->sstat1),\n                        jmp ? '=' : '!', scsi_phase_name(insn >> 24));\n                cond = (s->sstat1 & PHASE_MASK) == ((insn >> 24) & 7);\n            }\n            if (cond == jmp && (insn & (1 << 18))) {\n                uint8_t mask;\n\n                mask = (~insn >> 8) & 0xff;\n                trace_lsi_execute_script_tc_compd(\n                        s->sfbr, mask, jmp ? '=' : '!', insn & mask);\n                cond = (s->sfbr & mask) == (insn & mask);\n            }\n            if (cond == jmp) {\n                if (insn & (1 << 23)) {\n                    /* Relative address.  */\n                    addr = s->dsp + sextract32(addr, 0, 24);\n                }\n                switch ((insn >> 27) & 7) {\n                case 0: /* Jump */\n                    trace_lsi_execute_script_tc_jump(addr);\n                    s->adder = addr;\n                    s->dsp = addr;\n                    break;\n                case 1: /* Call */\n                    trace_lsi_execute_script_tc_call(addr);\n                    s->temp = s->dsp;\n                    s->dsp = addr;\n                    break;\n                case 2: /* Return */\n                    trace_lsi_execute_script_tc_return(s->temp);\n                    s->dsp = s->temp;\n                    break;\n                case 3: /* Interrupt */\n                    trace_lsi_execute_script_tc_interrupt(s->dsps);\n                    if ((insn & (1 << 20)) != 0) {\n                        s->istat0 |= LSI_ISTAT0_INTF;\n                        lsi_update_irq(s);\n                    } else {\n                        lsi_script_dma_interrupt(s, LSI_DSTAT_SIR);\n                    }\n                    break;\n                default:\n                    trace_lsi_execute_script_tc_illegal();\n                    lsi_script_dma_interrupt(s, LSI_DSTAT_IID);\n                    break;\n                }\n            } else {\n                trace_lsi_execute_script_tc_cc_failed();\n            }\n        }\n        break;\n\n    case 3:\n        if ((insn & (1 << 29)) == 0) {\n            /* Memory move.  */\n            uint32_t dest;\n            /* ??? The docs imply the destination address is loaded into\n               the TEMP register.  However the Linux drivers rely on\n               the value being presrved.  */\n            dest = read_dword(s, s->dsp);\n            s->dsp += 4;\n            lsi_memcpy(s, dest, addr, insn & 0xffffff);\n        } else {\n            uint8_t data[7];\n            int reg;\n            int n;\n            int i;\n\n            if (insn & (1 << 28)) {\n                addr = s->dsa + sextract32(addr, 0, 24);\n            }\n            n = (insn & 7);\n            reg = (insn >> 16) & 0xff;\n            if (insn & (1 << 24)) {\n                pci_dma_read(pci_dev, addr, data, n);\n                trace_lsi_execute_script_mm_load(reg, n, addr, *(int *)data);\n                for (i = 0; i < n; i++) {\n                    lsi_reg_writeb(s, reg + i, data[i]);\n                }\n            } else {\n                trace_lsi_execute_script_mm_store(reg, n, addr);\n                for (i = 0; i < n; i++) {\n                    data[i] = lsi_reg_readb(s, reg + i);\n                }\n                pci_dma_write(pci_dev, addr, data, n);\n            }\n        }\n    }\n    if (insn_processed > 10000 && s->waiting == LSI_NOWAIT) {\n        /* Some windows drivers make the device spin waiting for a memory\n           location to change.  If we have been executed a lot of code then\n           assume this is the case and force an unexpected device disconnect.\n           This is apparently sufficient to beat the drivers into submission.\n         */\n        if (!(s->sien0 & LSI_SIST0_UDC)) {\n            qemu_log_mask(LOG_GUEST_ERROR,\n                          \"lsi_scsi: inf. loop with UDC masked\");\n        }\n        lsi_script_scsi_interrupt(s, LSI_SIST0_UDC, 0);\n        lsi_disconnect(s);\n    } else if (s->istat1 & LSI_ISTAT1_SRUN && s->waiting == LSI_NOWAIT) {\n        if (s->dcntl & LSI_DCNTL_SSM) {\n             }\n         }\n     }\n",
        "commit_message": "scsi: lsi: exit infinite loop while executing script (CVE-2019-12068)\n\nWhen executing script in lsi_execute_script(), the LSI scsi adapter\nemulator advances 's->dsp' index to read next opcode. This can lead\nto an infinite loop if the next opcode is empty. Move the existing\nloop exit after 10k iterations so that it covers no-op opcodes as\nwell.\n\nReported-by: Bugs SysSec <bugs-syssec@rub.de>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>\nSigned-off-by: Prasad J Pandit <pjp@fedoraproject.org>\nSigned-off-by: Paolo Bonzini <pbonzini@redhat.com>",
        "cve_desc": "In QEMU 1:4.1-1, 1:2.1+dfsg-12+deb8u6, 1:2.8+dfsg-6+deb9u8, 1:3.1+dfsg-8~deb10u1, 1:3.1+dfsg-8+deb10u2, and 1:2.1+dfsg-12+deb8u12 (fixed), when executing script in lsi_execute_script(), the LSI scsi adapter emulator advances 's->dsp' index to read next opcode. This can lead to an infinite loop if the next opcode is empty. Move the existing loop exit after 10k iterations so that it covers no-op opcodes as well.",
        "target": 1
      },
      {
        "idx": 10274,
        "reasoning": "This code is vulnerable because it initially sets `umask(0)` after forking, effectively removing all permission restrictions for group and others when creating files as the daemon. This allows local users to read and write sensitive files like logs and state files created by the qemu guest agent, as described in CVE-2013-2007, due to overly permissive default file creation modes.",
        "func": "static void become_daemon(const char *pidfile)\n{\n#ifndef _WIN32\n    pid_t pid, sid;\n\n    pid = fork();\n    if (pid < 0) {\n        exit(EXIT_FAILURE);\n    }\n    if (pid > 0) {\n        exit(EXIT_SUCCESS);\n    }\n\n    if (pidfile) {\n        if (!ga_open_pidfile(pidfile)) {\n            g_critical(\"failed to create pidfile\");\n            exit(EXIT_FAILURE);\n         }\n     }\n \n    umask(0);\n     sid = setsid();\n     if (sid < 0) {\n         goto fail;\n    }\n    if ((chdir(\"/\")) < 0) {\n        goto fail;\n    }\n\n    reopen_fd_to_null(STDIN_FILENO);\n    reopen_fd_to_null(STDOUT_FILENO);\n    reopen_fd_to_null(STDERR_FILENO);\n    return;\n\nfail:\n    if (pidfile) {\n        unlink(pidfile);\n    }\n    g_critical(\"failed to daemonize\");\n    exit(EXIT_FAILURE);\n#endif\n}\n",
        "commit_message": "qga: set umask 0077 when daemonizing (CVE-2013-2007)\n\nThe qemu guest agent creates a bunch of files with insecure permissions\nwhen started in daemon mode. For example:\n\n  -rw-rw-rw- 1 root root /var/log/qemu-ga.log\n  -rw-rw-rw- 1 root root /var/run/qga.state\n  -rw-rw-rw- 1 root root /var/log/qga-fsfreeze-hook.log\n\nIn addition, at least all files created with the \"guest-file-open\" QMP\ncommand, and all files created with shell output redirection (or\notherwise) by utilities invoked by the fsfreeze hook script are affected.\n\nFor now mask all file mode bits for \"group\" and \"others\" in\nbecome_daemon().\n\nTemporarily, for compatibility reasons, stick with the 0666 file-mode in\ncase of files newly created by the \"guest-file-open\" QMP call. Do so\nwithout changing the umask temporarily.\n\nSigned-off-by: Laszlo Ersek <lersek@redhat.com>\nSigned-off-by: Anthony Liguori <aliguori@us.ibm.com>",
        "cve_desc": "The qemu guest agent in Qemu 1.4.1 and earlier, as used by Xen, when started in daemon mode, uses weak permissions for certain files, which allows local users to read and write to these files.",
        "target": 1
      },
      {
        "idx": 10293,
        "reasoning": "This code is vulnerable to a denial of service due to a potential for infinite recursion within the `xhci_kick_ep` and `xhci_kick_epctx` functions, as highlighted by the CVE description. While the commit attempts to mitigate this with an assertion, the provided snippet doesn't show the added tracking variable and assertion being *used* to prevent the recursive call *before* `xhci_kick_epctx` is invoked, leaving the recursion possibility open.",
        "func": "static void xhci_kick_ep(XHCIState *xhci, unsigned int slotid,\n                         unsigned int epid, unsigned int streamid)\n{\n    XHCIEPContext *epctx;\n\n    assert(slotid >= 1 && slotid <= xhci->numslots);\n    assert(epid >= 1 && epid <= 31);\n\n    if (!xhci->slots[slotid-1].enabled) {\n        DPRINTF(\"xhci: xhci_kick_ep for disabled slot %d\\n\", slotid);\n        return;\n    }\n    epctx = xhci->slots[slotid-1].eps[epid-1];\n    if (!epctx) {\n        DPRINTF(\"xhci: xhci_kick_ep for disabled endpoint %d,%d\\n\",\n                epid, slotid);\n        return;\n         return;\n     }\n \n     xhci_kick_epctx(epctx, streamid);\n }\n",
        "commit_message": "xhci: guard xhci_kick_epctx against recursive calls\n\nTrack xhci_kick_epctx processing being active in a variable.  Check the\nvariable before calling xhci_kick_epctx from xhci_kick_ep.  Add an\nassert to make sure we don't call recursively into xhci_kick_epctx.\n\nCc: 1653384@bugs.launchpad.net\nFixes: 94b037f2a451b3dc855f9f2c346e5049a361bd55\nReported-by: Fabian Lesniak <fabian@lesniak-it.de>\nSigned-off-by: Gerd Hoffmann <kraxel@redhat.com>\nMessage-id: 1486035372-3621-1-git-send-email-kraxel@redhat.com\nMessage-id: 1485790607-31399-5-git-send-email-kraxel@redhat.com",
        "cve_desc": "QEMU (aka Quick Emulator), when built with USB xHCI controller emulator support, allows local guest OS privileged users to cause a denial of service (infinite recursive call) via vectors involving control transfer descriptors sequencing.",
        "target": 1
      }
    ]
  },
  "qpdf": {
    "0": [
      {
        "idx": 254951,
        "reasoning": "This code snippet is not inherently vulnerable. It simply retrieves a stored buffer and then nullifies the pointer, preventing potential double-free issues\u2014it addresses a previous infinite loop condition as stated in the commit message, but doesn't introduce new security risks based on the provided code alone. \n\n\n\n",
        "func": "QPDFWriter::getBuffer()\n{\n    Buffer* result = this->output_buffer;\n    this->output_buffer = 0;\n    return result;\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 0
      },
      {
        "idx": 254952,
        "reasoning": "This code appears safe as it focuses on converting indirect object references to direct ones within a PDF file structure, primarily to flatten the file for writing\u2014it doesn't introduce any obvious logic errors that could lead to exploitable vulnerabilities like buffer overflows or arbitrary code execution. The code includes checks to prevent revisiting already processed objects (`visited` set) and handles different object types (arrays, dictionaries, streams) in a controlled manner, mitigating potential issues during object manipulation.\n\n\n\n",
        "func": "QPDFWriter::prepareFileForWrite()\n{\n    // Do a traversal of the entire PDF file structure replacing all\n    // indirect objects that QPDFWriter wants to be direct.  This\n    // includes stream lengths, stream filtering parameters, and\n    // document extension level information.\n\n    std::list<QPDFObjectHandle> queue;\n    queue.push_back(getTrimmedTrailer());\n    std::set<int> visited;\n\n    while (! queue.empty())\n    {\n\tQPDFObjectHandle node = queue.front();\n\tqueue.pop_front();\n\tif (node.isIndirect())\n\t{\n\t    if (visited.count(node.getObjectID()) > 0)\n\t    {\n\t\tcontinue;\n\t    }\n\t    visited.insert(node.getObjectID());\n\t}\n\n\tif (node.isArray())\n\t{\n\t    int nitems = node.getArrayNItems();\n\t    for (int i = 0; i < nitems; ++i)\n\t    {\n\t\tQPDFObjectHandle oh = node.getArrayItem(i);\n                if (oh.isIndirect() && oh.isNull())\n                {\n                    QTC::TC(\"qpdf\", \"QPDFWriter flatten array null\");\n                    oh.makeDirect();\n                    node.setArrayItem(i, oh);\n                }\n\t\telse if (! oh.isScalar())\n\t\t{\n\t\t    queue.push_back(oh);\n\t\t}\n\t    }\n\t}\n\telse if (node.isDictionary() || node.isStream())\n\t{\n            bool is_stream = false;\n            bool is_root = false;\n            bool filterable = false;\n\t    QPDFObjectHandle dict = node;\n\t    if (node.isStream())\n\t    {\n                is_stream = true;\n\t\tdict = node.getDict();\n                // See whether we are able to filter this stream.\n                filterable = node.pipeStreamData(0, true, false, false);\n\t    }\n            else if (pdf.getRoot().getObjectID() == node.getObjectID())\n            {\n                is_root = true;\n            }\n\n\t    std::set<std::string> keys = dict.getKeys();\n\t    for (std::set<std::string>::iterator iter = keys.begin();\n\t\t iter != keys.end(); ++iter)\n\t    {\n\t\tstd::string const& key = *iter;\n\t\tQPDFObjectHandle oh = dict.getKey(key);\n                bool add_to_queue = true;\n                if (is_stream)\n                {\n                    if (oh.isIndirect() &&\n                        ((key == \"/Length\") ||\n                         (filterable &&\n                          ((key == \"/Filter\") ||\n                           (key == \"/DecodeParms\")))))\n                    {\n                        QTC::TC(\"qpdf\", \"QPDFWriter make stream key direct\");\n                        add_to_queue = false;\n                        oh.makeDirect();\n                        dict.replaceKey(key, oh);\n                    }\n                }\n                else if (is_root)\n                {\n                    if ((key == \"/Extensions\") && (oh.isDictionary()))\n                    {\n                        bool extensions_indirect = false;\n                        if (oh.isIndirect())\n                        {\n                            QTC::TC(\"qpdf\", \"QPDFWriter make Extensions direct\");\n                            extensions_indirect = true;\n                            add_to_queue = false;\n                            oh = oh.shallowCopy();\n                            dict.replaceKey(key, oh);\n                        }\n                        if (oh.hasKey(\"/ADBE\"))\n                        {\n                            QPDFObjectHandle adbe = oh.getKey(\"/ADBE\");\n                            if (adbe.isIndirect())\n                            {\n                                QTC::TC(\"qpdf\", \"QPDFWriter make ADBE direct\",\n                                        extensions_indirect ? 0 : 1);\n                                adbe.makeDirect();\n                                oh.replaceKey(\"/ADBE\", adbe);\n                            }\n                        }\n                    }\n                }\n\n                if (add_to_queue)\n                {\n                    queue.push_back(oh);\n\t\t}\n\t    }\n\t}\n    }\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 0
      },
      {
        "idx": 254953,
        "reasoning": "This code snippet is not vulnerable because it simply sets a boolean member variable (`qdf_mode`) based on the input `val`. There's no input validation missing, no potential for buffer overflows, or any other exploitable condition present in this straightforward assignment operation; the fix referenced in the commit message likely addressed a different part of the `QPDFWriter` class.\n\n\n\n",
        "func": "QPDFWriter::setQDFMode(bool val)\n{\n    this->qdf_mode = val;\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 0
      },
      {
        "idx": 254954,
        "reasoning": "This code fixes an infinite loop condition, specifically addressing issue #143, and doesn't introduce any new obvious vulnerabilities like memory corruption or use-after-free. The logic carefully manages pipeline objects, deleting them after use and conditionally handling MD5 pipelines and buffer extraction, all within a controlled loop that now has a defined exit condition due to the fix. \n\n\n\n",
        "func": "QPDFWriter::popPipelineStack(PointerHolder<Buffer>* bp)\n{\n    assert(this->pipeline_stack.size() >= 2);\n    this->pipeline->finish();\n    assert(dynamic_cast<Pl_Count*>(this->pipeline_stack.back()) ==\n\t   this->pipeline);\n    delete this->pipeline_stack.back();\n    this->pipeline_stack.pop_back();\n    while (dynamic_cast<Pl_Count*>(this->pipeline_stack.back()) == 0)\n    {\n\tPipeline* p = this->pipeline_stack.back();\n        if (dynamic_cast<Pl_MD5*>(p) == this->md5_pipeline)\n        {\n            this->md5_pipeline = 0;\n        }\n\tthis->pipeline_stack.pop_back();\n\tPl_Buffer* buf = dynamic_cast<Pl_Buffer*>(p);\n\tif (bp && buf)\n\t{\n\t    *bp = buf->getBuffer();\n\t}\n\tdelete p;\n    }\n    this->pipeline = dynamic_cast<Pl_Count*>(this->pipeline_stack.back());\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 0
      },
      {
        "idx": 254955,
        "reasoning": "This code snippet is not vulnerable because it simply sets a boolean member variable (`static_id`) within a class. There's no input validation missing, no potential for buffer overflows, or any other common vulnerability pattern present in this straightforward assignment operation.",
        "func": "QPDFWriter::setStaticID(bool val)\n{\n    this->static_id = val;\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 197182,
        "reasoning": "The code is vulnerable to an infinite loop because when encountering an object within an object stream (`object_to_object_stream`), it recursively calls `enqueueObject` with the object stream itself. This recursion can occur repeatedly if the object stream contains further object streams, leading to a stack overflow and denial of service.",
        "func": "QPDFWriter::enqueueObject(QPDFObjectHandle object)\n{\n    if (object.isIndirect())\n    {\n        if (object.getOwningQPDF() != &(this->pdf))\n        {\n            QTC::TC(\"qpdf\", \"QPDFWriter foreign object\");\n            throw std::logic_error(\n                \"QPDFObjectHandle from different QPDF found while writing.\"\n                \"  Use QPDF::copyForeignObject to add objects from\"\n                \" another file.\");\n        }\n\n\tQPDFObjGen og = object.getObjGen();\n\n\tif (obj_renumber.count(og) == 0)\n\t{\n\t    if (this->object_to_object_stream.count(og))\n\t    {\n\t\t// This is in an object stream.  Don't process it\n\t\t// here.  Instead, enqueue the object stream.  Object\n\t\t// streams always have generation 0.\n\t\tint stream_id = this->object_to_object_stream[og];\n\t\tenqueueObject(this->pdf.getObjectByID(stream_id, 0));\n\t    }\n\t    else\n\t    {\n\t\tobject_queue.push_back(object);\n\t\tobj_renumber[og] = next_objid++;\n\n\t\tif ((og.getGen() == 0) &&\n                    this->object_stream_to_objects.count(og.getObj()))\n\t\t{\n\t\t    // For linearized files, uncompressed objects go\n\t\t    // at end, and we take care of assigning numbers\n\t\t    // to them elsewhere.\n\t\t    if (! this->linearized)\n\t\t    {\n\t\t\tassignCompressedObjectNumbers(og);\n\t\t    }\n\t\t}\n\t\telse if ((! this->direct_stream_lengths) && object.isStream())\n\t\t{\n\t\t    // reserve next object ID for length\n\t\t    ++next_objid;\n\t\t}\n\t    }\n\t}\n    }\n    else if (object.isArray())\n    {\n\tint n = object.getArrayNItems();\n\tfor (int i = 0; i < n; ++i)\n\t{\n\t    if (! this->linearized)\n\t    {\n\t\tenqueueObject(object.getArrayItem(i));\n\t    }\n\t}\n    }\n    else if (object.isDictionary())\n    {\n\tstd::set<std::string> keys = object.getKeys();\n\tfor (std::set<std::string>::iterator iter = keys.begin();\n\t     iter != keys.end(); ++iter)\n\t{\n\t    if (! this->linearized)\n\t    {\n\t\tenqueueObject(object.getKey(*iter));\n\t    }\n\t}\n    }\n    else\n    {\n\t// ignore\n    }\n}",
        "commit_message": "Fix infinite loop in QPDFWriter (fixes #143)",
        "cve_desc": "An issue was discovered in QPDF before 7.0.0. There is an infinite loop in the QPDFWriter::enqueueObject() function in libqpdf/QPDFWriter.cc.",
        "target": 1
      },
      {
        "idx": 202933,
        "reasoning": "This code is vulnerable because the `resolve` function doesn't explicitly track the objects currently being resolved, allowing for recursive calls when an object's resolution depends on itself\u2014directly or indirectly\u2014leading to an infinite loop as described in the CVE. This infinite loop consumes stack space with each recursive call, ultimately resulting in a denial of service.",
        "func": "QPDF::resolve(int objid, int generation)\n{\n    // Check object cache before checking xref table.  This allows us\n    // to insert things into the object cache that don't actually\n    // exist in the file.\n    QPDFObjGen og(objid, generation);\n    if (! this->obj_cache.count(og))\n    {\n\tif (! this->xref_table.count(og))\n\t{\n\t    // PDF spec says unknown objects resolve to the null object.\n\t    return new QPDF_Null;\n\t}\n\n\tQPDFXRefEntry const& entry = this->xref_table[og];\n\tswitch (entry.getType())\n\t{\n\t  case 1:\n\t    {\n\t\tqpdf_offset_t offset = entry.getOffset();\n\t\t// Object stored in cache by readObjectAtOffset\n\t\tint aobjid;\n\t\tint ageneration;\n\t\tQPDFObjectHandle oh =\n\t\t    readObjectAtOffset(true, offset, \"\", objid, generation,\n\t\t\t\t       aobjid, ageneration);\n\t    }\n\t    break;\n\n\t  case 2:\n\t    resolveObjectsInStream(entry.getObjStreamNumber());\n\t    break;\n\n\t  default:\n\t    throw QPDFExc(qpdf_e_damaged_pdf, this->file->getName(), \"\", 0,\n\t\t\t  \"object \" +\n\t\t\t  QUtil::int_to_string(objid) + \"/\" +\n\t\t\t  QUtil::int_to_string(generation) +\n\t\t\t  \" has unexpected xref entry type\");\n\t}\n    }\n\n    return this->obj_cache[og].object;\n}",
        "commit_message": "Detect recursion loops resolving objects (fixes #51)\n\nDuring parsing of an object, sometimes parts of the object have to be\nresolved. An example is stream lengths. If such an object directly or\nindirectly points to the object being parsed, it can cause an infinite\nloop. Guard against all cases of re-entrant resolution of objects.",
        "cve_desc": "A stack-consumption vulnerability was found in libqpdf in QPDF 6.0.0, which allows attackers to cause a denial of service via a crafted file, related to the QPDFTokenizer::resolveLiteral function in QPDFTokenizer.cc after two consecutive calls to QPDFObjectHandle::parseInternal, aka an \"infinite loop.\"",
        "target": 1
      },
      {
        "idx": 206281,
        "reasoning": "This code is vulnerable because the initialization doesn't address the root cause of CVE-2017-9209, an infinite loop within the `QPDFTokenizer::resolveLiteral` function triggered by crafted PDF files after consecutive calls to `QPDFObjectHandle::parseInternal`. The provided snippet only shows constructor initialization and doesn't include any logic to prevent the problematic parsing behavior that leads to excessive stack consumption and a denial of service.",
        "func": "QPDF::QPDF() :\n    encrypted(false),\n    encryption_initialized(false),\n    ignore_xref_streams(false),\n    suppress_warnings(false),\n    out_stream(&std::cout),\n    err_stream(&std::cerr),\n    attempt_recovery(true),\n    encryption_V(0),\n    encryption_R(0),\n    encrypt_metadata(true),\n    cf_stream(e_none),\n    cf_string(e_none),\n    cf_file(e_none),\n    cached_key_objid(0),\n    cached_key_generation(0),\n    pushed_inherited_attributes_to_pages(false),\n    copied_stream_data_provider(0),\n    first_xref_item_offset(0),\n    uncompressed_after_compressed(false)\n{\n}",
        "commit_message": "Avoid xref reconstruction infinite loop (fixes #100)\n\nThis is CVE-2017-9209.",
        "cve_desc": "A stack-consumption vulnerability was found in libqpdf in QPDF 6.0.0, which allows attackers to cause a denial of service via a crafted file, related to the QPDFTokenizer::resolveLiteral function in QPDFTokenizer.cc after two consecutive calls to QPDFObjectHandle::parseInternal, aka an \"infinite loop.\"",
        "target": 1
      }
    ]
  },
  "radare2": {
    "0": [
      {
        "idx": 57132,
        "reasoning": "This code snippet is safe and doesn't introduce a vulnerability despite the commit message referencing a potential wraparound issue elsewhere. The `is_in_pphdr` function itself performs a straightforward range check using unsigned 64-bit integers (`ut64`), preventing potential integer overflows or wraparound issues within *this specific function's logic*. \n\n\n\n",
        "func": "static int is_in_pphdr (Elf_(Phdr) *p, ut64 addr) {\n\treturn addr >= p->p_offset && addr < p->p_offset + p->p_memsz;\n}\n",
        "commit_message": "Fix #8764 - huge vd_aux caused pointer wraparound",
        "cve_desc": "In radare 2.0.1, a pointer wraparound vulnerability exists in store_versioninfo_gnu_verdef() in libr/bin/format/elf/elf.c.",
        "target": 0
      },
      {
        "idx": 57133,
        "reasoning": "This code snippet is safe and doesn't introduce a vulnerability despite the commit message referencing a potential wraparound issue elsewhere. The `is_in_vphdr` function itself performs standard bounds checking\u2014ensuring an address falls within the virtual address range and memory size of a program header\u2014and doesn't exhibit any arithmetic operations susceptible to integer overflows or wraparound given the use of `ut64` for the address and size. \n\n\n\n",
        "func": "static int is_in_vphdr (Elf_(Phdr) *p, ut64 addr) {\n\treturn addr >= p->p_vaddr && addr < p->p_vaddr + p->p_memsz;\n}\n",
        "commit_message": "Fix #8764 - huge vd_aux caused pointer wraparound",
        "cve_desc": "In radare 2.0.1, a pointer wraparound vulnerability exists in store_versioninfo_gnu_verdef() in libr/bin/format/elf/elf.c.",
        "target": 0
      },
      {
        "idx": 57135,
        "reasoning": "This code snippet initializes data structures for ELF file parsing within radare2, and the commit message explicitly addresses a pointer wraparound issue (\"huge vd_aux\")\u2014however, the fix isn't *in* this code. The provided `elf_init` function itself doesn't appear to directly handle potentially overflowing data or perform calculations susceptible to wraparound, making it safe based on the information given.",
        "func": "static int elf_init(ELFOBJ *bin) {\n\tbin->phdr = NULL;\n\tbin->shdr = NULL;\n\tbin->strtab = NULL;\n\tbin->shstrtab = NULL;\n\tbin->strtab_size = 0;\n\tbin->strtab_section = NULL;\n\tbin->dyn_buf = NULL;\n\tbin->dynstr = NULL;\n\tZERO_FILL (bin->version_info);\n\n\tbin->g_sections = NULL;\n\tbin->g_symbols = NULL;\n\tbin->g_imports = NULL;\n\t/* bin is not an ELF */\n\tif (!init_ehdr (bin)) {\n\t\treturn false;\n\t}\n\tif (!init_phdr (bin)) {\n\t\tbprintf (\"Warning: Cannot initialize program headers\\n\");\n\t}\n\tif (!init_shdr (bin)) {\n\t\tbprintf (\"Warning: Cannot initialize section headers\\n\");\n\t}\n\tif (!init_strtab (bin)) {\n\t\tbprintf (\"Warning: Cannot initialize strings table\\n\");\n\t}\n\tif (!init_dynstr (bin)) {\n\t\tbprintf (\"Warning: Cannot initialize dynamic strings\\n\");\n\t}\n\tbin->baddr = Elf_(r_bin_elf_get_baddr) (bin);\n\tif (!init_dynamic_section (bin) && !Elf_(r_bin_elf_get_static)(bin))\n\t\tbprintf (\"Warning: Cannot initialize dynamic section\\n\");\n\n\tbin->imports_by_ord_size = 0;\n\tbin->imports_by_ord = NULL;\n\tbin->symbols_by_ord_size = 0;\n\tbin->symbols_by_ord = NULL;\n\tbin->g_sections = Elf_(r_bin_elf_get_sections) (bin);\n\tbin->boffset = Elf_(r_bin_elf_get_boffset) (bin);\n\tsdb_ns_set (bin->kv, \"versioninfo\", store_versioninfo (bin));\n\n\treturn true;\n}\n",
        "commit_message": "Fix #8764 - huge vd_aux caused pointer wraparound",
        "cve_desc": "In radare 2.0.1, a pointer wraparound vulnerability exists in store_versioninfo_gnu_verdef() in libr/bin/format/elf/elf.c.",
        "target": 0
      }
    ],
    "1": []
  },
  "radvd": {
    "0": [
      {
        "idx": 40993,
        "reasoning": "This code snippet is **not vulnerable** to the described issue because it only *reads* from a file (`PATH_PROC_NET_IGMP6`) and does not involve writing to any file based on untrusted input like the interface name. The vulnerability described in the commit message concerns the `set_interface_var()` function, which is not present in this code snippet, and involves potentially overwriting arbitrary files via `fopen()` with a crafted interface name.\n\n\n\n",
        "func": "int check_allrouters_membership(struct Interface *iface)\n{\n\t#define ALL_ROUTERS_MCAST \"ff020000000000000000000000000002\"\n\n\tFILE *fp;\n\tunsigned int if_idx, allrouters_ok=0;\n\tchar addr[32+1];\n\tchar buffer[301] = {\"\"}, *str;\n\tint ret=0;\n\n\tif ((fp = fopen(PATH_PROC_NET_IGMP6, \"r\")) == NULL)\n\t{\n\t\tflog(LOG_ERR, \"can't open %s: %s\", PATH_PROC_NET_IGMP6,\n\t\t\tstrerror(errno));\n\t\treturn (-1);\n\t}\n\n\tstr = fgets(buffer, 300, fp);\n\n\twhile (str && (ret = sscanf(str, \"%u %*s %32[0-9A-Fa-f]\", &if_idx, addr)) ) {\n\t\tif (ret == 2) {\n\t\t\tif (iface->if_index == if_idx) {\n\t\t\t\tif (strncmp(addr, ALL_ROUTERS_MCAST, sizeof(addr)) == 0){\n\t\t\t\t\tallrouters_ok = 1;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tstr = fgets(buffer, 300, fp);\n\t}\n\n\tfclose(fp);\n\n\tif (!allrouters_ok) {\n\t\tflog(LOG_WARNING, \"resetting ipv6-allrouters membership on %s\", iface->Name);\n\t\tsetup_allrouters_membership(iface);\n\t}\n\n\treturn(0);\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 0
      },
      {
        "idx": 40994,
        "reasoning": "This code *is* vulnerable, despite appearing to only call another function. The commit message explicitly states `set_interface_var()`\u2014which is called by `set_interface_linkmtu()` when not in privileged separation mode\u2014has a file path construction vulnerability due to unchecked user input in the `ifname` variable, allowing arbitrary file overwrites. \n\n\n\n",
        "func": "set_interface_linkmtu(const char *iface, uint32_t mtu)\n{\n\tif (privsep_enabled())\n\t\treturn privsep_interface_linkmtu(iface, mtu);\n\n\treturn set_interface_var(iface,\n\t\t\t\t PROC_SYS_IP6_LINKMTU, \"LinkMTU\",\n\t\t\t\t mtu);\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 0
      },
      {
        "idx": 40995,
        "reasoning": "This code is **not directly vulnerable** because it calls `set_interface_var`, but the vulnerability lies *within* the `set_interface_var` function itself, not in how it's called here. The provided snippet only shows the calling function and doesn't contain the problematic file opening logic described in the commit message; therefore, assessing vulnerability based solely on this code is impossible.\n\n\n\n",
        "func": "set_interface_reachtime(const char *iface, uint32_t rtime)\n{\n\tint ret;\n\n\tif (privsep_enabled())\n\t\treturn privsep_interface_reachtime(iface, rtime);\n\n\tret = set_interface_var(iface,\n\t\t\t\tPROC_SYS_IP6_BASEREACHTIME_MS,\n\t\t\t\tNULL,\n\t\t\t\trtime);\n\tif (ret)\n\t\tret = set_interface_var(iface,\n\t\t\t\t\tPROC_SYS_IP6_BASEREACHTIME,\n\t\t\t\t\t\"BaseReachableTimer\",\n\t\t\t\t\trtime / 1000); /* sec */\n\treturn ret;\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 0
      },
      {
        "idx": 40996,
        "reasoning": "This code is **not directly vulnerable** because it calls `set_interface_var`, but the vulnerability lies *within* the `set_interface_var` function itself, not in how it's called here. The commit message explicitly states the issue is with how `set_interface_var` handles untrusted input for the interface name, opening it for potential arbitrary file overwrites \u2013 this snippet merely *uses* that function.\n\n\n\n",
        "func": "set_interface_retranstimer(const char *iface, uint32_t rettimer)\n{\n\tint ret;\n\n\tif (privsep_enabled())\n\t\treturn privsep_interface_retranstimer(iface, rettimer);\n\n\tret = set_interface_var(iface,\n\t\t\t\tPROC_SYS_IP6_RETRANSTIMER_MS,\n\t\t\t\tNULL,\n\t\t\t\trettimer);\n\tif (ret)\n\t\tret = set_interface_var(iface,\n\t\t\t\t\tPROC_SYS_IP6_RETRANSTIMER,\n\t\t\t\t\t\"RetransTimer\",\n\t\t\t\t\trettimer / 1000 * USER_HZ); /* XXX user_hz */\n\treturn ret;\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 0
      },
      {
        "idx": 40997,
        "reasoning": "This code snippet is **not directly vulnerable** to the issue described in the commit message. The provided code only *reads* interface information using `ioctl` and logs data; it doesn't contain the `fopen` call with unsanitized input that the commit message highlights as the source of the vulnerability. \n\n\n\n",
        "func": "setup_deviceinfo(struct Interface *iface)\n{\n\tstruct ifreq\tifr;\n\tstruct AdvPrefix *prefix;\n\tchar zero[sizeof(iface->if_addr)];\n\n\tstrncpy(ifr.ifr_name, iface->Name, IFNAMSIZ-1);\n\tifr.ifr_name[IFNAMSIZ-1] = '\\0';\n\n\tif (ioctl(sock, SIOCGIFMTU, &ifr) < 0) {\n\t\tflog(LOG_ERR, \"ioctl(SIOCGIFMTU) failed for %s: %s\",\n\t\t\tiface->Name, strerror(errno));\n\t\treturn (-1);\n\t}\n\n\tdlog(LOG_DEBUG, 3, \"mtu for %s is %d\", iface->Name, ifr.ifr_mtu);\n\tiface->if_maxmtu = ifr.ifr_mtu;\n\n\tif (ioctl(sock, SIOCGIFHWADDR, &ifr) < 0)\n\t{\n\t\tflog(LOG_ERR, \"ioctl(SIOCGIFHWADDR) failed for %s: %s\",\n\t\t\tiface->Name, strerror(errno));\n\t\treturn (-1);\n\t}\n\n\tdlog(LOG_DEBUG, 3, \"hardware type for %s is %d\", iface->Name,\n\t\tifr.ifr_hwaddr.sa_family);\n\n\tswitch(ifr.ifr_hwaddr.sa_family)\n        {\n\tcase ARPHRD_ETHER:\n\t\tiface->if_hwaddr_len = 48;\n\t\tiface->if_prefix_len = 64;\n\t\tbreak;\n#ifdef ARPHRD_FDDI\n\tcase ARPHRD_FDDI:\n\t\tiface->if_hwaddr_len = 48;\n\t\tiface->if_prefix_len = 64;\n\t\tbreak;\n#endif /* ARPHDR_FDDI */\n#ifdef ARPHRD_ARCNET\n\tcase ARPHRD_ARCNET:\n\t\tiface->if_hwaddr_len = 8;\n\t\tiface->if_prefix_len = -1;\n\t\tiface->if_maxmtu = -1;\n\t\tbreak;\n#endif /* ARPHDR_ARCNET */\n\tdefault:\n\t\tiface->if_hwaddr_len = -1;\n\t\tiface->if_prefix_len = -1;\n\t\tiface->if_maxmtu = -1;\n\t\tbreak;\n\t}\n\n\tdlog(LOG_DEBUG, 3, \"link layer token length for %s is %d\", iface->Name,\n\t\tiface->if_hwaddr_len);\n\n\tdlog(LOG_DEBUG, 3, \"prefix length for %s is %d\", iface->Name,\n\t\tiface->if_prefix_len);\n\n\tif (iface->if_hwaddr_len != -1) {\n\t\tunsigned int if_hwaddr_len_bytes = (iface->if_hwaddr_len + 7) >> 3;\n\n\t\tif (if_hwaddr_len_bytes > sizeof(iface->if_hwaddr)) {\n\t\t\tflog(LOG_ERR, \"address length %d too big for %s\", if_hwaddr_len_bytes, iface->Name);\n\t\t\treturn(-2);\n\t\t}\n\t\tmemcpy(iface->if_hwaddr, ifr.ifr_hwaddr.sa_data, if_hwaddr_len_bytes);\n\n\t\tmemset(zero, 0, sizeof(zero));\n\t\tif (!memcmp(iface->if_hwaddr, zero, if_hwaddr_len_bytes))\n\t\t\tflog(LOG_WARNING, \"WARNING, MAC address on %s is all zero!\",\n\t\t\t\tiface->Name);\n\t}\n\n\tprefix = iface->AdvPrefixList;\n\twhile (prefix)\n\t{\n\t\tif ((iface->if_prefix_len != -1) &&\n\t\t   (iface->if_prefix_len != prefix->PrefixLen))\n\t\t{\n\t\t\tflog(LOG_WARNING, \"prefix length should be %d for %s\",\n\t\t\t\tiface->if_prefix_len, iface->Name);\n \t\t}\n\n \t\tprefix = prefix->next;\n\t}\n\n\treturn (0);\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1418,
        "reasoning": "This code is vulnerable to a directory traversal vulnerability because the `set_interface_var` function doesn't sanitize the `iface` input before using it to construct a file path, allowing an attacker to use \"..\" or \"/\" in the interface name to write to arbitrary files. Combined with the ability to create symlinks, a local attacker can overwrite any file on the system with a controlled 32-bit value.\n\n\n\n",
        "func": "set_interface_var(const char *iface,\n\t\t  const char *var, const char *name,\n\t\t  uint32_t val)\n{\n\tFILE *fp;\n\tchar spath[64+IFNAMSIZ];\t/* XXX: magic constant */\n \tif (snprintf(spath, sizeof(spath), var, iface) >= sizeof(spath))\n \t\treturn -1;\n \n \tif (access(spath, F_OK) != 0)\n \t\treturn -1;\n \n\tfp = fopen(spath, \"w\");\n\tif (!fp) {\n\t\tif (name)\n\t\t\tflog(LOG_ERR, \"failed to set %s (%u) for %s: %s\",\n\t\t\t     name, val, iface, strerror(errno));\n\t\treturn -1;\n\t}\n\tfprintf(fp, \"%u\", val);\n\tfclose(fp);\n\n\treturn 0;\n}\n",
        "commit_message": "set_interface_var() doesn't check interface name and blindly does\nfopen(path \"/\" ifname, \"w\") on it.  As \"ifname\" is an untrusted input, it\nshould be checked for \"..\" and/or \"/\" in it.  Otherwise, an infected\nunprivileged daemon may overwrite contents of file named \"mtu\",\n\"hoplimit\", etc. in arbitrary location with arbitrary 32-bit value in\ndecimal representation (\"%d\").  If an attacker has a local account or\nmay create arbitrary symlinks with these names in any location (e.g.\n/tmp), any file may be overwritten with a decimal value.",
        "cve_desc": "Directory traversal vulnerability in device-linux.c in the router advertisement daemon (radvd) before 1.8.2 allows local users to overwrite arbitrary files, and remote attackers to overwrite certain files, via a .. (dot dot) in an interface name.  NOTE: this can be leveraged with a symlink to overwrite arbitrary files.",
        "target": 1
      },
      {
        "idx": 200652,
        "reasoning": "The `process_ra` function in `radvd` is vulnerable to a buffer overflow because the `label_len` value within the `ND_OPT_DNSSL_INFORMATION` option parsing is not validated for negativity. A negative `label_len` allows an attacker to control the amount of data copied into the `suffix` buffer, potentially overwriting adjacent memory and leading to arbitrary code execution or a denial of service.\n\n\n\n",
        "func": "process_ra(struct Interface *iface, unsigned char *msg, int len,\n\tstruct sockaddr_in6 *addr)\n{\n\tstruct nd_router_advert *radvert;\n\tchar addr_str[INET6_ADDRSTRLEN];\n\tuint8_t *opt_str;\n\n\tprint_addr(&addr->sin6_addr, addr_str);\n\n\tradvert = (struct nd_router_advert *) msg;\n\n\tif ((radvert->nd_ra_curhoplimit && iface->AdvCurHopLimit) &&\n\t   (radvert->nd_ra_curhoplimit != iface->AdvCurHopLimit))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvCurHopLimit on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_flags_reserved & ND_RA_FLAG_MANAGED) && !iface->AdvManagedFlag)\n\t{\n\t\tflog(LOG_WARNING, \"our AdvManagedFlag on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_flags_reserved & ND_RA_FLAG_OTHER) && !iface->AdvOtherConfigFlag)\n\t{\n\t\tflog(LOG_WARNING, \"our AdvOtherConfigFlag on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\t/* note: we don't check the default router preference here, because they're likely different */\n\n\tif ((radvert->nd_ra_reachable && iface->AdvReachableTime) &&\n\t   (ntohl(radvert->nd_ra_reachable) != iface->AdvReachableTime))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvReachableTime on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_retransmit && iface->AdvRetransTimer) &&\n\t   (ntohl(radvert->nd_ra_retransmit) != iface->AdvRetransTimer))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvRetransTimer on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tlen -= sizeof(struct nd_router_advert);\n\n\tif (len == 0)\n\t\treturn;\n\n\topt_str = (uint8_t *)(msg + sizeof(struct nd_router_advert));\n\n\twhile (len > 0)\n\t{\n\t\tint optlen;\n\t\tstruct nd_opt_prefix_info *pinfo;\n\t\tstruct nd_opt_rdnss_info_local *rdnssinfo;\n\t\tstruct nd_opt_dnssl_info_local *dnsslinfo;\n\t\tstruct nd_opt_mtu *mtu;\n\t\tstruct AdvPrefix *prefix;\n\t\tstruct AdvRDNSS *rdnss;\n\t\tchar prefix_str[INET6_ADDRSTRLEN];\n\t\tchar rdnss_str[INET6_ADDRSTRLEN];\n\t\tchar suffix[256];\n\t\tint offset, label_len;\n\t\tuint32_t preferred, valid, count;\n\n\t\tif (len < 2)\n\t\t{\n\t\t\tflog(LOG_ERR, \"trailing garbage in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\toptlen = (opt_str[1] << 3);\n\n\t\tif (optlen == 0)\n\t\t{\n\t\t\tflog(LOG_ERR, \"zero length option in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\t\telse if (optlen > len)\n\t\t{\n\t\t\tflog(LOG_ERR, \"option length greater than total\"\n\t\t\t\t\" length in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (*opt_str)\n\t\t{\n\t\tcase ND_OPT_MTU:\n\t\t\tmtu = (struct nd_opt_mtu *)opt_str;\n\n\t\t\tif (iface->AdvLinkMTU && (ntohl(mtu->nd_opt_mtu_mtu) != iface->AdvLinkMTU))\n\t\t\t{\n\t\t\t\tflog(LOG_WARNING, \"our AdvLinkMTU on %s doesn't agree with %s\",\n\t\t\t\t\tiface->Name, addr_str);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ND_OPT_PREFIX_INFORMATION:\n\t\t\tpinfo = (struct nd_opt_prefix_info *) opt_str;\n\t\t\tpreferred = ntohl(pinfo->nd_opt_pi_preferred_time);\n\t\t\tvalid = ntohl(pinfo->nd_opt_pi_valid_time);\n\n\t\t\tprefix = iface->AdvPrefixList;\n\t\t\twhile (prefix)\n\t\t\t{\n\t\t\t\tif (prefix->enabled &&\n\t\t\t\t    (prefix->PrefixLen == pinfo->nd_opt_pi_prefix_len) &&\n\t\t\t\t    addr_match(&prefix->Prefix, &pinfo->nd_opt_pi_prefix,\n\t\t\t\t    \t prefix->PrefixLen))\n\t\t\t\t{\n\t\t\t\t\tprint_addr(&prefix->Prefix, prefix_str);\n\n\t\t\t\t\tif (!prefix->DecrementLifetimesFlag && valid != prefix->AdvValidLifetime)\n\t\t\t\t\t{\n\t\t\t\t\t\tflog(LOG_WARNING, \"our AdvValidLifetime on\"\n\t\t\t\t\t\t \" %s for %s doesn't agree with %s\",\n\t\t\t\t\t\t iface->Name,\n\t\t\t\t\t\t prefix_str,\n\t\t\t\t\t\t addr_str\n\t\t\t\t\t\t );\n\t\t\t\t\t}\n\t\t\t\t\tif (!prefix->DecrementLifetimesFlag && preferred != prefix->AdvPreferredLifetime)\n\t\t\t\t\t{\n\t\t\t\t\t\tflog(LOG_WARNING, \"our AdvPreferredLifetime on\"\n\t\t\t\t\t\t \" %s for %s doesn't agree with %s\",\n\t\t\t\t\t\t iface->Name,\n\t\t\t\t\t\t prefix_str,\n\t\t\t\t\t\t addr_str\n\t\t\t\t\t\t );\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tprefix = prefix->next;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ND_OPT_ROUTE_INFORMATION:\n\t\t\t/* not checked: these will very likely vary a lot */\n\t\t\tbreak;\n\t\tcase ND_OPT_SOURCE_LINKADDR:\n\t\t\t/* not checked */\n\t\t\tbreak;\n\t\tcase ND_OPT_TARGET_LINKADDR:\n\t\tcase ND_OPT_REDIRECTED_HEADER:\n\t\t\tflog(LOG_ERR, \"invalid option %d in RA on %s from %s\",\n\t\t\t\t(int)*opt_str, iface->Name, addr_str);\n\t\t\tbreak;\n\t\t/* Mobile IPv6 extensions */\n\t\tcase ND_OPT_RTR_ADV_INTERVAL:\n\t\tcase ND_OPT_HOME_AGENT_INFO:\n\t\t\t/* not checked */\n\t\t\tbreak;\n\t\tcase ND_OPT_RDNSS_INFORMATION:\n\t\t\trdnssinfo = (struct nd_opt_rdnss_info_local *) opt_str;\n\t\t\tcount = rdnssinfo->nd_opt_rdnssi_len;\n\n\t\t\t/* Check the RNDSS addresses received */\n\t\t\tswitch (count) {\n\t\t\t\tcase 7:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr3 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr3, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\t\t\t\t\t/* FALLTHROUGH */\n\t\t\t\tcase 5:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr2 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr2, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\t\t\t\t\t/* FALLTHROUGH */\n\t\t\t\tcase 3:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr1 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr1, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tflog(LOG_ERR, \"invalid len %i in RDNSS option on %s from %s\",\n\t\t\t\t\t\t\tcount, iface->Name, addr_str);\n\t\t\t}\n\n\t\t\tbreak;\n\t\tcase ND_OPT_DNSSL_INFORMATION:\n\t\t\tdnsslinfo = (struct nd_opt_dnssl_info_local *) opt_str;\n\t\t\tsuffix[0] = '\\0';\n\t\t\tfor (offset = 0; offset < (dnsslinfo->nd_opt_dnssli_len-1)*8;) {\n\t\t\t\tlabel_len = dnsslinfo->nd_opt_dnssli_suffixes[offset++];\n\n\t\t\t\tif (label_len == 0) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Ignore empty suffixes. They're\n\t\t\t\t\t * probably just padding...\n\t\t\t\t\t */\n\t\t\t\t\tif (suffix[0] == '\\0')\n\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\tif (!check_dnssl_presence(iface->AdvDNSSLList, suffix)) {\n\t\t\t\t\t\tflog(LOG_WARNING, \"DNSSL suffix %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\tsuffix, iface->Name, addr_str);\n\t\t\t\t\t}\n\n\t\t\t\t\tsuffix[0] = '\\0';\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\tif ((sizeof(suffix) - strlen(suffix)) < (label_len + 2)) {\n\t\t\t\t\tflog(LOG_ERR, \"oversized suffix in DNSSL option on %s from %s\",\n\t\t\t\t\t\t\tiface->Name, addr_str);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (suffix[0] != '\\0')\n\t\t\t\t\tstrcat(suffix, \".\");\n\t\t\t\tstrncat(suffix, &dnsslinfo->nd_opt_dnssli_suffixes[offset], label_len);\n\t\t\t\toffset += label_len;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdlog(LOG_DEBUG, 1, \"unknown option %d in RA on %s from %s\",\n\t\t\t\t(int)*opt_str, iface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\tlen -= optlen;\n\t\topt_str += optlen;\n\t}\n}",
        "commit_message": "In process_ra() ND_OPT_DNSSL_INFORMATION option parsing \"label_len\"\nis not checked for negativeness;  it leads to \"suffix\" buffer overflow,\nwhich leads to privilege escalation (at least with -fno-stack-protector,\nI didn't discover whether it's possible with -fstack-protector).",
        "cve_desc": "Buffer overflow in the process_ra function in the router advertisement daemon (radvd) before 1.8.2 allows remote attackers to execute arbitrary code or cause a denial of service (crash) via a negative value in a label_len value.",
        "target": 1
      },
      {
        "idx": 200772,
        "reasoning": "The provided code snippet, while addressing an infinite loop issue, doesn't directly fix the root privilege escalation vulnerability described in the CVE. The `privsep_read_loop` function continues to process commands from a file descriptor (`pfd`) potentially established *before* proper privilege separation, meaning a malicious actor could exploit vulnerabilities in the command handling (like the `set_interface_var` calls) while radvd is still running with elevated privileges.",
        "func": "privsep_read_loop(void)\n{\n\tstruct privsep_command cmd;\n\tint ret;\n\n\twhile (1) {\n\t\tret = readn(pfd, &cmd, sizeof(cmd));\n\t\tif (ret <= 0) {\n\t\t\t/* Error or EOF, give up */\n\t\t\tif (ret < 0) {\n\t\t\t\tflog(LOG_ERR, \"Exiting, privsep_read_loop had readn error: %s\\n\",\n\t\t\t\t     strerror(errno));\n\t\t\t} else {\n\t\t\t\tflog(LOG_ERR, \"Exiting, privsep_read_loop had readn return 0 bytes\\n\");\n\t\t\t}\n\t\t\tclose(pfd);\n\t\t\t_exit(0);\n\t\t}\n\t\tif (ret != sizeof(cmd)) {\n\t\t\t/* Short read, ignore */\n\t\t\tcontinue;\n\t\t}\n\n\t\tcmd.iface[IFNAMSIZ-1] = '\\0';\n\n\t\tswitch(cmd.type) {\n\n\t\tcase SET_INTERFACE_LINKMTU:\n\t\t\tif (cmd.val < MIN_AdvLinkMTU || cmd.val > MAX_AdvLinkMTU) {\n\t\t\t\tflog(LOG_ERR, \"(privsep) %s: LinkMTU (%u) is not within the defined bounds, ignoring\", cmd.iface, cmd.val);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret = set_interface_var(cmd.iface, PROC_SYS_IP6_LINKMTU, \"LinkMTU\", cmd.val);\n\t\t\tbreak;\n\n\t\tcase SET_INTERFACE_CURHLIM:\n\t\t\tif (cmd.val < MIN_AdvCurHopLimit || cmd.val > MAX_AdvCurHopLimit) {\n\t\t\t\tflog(LOG_ERR, \"(privsep) %s: CurHopLimit (%u) is not within the defined bounds, ignoring\", cmd.iface, cmd.val);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret = set_interface_var(cmd.iface, PROC_SYS_IP6_CURHLIM, \"CurHopLimit\", cmd.val);\n\t\t\tbreak;\n\n\t\tcase SET_INTERFACE_REACHTIME:\n\t\t\tif (cmd.val < MIN_AdvReachableTime || cmd.val > MAX_AdvReachableTime) {\n\t\t\t\tflog(LOG_ERR, \"(privsep) %s: BaseReachableTimer (%u) is not within the defined bounds, ignoring\", cmd.iface, cmd.val);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret = set_interface_var(cmd.iface, PROC_SYS_IP6_BASEREACHTIME_MS, \"BaseReachableTimer (ms)\", cmd.val);\n\t\t\tif (ret == 0)\n\t\t\t\tbreak;\n\t\t\tset_interface_var(cmd.iface, PROC_SYS_IP6_BASEREACHTIME, \"BaseReachableTimer\", cmd.val / 1000);\n\t\t\tbreak;\n\n\t\tcase SET_INTERFACE_RETRANSTIMER:\n\t\t\tif (cmd.val < MIN_AdvRetransTimer || cmd.val > MAX_AdvRetransTimer) {\n\t\t\t\tflog(LOG_ERR, \"(privsep) %s: RetransTimer (%u) is not within the defined bounds, ignoring\", cmd.iface, cmd.val);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tret = set_interface_var(cmd.iface, PROC_SYS_IP6_RETRANSTIMER_MS, \"RetransTimer (ms)\", cmd.val);\n\t\t\tif (ret == 0)\n\t\t\t\tbreak;\n\t\t\tset_interface_var(cmd.iface, PROC_SYS_IP6_RETRANSTIMER, \"RetransTimer\", cmd.val / 1000 * USER_HZ); /* XXX user_hz */\n\t\t\tbreak;\n\n\t\tdefault:\n\t\t\t/* Bad command */\n\t\t\tbreak;\n\t\t}\n\t}\n}",
        "commit_message": "privsep_read_loop() should return on unprivileged daemon death /\nsocket close(), not loop forever with polling read() getting -1.",
        "cve_desc": "The router advertisement daemon (radvd) before 1.8.2 does not properly handle errors in the privsep_init function, which causes the radvd daemon to run as root and has an unspecified impact.",
        "target": 1
      },
      {
        "idx": 204289,
        "reasoning": "The `process_ra` function is vulnerable to buffer over-reads due to missing length checks when processing options within the Router Advertisement message. Specifically, the code calculates `optlen` based on the message data but doesn't always ensure that accessing memory at `opt_str + optlen` remains within the bounds of the received message (`msg`), leading to potential reads beyond the allocated buffer.",
        "func": "process_ra(struct Interface *iface, unsigned char *msg, int len,\n\tstruct sockaddr_in6 *addr)\n{\n\tstruct nd_router_advert *radvert;\n\tchar addr_str[INET6_ADDRSTRLEN];\n\tuint8_t *opt_str;\n\n\tprint_addr(&addr->sin6_addr, addr_str);\n\n\tradvert = (struct nd_router_advert *) msg;\n\n\tif ((radvert->nd_ra_curhoplimit && iface->AdvCurHopLimit) &&\n\t   (radvert->nd_ra_curhoplimit != iface->AdvCurHopLimit))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvCurHopLimit on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_flags_reserved & ND_RA_FLAG_MANAGED) && !iface->AdvManagedFlag)\n\t{\n\t\tflog(LOG_WARNING, \"our AdvManagedFlag on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_flags_reserved & ND_RA_FLAG_OTHER) && !iface->AdvOtherConfigFlag)\n\t{\n\t\tflog(LOG_WARNING, \"our AdvOtherConfigFlag on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\t/* note: we don't check the default router preference here, because they're likely different */\n\n\tif ((radvert->nd_ra_reachable && iface->AdvReachableTime) &&\n\t   (ntohl(radvert->nd_ra_reachable) != iface->AdvReachableTime))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvReachableTime on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tif ((radvert->nd_ra_retransmit && iface->AdvRetransTimer) &&\n\t   (ntohl(radvert->nd_ra_retransmit) != iface->AdvRetransTimer))\n\t{\n\t\tflog(LOG_WARNING, \"our AdvRetransTimer on %s doesn't agree with %s\",\n\t\t\tiface->Name, addr_str);\n\t}\n\n\tlen -= sizeof(struct nd_router_advert);\n\n\tif (len == 0)\n\t\treturn;\n\n\topt_str = (uint8_t *)(msg + sizeof(struct nd_router_advert));\n\n\twhile (len > 0)\n\t{\n\t\tint optlen;\n\t\tstruct nd_opt_prefix_info *pinfo;\n\t\tstruct nd_opt_rdnss_info_local *rdnssinfo;\n\t\tstruct nd_opt_dnssl_info_local *dnsslinfo;\n\t\tstruct nd_opt_mtu *mtu;\n\t\tstruct AdvPrefix *prefix;\n\t\tstruct AdvRDNSS *rdnss;\n\t\tchar prefix_str[INET6_ADDRSTRLEN];\n\t\tchar rdnss_str[INET6_ADDRSTRLEN];\n\t\tchar suffix[256];\n\t\tunsigned int offset, label_len;\n\t\tuint32_t preferred, valid, count;\n\n\t\tif (len < 2)\n\t\t{\n\t\t\tflog(LOG_ERR, \"trailing garbage in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\toptlen = (opt_str[1] << 3);\n\n\t\tif (optlen == 0)\n\t\t{\n\t\t\tflog(LOG_ERR, \"zero length option in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\t\telse if (optlen > len)\n\t\t{\n\t\t\tflog(LOG_ERR, \"option length greater than total\"\n\t\t\t\t\" length in RA on %s from %s\",\n\t\t\t\tiface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\tswitch (*opt_str)\n\t\t{\n\t\tcase ND_OPT_MTU:\n\t\t\tmtu = (struct nd_opt_mtu *)opt_str;\n\n\t\t\tif (iface->AdvLinkMTU && (ntohl(mtu->nd_opt_mtu_mtu) != iface->AdvLinkMTU))\n\t\t\t{\n\t\t\t\tflog(LOG_WARNING, \"our AdvLinkMTU on %s doesn't agree with %s\",\n\t\t\t\t\tiface->Name, addr_str);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ND_OPT_PREFIX_INFORMATION:\n\t\t\tpinfo = (struct nd_opt_prefix_info *) opt_str;\n\t\t\tpreferred = ntohl(pinfo->nd_opt_pi_preferred_time);\n\t\t\tvalid = ntohl(pinfo->nd_opt_pi_valid_time);\n\n\t\t\tprefix = iface->AdvPrefixList;\n\t\t\twhile (prefix)\n\t\t\t{\n\t\t\t\tif (prefix->enabled &&\n\t\t\t\t    (prefix->PrefixLen == pinfo->nd_opt_pi_prefix_len) &&\n\t\t\t\t    addr_match(&prefix->Prefix, &pinfo->nd_opt_pi_prefix,\n\t\t\t\t    \t prefix->PrefixLen))\n\t\t\t\t{\n\t\t\t\t\tprint_addr(&prefix->Prefix, prefix_str);\n\n\t\t\t\t\tif (!prefix->DecrementLifetimesFlag && valid != prefix->AdvValidLifetime)\n\t\t\t\t\t{\n\t\t\t\t\t\tflog(LOG_WARNING, \"our AdvValidLifetime on\"\n\t\t\t\t\t\t \" %s for %s doesn't agree with %s\",\n\t\t\t\t\t\t iface->Name,\n\t\t\t\t\t\t prefix_str,\n\t\t\t\t\t\t addr_str\n\t\t\t\t\t\t );\n\t\t\t\t\t}\n\t\t\t\t\tif (!prefix->DecrementLifetimesFlag && preferred != prefix->AdvPreferredLifetime)\n\t\t\t\t\t{\n\t\t\t\t\t\tflog(LOG_WARNING, \"our AdvPreferredLifetime on\"\n\t\t\t\t\t\t \" %s for %s doesn't agree with %s\",\n\t\t\t\t\t\t iface->Name,\n\t\t\t\t\t\t prefix_str,\n\t\t\t\t\t\t addr_str\n\t\t\t\t\t\t );\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tprefix = prefix->next;\n\t\t\t}\n\t\t\tbreak;\n\t\tcase ND_OPT_ROUTE_INFORMATION:\n\t\t\t/* not checked: these will very likely vary a lot */\n\t\t\tbreak;\n\t\tcase ND_OPT_SOURCE_LINKADDR:\n\t\t\t/* not checked */\n\t\t\tbreak;\n\t\tcase ND_OPT_TARGET_LINKADDR:\n\t\tcase ND_OPT_REDIRECTED_HEADER:\n\t\t\tflog(LOG_ERR, \"invalid option %d in RA on %s from %s\",\n\t\t\t\t(int)*opt_str, iface->Name, addr_str);\n\t\t\tbreak;\n\t\t/* Mobile IPv6 extensions */\n\t\tcase ND_OPT_RTR_ADV_INTERVAL:\n\t\tcase ND_OPT_HOME_AGENT_INFO:\n\t\t\t/* not checked */\n\t\t\tbreak;\n\t\tcase ND_OPT_RDNSS_INFORMATION:\n\t\t\trdnssinfo = (struct nd_opt_rdnss_info_local *) opt_str;\n\t\t\tcount = rdnssinfo->nd_opt_rdnssi_len;\n\n\t\t\t/* Check the RNDSS addresses received */\n\t\t\tswitch (count) {\n\t\t\t\tcase 7:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr3 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr3, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\t\t\t\t\t/* FALLTHROUGH */\n\t\t\t\tcase 5:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr2 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr2, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\t\t\t\t\t/* FALLTHROUGH */\n\t\t\t\tcase 3:\n\t\t\t\t\trdnss = iface->AdvRDNSSList;\n\t\t\t\t\tif (!check_rdnss_presence(rdnss, &rdnssinfo->nd_opt_rdnssi_addr1 )) {\n\t\t\t\t\t\t/* no match found in iface->AdvRDNSSList */\n\t\t\t\t\t\tprint_addr(&rdnssinfo->nd_opt_rdnssi_addr1, rdnss_str);\n\t\t\t\t\t\tflog(LOG_WARNING, \"RDNSS address %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\trdnss_str, iface->Name, addr_str);\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\tdefault:\n\t\t\t\t\tflog(LOG_ERR, \"invalid len %i in RDNSS option on %s from %s\",\n\t\t\t\t\t\t\tcount, iface->Name, addr_str);\n\t\t\t}\n\n\t\t\tbreak;\n\t\tcase ND_OPT_DNSSL_INFORMATION:\n\t\t\tdnsslinfo = (struct nd_opt_dnssl_info_local *) opt_str;\n\t\t\tsuffix[0] = '\\0';\n\t\t\tfor (offset = 0; offset < (dnsslinfo->nd_opt_dnssli_len-1)*8;) {\n\t\t\t\tlabel_len = dnsslinfo->nd_opt_dnssli_suffixes[offset++];\n\n\t\t\t\tif (label_len == 0) {\n\t\t\t\t\t/*\n\t\t\t\t\t * Ignore empty suffixes. They're\n\t\t\t\t\t * probably just padding...\n\t\t\t\t\t */\n\t\t\t\t\tif (suffix[0] == '\\0')\n\t\t\t\t\t\tcontinue;\n\n\t\t\t\t\tif (!check_dnssl_presence(iface->AdvDNSSLList, suffix)) {\n\t\t\t\t\t\tflog(LOG_WARNING, \"DNSSL suffix %s received on %s from %s is not advertised by us\",\n\t\t\t\t\t\t\tsuffix, iface->Name, addr_str);\n\t\t\t\t\t}\n\n\t\t\t\t\tsuffix[0] = '\\0';\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\n\t\t\t\t/*\n\t\t\t\t * 1) must not overflow int: label + 2, offset + label_len\n\t\t\t\t * 2) last byte of dnssli_suffix must not overflow opt_str + len\n\t\t\t\t */\n\t\t\t\tif ((sizeof(suffix) - strlen(suffix)) < (label_len + 2) ||\n\t\t\t\t    label_len > label_len + 2 ||\n\t\t\t\t    &dnsslinfo->nd_opt_dnssli_suffixes[offset+label_len] - (char*)opt_str >= len ||\n\t\t\t\t    offset + label_len < offset) {\n\t\t\t\t\tflog(LOG_ERR, \"oversized suffix in DNSSL option on %s from %s\",\n\t\t\t\t\t\t\tiface->Name, addr_str);\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tif (suffix[0] != '\\0')\n\t\t\t\t\tstrcat(suffix, \".\");\n\t\t\t\tstrncat(suffix, &dnsslinfo->nd_opt_dnssli_suffixes[offset], label_len);\n\t\t\t\toffset += label_len;\n\t\t\t}\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tdlog(LOG_DEBUG, 1, \"unknown option %d in RA on %s from %s\",\n\t\t\t\t(int)*opt_str, iface->Name, addr_str);\n\t\t\tbreak;\n\t\t}\n\n\t\tlen -= optlen;\n\t\topt_str += optlen;\n\t}\n}",
        "commit_message": "process_ra() has numerous missed len checks.  It leads to buffer\noverreads.",
        "cve_desc": "The process_ra function in the router advertisement daemon (radvd) before 1.8.2 allows remote attackers to cause a denial of service (stack-based buffer over-read and crash) via unspecified vectors.",
        "target": 1
      },
      {
        "idx": 206908,
        "reasoning": "The code is vulnerable because it doesn't consistently exit if `privsep_init()` fails, potentially allowing the daemon to continue running with root privileges. This contradicts the intended security measure of dropping root privileges and could lead to a compromise if a vulnerability exists in the daemon's later operations.",
        "func": "main(int argc, char *argv[])\n{\n\tchar pidstr[16];\n\tssize_t ret;\n\tint c, log_method;\n\tchar *logfile, *pidfile;\n\tint facility, fd;\n\tchar *username = NULL;\n\tchar *chrootdir = NULL;\n\tint configtest = 0;\n\tint singleprocess = 0;\n#ifdef HAVE_GETOPT_LONG\n\tint opt_idx;\n#endif\n\n\tpname = ((pname=strrchr(argv[0],'/')) != NULL)?pname+1:argv[0];\n\n\tsrand((unsigned int)time(NULL));\n\n\tlog_method = L_STDERR_SYSLOG;\n\tlogfile = PATH_RADVD_LOG;\n\tconf_file = PATH_RADVD_CONF;\n\tfacility = LOG_FACILITY;\n\tpidfile = PATH_RADVD_PID;\n\n\t/* parse args */\n#define OPTIONS_STR \"d:C:l:m:p:t:u:vhcs\"\n#ifdef HAVE_GETOPT_LONG\n\twhile ((c = getopt_long(argc, argv, OPTIONS_STR, prog_opt, &opt_idx)) > 0)\n#else\n\twhile ((c = getopt(argc, argv, OPTIONS_STR)) > 0)\n#endif\n\t{\n\t\tswitch (c) {\n\t\tcase 'C':\n\t\t\tconf_file = optarg;\n\t\t\tbreak;\n\t\tcase 'd':\n\t\t\tset_debuglevel(atoi(optarg));\n\t\t\tbreak;\n\t\tcase 'f':\n\t\t\tfacility = atoi(optarg);\n\t\t\tbreak;\n\t\tcase 'l':\n\t\t\tlogfile = optarg;\n\t\t\tbreak;\n\t\tcase 'p':\n\t\t\tpidfile = optarg;\n\t\t\tbreak;\n\t\tcase 'm':\n\t\t\tif (!strcmp(optarg, \"syslog\"))\n\t\t\t{\n\t\t\t\tlog_method = L_SYSLOG;\n\t\t\t}\n\t\t\telse if (!strcmp(optarg, \"stderr_syslog\"))\n\t\t\t{\n\t\t\t\tlog_method = L_STDERR_SYSLOG;\n\t\t\t}\n\t\t\telse if (!strcmp(optarg, \"stderr\"))\n\t\t\t{\n\t\t\t\tlog_method = L_STDERR;\n\t\t\t}\n\t\t\telse if (!strcmp(optarg, \"logfile\"))\n\t\t\t{\n\t\t\t\tlog_method = L_LOGFILE;\n\t\t\t}\n\t\t\telse if (!strcmp(optarg, \"none\"))\n\t\t\t{\n\t\t\t\tlog_method = L_NONE;\n\t\t\t}\n\t\t\telse\n\t\t\t{\n\t\t\t\tfprintf(stderr, \"%s: unknown log method: %s\\n\", pname, optarg);\n\t\t\t\texit(1);\n\t\t\t}\n\t\t\tbreak;\n\t\tcase 't':\n\t\t\tchrootdir = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'u':\n\t\t\tusername = strdup(optarg);\n\t\t\tbreak;\n\t\tcase 'v':\n\t\t\tversion();\n\t\t\tbreak;\n\t\tcase 'c':\n\t\t\tconfigtest = 1;\n\t\t\tbreak;\n\t\tcase 's':\n\t\t\tsingleprocess = 1;\n\t\t\tbreak;\n\t\tcase 'h':\n\t\t\tusage();\n#ifdef HAVE_GETOPT_LONG\n\t\tcase ':':\n\t\t\tfprintf(stderr, \"%s: option %s: parameter expected\\n\", pname,\n\t\t\t\tprog_opt[opt_idx].name);\n\t\t\texit(1);\n#endif\n\t\tcase '?':\n\t\t\texit(1);\n\t\t}\n\t}\n\n\tif (chrootdir) {\n\t\tif (!username) {\n\t\t\tfprintf(stderr, \"Chroot as root is not safe, exiting\\n\");\n\t\t\texit(1);\n\t\t}\n\n\t\tif (chroot(chrootdir) == -1) {\n\t\t\tperror(\"chroot\");\n\t\t\texit (1);\n\t\t}\n\n\t\tif (chdir(\"/\") == -1) {\n\t\t\tperror(\"chdir\");\n\t\t\texit (1);\n\t\t}\n\t\t/* username will be switched later */\n\t}\n\n\tif (configtest) {\n\t\tlog_method = L_STDERR;\n\t}\n\n\tif (log_open(log_method, pname, logfile, facility) < 0) {\n\t\tperror(\"log_open\");\n\t\texit(1);\n\t}\n\n\tif (!configtest) {\n\t\tflog(LOG_INFO, \"version %s started\", VERSION);\n\t}\n\n\t/* get a raw socket for sending and receiving ICMPv6 messages */\n\tsock = open_icmpv6_socket();\n\tif (sock < 0) {\n\t\tperror(\"open_icmpv6_socket\");\n\t\texit(1);\n\t}\n\n\t/* check that 'other' cannot write the file\n         * for non-root, also that self/own group can't either\n         */\n\tif (check_conffile_perm(username, conf_file) < 0) {\n\t\tif (get_debuglevel() == 0) {\n\t\t\tflog(LOG_ERR, \"Exiting, permissions on conf_file invalid.\\n\");\n\t\t\texit(1);\n\t\t}\n\t\telse\n\t\t\tflog(LOG_WARNING, \"Insecure file permissions, but continuing anyway\");\n\t}\n\n\t/* if we know how to do it, check whether forwarding is enabled */\n\tif (check_ip6_forwarding()) {\n\t\tflog(LOG_WARNING, \"IPv6 forwarding seems to be disabled, but continuing anyway.\");\n\t}\n\n\t/* parse config file */\n\tif (readin_config(conf_file) < 0) {\n\t\tflog(LOG_ERR, \"Exiting, failed to read config file.\\n\");\n\t\texit(1);\n\t}\n\n\tif (configtest) {\n\t\tfprintf(stderr, \"Syntax OK\\n\");\n\t\texit(0);\n\t}\n\n\t/* drop root privileges if requested. */\n\tif (username) {\n\t\tif (!singleprocess) {\n\t\t \tdlog(LOG_DEBUG, 3, \"Initializing privsep\");\n\t\t \tif (privsep_init() < 0)\n\t\t\t\tperror(\"Failed to initialize privsep.\");\n\t\t}\n\n\t\tif (drop_root_privileges(username) < 0) {\n\t\t\tperror(\"drop_root_privileges\");\n\t\t\texit(1);\n\t\t}\n\t}\n\n\tif ((fd = open(pidfile, O_RDONLY, 0)) > 0)\n\t{\n\t\tret = read(fd, pidstr, sizeof(pidstr) - 1);\n\t\tif (ret < 0)\n\t\t{\n\t\t\tflog(LOG_ERR, \"cannot read radvd pid file, terminating: %s\", strerror(errno));\n\t\t\texit(1);\n\t\t}\n\t\tpidstr[ret] = '\\0';\n\t\tif (!kill((pid_t)atol(pidstr), 0))\n\t\t{\n\t\t\tflog(LOG_ERR, \"radvd already running, terminating.\");\n\t\t\texit(1);\n\t\t}\n\t\tclose(fd);\n\t\tfd = open(pidfile, O_CREAT|O_TRUNC|O_WRONLY, 0644);\n\t}\n\telse\t/* FIXME: not atomic if pidfile is on an NFS mounted volume */\n\t\tfd = open(pidfile, O_CREAT|O_EXCL|O_WRONLY, 0644);\n\n\tif (fd < 0)\n\t{\n\t\tflog(LOG_ERR, \"cannot create radvd pid file, terminating: %s\", strerror(errno));\n\t\texit(1);\n\t}\n\n\t/*\n\t * okay, config file is read in, socket and stuff is setup, so\n\t * lets fork now...\n\t */\n\n\tif (get_debuglevel() == 0) {\n\n\t\t/* Detach from controlling terminal */\n\t\tif (daemon(0, 0) < 0)\n\t\t\tperror(\"daemon\");\n\n\t\t/* close old logfiles, including stderr */\n\t\tlog_close();\n\n\t\t/* reopen logfiles, but don't log to stderr unless explicitly requested */\n\t\tif (log_method == L_STDERR_SYSLOG)\n\t\t\tlog_method = L_SYSLOG;\n\t\tif (log_open(log_method, pname, logfile, facility) < 0) {\n\t\t\tperror(\"log_open\");\n\t\t\texit(1);\n\t\t}\n\n\t}\n\n\t/*\n\t *\tconfig signal handlers\n\t */\n\tsignal(SIGHUP, sighup_handler);\n\tsignal(SIGTERM, sigterm_handler);\n\tsignal(SIGINT, sigint_handler);\n\tsignal(SIGUSR1, sigusr1_handler);\n\n\tsnprintf(pidstr, sizeof(pidstr), \"%ld\\n\", (long)getpid());\n\n\tret = write(fd, pidstr, strlen(pidstr));\n\tif (ret != strlen(pidstr))\n\t{\n\t\tflog(LOG_ERR, \"cannot write radvd pid file, terminating: %s\", strerror(errno));\n\t\texit(1);\n\t}\n\n\tclose(fd);\n\n\tconfig_interface();\n\tkickoff_adverts();\n\tmain_loop();\n\tstop_adverts();\n\tunlink(pidfile);\n\n\treturn 0;\n}",
        "commit_message": "Really exit on privsep init failure.",
        "cve_desc": "The router advertisement daemon (radvd) before 1.8.2 does not properly handle errors in the privsep_init function, which causes the radvd daemon to run as root and has an unspecified impact.",
        "target": 1
      }
    ]
  },
  "redcarpet": {
    "0": [
      {
        "idx": 410629,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message, which concerns auto-linking and HTML tag rewinding within the Redcarpet Markdown parser. The provided `is_empty` function simply checks for leading whitespace up to a newline and doesn't interact with Markdown parsing or HTML rendering, therefore posing no apparent risk related to the described issue.\n\n\n\n",
        "func": "is_empty(const uint8_t *data, size_t size)\n{\n\tsize_t i;\n\n\tfor (i = 0; i < size && data[i] != '\\n'; i++)\n\t\tif (data[i] != ' ')\n\t\t\treturn 0;\n\n\treturn i + 1;\n}",
        "commit_message": "Avoid rewinding previous inline when auto-linking\n\nWhen a bit like \"_foo_1@bar.com\" is processed, first the emphasis is\nrendered, then the 1 is output verbatim. When the `@` is encountered,\nRedcarpet tries to find the \"local part\" of the address and stops when\nit encounters an invalid char (i.e. here the `!`).\n\nThe problem is that when it searches for the local part, Redcarpet\nrewinds the characters but here, the emphasis is already rendered so\nthe previous HTML tag is rewinded as well and is not correctly closed.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 410630,
        "reasoning": "This code snippet focuses on parsing blockquotes and managing data within a buffer, and doesn't appear to handle any user-supplied input directly involved in HTML rendering or URL processing where the described vulnerability (rewinding rendered HTML tags during autolinking) occurs. Therefore, based on the provided context, this code is not vulnerable to the reported issue and isn't flagged as such.\n\n\n\n",
        "func": "parse_blockquote(struct buf *ob, struct sd_markdown *rndr, uint8_t *data, size_t size)\n{\n\tsize_t beg, end = 0, pre, work_size = 0;\n\tuint8_t *work_data = 0;\n\tstruct buf *out = 0;\n\n\tout = rndr_newbuf(rndr, BUFFER_BLOCK);\n\tbeg = 0;\n\twhile (beg < size) {\n\t\tfor (end = beg + 1; end < size && data[end - 1] != '\\n'; end++);\n\n\t\tpre = prefix_quote(data + beg, end - beg);\n\n\t\tif (pre)\n\t\t\tbeg += pre; /* skipping prefix */\n\n\t\t/* empty line followed by non-quote line */\n\t\telse if (is_empty(data + beg, end - beg) &&\n\t\t\t\t(end >= size || (prefix_quote(data + end, size - end) == 0 &&\n\t\t\t\t!is_empty(data + end, size - end))))\n\t\t\tbreak;\n\n\t\tif (beg < end) { /* copy into the in-place working buffer */\n\t\t\t/* bufput(work, data + beg, end - beg); */\n\t\t\tif (!work_data)\n\t\t\t\twork_data = data + beg;\n\t\t\telse if (data + beg != work_data + work_size)\n\t\t\t\tmemmove(work_data + work_size, data + beg, end - beg);\n\t\t\twork_size += end - beg;\n\t\t}\n\t\tbeg = end;\n\t}\n\n\tparse_block(out, rndr, work_data, work_size);\n\tif (rndr->cb.blockquote)\n\t\trndr->cb.blockquote(ob, out, rndr->opaque);\n\trndr_popbuf(rndr, BUFFER_BLOCK);\n\treturn end;\n}",
        "commit_message": "Avoid rewinding previous inline when auto-linking\n\nWhen a bit like \"_foo_1@bar.com\" is processed, first the emphasis is\nrendered, then the 1 is output verbatim. When the `@` is encountered,\nRedcarpet tries to find the \"local part\" of the address and stops when\nit encounters an invalid char (i.e. here the `!`).\n\nThe problem is that when it searches for the local part, Redcarpet\nrewinds the characters but here, the emphasis is already rendered so\nthe previous HTML tag is rewinded as well and is not correctly closed.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 410631,
        "reasoning": "This code snippet focuses on parsing list items and doesn't directly handle the auto-linking or emphasis rendering described in the commit message where the vulnerability lies. Therefore, based on the provided code, there's no indication of a vulnerability related to incorrectly closing HTML tags during auto-linking; it's a safe snippet in the context of the described issue.\n\n\n\n",
        "func": "parse_list(struct buf *ob, struct sd_markdown *rndr, uint8_t *data, size_t size, int flags)\n{\n\tstruct buf *work = 0;\n\tsize_t i = 0, j;\n\n\twork = rndr_newbuf(rndr, BUFFER_BLOCK);\n\n\twhile (i < size) {\n\t\tj = parse_listitem(work, rndr, data + i, size - i, &flags);\n\t\ti += j;\n\n\t\tif (!j || (flags & MKD_LI_END))\n\t\t\tbreak;\n\t}\n\n\tif (rndr->cb.list)\n\t\trndr->cb.list(ob, work, flags, rndr->opaque);\n\trndr_popbuf(rndr, BUFFER_BLOCK);\n\treturn i;\n}",
        "commit_message": "Avoid rewinding previous inline when auto-linking\n\nWhen a bit like \"_foo_1@bar.com\" is processed, first the emphasis is\nrendered, then the 1 is output verbatim. When the `@` is encountered,\nRedcarpet tries to find the \"local part\" of the address and stops when\nit encounters an invalid char (i.e. here the `!`).\n\nThe problem is that when it searches for the local part, Redcarpet\nrewinds the characters but here, the emphasis is already rendered so\nthe previous HTML tag is rewinded as well and is not correctly closed.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 410632,
        "reasoning": "This code snippet focuses on tab expansion within a buffer and doesn't relate to the described vulnerability regarding HTML tag rewinding during auto-linking in Redcarpet. The vulnerability lies in how Redcarpet handles character processing during email address parsing, not in a function responsible for whitespace manipulation like `expand_tabs`.\n\n\n\n",
        "func": "static void expand_tabs(struct buf *ob, const uint8_t *line, size_t size)\n{\n\tsize_t  i = 0, tab = 0;\n\n\twhile (i < size) {\n\t\tsize_t org = i;\n\n\t\twhile (i < size && line[i] != '\\t') {\n\t\t\ti++; tab++;\n\t\t}\n\n\t\tif (i > org)\n\t\t\tbufput(ob, line + org, i - org);\n\n\t\tif (i >= size)\n\t\t\tbreak;\n\n\t\tdo {\n\t\t\tbufputc(ob, ' '); tab++;\n\t\t} while (tab % 4);\n\n\t\ti++;\n\t}\n}",
        "commit_message": "Avoid rewinding previous inline when auto-linking\n\nWhen a bit like \"_foo_1@bar.com\" is processed, first the emphasis is\nrendered, then the 1 is output verbatim. When the `@` is encountered,\nRedcarpet tries to find the \"local part\" of the address and stops when\nit encounters an invalid char (i.e. here the `!`).\n\nThe problem is that when it searches for the local part, Redcarpet\nrewinds the characters but here, the emphasis is already rendered so\nthe previous HTML tag is rewinded as well and is not correctly closed.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 410633,
        "reasoning": "This code snippet focuses on parsing and rendering footnote lists and doesn't appear to handle any user-supplied input directly involved in the auto-linking process described in the commit message. Therefore, it's unlikely to be affected by the vulnerability related to incorrectly closing HTML tags during auto-linking, and is not flagged as vulnerable based on the provided context.\n\n\n\n",
        "func": "parse_footnote_list(struct buf *ob, struct sd_markdown *rndr, struct footnote_list *footnotes)\n{\n\tstruct buf *work = 0;\n\tstruct footnote_item *item;\n\tstruct footnote_ref *ref;\n\n\tif (footnotes->count == 0)\n\t\treturn;\n\n\twork = rndr_newbuf(rndr, BUFFER_BLOCK);\n\n\titem = footnotes->head;\n\twhile (item) {\n\t\tref = item->ref;\n\t\tparse_footnote_def(work, rndr, ref->num, ref->contents->data, ref->contents->size);\n\t\titem = item->next;\n\t}\n\n\tif (rndr->cb.footnotes)\n\t\trndr->cb.footnotes(ob, work, rndr->opaque);\n\trndr_popbuf(rndr, BUFFER_BLOCK);\n}",
        "commit_message": "Avoid rewinding previous inline when auto-linking\n\nWhen a bit like \"_foo_1@bar.com\" is processed, first the emphasis is\nrendered, then the 1 is output verbatim. When the `@` is encountered,\nRedcarpet tries to find the \"local part\" of the address and stops when\nit encounters an invalid char (i.e. here the `!`).\n\nThe problem is that when it searches for the local part, Redcarpet\nrewinds the characters but here, the emphasis is already rendered so\nthe previous HTML tag is rewinded as well and is not correctly closed.",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": []
  },
  "redis": {
    "0": [
      {
        "idx": 192002,
        "reasoning": "This code snippet focuses on managing return hooks within the Redis Lua scripting engine and doesn't directly handle loading or parsing Lua bytecode\u2014the functionality disabled by the commit message. Therefore, the change to disable loading bytecode isn't reflected in this specific code, and it doesn't introduce or mitigate any vulnerabilities related to the hook mechanism itself.\n\n\n\n",
        "func": "static StkId callrethooks (lua_State *L, StkId firstResult) {\n  ptrdiff_t fr = savestack(L, firstResult);  /* next call may change stack */\n  luaD_callhook(L, LUA_HOOKRET, -1);\n  if (f_isLua(L->ci)) {  /* Lua function? */\n    while ((L->hookmask & LUA_MASKRET) && L->ci->tailcalls--) /* tail calls */\n      luaD_callhook(L, LUA_HOOKTAILRET, -1);\n  }\n  return restorestack(L, fr);\n}\n",
        "commit_message": "disable loading lua bytecode",
        "cve_desc": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "target": 0
      },
      {
        "idx": 192003,
        "reasoning": "This code snippet focuses on stack correction within Redis's Lua scripting engine and doesn't directly handle external input or bytecode loading\u2014the commit message indicates bytecode loading is *disabled* elsewhere. Therefore, there's no apparent vulnerability related to code injection, arbitrary execution, or data manipulation stemming from this specific stack management function, as it operates on internal Lua state.\n\n\n\n",
        "func": "static void correctstack (lua_State *L, TValue *oldstack) {\n  CallInfo *ci;\n  GCObject *up;\n  L->top = (L->top - oldstack) + L->stack;\n  for (up = L->openupval; up != NULL; up = up->gch.next)\n    gco2uv(up)->v = (gco2uv(up)->v - oldstack) + L->stack;\n  for (ci = L->base_ci; ci <= L->ci; ci++) {\n    ci->top = (ci->top - oldstack) + L->stack;\n    ci->base = (ci->base - oldstack) + L->stack;\n    ci->func = (ci->func - oldstack) + L->stack;\n  }\n  L->base = (L->base - oldstack) + L->stack;\n}\n",
        "commit_message": "disable loading lua bytecode",
        "cve_desc": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "target": 0
      },
      {
        "idx": 192004,
        "reasoning": "This code snippet focuses on stack management within Redis's Lua interpreter and doesn't directly relate to loading or handling Lua bytecode, despite the commit message mentioning bytecode disabling. The code safely checks for stack overflow conditions (`LUAI_MAXCALLS`) and throws errors, preventing potential denial-of-service scenarios related to excessive stack usage, but doesn't introduce new vulnerabilities itself.\n\n\n\n",
        "func": "static CallInfo *growCI (lua_State *L) {\n  if (L->size_ci > LUAI_MAXCALLS)  /* overflow while handling overflow? */\n    luaD_throw(L, LUA_ERRERR);\n  else {\n    luaD_reallocCI(L, 2*L->size_ci);\n    if (L->size_ci > LUAI_MAXCALLS)\n      luaG_runerror(L, \"stack overflow\");\n  }\n  return ++L->ci;\n}\n",
        "commit_message": "disable loading lua bytecode",
        "cve_desc": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "target": 0
      },
      {
        "idx": 192005,
        "reasoning": "This code snippet focuses on call stack management within Lua and doesn't directly relate to loading or handling Lua bytecode\u2014the functionality disabled by the commit message. Therefore, there's no apparent vulnerability introduced or mitigated by this code concerning the bytecode loading change; it simply manages function calls regardless of how those functions were initially defined or loaded.\n\n\n\n",
        "func": "void luaD_call (lua_State *L, StkId func, int nResults) {\n  if (++L->nCcalls >= LUAI_MAXCCALLS) {\n    if (L->nCcalls == LUAI_MAXCCALLS)\n      luaG_runerror(L, \"C stack overflow\");\n    else if (L->nCcalls >= (LUAI_MAXCCALLS + (LUAI_MAXCCALLS>>3)))\n      luaD_throw(L, LUA_ERRERR);  /* error while handing stack error */\n  }\n  if (luaD_precall(L, func, nResults) == PCRLUA)  /* is a Lua function? */\n    luaV_execute(L, 1);  /* call it */\n  L->nCcalls--;\n  luaC_checkGC(L);\n}\n",
        "commit_message": "disable loading lua bytecode",
        "cve_desc": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 10559,
        "reasoning": "This code is vulnerable because it directly parses and executes Lua bytecode provided through the `eval` command without sufficient validation, as demonstrated by the `luaU_undump` function call. The CVE highlights that malicious Lua bytecode can be crafted and sent to the Redis server, leading to arbitrary code execution due to this lack of sanitization during the loading process.",
        "func": "static void f_parser (lua_State *L, void *ud) {\n  int i;\n  Proto *tf;\n  Closure *cl;\n   struct SParser *p = cast(struct SParser *, ud);\n   int c = luaZ_lookahead(p->z);\n   luaC_checkGC(L);\n  tf = ((c == LUA_SIGNATURE[0]) ? luaU_undump : luaY_parser)(L, p->z,\n                                                              &p->buff, p->name);\n   cl = luaF_newLclosure(L, tf->nups, hvalue(gt(L)));\n   cl->l.p = tf;\n  for (i = 0; i < tf->nups; i++)  /* initialize eventual upvalues */\n    cl->l.upvals[i] = luaF_newupval(L);\n  setclvalue(L, L->top, cl);\n  incr_top(L);\n}\n",
        "commit_message": "disable loading lua bytecode",
        "cve_desc": "Redis before 2.8.21 and 3.x before 3.0.2 allows remote attackers to execute arbitrary Lua bytecode via the eval command.",
        "target": 1
      },
      {
        "idx": 10586,
        "reasoning": "The code is vulnerable to Cross Protocol Scripting because it doesn't explicitly check for and reject HTTP-specific headers like \"POST\" and \"Host:\" within the input buffer before attempting to parse it as a Redis command. This allows attackers to send HTTP requests to the Redis port, which are partially processed, potentially leading to unintended command execution or denial of service before the connection is terminated, as the commit message acknowledges successive commands in a pipelined request *are* executed before termination.",
        "func": "void processInputBuffer(client *c) {\n    server.current_client = c;\n    /* Keep processing while there is something in the input buffer */\n    while(sdslen(c->querybuf)) {\n        /* Return if clients are paused. */\n        if (!(c->flags & CLIENT_SLAVE) && clientsArePaused()) break;\n\n        /* Immediately abort if the client is in the middle of something. */\n        if (c->flags & CLIENT_BLOCKED) break;\n \n         /* CLIENT_CLOSE_AFTER_REPLY closes the connection once the reply is\n          * written to the client. Make sure to not let the reply grow after\n         * this flag has been set (i.e. don't process more commands). */\n        if (c->flags & CLIENT_CLOSE_AFTER_REPLY) break;\n \n         /* Determine request type when unknown. */\n         if (!c->reqtype) {\n            if (c->querybuf[0] == '*') {\n                c->reqtype = PROTO_REQ_MULTIBULK;\n            } else {\n                c->reqtype = PROTO_REQ_INLINE;\n            }\n        }\n\n        if (c->reqtype == PROTO_REQ_INLINE) {\n            if (processInlineBuffer(c) != C_OK) break;\n        } else if (c->reqtype == PROTO_REQ_MULTIBULK) {\n            if (processMultibulkBuffer(c) != C_OK) break;\n        } else {\n            serverPanic(\"Unknown request type\");\n        }\n\n        /* Multibulk processing could see a <= 0 length. */\n        if (c->argc == 0) {\n            resetClient(c);\n        } else {\n            /* Only reset the client when the command was executed. */\n            if (processCommand(c) == C_OK)\n                resetClient(c);\n            /* freeMemoryIfNeeded may flush slave output buffers. This may result\n             * into a slave, that may be the active client, to be freed. */\n            if (server.current_client == NULL) break;\n        }\n    }\n    server.current_client = NULL;\n}\n",
        "commit_message": "Security: Cross Protocol Scripting protection.\n\nThis is an attempt at mitigating problems due to cross protocol\nscripting, an attack targeting services using line oriented protocols\nlike Redis that can accept HTTP requests as valid protocol, by\ndiscarding the invalid parts and accepting the payloads sent, for\nexample, via a POST request.\n\nFor this to be effective, when we detect POST and Host: and terminate\nthe connection asynchronously, the networking code was modified in order\nto never process further input. It was later verified that in a\npipelined request containing a POST command, the successive commands are\nnot executed.",
        "cve_desc": "networking.c in Redis before 3.2.7 allows \"Cross Protocol Scripting\" because it lacks a check for POST and Host: strings, which are not valid in the Redis protocol (but commonly occur when an attack triggers an HTTP request to the Redis TCP port).",
        "target": 1
      },
      {
        "idx": 10598,
        "reasoning": "The code lacks a check to ensure the key being operated on is actually a stream data type before proceeding with XGROUP commands like CREATE, SETID, or DELCONSUMER. This allows an attacker to provide a key that isn't a stream, leading to a type confusion and potentially a denial-of-service as the code attempts to treat a non-stream object as a stream.",
        "func": "void xgroupCommand(client *c) {\n    const char *help[] = {\n\"CREATE      <key> <groupname> <id or $>  -- Create a new consumer group.\",\n\"SETID       <key> <groupname> <id or $>  -- Set the current group ID.\",\n\"DELGROUP    <key> <groupname>            -- Remove the specified group.\",\n\"DELCONSUMER <key> <groupname> <consumer> -- Remove the specified conusmer.\",\n\"HELP                                     -- Prints this help.\",\nNULL\n    };\n    stream *s = NULL;\n    sds grpname = NULL;\n    streamCG *cg = NULL;\n    char *opt = c->argv[1]->ptr; /* Subcommand name. */\n\n     /* Lookup the key now, this is common for all the subcommands but HELP. */\n     if (c->argc >= 4) {\n         robj *o = lookupKeyWriteOrReply(c,c->argv[2],shared.nokeyerr);\n        if (o == NULL) return;\n         s = o->ptr;\n         grpname = c->argv[3]->ptr;\n \n        /* Certain subcommands require the group to exist. */\n        if ((cg = streamLookupCG(s,grpname)) == NULL &&\n            (!strcasecmp(opt,\"SETID\") ||\n             !strcasecmp(opt,\"DELCONSUMER\")))\n        {\n            addReplyErrorFormat(c, \"-NOGROUP No such consumer group '%s' \"\n                                   \"for key name '%s'\",\n                                   (char*)grpname, (char*)c->argv[2]->ptr);\n            return;\n        }\n    }\n\n    /* Dispatch the different subcommands. */\n    if (!strcasecmp(opt,\"CREATE\") && c->argc == 5) {\n        streamID id;\n        if (!strcmp(c->argv[4]->ptr,\"$\")) {\n            id = s->last_id;\n        } else if (streamParseIDOrReply(c,c->argv[4],&id,0) != C_OK) {\n            return;\n        }\n        streamCG *cg = streamCreateCG(s,grpname,sdslen(grpname),&id);\n        if (cg) {\n            addReply(c,shared.ok);\n            server.dirty++;\n        } else {\n            addReplySds(c,\n                sdsnew(\"-BUSYGROUP Consumer Group name already exists\\r\\n\"));\n        }\n    } else if (!strcasecmp(opt,\"SETID\") && c->argc == 5) {\n        streamID id;\n        if (!strcmp(c->argv[4]->ptr,\"$\")) {\n            id = s->last_id;\n        } else if (streamParseIDOrReply(c,c->argv[4],&id,0) != C_OK) {\n            return;\n        }\n        cg->last_id = id;\n        addReply(c,shared.ok);\n    } else if (!strcasecmp(opt,\"DESTROY\") && c->argc == 4) {\n        if (cg) {\n            raxRemove(s->cgroups,(unsigned char*)grpname,sdslen(grpname),NULL);\n            streamFreeCG(cg);\n            addReply(c,shared.cone);\n        } else {\n            addReply(c,shared.czero);\n        }\n    } else if (!strcasecmp(opt,\"DELCONSUMER\") && c->argc == 5) {\n        /* Delete the consumer and returns the number of pending messages\n         * that were yet associated with such a consumer. */\n        long long pending = streamDelConsumer(cg,c->argv[4]->ptr);\n        addReplyLongLong(c,pending);\n        server.dirty++;\n    } else if (!strcasecmp(opt,\"HELP\")) {\n        addReplyHelp(c, help);\n    } else {\n        addReply(c,shared.syntaxerr);\n    }\n}\n",
        "commit_message": "Abort in XGROUP if the key is not a stream",
        "cve_desc": "Type confusion in the xgroupCommand function in t_stream.c in redis-server in Redis before 5.0 allows remote attackers to cause denial-of-service via an XGROUP command in which the key is not a stream.",
        "target": 1
      },
      {
        "idx": 10599,
        "reasoning": "The code is vulnerable to a buffer overflow because `snprintf` is used multiple times to append to `config.prompt` without adequately ensuring sufficient space remains in the buffer after each call, potentially writing beyond the allocated memory. The CVE description confirms this allows for code execution via a crafted command line, likely exploiting this overflow when constructing the prompt string with potentially long hostnames, IP addresses, or database numbers.",
        "func": " static void cliRefreshPrompt(void) {\n    int len;\n     if (config.eval_ldb) return;\n    if (config.hostsocket != NULL)\n        len = snprintf(config.prompt,sizeof(config.prompt),\"redis %s\",\n                       config.hostsocket);\n    else\n        len = anetFormatAddr(config.prompt, sizeof(config.prompt),\n                           config.hostip, config.hostport);\n     /* Add [dbnum] if needed */\n     if (config.dbnum != 0)\n        len += snprintf(config.prompt+len,sizeof(config.prompt)-len,\"[%d]\",\n            config.dbnum);\n    snprintf(config.prompt+len,sizeof(config.prompt)-len,\"> \");\n }\n",
        "commit_message": "Security: fix redis-cli buffer overflow.\n\nThanks to Fakhri Zulkifli for reporting it.\n\nThe fix switched to dynamic allocation, copying the final prompt in the\nstatic buffer only at the end.",
        "cve_desc": "Buffer overflow in redis-cli of Redis before 4.0.10 and 5.x before 5.0 RC3 allows an attacker to achieve code execution and escalate to higher privileges via a crafted command line. NOTE: It is unclear whether there are any common situations in which redis-cli is used with, for example, a -h (aka hostname) argument from an untrusted source.",
        "target": 1
      },
      {
        "idx": 10601,
        "reasoning": "This code is vulnerable to an integer overflow due to insufficient bounds checking when calculating the memory access position `pos` within the `data` string, as demonstrated by the provided test case `struct.unpack('f', \"xxxxxxxxxxxxx\",-3)`. The negative `pos` value, combined with subsequent additions of `size`, can wrap around, leading to reading from memory *before* the start of the `data` buffer \u2013 a classic out-of-bounds read \u2013 which is precisely what the CVE describes as a failure of bounds checking.",
        "func": "static int b_unpack (lua_State *L) {\n  Header h;\n   const char *fmt = luaL_checkstring(L, 1);\n   size_t ld;\n   const char *data = luaL_checklstring(L, 2, &ld);\n  size_t pos = luaL_optinteger(L, 3, 1) - 1;\n   int n = 0;  /* number of results */\n   defaultoptions(&h);\n   while (*fmt) {\n     int opt = *fmt++;\n     size_t size = optsize(L, opt, &fmt);\n     pos += gettoalign(pos, &h, opt, size);\n    luaL_argcheck(L, pos+size <= ld, 2, \"data string too short\");\n     /* stack space for item + next position */\n     luaL_checkstack(L, 2, \"too many results\");\n     switch (opt) {\n      case 'b': case 'B': case 'h': case 'H':\n      case 'l': case 'L': case 'T': case 'i':  case 'I': {  /* integer types */\n        int issigned = islower(opt);\n        lua_Number res = getinteger(data+pos, h.endian, issigned, size);\n        lua_pushnumber(L, res); n++;\n        break;\n      }\n      case 'x': {\n        break;\n      }\n      case 'f': {\n        float f;\n        memcpy(&f, data+pos, size);\n        correctbytes((char *)&f, sizeof(f), h.endian);\n        lua_pushnumber(L, f); n++;\n        break;\n      }\n      case 'd': {\n        double d;\n        memcpy(&d, data+pos, size);\n        correctbytes((char *)&d, sizeof(d), h.endian);\n        lua_pushnumber(L, d); n++;\n        break;\n      }\n      case 'c': {\n        if (size == 0) {\n          if (n == 0 || !lua_isnumber(L, -1))\n            luaL_error(L, \"format 'c0' needs a previous size\");\n          size = lua_tonumber(L, -1);\n          lua_pop(L, 1); n--;\n          luaL_argcheck(L, size <= ld && pos <= ld - size,\n                           2, \"data string too short\");\n        }\n        lua_pushlstring(L, data+pos, size); n++;\n        break;\n      }\n      case 's': {\n        const char *e = (const char *)memchr(data+pos, '\\0', ld - pos);\n        if (e == NULL)\n          luaL_error(L, \"unfinished string in data\");\n        size = (e - (data+pos)) + 1;\n        lua_pushlstring(L, data+pos, size - 1); n++;\n        break;\n      }\n      default: controloptions(L, opt, &fmt, &h);\n    }\n    pos += size;\n  }\n  lua_pushinteger(L, pos + 1);  /* next position */\n  return n + 1;\n}\n",
        "commit_message": "Security: fix Lua struct package offset handling.\n\nAfter the first fix to the struct package I found another similar\nproblem, which is fixed by this patch. It could be reproduced easily by\nrunning the following script:\n\n    return struct.unpack('f', \"xxxxxxxxxxxxx\",-3)\n\nThe above will access bytes before the 'data' pointer.",
        "cve_desc": "An Integer Overflow issue was discovered in the struct library in the Lua subsystem in Redis before 3.2.12, 4.x before 4.0.10, and 5.x before 5.0 RC2, leading to a failure of bounds checking.",
        "target": 1
      }
    ]
  },
  "rpm": {
    "0": [
      {
        "idx": 193681,
        "reasoning": "This code snippet is not directly related to the commit message's focus on symlink verification and security fixes for CVE-2017-7500. The `cap_compare` function simply compares capabilities (security contexts) and doesn't introduce any vulnerabilities related to file system access or symlink handling, therefore it's not flagged as vulnerable based on the provided context.\n\n\n\n",
        "func": "static int cap_compare(cap_t acap, cap_t bcap)\n{\n    int rc = 0;\n    size_t asize = cap_size(acap);\n    size_t bsize = cap_size(bcap);\n\n    if (asize != bsize) {\n\trc = 1;\n    } else {\n\tchar *abuf = xcalloc(asize, sizeof(*abuf));\n\tchar *bbuf = xcalloc(bsize, sizeof(*bbuf));\n\tcap_copy_ext(abuf, acap, asize);\n\tcap_copy_ext(bbuf, bcap, bsize);\n\trc = memcmp(abuf, bbuf, asize);\n\tfree(abuf);\n\tfree(bbuf);\n    }\n    return rc;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 0
      },
      {
        "idx": 193682,
        "reasoning": "This code snippet is not directly vulnerable. It simply constructs a string representation of file flags for RPM packages and doesn't handle any file system operations or user input that could lead to security issues; the commit message details changes to *how* files are verified, not the code *performing* the verification itself, and this snippet isn't involved in that process.\n\n\n\n",
        "func": "char * rpmFFlagsString(uint32_t fflags, const char *pad)\n{\n    char *fmt = NULL;\n    rasprintf(&fmt, \"%s%s%s%s%s%s%s%s\",\n\t\t(fflags & RPMFILE_DOC) ? \"d\" : pad,\n\t\t(fflags & RPMFILE_CONFIG) ? \"c\" : pad,\n\t\t(fflags & RPMFILE_SPECFILE) ? \"s\" : pad,\n\t\t(fflags & RPMFILE_MISSINGOK) ? \"m\" : pad,\n\t\t(fflags & RPMFILE_NOREPLACE) ? \"n\" : pad,\n\t\t(fflags & RPMFILE_GHOST) ? \"g\" : pad,\n\t\t(fflags & RPMFILE_LICENSE) ? \"l\" : pad,\n\t\t(fflags & RPMFILE_README) ? \"r\" : pad);\n    return fmt;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 0
      },
      {
        "idx": 193683,
        "reasoning": "This code snippet addresses a potential vulnerability related to symlink traversal during package verification (CVE-2017-7500) by restricting symlink following to links owned by the target directory owner or root. The commit message explicitly states the change *matches* the behavior of a fix for CVE-2017-7500 and corrects previous incorrect logic, indicating a security improvement rather than introducing a new vulnerability.\n\n\n\n",
        "func": "int rpmVerifyFile(const rpmts ts, const rpmfi fi,\n\t\trpmVerifyAttrs * res, rpmVerifyAttrs omitMask)\n{\n    rpmVerifyAttrs vfy = rpmfiVerify(fi, omitMask);\n    if (res)\n\t*res = vfy;\n\n    return (vfy & RPMVERIFY_LSTATFAIL) ? 1 : 0;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 0
      },
      {
        "idx": 193684,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message details changes to *how* files are verified (specifically symlinks) to align with a fix for CVE-2017-7500, and focuses on ensuring verification occurs correctly even with restricted symlink behavior \u2013 it doesn\u2019t introduce new functionality that could be exploited, but rather corrects existing logic.\n\n\n\n",
        "func": "static int rpmVerifyScript(rpmts ts, Header h)\n{\n    int rc = 0;\n\n    if (headerIsEntry(h, RPMTAG_VERIFYSCRIPT)) {\n\t/* fake up a erasure transaction element */\n\trpmte p = rpmteNew(ts, h, TR_REMOVED, NULL, NULL);\n\n\tif (p != NULL) {\n\t    rpmteSetHeader(p, h);\n\n\t    rc = (rpmpsmRun(ts, p, PKG_VERIFY) != RPMRC_OK);\n\n\t    /* clean up our fake transaction bits */\n\t    rpmteFree(p);\n\t} else {\n\t    rc = RPMRC_FAIL;\n\t}\n    }\n\n    return rc;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 0
      },
      {
        "idx": 193685,
        "reasoning": "This code snippet is not directly vulnerable. The commit message explicitly addresses a security fix (CVE-2017-7500) by restricting symlink following during verification to only links owned by the target directory owner or root, preventing potential path traversal exploits\u2014the code change *improves* security rather than introducing a vulnerability.\n\n\n\n",
        "func": "char * rpmVerifyString(uint32_t verifyResult, const char *pad)\n{\n    char *fmt = NULL;\n    rasprintf(&fmt, \"%s%s%s%s%s%s%s%s%s\",\n\t\t_verify(RPMVERIFY_FILESIZE, \"S\", pad),\n\t\t_verify(RPMVERIFY_MODE, \"M\", pad),\n\t\t_verifyfile(RPMVERIFY_FILEDIGEST, \"5\", pad),\n\t\t_verify(RPMVERIFY_RDEV, \"D\", pad),\n\t\t_verifylink(RPMVERIFY_LINKTO, \"L\", pad),\n\t\t_verify(RPMVERIFY_USER, \"U\", pad),\n\t\t_verify(RPMVERIFY_GROUP, \"G\", pad),\n\t\t_verify(RPMVERIFY_MTIME, \"T\", pad),\n\t\t_verify(RPMVERIFY_CAPS, \"P\", pad));\n\t\t\n    return fmt;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 10617,
        "reasoning": "This code is vulnerable because it follows symbolic links to directories during verification, but only checks ownership against the target directory's owner or root, potentially allowing an attacker to redirect a directory to an arbitrary location and gain elevated privileges as described in CVE-2017-7500. The insufficient ownership validation when following symlinks can lead to unintended file placement and permission changes, effectively allowing an attacker to write to arbitrary locations as root.",
        "func": "rpmVerifyAttrs rpmfilesVerify(rpmfiles fi, int ix, rpmVerifyAttrs omitMask)\n{\n    rpm_mode_t fmode = rpmfilesFMode(fi, ix);\n    rpmfileAttrs fileAttrs = rpmfilesFFlags(fi, ix);\n    rpmVerifyAttrs flags = rpmfilesVFlags(fi, ix);\n    const char * fn = rpmfilesFN(fi, ix);\n    struct stat sb;\n    rpmVerifyAttrs vfy = RPMVERIFY_NONE;\n\n    /*\n     * Check to see if the file was installed - if not pretend all is OK.\n     */\n    switch (rpmfilesFState(fi, ix)) {\n    case RPMFILE_STATE_NETSHARED:\n    case RPMFILE_STATE_NOTINSTALLED:\n\tgoto exit;\n\tbreak;\n    case RPMFILE_STATE_REPLACED:\n\t/* For replaced files we can only verify if it exists at all */\n\tflags = RPMVERIFY_LSTATFAIL;\n\tbreak;\n    case RPMFILE_STATE_WRONGCOLOR:\n\t/*\n\t * Files with wrong color are supposed to share some attributes\n\t * with the actually installed file - verify what we can.\n\t */\n\tflags &= ~(RPMVERIFY_FILEDIGEST | RPMVERIFY_FILESIZE |\n\t\t   RPMVERIFY_MTIME | RPMVERIFY_RDEV);\n\tbreak;\n    case RPMFILE_STATE_NORMAL:\n    /* File from a non-installed package, try to verify nevertheless */\n    case RPMFILE_STATE_MISSING:\n\tbreak;\n    }\n\n    if (fn == NULL || lstat(fn, &sb) != 0) {\n\tvfy |= RPMVERIFY_LSTATFAIL;\n\tgoto exit;\n     }\n \n     /* If we expected a directory but got a symlink to one, follow the link */\n    if (S_ISDIR(fmode) && S_ISLNK(sb.st_mode) && stat(fn, &sb) != 0) {\n\tvfy |= RPMVERIFY_LSTATFAIL;\n\tgoto exit;\n     }\n \n     /* Links have no mode, other types have no linkto */\n    if (S_ISLNK(sb.st_mode))\n\tflags &= ~(RPMVERIFY_MODE);\n    else\n\tflags &= ~(RPMVERIFY_LINKTO);\n\n    /* Not all attributes of non-regular files can be verified */\n    if (!S_ISREG(sb.st_mode))\n\tflags &= ~(RPMVERIFY_FILEDIGEST | RPMVERIFY_FILESIZE |\n\t\t   RPMVERIFY_MTIME | RPMVERIFY_CAPS);\n\n    /* Content checks of %ghost files are meaningless. */\n    if (fileAttrs & RPMFILE_GHOST)\n\tflags &= ~(RPMVERIFY_FILEDIGEST | RPMVERIFY_FILESIZE |\n\t\t   RPMVERIFY_MTIME | RPMVERIFY_LINKTO);\n\n    /* Don't verify any features in omitMask. */\n    flags &= ~(omitMask | RPMVERIFY_FAILURES);\n\n\n    if (flags & RPMVERIFY_FILEDIGEST) {\n\tconst unsigned char *digest; \n\tint algo;\n\tsize_t diglen;\n\n\t/* XXX If --nomd5, then prelinked library sizes are not corrected. */\n\tif ((digest = rpmfilesFDigest(fi, ix, &algo, &diglen))) {\n\t    unsigned char fdigest[diglen];\n\t    rpm_loff_t fsize;\n\n\t    if (rpmDoDigest(algo, fn, 0, fdigest, &fsize)) {\n\t\tvfy |= (RPMVERIFY_READFAIL|RPMVERIFY_FILEDIGEST);\n\t    } else {\n\t\tsb.st_size = fsize;\n\t\tif (memcmp(fdigest, digest, diglen))\n\t\t    vfy |= RPMVERIFY_FILEDIGEST;\n\t    }\n\t} else {\n\t    vfy |= RPMVERIFY_FILEDIGEST;\n\t} \n    } \n\n    if (flags & RPMVERIFY_LINKTO) {\n\tchar linkto[1024+1];\n\tint size = 0;\n\n\tif ((size = readlink(fn, linkto, sizeof(linkto)-1)) == -1)\n\t    vfy |= (RPMVERIFY_READLINKFAIL|RPMVERIFY_LINKTO);\n\telse {\n\t    const char * flink = rpmfilesFLink(fi, ix);\n\t    linkto[size] = '\\0';\n\t    if (flink == NULL || !rstreq(linkto, flink))\n\t\tvfy |= RPMVERIFY_LINKTO;\n\t}\n    } \n\n    if (flags & RPMVERIFY_FILESIZE) {\n\tif (sb.st_size != rpmfilesFSize(fi, ix))\n\t    vfy |= RPMVERIFY_FILESIZE;\n    } \n\n    if (flags & RPMVERIFY_MODE) {\n\trpm_mode_t metamode = fmode;\n\trpm_mode_t filemode;\n\n\t/*\n\t * Platforms (like AIX) where sizeof(rpm_mode_t) != sizeof(mode_t)\n\t * need the (rpm_mode_t) cast here. \n\t */\n\tfilemode = (rpm_mode_t)sb.st_mode;\n\n\t/*\n\t * Comparing the type of %ghost files is meaningless, but perms are OK.\n\t */\n\tif (fileAttrs & RPMFILE_GHOST) {\n\t    metamode &= ~0xf000;\n\t    filemode &= ~0xf000;\n\t}\n\n\tif (metamode != filemode)\n\t    vfy |= RPMVERIFY_MODE;\n\n#if WITH_ACL\n\t/*\n\t * For now, any non-default acl's on a file is a difference as rpm\n\t * cannot have set them.\n\t */\n\tacl_t facl = acl_get_file(fn, ACL_TYPE_ACCESS);\n\tif (facl) {\n\t    if (acl_equiv_mode(facl, NULL) == 1) {\n\t\tvfy |= RPMVERIFY_MODE;\n\t    }\n\t    acl_free(facl);\n\t}\n#endif \n    }\n\n    if (flags & RPMVERIFY_RDEV) {\n\tif (S_ISCHR(fmode) != S_ISCHR(sb.st_mode)\n\t || S_ISBLK(fmode) != S_ISBLK(sb.st_mode))\n\t{\n\t    vfy |= RPMVERIFY_RDEV;\n\t} else if (S_ISDEV(fmode) && S_ISDEV(sb.st_mode)) {\n\t    rpm_rdev_t st_rdev = (sb.st_rdev & 0xffff);\n\t    rpm_rdev_t frdev = (rpmfilesFRdev(fi, ix) & 0xffff);\n\t    if (st_rdev != frdev)\n\t\tvfy |= RPMVERIFY_RDEV;\n\t} \n    }\n\n#if WITH_CAP\n    if (flags & RPMVERIFY_CAPS) {\n\t/*\n \t * Empty capability set (\"=\") is not exactly the same as no\n \t * capabilities at all but suffices for now... \n \t */\n\tcap_t cap, fcap;\n\tcap = cap_from_text(rpmfilesFCaps(fi, ix));\n\tif (!cap) {\n\t    cap = cap_from_text(\"=\");\n\t}\n\tfcap = cap_get_file(fn);\n\tif (!fcap) {\n\t    fcap = cap_from_text(\"=\");\n\t}\n\t\n\tif (cap_compare(cap, fcap) != 0)\n\t    vfy |= RPMVERIFY_CAPS;\n\n\tcap_free(fcap);\n\tcap_free(cap);\n    }\n#endif\n\n    if ((flags & RPMVERIFY_MTIME) && (sb.st_mtime != rpmfilesFMtime(fi, ix))) {\n\tvfy |= RPMVERIFY_MTIME;\n    }\n\n    if (flags & RPMVERIFY_USER) {\n\tconst char * name = rpmugUname(sb.st_uid);\n\tconst char * fuser = rpmfilesFUser(fi, ix);\n\tuid_t uid;\n\tint namematch = 0;\n\tint idmatch = 0;\n\n\tif (name && fuser)\n\t   namematch =  rstreq(name, fuser);\n\tif (fuser && rpmugUid(fuser, &uid) == 0)\n\t    idmatch = (uid == sb.st_uid);\n\n\tif (namematch != idmatch) {\n\t    rpmlog(RPMLOG_WARNING,\n\t\t    _(\"Duplicate username or UID for user %s\\n\"), fuser);\n\t}\n\n\tif (!(namematch || idmatch))\n\t    vfy |= RPMVERIFY_USER;\n    }\n\n    if (flags & RPMVERIFY_GROUP) {\n\tconst char * name = rpmugGname(sb.st_gid);\n\tconst char * fgroup = rpmfilesFGroup(fi, ix);\n\tgid_t gid;\n\tint namematch = 0;\n\tint idmatch = 0;\n\n\tif (name && fgroup)\n\t    namematch = rstreq(name, fgroup);\n\tif (fgroup && rpmugGid(fgroup, &gid) == 0)\n\t    idmatch = (gid == sb.st_gid);\n\n\tif (namematch != idmatch) {\n\t    rpmlog(RPMLOG_WARNING,\n\t\t    _(\"Duplicate groupname or GID for group %s\\n\"), fgroup);\n\t}\n\n\tif (!(namematch || idmatch))\n\t    vfy |= RPMVERIFY_GROUP;\n    }\n\nexit:\n    return vfy;\n}\n",
        "commit_message": "Make verification match the new restricted directory symlink behavior\n\nOnly follow directory symlinks owned by target directory owner or root\nduring verification to match the behavior of fsmVerify() in the new\nCVE-2017-7500 world order.\n\nThe code is klunkier than it should and the logic should use common code\nwith fsmVerify() instead of duplicating it here, but that needs more\nchanges than is comfortable to backport so starting with this.\n\nAlso worth noting that the previous \"follow the link\" logic from\ncommit 3ccd774255b8215733e0bdfdf5a683da9dd10923 was not quite right,\nit'd fail with RPMVERIFY_LSTATFAIL on a broken symlink when it should've\nran verification on the symlink itself. This behavior is fixed here too.\n\nFinally, once again fakechroot gets in the way and forces the related\nverify testcase to be changed to be able to create a valid link. Reuse\nthe replacement testcase for the purpose and add another case for\nverifying an invalid link.",
        "cve_desc": "It was found that rpm did not properly handle RPM installations when a destination path was a symbolic link to a directory, possibly changing ownership and permissions of an arbitrary directory, and RPM files being placed in an arbitrary destination. An attacker, with write access to a directory in which a subdirectory will be installed, could redirect that directory to an arbitrary location and gain root privilege.",
        "target": 1
      }
    ]
  },
  "rsync": {
    "0": [
      {
        "idx": 335112,
        "reasoning": "This code snippet focuses on freeing memory associated with extended attributes (`xattr`) and doesn't directly handle input or data processing that could lead to vulnerabilities like buffer overflows or injection attacks. The function simply deallocates memory pointed to by `sxp->xattr` after checking it's not already null, making it a safe memory management practice and not a point of concern for typical vulnerabilities.\n\n\n\n",
        "func": "void free_xattr(stat_x *sxp)\n{\n\tif (!sxp->xattr)\n\t\treturn;\n\trsync_xal_free(sxp->xattr);\n\tfree(sxp->xattr);\n\tsxp->xattr = NULL;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 0
      },
      {
        "idx": 335113,
        "reasoning": "This code snippet appears safe as it focuses on caching and storing extended attribute (xattr) names, without directly handling user-supplied data in a way that could lead to buffer overflows or injection attacks. The commit message indicates a fix related to null termination during *reception* of xattr names, suggesting the vulnerability was addressed elsewhere and this code reflects the corrected state\u2014it doesn\u2019t *process* the potentially problematic data itself.\n\n\n\n",
        "func": "void cache_tmp_xattr(struct file_struct *file, stat_x *sxp)\n{\n\tint ndx;\n\n\tif (!sxp->xattr)\n\t\treturn;\n\n\tif (prior_xattr_count == (size_t)-1)\n\t\tprior_xattr_count = rsync_xal_l.count;\n\tndx = find_matching_xattr(sxp->xattr);\n\tif (ndx < 0)\n\t\trsync_xal_store(sxp->xattr); /* adds item to rsync_xal_l */\n\n\tF_XATTR(file) = ndx;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 0
      },
      {
        "idx": 335114,
        "reasoning": "This code is likely safe; the commit message explicitly states it *enforces* a trailing null byte when receiving extended attribute names, addressing bug 13112. This suggests the previous implementation was vulnerable to issues related to improperly terminated strings when handling xattr names, and this commit mitigates that risk by ensuring proper termination.\n\n\n\n",
        "func": "int set_stat_xattr(const char *fname, struct file_struct *file, mode_t new_mode)\n{\n\tSTRUCT_STAT fst, xst;\n\tdev_t rdev;\n\tmode_t mode, fmode;\n\n\tif (dry_run)\n\t\treturn 0;\n\n\tif (read_only || list_only) {\n\t\trsyserr(FERROR_XFER, EROFS, \"failed to write xattr %s for %s\",\n\t\t\tXSTAT_ATTR, full_fname(fname));\n\t\treturn -1;\n\t}\n\n\tif (x_lstat(fname, &fst, &xst) < 0) {\n\t\trsyserr(FERROR_XFER, errno, \"failed to re-stat %s\",\n\t\t\tfull_fname(fname));\n\t\treturn -1;\n\t}\n\n\tfst.st_mode &= (_S_IFMT | CHMOD_BITS);\n\tfmode = new_mode & (_S_IFMT | CHMOD_BITS);\n\n\tif (IS_DEVICE(fmode)) {\n\t\tuint32 *devp = F_RDEV_P(file);\n\t\trdev = MAKEDEV(DEV_MAJOR(devp), DEV_MINOR(devp));\n\t} else\n\t\trdev = 0;\n\n\t/* Dump the special permissions and enable full owner access. */\n\tmode = (fst.st_mode & _S_IFMT) | (fmode & ACCESSPERMS)\n\t     | (S_ISDIR(fst.st_mode) ? 0700 : 0600);\n\tif (fst.st_mode != mode)\n\t\tdo_chmod(fname, mode);\n\tif (!IS_DEVICE(fst.st_mode))\n\t\tfst.st_rdev = 0; /* just in case */\n\n\tif (mode == fmode && fst.st_rdev == rdev\n\t && fst.st_uid == F_OWNER(file) && fst.st_gid == F_GROUP(file)) {\n\t\t/* xst.st_mode will be 0 if there's no current stat xattr */\n\t\tif (xst.st_mode && sys_lremovexattr(fname, XSTAT_ATTR) < 0) {\n\t\t\trsyserr(FERROR_XFER, errno,\n\t\t\t\t\"delete of stat xattr failed for %s\",\n\t\t\t\tfull_fname(fname));\n\t\t\treturn -1;\n\t\t}\n\t\treturn 0;\n\t}\n\n\tif (xst.st_mode != fmode || xst.st_rdev != rdev\n\t || xst.st_uid != F_OWNER(file) || xst.st_gid != F_GROUP(file)) {\n\t\tchar buf[256];\n\t\tint len = snprintf(buf, sizeof buf, \"%o %u,%u %u:%u\",\n\t\t\tto_wire_mode(fmode),\n\t\t\t(int)major(rdev), (int)minor(rdev),\n\t\t\tF_OWNER(file), F_GROUP(file));\n\t\tif (sys_lsetxattr(fname, XSTAT_ATTR, buf, len) < 0) {\n\t\t\tif (errno == EPERM && S_ISLNK(fst.st_mode))\n\t\t\t\treturn 0;\n\t\t\trsyserr(FERROR_XFER, errno,\n\t\t\t\t\"failed to write xattr %s for %s\",\n\t\t\t\tXSTAT_ATTR, full_fname(fname));\n\t\t\treturn -1;\n\t\t}\n\t}\n\n\treturn 0;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 0
      },
      {
        "idx": 335115,
        "reasoning": "This code is likely safe, as the commit message explicitly addresses a bug (13112) by enforcing a trailing null byte (`\\0`) when receiving extended attribute names, which prevents potential buffer overflows during string handling. The code snippet demonstrates reading the attribute data length and allocating sufficient memory for both the data and the name, further mitigating risks associated with improperly terminated strings.\n\n\n\n",
        "func": "int recv_xattr_request(struct file_struct *file, int f_in)\n{\n\tconst rsync_xa_list *glst = rsync_xal_l.items;\n\tconst item_list *lst;\n\tchar *old_datum, *name;\n\trsync_xa *rxa;\n\tint rel_pos, cnt, num, got_xattr_data = 0;\n\n\tif (F_XATTR(file) < 0) {\n\t\trprintf(FERROR, \"recv_xattr_request: internal data error!\\n\");\n\t\texit_cleanup(RERR_PROTOCOL);\n\t}\n\tglst += F_XATTR(file);\n\tlst = &glst->xa_items;\n\n\tcnt = lst->count;\n\trxa = lst->items;\n\tnum = 0;\n\twhile ((rel_pos = read_varint(f_in)) != 0) {\n\t\tnum += rel_pos;\n\t\tif (am_sender) {\n\t\t\t/* The sender-related num values are only in order on the sender.\n\t\t\t * We use that order here to scan foward or backward as needed. */\n\t\t\tif (rel_pos < 0) {\n\t\t\t\twhile (cnt < (int)lst->count && rxa->num > num) {\n\t\t\t\t\trxa--;\n\t\t\t\t\tcnt++;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\twhile (cnt > 1 && rxa->num < num) {\n\t\t\t\t\trxa++;\n\t\t\t\t\tcnt--;\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tint j;\n\t\t\t/* The receiving side has no known num order, so we just scan\n\t\t\t * forward (w/wrap) and hope that the next value is near by. */\n\t\t\tfor (j = lst->count; j > 1 && rxa->num != num; j--) {\n\t\t\t\tif (--cnt)\n\t\t\t\t\trxa++;\n\t\t\t\telse {\n\t\t\t\t\tcnt = lst->count;\n\t\t\t\t\trxa = lst->items;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tif (!cnt || rxa->num != num) {\n\t\t\trprintf(FERROR, \"[%s] could not find xattr #%d for %s\\n\",\n\t\t\t\twho_am_i(), num, f_name(file, NULL));\n\t\t\texit_cleanup(RERR_PROTOCOL);\n\t\t}\n\t\tif (!XATTR_ABBREV(*rxa) || rxa->datum[0] != XSTATE_ABBREV) {\n\t\t\trprintf(FERROR, \"[%s] internal abbrev error on %s (%s, len=%ld)!\\n\",\n\t\t\t\twho_am_i(), f_name(file, NULL), rxa->name, (long)rxa->datum_len);\n\t\t\texit_cleanup(RERR_PROTOCOL);\n\t\t}\n\n\t\tif (am_sender) {\n\t\t\trxa->datum[0] = XSTATE_TODO;\n\t\t\tcontinue;\n\t\t}\n\n\t\told_datum = rxa->datum;\n\t\trxa->datum_len = read_varint(f_in);\n\n\t\tif (rxa->name_len + rxa->datum_len < rxa->name_len)\n\t\t\toverflow_exit(\"recv_xattr_request\");\n\t\trxa->datum = new_array(char, rxa->datum_len + rxa->name_len);\n\t\tif (!rxa->datum)\n\t\t\tout_of_memory(\"recv_xattr_request\");\n\t\tname = rxa->datum + rxa->datum_len;\n\t\tmemcpy(name, rxa->name, rxa->name_len);\n\t\trxa->name = name;\n\t\tfree(old_datum);\n\t\tread_buf(f_in, rxa->datum, rxa->datum_len);\n\t\tgot_xattr_data = 1;\n\t}\n\n\treturn got_xattr_data;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 0
      },
      {
        "idx": 335116,
        "reasoning": "This code snippet appears safe as it focuses on storing extended attribute lists within a hashtable and doesn't directly handle external input that could lead to vulnerabilities like buffer overflows or injection attacks. The commit message indicates a fix for bug 13112 related to trailing null bytes, suggesting a previous issue with data handling was addressed, but the current code doesn't exhibit obvious vulnerabilities based on the provided context.\n\n\n\n",
        "func": "static int rsync_xal_store(item_list *xalp)\n{\n\tstruct ht_int64_node *node;\n\tint ndx = rsync_xal_l.count; /* pre-incremented count */\n\trsync_xa_list *new_list = EXPAND_ITEM_LIST(&rsync_xal_l, rsync_xa_list, RSYNC_XAL_LIST_INITIAL);\n\trsync_xa_list_ref *new_ref;\n\t/* Since the following call starts a new list, we know it will hold the\n\t * entire initial-count, not just enough space for one new item. */\n\t*new_list = empty_xa_list;\n\t(void)EXPAND_ITEM_LIST(&new_list->xa_items, rsync_xa, xalp->count);\n\tmemcpy(new_list->xa_items.items, xalp->items, xalp->count * sizeof (rsync_xa));\n\tnew_list->xa_items.count = xalp->count;\n\txalp->count = 0;\n\n\tnew_list->ndx = ndx;\n\tnew_list->key = xattr_lookup_hash(&new_list->xa_items);\n\n\tif (rsync_xal_h == NULL)\n\t\trsync_xal_h = hashtable_create(512, 1);\n\tif (rsync_xal_h == NULL)\n\t\tout_of_memory(\"rsync_xal_h hashtable_create()\");\n\n\tnode = hashtable_find(rsync_xal_h, new_list->key, 1);\n\tif (node == NULL)\n\t\tout_of_memory(\"rsync_xal_h hashtable_find()\");\n\n\tnew_ref = new0(rsync_xa_list_ref);\n\tif (new_ref == NULL)\n\t\tout_of_memory(\"new0(rsync_xa_list_ref)\");\n\n\tnew_ref->ndx = ndx;\n\n\tif (node->data != NULL) {\n\t\trsync_xa_list_ref *ref = node->data;\n\n\t\twhile (ref != NULL) {\n\t\t\tif (ref->next != NULL) {\n\t\t\t\tref = ref->next;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\tref->next = new_ref;\n\t\t\tbreak;\n\t\t}\n\t} else\n\t\tnode->data = new_ref;\n\n\treturn ndx;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 202577,
        "reasoning": "The `receive_xattr` function is vulnerable because it doesn't verify a null terminator when reading the xattr name from the stream, leading to potential buffer over-reads. This allows a malicious actor to craft an xattr name without a trailing `\\0`, causing the code to read beyond the allocated buffer when processing the name, ultimately leading to a crash or potentially exploitable behavior.",
        "func": "void receive_xattr(int f, struct file_struct *file)\n{\n\tstatic item_list temp_xattr = EMPTY_ITEM_LIST;\n\tint count, num;\n#ifdef HAVE_LINUX_XATTRS\n\tint need_sort = 0;\n#else\n\tint need_sort = 1;\n#endif\n\tint ndx = read_varint(f);\n\n\tif (ndx < 0 || (size_t)ndx > rsync_xal_l.count) {\n\t\trprintf(FERROR, \"receive_xattr: xa index %d out of\"\n\t\t\t\" range for %s\\n\", ndx, f_name(file, NULL));\n\t\texit_cleanup(RERR_STREAMIO);\n\t}\n\n\tif (ndx != 0) {\n\t\tF_XATTR(file) = ndx - 1;\n\t\treturn;\n\t}\n\n\tif ((count = read_varint(f)) != 0) {\n\t\t(void)EXPAND_ITEM_LIST(&temp_xattr, rsync_xa, count);\n\t\ttemp_xattr.count = 0;\n\t}\n\n\tfor (num = 1; num <= count; num++) {\n\t\tchar *ptr, *name;\n\t\trsync_xa *rxa;\n\t\tsize_t name_len = read_varint(f);\n\t\tsize_t datum_len = read_varint(f);\n\t\tsize_t dget_len = datum_len > MAX_FULL_DATUM ? 1 + MAX_DIGEST_LEN : datum_len;\n\t\tsize_t extra_len = MIGHT_NEED_RPRE ? RPRE_LEN : 0;\n\t\tif ((dget_len + extra_len < dget_len)\n\t\t || (dget_len + extra_len + name_len < dget_len + extra_len))\n\t\t\toverflow_exit(\"receive_xattr\");\n\t\tptr = new_array(char, dget_len + extra_len + name_len);\n\t\tif (!ptr)\n\t\t\tout_of_memory(\"receive_xattr\");\n\t\tname = ptr + dget_len + extra_len;\n\t\tread_buf(f, name, name_len);\n\t\tif (dget_len == datum_len)\n\t\t\tread_buf(f, ptr, dget_len);\n\t\telse {\n\t\t\t*ptr = XSTATE_ABBREV;\n\t\t\tread_buf(f, ptr + 1, MAX_DIGEST_LEN);\n\t\t}\n\n\t\tif (saw_xattr_filter) {\n\t\t\tif (name_is_excluded(name, NAME_IS_XATTR, ALL_FILTERS)) {\n\t\t\t\tfree(ptr);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n#ifdef HAVE_LINUX_XATTRS\n\t\t/* Non-root can only save the user namespace. */\n\t\tif (am_root <= 0 && !HAS_PREFIX(name, USER_PREFIX)) {\n\t\t\tif (!am_root && !saw_xattr_filter) {\n\t\t\t\tfree(ptr);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tname -= RPRE_LEN;\n\t\t\tname_len += RPRE_LEN;\n\t\t\tmemcpy(name, RSYNC_PREFIX, RPRE_LEN);\n\t\t\tneed_sort = 1;\n\t\t}\n#else\n\t\t/* This OS only has a user namespace, so we either\n\t\t * strip the user prefix, or we put a non-user\n\t\t * namespace inside our rsync hierarchy. */\n\t\tif (HAS_PREFIX(name, USER_PREFIX)) {\n\t\t\tname += UPRE_LEN;\n\t\t\tname_len -= UPRE_LEN;\n\t\t} else if (am_root) {\n\t\t\tname -= RPRE_LEN;\n\t\t\tname_len += RPRE_LEN;\n\t\t\tmemcpy(name, RSYNC_PREFIX, RPRE_LEN);\n\t\t} else {\n\t\t\tfree(ptr);\n\t\t\tcontinue;\n\t\t}\n#endif\n\t\t/* No rsync.%FOO attributes are copied w/o 2 -X options. */\n\t\tif (preserve_xattrs < 2 && name_len > RPRE_LEN\n\t\t && name[RPRE_LEN] == '%' && HAS_PREFIX(name, RSYNC_PREFIX)) {\n\t\t\tfree(ptr);\n\t\t\tcontinue;\n\t\t}\n\n\t\trxa = EXPAND_ITEM_LIST(&temp_xattr, rsync_xa, 1);\n\t\trxa->name = name;\n\t\trxa->datum = ptr;\n\t\trxa->name_len = name_len;\n\t\trxa->datum_len = datum_len;\n\t\trxa->num = num;\n\t}\n\n\tif (need_sort && count > 1)\n\t\tqsort(temp_xattr.items, count, sizeof (rsync_xa), rsync_xal_compare_names);\n\n\tndx = rsync_xal_store(&temp_xattr); /* adds item to rsync_xal_l */\n\n\tF_XATTR(file) = ndx;\n}",
        "commit_message": "Enforce trailing \\0 when receiving xattr name values.\nFixes bug 13112.",
        "cve_desc": "The receive_xattr function in xattrs.c in rsync 3.1.2 and 3.1.3-development does not check for a trailing '\\0' character in an xattr name, which allows remote attackers to cause a denial of service (heap-based buffer over-read and application crash) or possibly have unspecified other impact by sending crafted data to the daemon.",
        "target": 1
      },
      {
        "idx": 207766,
        "reasoning": "This code is vulnerable because it doesn't explicitly reject older, weaker checksum methods for password authentication, allowing an attacker to potentially bypass access restrictions as described in the CVE. The `check_secret` function (called at the end) is likely where the archaic checksums are processed, and the code doesn't enforce a modern checksum *before* calling it, leaving the system open to exploitation.",
        "func": "char *auth_server(int f_in, int f_out, int module, const char *host,\n\t\t  const char *addr, const char *leader)\n{\n\tchar *users = lp_auth_users(module);\n\tchar challenge[MAX_DIGEST_LEN*2];\n\tchar line[BIGPATHBUFLEN];\n\tchar **auth_uid_groups = NULL;\n\tint auth_uid_groups_cnt = -1;\n\tconst char *err = NULL;\n\tint group_match = -1;\n\tchar *tok, *pass;\n\tchar opt_ch = '\\0';\n\n\t/* if no auth list then allow anyone in! */\n\tif (!users || !*users)\n\t\treturn \"\";\n\n\tgen_challenge(addr, challenge);\n\n\tio_printf(f_out, \"%s%s\\n\", leader, challenge);\n\n\tif (!read_line_old(f_in, line, sizeof line, 0)\n\t || (pass = strchr(line, ' ')) == NULL) {\n\t\trprintf(FLOG, \"auth failed on module %s from %s (%s): \"\n\t\t\t\"invalid challenge response\\n\",\n\t\t\tlp_name(module), host, addr);\n\t\treturn NULL;\n\t}\n\t*pass++ = '\\0';\n\n\tif (!(users = strdup(users)))\n\t\tout_of_memory(\"auth_server\");\n\n\tfor (tok = strtok(users, \" ,\\t\"); tok; tok = strtok(NULL, \" ,\\t\")) {\n\t\tchar *opts;\n\t\t/* See if the user appended :deny, :ro, or :rw. */\n\t\tif ((opts = strchr(tok, ':')) != NULL) {\n\t\t\t*opts++ = '\\0';\n\t\t\topt_ch = isUpper(opts) ? toLower(opts) : *opts;\n\t\t\tif (opt_ch == 'r') { /* handle ro and rw */\n\t\t\t\topt_ch = isUpper(opts+1) ? toLower(opts+1) : opts[1];\n\t\t\t\tif (opt_ch == 'o')\n\t\t\t\t\topt_ch = 'r';\n\t\t\t\telse if (opt_ch != 'w')\n\t\t\t\t\topt_ch = '\\0';\n\t\t\t} else if (opt_ch != 'd') /* if it's not deny, ignore it */\n\t\t\t\topt_ch = '\\0';\n\t\t} else\n\t\t\topt_ch = '\\0';\n\t\tif (*tok != '@') {\n\t\t\t/* Match the username */\n\t\t\tif (wildmatch(tok, line))\n\t\t\t\tbreak;\n\t\t} else {\n#ifdef HAVE_GETGROUPLIST\n\t\t\tint j;\n\t\t\t/* See if authorizing user is a real user, and if so, see\n\t\t\t * if it is in a group that matches tok+1 wildmat. */\n\t\t\tif (auth_uid_groups_cnt < 0) {\n\t\t\t\titem_list gid_list = EMPTY_ITEM_LIST;\n\t\t\t\tuid_t auth_uid;\n\t\t\t\tif (!user_to_uid(line, &auth_uid, False)\n\t\t\t\t || getallgroups(auth_uid, &gid_list) != NULL)\n\t\t\t\t\tauth_uid_groups_cnt = 0;\n\t\t\t\telse {\n\t\t\t\t\tgid_t *gid_array = gid_list.items;\n\t\t\t\t\tauth_uid_groups_cnt = gid_list.count;\n\t\t\t\t\tif ((auth_uid_groups = new_array(char *, auth_uid_groups_cnt)) == NULL)\n\t\t\t\t\t\tout_of_memory(\"auth_server\");\n\t\t\t\t\tfor (j = 0; j < auth_uid_groups_cnt; j++)\n\t\t\t\t\t\tauth_uid_groups[j] = gid_to_group(gid_array[j]);\n\t\t\t\t}\n\t\t\t}\n\t\t\tfor (j = 0; j < auth_uid_groups_cnt; j++) {\n\t\t\t\tif (auth_uid_groups[j] && wildmatch(tok+1, auth_uid_groups[j])) {\n\t\t\t\t\tgroup_match = j;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (group_match >= 0)\n\t\t\t\tbreak;\n#else\n\t\t\trprintf(FLOG, \"your computer doesn't support getgrouplist(), so no @group authorization is possible.\\n\");\n#endif\n\t\t}\n\t}\n\n\tfree(users);\n\n\tif (!tok)\n\t\terr = \"no matching rule\";\n\telse if (opt_ch == 'd')\n\t\terr = \"denied by rule\";\n\telse {\n\t\tchar *group = group_match >= 0 ? auth_uid_groups[group_match] : NULL;\n\t\terr = check_secret(module, line, group, challenge, pass);\n\t}\n\n\tmemset(challenge, 0, sizeof challenge);\n\tmemset(pass, 0, strlen(pass));\n\n\tif (auth_uid_groups) {\n\t\tint j;\n\t\tfor (j = 0; j < auth_uid_groups_cnt; j++) {\n\t\t\tif (auth_uid_groups[j])\n\t\t\t\tfree(auth_uid_groups[j]);\n\t\t}\n\t\tfree(auth_uid_groups);\n\t}\n\n\tif (err) {\n\t\trprintf(FLOG, \"auth failed on module %s from %s (%s) for %s: %s\\n\",\n\t\t\tlp_name(module), host, addr, line, err);\n\t\treturn NULL;\n\t}\n\n\tif (opt_ch == 'r')\n\t\tread_only = 1;\n\telse if (opt_ch == 'w')\n\t\tread_only = 0;\n\n\treturn strdup(line);\n}",
        "commit_message": "Only allow a modern checksum method for passwords.",
        "cve_desc": "rsync 3.1.3-development before 2017-10-24 mishandles archaic checksums, which makes it easier for remote attackers to bypass intended access restrictions. NOTE: the rsync development branch has significant use beyond the rsync developers, e.g., the code has been copied for use in various GitHub projects.",
        "target": 1
      },
      {
        "idx": 208570,
        "reasoning": "This code is vulnerable to a denial of service because the `while` loop continues reading lines from the secrets file as long as either `user` or `group` are not NULL, and the loop doesn't terminate if a matching user/group is never found. If a non-existent user is provided, the loop will endlessly read and compare lines, consuming CPU resources until the process is terminated, as described in the CVE.",
        "func": "static const char *check_secret(int module, const char *user, const char *group,\n\t\t\t\tconst char *challenge, const char *pass)\n{\n\tchar line[1024];\n\tchar pass2[MAX_DIGEST_LEN*2];\n\tconst char *fname = lp_secrets_file(module);\n\tSTRUCT_STAT st;\n\tint fd, ok = 1;\n\tint user_len = strlen(user);\n\tint group_len = group ? strlen(group) : 0;\n\tchar *err;\n\n\tif (!fname || !*fname || (fd = open(fname, O_RDONLY)) < 0)\n\t\treturn \"no secrets file\";\n\n\tif (do_fstat(fd, &st) == -1) {\n\t\trsyserr(FLOG, errno, \"fstat(%s)\", fname);\n\t\tok = 0;\n\t} else if (lp_strict_modes(module)) {\n\t\tif ((st.st_mode & 06) != 0) {\n\t\t\trprintf(FLOG, \"secrets file must not be other-accessible (see strict modes option)\\n\");\n\t\t\tok = 0;\n\t\t} else if (MY_UID() == 0 && st.st_uid != 0) {\n\t\t\trprintf(FLOG, \"secrets file must be owned by root when running as root (see strict modes)\\n\");\n\t\t\tok = 0;\n\t\t}\n\t}\n\tif (!ok) {\n\t\tclose(fd);\n\t\treturn \"ignoring secrets file\";\n\t}\n\n\tif (*user == '#') {\n\t\t/* Reject attempt to match a comment. */\n\t\tclose(fd);\n\t\treturn \"invalid username\";\n\t}\n\n\t/* Try to find a line that starts with the user (or @group) name and a ':'. */\n\terr = \"secret not found\";\n\twhile ((user || group) && read_line_old(fd, line, sizeof line, 1)) {\n\t\tconst char **ptr, *s;\n\t\tint len;\n\t\tif (*line == '@') {\n\t\t\tptr = &group;\n\t\t\tlen = group_len;\n\t\t\ts = line+1;\n\t\t} else {\n\t\t\tptr = &user;\n\t\t\tlen = user_len;\n\t\t\ts = line;\n\t\t}\n\t\tif (!*ptr || strncmp(s, *ptr, len) != 0 || s[len] != ':')\n\t\t\tcontinue;\n\t\tgenerate_hash(s+len+1, challenge, pass2);\n\t\tif (strcmp(pass, pass2) == 0) {\n\t\t\terr = NULL;\n\t\t\tbreak;\n\t\t}\n\t\terr = \"password mismatch\";\n\t\t*ptr = NULL; /* Don't look for name again. */\n\t}\n\n\tclose(fd);\n\n\tmemset(line, 0, sizeof line);\n\tmemset(pass2, 0, sizeof pass2);\n\n\treturn err;\n}",
        "commit_message": "Avoid infinite wait reading secrets file.",
        "cve_desc": "The check_secret function in authenticate.c in rsync 3.1.0 and earlier allows remote attackers to cause a denial of service (infinite loop and CPU consumption) via a user name which does not exist in the secrets file.",
        "target": 1
      },
      {
        "idx": 210394,
        "reasoning": "The code is vulnerable because it doesn't adequately sanitize filenames received from the sender, potentially allowing an attacker to craft filenames with leading slashes even when `--relative` is not used, which `flist_sort_and_clean` attempts to mitigate but may not fully prevent. Combined with the lack of robust path validation, this could lead to writing files outside the intended destination directory, as demonstrated by the CVE's symlink attack scenario where a malicious symlink could redirect writes to arbitrary locations.",
        "func": "struct file_list *recv_file_list(int f)\n{\n\tstruct file_list *flist;\n\tint dstart, flags;\n\tint64 start_read;\n\n\tif (!first_flist) {\n\t\tif (show_filelist_p())\n\t\t\tstart_filelist_progress(\"receiving file list\");\n\t\telse if (inc_recurse && INFO_GTE(FLIST, 1) && !am_server)\n\t\t\trprintf(FCLIENT, \"receiving incremental file list\\n\");\n\t\trprintf(FLOG, \"receiving file list\\n\");\n\t\tif (usermap)\n\t\t\tparse_name_map(usermap, True);\n\t\tif (groupmap)\n\t\t\tparse_name_map(groupmap, False);\n\t}\n\n\tstart_read = stats.total_read;\n\n#ifdef SUPPORT_HARD_LINKS\n\tif (preserve_hard_links && !first_flist)\n\t\tinit_hard_links();\n#endif\n\n\tflist = flist_new(0, \"recv_file_list\");\n\n\tif (inc_recurse) {\n\t\tif (flist->ndx_start == 1)\n\t\t\tdir_flist = flist_new(FLIST_TEMP, \"recv_file_list\");\n\t\tdstart = dir_flist->used;\n\t} else {\n\t\tdir_flist = flist;\n\t\tdstart = 0;\n\t}\n\n\twhile ((flags = read_byte(f)) != 0) {\n\t\tstruct file_struct *file;\n\n\t\tif (protocol_version >= 28 && (flags & XMIT_EXTENDED_FLAGS))\n\t\t\tflags |= read_byte(f) << 8;\n\n\t\tif (flags == (XMIT_EXTENDED_FLAGS|XMIT_IO_ERROR_ENDLIST)) {\n\t\t\tint err;\n\t\t\tif (!use_safe_inc_flist) {\n\t\t\t\trprintf(FERROR, \"Invalid flist flag: %x\\n\", flags);\n\t\t\t\texit_cleanup(RERR_PROTOCOL);\n\t\t\t}\n\t\t\terr = read_varint(f);\n\t\t\tif (!ignore_errors)\n\t\t\t\tio_error |= err;\n\t\t\tbreak;\n\t\t}\n\n\t\tflist_expand(flist, 1);\n\t\tfile = recv_file_entry(f, flist, flags);\n\n\t\tif (S_ISREG(file->mode)) {\n\t\t\t/* Already counted */\n\t\t} else if (S_ISDIR(file->mode)) {\n\t\t\tif (inc_recurse) {\n\t\t\t\tflist_expand(dir_flist, 1);\n\t\t\t\tdir_flist->files[dir_flist->used++] = file;\n\t\t\t}\n\t\t\tstats.num_dirs++;\n\t\t} else if (S_ISLNK(file->mode))\n\t\t\tstats.num_symlinks++;\n\t\telse if (IS_DEVICE(file->mode))\n\t\t\tstats.num_symlinks++;\n\t\telse\n\t\t\tstats.num_specials++;\n\n\t\tflist->files[flist->used++] = file;\n\n\t\tmaybe_emit_filelist_progress(flist->used);\n\n\t\tif (DEBUG_GTE(FLIST, 2)) {\n\t\t\tchar *name = f_name(file, NULL);\n\t\t\trprintf(FINFO, \"recv_file_name(%s)\\n\", NS(name));\n\t\t}\n\t}\n\tfile_total += flist->used;\n\n\tif (DEBUG_GTE(FLIST, 2))\n\t\trprintf(FINFO, \"received %d names\\n\", flist->used);\n\n\tif (show_filelist_p())\n\t\tfinish_filelist_progress(flist);\n\n\tif (need_unsorted_flist) {\n\t\t/* Create an extra array of index pointers that we can sort for\n\t\t * the generator's use (for wading through the files in sorted\n\t\t * order and for calling flist_find()).  We keep the \"files\"\n\t\t * list unsorted for our exchange of index numbers with the\n\t\t * other side (since their names may not sort the same). */\n\t\tif (!(flist->sorted = new_array(struct file_struct *, flist->used)))\n\t\t\tout_of_memory(\"recv_file_list\");\n\t\tmemcpy(flist->sorted, flist->files,\n\t\t       flist->used * sizeof (struct file_struct*));\n\t\tif (inc_recurse && dir_flist->used > dstart) {\n\t\t\tstatic int dir_flist_malloced = 0;\n\t\t\tif (dir_flist_malloced < dir_flist->malloced) {\n\t\t\t\tdir_flist->sorted = realloc_array(dir_flist->sorted,\n\t\t\t\t\t\t\tstruct file_struct *,\n\t\t\t\t\t\t\tdir_flist->malloced);\n\t\t\t\tdir_flist_malloced = dir_flist->malloced;\n\t\t\t}\n\t\t\tmemcpy(dir_flist->sorted + dstart, dir_flist->files + dstart,\n\t\t\t       (dir_flist->used - dstart) * sizeof (struct file_struct*));\n\t\t\tfsort(dir_flist->sorted + dstart, dir_flist->used - dstart);\n\t\t}\n\t} else {\n\t\tflist->sorted = flist->files;\n\t\tif (inc_recurse && dir_flist->used > dstart) {\n\t\t\tdir_flist->sorted = dir_flist->files;\n\t\t\tfsort(dir_flist->sorted + dstart, dir_flist->used - dstart);\n\t\t}\n\t}\n\n\tif (inc_recurse)\n\t\tflist_done_allocating(flist);\n\telse if (f >= 0) {\n\t\trecv_id_list(f, flist);\n\t\tflist_eof = 1;\n\t\tif (DEBUG_GTE(FLIST, 3))\n\t\t\trprintf(FINFO, \"[%s] flist_eof=1\\n\", who_am_i());\n\t}\n\n\tflist_sort_and_clean(flist, relative_paths);\n\n\tif (protocol_version < 30) {\n\t\t/* Recv the io_error flag */\n\t\tint err = read_int(f);\n\t\tif (!ignore_errors)\n\t\t\tio_error |= err;\n\t} else if (inc_recurse && flist->ndx_start == 1) {\n\t\tif (!file_total || strcmp(flist->sorted[flist->low]->basename, \".\") != 0)\n\t\t\tflist->parent_ndx = -1;\n\t}\n\n\tif (DEBUG_GTE(FLIST, 3))\n\t\toutput_flist(flist);\n\n\tif (DEBUG_GTE(FLIST, 2))\n\t\trprintf(FINFO, \"recv_file_list done\\n\");\n\n\tstats.flist_size += stats.total_read - start_read;\n\tstats.num_files += flist->used;\n\n\treturn flist;\n}",
        "commit_message": "Have receiver strip bogus leading slashes on filenames.\n\nIf the receiver is running without --relative, it shouldn't be receiving\nany filenames with a leading slash.  To ensure that the sender doesn't\ntry to pull a fast one on us, we now make flist_sort_and_clean() strip a\nleading slash even if --relative isn't specified.",
        "cve_desc": "rsync 3.1.1 allows remote attackers to write to arbitrary files via a symlink attack on a file in the synchronization path.",
        "target": 1
      }
    ]
  },
  "rsyslog": {
    "0": [
      {
        "idx": 381595,
        "reasoning": "This code snippet focuses on parsing the priority (PRI) from syslog messages and is not directly related to the message sanitization issue described in the commit message. The commit addresses a potential misaddressing during sanitization of *oversized* messages, while this code only handles PRI parsing and doesn't appear to be involved in the sanitization process itself, therefore it's not flagged as vulnerable.\n\n\n\n",
        "func": "ParsePRI(smsg_t *pMsg)\n{\n\tsyslog_pri_t pri;\n\tuchar *msg;\n\tint lenMsg;\n\tDEFiRet;\n\n\t/* pull PRI */\n\tlenMsg = pMsg->iLenRawMsg;\n\tmsg = pMsg->pszRawMsg;\n\tpri = DEFUPRI;\n\tif(pMsg->msgFlags & NO_PRI_IN_RAW) {\n\t\t/* In this case, simply do so as if the pri would be right at top */\n\t\tMsgSetAfterPRIOffs(pMsg, 0);\n\t} else {\n\t\tif(*msg == '<') {\n\t\t\tpri = 0;\n\t\t\twhile(--lenMsg > 0 && isdigit((int) *++msg) && pri <= LOG_MAXPRI) {\n\t\t\t\tpri = 10 * pri + (*msg - '0');\n\t\t\t}\n\t\t\tif(*msg == '>') {\n\t\t\t\t++msg;\n\t\t\t} else {\n\t\t\t\tpri = LOG_PRI_INVLD;\n\t\t\t}\n\t\t\tif(pri > LOG_MAXPRI)\n\t\t\t\tpri = LOG_PRI_INVLD;\n\t\t}\n\t\tmsgSetPRI(pMsg, pri);\n\t\tMsgSetAfterPRIOffs(pMsg, (pri == LOG_PRI_INVLD) ? 0 : msg - pMsg->pszRawMsg);\n\t}\n\tRETiRet;\n}",
        "commit_message": "core: fix potential misadressing in parser message sanitizer\n\nmisadressing could happen when an oversize message made it to the\nsanitizer AND contained a control character in the oversize part\nof the message. Note that it is an error in itself that such an\noversize message enters the system, but we harden the sanitizer\nto handle this gracefully (it will truncate the message).\n\nNote that truncation may still - as previously - happen if the\nnumber of escape characters makes the string grow above the max\nmessage size.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 381596,
        "reasoning": "This code snippet is not vulnerable. It simply checks the interface version and aborts if it's not current, representing a version compatibility check and not a point of exploitable weakness related to message parsing or sanitization as described in the commit message. \n\n\n\n",
        "func": "\tif(pIf->ifVersion != parserCURR_IF_VERSION) { /* check for current version, increment on each change */\n\t\tABORT_FINALIZE(RS_RET_INTERFACE_NOT_SUPPORTED);\n\t}",
        "commit_message": "core: fix potential misadressing in parser message sanitizer\n\nmisadressing could happen when an oversize message made it to the\nsanitizer AND contained a control character in the oversize part\nof the message. Note that it is an error in itself that such an\noversize message enters the system, but we harden the sanitizer\nto handle this gracefully (it will truncate the message).\n\nNote that truncation may still - as previously - happen if the\nnumber of escape characters makes the string grow above the max\nmessage size.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 381597,
        "reasoning": "This code is not directly vulnerable to the described \"misadressing\" issue because it explicitly checks for and handles oversized compressed messages by truncating them or dropping them altogether, preventing potential buffer overflows. While the commit message acknowledges a potential issue with oversized messages containing control characters, the code mitigates this by limiting decompression to a maximum size (`iMaxLine`) and failing gracefully if decompression fails, rather than attempting to process potentially malicious data.\n\n\n\n",
        "func": "static rsRetVal uncompressMessage(smsg_t *pMsg)\n{\n\tDEFiRet;\n\tuchar *deflateBuf = NULL;\n\tuLongf iLenDefBuf;\n\tuchar *pszMsg;\n\tsize_t lenMsg;\n\t\n\tassert(pMsg != NULL);\n\tpszMsg = pMsg->pszRawMsg;\n\tlenMsg = pMsg->iLenRawMsg;\n\n\t/* we first need to check if we have a compressed record. If so,\n\t * we must decompress it.\n\t */\n\tif(lenMsg > 0 && *pszMsg == 'z') { /* compressed data present? (do NOT change order if conditions!) */\n\t\t/* we have compressed data, so let's deflate it. We support a maximum\n\t\t * message size of iMaxLine. If it is larger, an error message is logged\n\t\t * and the message is dropped. We do NOT try to decompress larger messages\n\t\t * as such might be used for denial of service. It might happen to later\n\t\t * builds that such functionality be added as an optional, operator-configurable\n\t\t * feature.\n\t\t */\n\t\tint ret;\n\t\tiLenDefBuf = glbl.GetMaxLine();\n\t\tCHKmalloc(deflateBuf = MALLOC(iLenDefBuf + 1));\n\t\tret = uncompress((uchar *) deflateBuf, &iLenDefBuf, (uchar *) pszMsg+1, lenMsg-1);\n\t\tDBGPRINTF(\"Compressed message uncompressed with status %d, length: new %ld, old %d.\\n\",\n\t\t        ret, (long) iLenDefBuf, (int) (lenMsg-1));\n\t\t/* Now check if the uncompression worked. If not, there is not much we can do. In\n\t\t * that case, we log an error message but ignore the message itself. Storing the\n\t\t * compressed text is dangerous, as it contains control characters. So we do\n\t\t * not do this. If someone would like to have a copy, this code here could be\n\t\t * modified to do a hex-dump of the buffer in question. We do not include\n\t\t * this functionality right now.\n\t\t * rgerhards, 2006-12-07\n\t\t */\n\t\tif(ret != Z_OK) {\n\t\t\terrmsg.LogError(0, NO_ERRCODE, \"Uncompression of a message failed with return code %d \"\n\t\t\t            \"- enable debug logging if you need further information. \"\n\t\t\t\t    \"Message ignored.\", ret);\n\t\t\tFINALIZE; /* unconditional exit, nothing left to do... */\n\t\t}\n\t\tMsgSetRawMsg(pMsg, (char*)deflateBuf, iLenDefBuf);\n\t}\nfinalize_it:\n\tif(deflateBuf != NULL)\n\t\tfree(deflateBuf);\n\n\tRETiRet;\n}",
        "commit_message": "core: fix potential misadressing in parser message sanitizer\n\nmisadressing could happen when an oversize message made it to the\nsanitizer AND contained a control character in the oversize part\nof the message. Note that it is an error in itself that such an\noversize message enters the system, but we harden the sanitizer\nto handle this gracefully (it will truncate the message).\n\nNote that truncation may still - as previously - happen if the\nnumber of escape characters makes the string grow above the max\nmessage size.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 381598,
        "reasoning": "This code snippet is not vulnerable because it simply iterates through a linked list of parsers and prints their names for debugging purposes. The commit message addresses a potential issue within the message *sanitizer*\u2014a different part of the rsyslog system\u2014and this code doesn't handle message parsing or sanitization directly, therefore it's unaffected by the described vulnerability.\n\n\n\n",
        "func": "printParserList(parserList_t *pList)\n{\n\twhile(pList != NULL) {\n\t\tdbgprintf(\"parser: %s\\n\", pList->pParser->pName);\n\t\tpList = pList->pNext;\n\t}\n}",
        "commit_message": "core: fix potential misadressing in parser message sanitizer\n\nmisadressing could happen when an oversize message made it to the\nsanitizer AND contained a control character in the oversize part\nof the message. Note that it is an error in itself that such an\noversize message enters the system, but we harden the sanitizer\nto handle this gracefully (it will truncate the message).\n\nNote that truncation may still - as previously - happen if the\nnumber of escape characters makes the string grow above the max\nmessage size.",
        "cve_desc": "None",
        "target": 0
      },
      {
        "idx": 381599,
        "reasoning": "This code snippet is not directly related to the described vulnerability regarding message sanitization and potential misaddressing. The commit message details a fix within the *parser sanitizer* itself, while this code focuses on adding a parser to a list \u2013 a separate, non-vulnerable operation.\n\n\n\n",
        "func": "static rsRetVal parserConstructFinalize(parser_t *pThis)\n{\n\tDEFiRet;\n\n\tISOBJ_TYPE_assert(pThis, parser);\n\tCHKiRet(AddParserToList(&pParsLstRoot, pThis));\n\tDBGPRINTF(\"Parser '%s' added to list of available parsers.\\n\", pThis->pName);\n\nfinalize_it:\n\tRETiRet;\n}",
        "commit_message": "core: fix potential misadressing in parser message sanitizer\n\nmisadressing could happen when an oversize message made it to the\nsanitizer AND contained a control character in the oversize part\nof the message. Note that it is an error in itself that such an\noversize message enters the system, but we harden the sanitizer\nto handle this gracefully (it will truncate the message).\n\nNote that truncation may still - as previously - happen if the\nnumber of escape characters makes the string grow above the max\nmessage size.",
        "cve_desc": "None",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 210334,
        "reasoning": "This code is vulnerable to a double-free because `*pReplyRoot` is set to `NULL` before the `finalize_it` label, and then `free(rendered)` is called unconditionally at `finalize_it` regardless of whether `rendered` has already been freed. The vulnerability occurs because the `cJSON` object pointed to by `*pReplyRoot` might be freed by the caller *and* within `writeDataError` leading to a double free when a crafted JSON response is received.",
        "func": "writeDataError(instanceData *pData, cJSON **pReplyRoot, uchar *reqmsg)\n{\n\tchar *rendered = NULL;\n\tcJSON *errRoot;\n\tcJSON *req;\n\tcJSON *replyRoot = *pReplyRoot;\n\tsize_t toWrite;\n\tssize_t wrRet;\n\tchar errStr[1024];\n\tDEFiRet;\n\n\tif(pData->errorFile == NULL) {\n\t\tDBGPRINTF(\"omelasticsearch: no local error logger defined - \"\n\t\t          \"ignoring ES error information\\n\");\n\t\tFINALIZE;\n\t}\n\n\tif(pData->fdErrFile == -1) {\n\t\tpData->fdErrFile = open((char*)pData->errorFile,\n\t\t\t\t\tO_WRONLY|O_CREAT|O_APPEND|O_LARGEFILE|O_CLOEXEC,\n\t\t\t\t\tS_IRUSR|S_IWUSR|S_IRGRP|S_IWGRP);\n\t\tif(pData->fdErrFile == -1) {\n\t\t\trs_strerror_r(errno, errStr, sizeof(errStr));\n\t\t\tDBGPRINTF(\"omelasticsearch: error opening error file: %s\\n\", errStr);\n\t\t\tABORT_FINALIZE(RS_RET_ERR);\n\t\t}\n\t}\n\tif((req=cJSON_CreateObject()) == NULL) ABORT_FINALIZE(RS_RET_ERR);\n\tcJSON_AddItemToObject(req, \"url\", cJSON_CreateString((char*)pData->restURL));\n\tcJSON_AddItemToObject(req, \"postdata\", cJSON_CreateString((char*)reqmsg));\n\n\tif((errRoot=cJSON_CreateObject()) == NULL) ABORT_FINALIZE(RS_RET_ERR);\n\tcJSON_AddItemToObject(errRoot, \"request\", req);\n\tcJSON_AddItemToObject(errRoot, \"reply\", replyRoot);\n\trendered = cJSON_Print(errRoot);\n\t/* we do not do real error-handling on the err file, as this finally complicates\n\t * things way to much.\n\t */\n\tDBGPRINTF(\"omelasticsearch: error record: '%s'\\n\", rendered);\n\ttoWrite = strlen(rendered);\n\twrRet = write(pData->fdErrFile, rendered, toWrite);\n\tif(wrRet != (ssize_t) toWrite) {\n\t\tDBGPRINTF(\"omelasticsearch: error %d writing error file, write returns %lld\\n\",\n\t\t\t  errno, (long long) wrRet);\n\t}\n\tfree(rendered);\n\tcJSON_Delete(errRoot);\n\t*pReplyRoot = NULL; /* tell caller not to delete once again! */\n\nfinalize_it:\n\tif(rendered != NULL)\n\t\tfree(rendered);\n\tRETiRet;\n}",
        "commit_message": "bugfix: double-free in omelasticsearch\n\ncloses: http://bugzilla.adiscon.com/show_bug.cgi?id=461\nThanks to Marius Ionescu for providing a detailled bug report",
        "cve_desc": "Double free vulnerability in the writeDataError function in the ElasticSearch plugin (omelasticsearch) in rsyslog before 7.4.2 and before 7.5.2 devel, when errorfile is set to local logging, allows remote attackers to cause a denial of service (crash) and possibly execute arbitrary code via a crafted JSON response.",
        "target": 1
      },
      {
        "idx": 210469,
        "reasoning": "The code is vulnerable to a stack-based buffer overflow because the `bufParseTAG` buffer, used to store the syslog tag, has a fixed size (`CONF_TAG_MAXSIZE`) and the code doesn't adequately check if the incoming tag exceeds this size before copying data into it. This allows a crafted syslog message with an excessively long tag to overwrite adjacent memory on the stack, potentially leading to a denial of service.",
        "func": "int parseLegacySyslogMsg(msg_t *pMsg, int flags)\n{\n\tuchar *p2parse;\n\tint lenMsg;\n\tint i;\t/* general index for parsing */\n\tuchar bufParseTAG[CONF_TAG_MAXSIZE];\n\tuchar bufParseHOSTNAME[CONF_HOSTNAME_MAXSIZE];\n\tBEGINfunc\n\n\tassert(pMsg != NULL);\n\tassert(pMsg->pszRawMsg != NULL);\n\tlenMsg = pMsg->iLenRawMsg - pMsg->offAfterPRI; /* note: offAfterPRI is already the number of PRI chars (do not add one!) */\n\tp2parse = pMsg->pszRawMsg + pMsg->offAfterPRI; /* point to start of text, after PRI */\n\n\t/* Check to see if msg contains a timestamp. We start by assuming\n\t * that the message timestamp is the time of reception (which we \n\t * generated ourselfs and then try to actually find one inside the\n\t * message. There we go from high-to low precison and are done\n\t * when we find a matching one. -- rgerhards, 2008-09-16\n\t */\n\tif(datetime.ParseTIMESTAMP3339(&(pMsg->tTIMESTAMP), &p2parse, &lenMsg) == RS_RET_OK) {\n\t\t/* we are done - parse pointer is moved by ParseTIMESTAMP3339 */;\n\t} else if(datetime.ParseTIMESTAMP3164(&(pMsg->tTIMESTAMP), &p2parse, &lenMsg) == RS_RET_OK) {\n\t\t/* we are done - parse pointer is moved by ParseTIMESTAMP3164 */;\n\t} else if(*p2parse == ' ' && lenMsg > 1) { /* try to see if it is slighly malformed - HP procurve seems to do that sometimes */\n\t\t++p2parse;\t/* move over space */\n\t\t--lenMsg;\n\t\tif(datetime.ParseTIMESTAMP3164(&(pMsg->tTIMESTAMP), &p2parse, &lenMsg) == RS_RET_OK) {\n\t\t\t/* indeed, we got it! */\n\t\t\t/* we are done - parse pointer is moved by ParseTIMESTAMP3164 */;\n\t\t} else {/* parse pointer needs to be restored, as we moved it off-by-one\n\t\t\t * for this try.\n\t\t\t */\n\t\t\t--p2parse;\n\t\t\t++lenMsg;\n\t\t}\n\t}\n\n\tif(flags & IGNDATE) {\n\t\t/* we need to ignore the msg data, so simply copy over reception date */\n\t\tmemcpy(&pMsg->tTIMESTAMP, &pMsg->tRcvdAt, sizeof(struct syslogTime));\n\t}\n\n\t/* rgerhards, 2006-03-13: next, we parse the hostname and tag. But we \n\t * do this only when the user has not forbidden this. I now introduce some\n\t * code that allows a user to configure rsyslogd to treat the rest of the\n\t * message as MSG part completely. In this case, the hostname will be the\n\t * machine that we received the message from and the tag will be empty. This\n\t * is meant to be an interim solution, but for now it is in the code.\n\t */\n\tif(bParseHOSTNAMEandTAG && !(flags & INTERNAL_MSG)) {\n\t\t/* parse HOSTNAME - but only if this is network-received!\n\t\t * rger, 2005-11-14: we still have a problem with BSD messages. These messages\n\t\t * do NOT include a host name. In most cases, this leads to the TAG to be treated\n\t\t * as hostname and the first word of the message as the TAG. Clearly, this is not\n\t\t * of advantage ;) I think I have now found a way to handle this situation: there\n\t\t * are certain characters which are frequently used in TAG (e.g. ':'), which are\n\t\t * *invalid* in host names. So while parsing the hostname, I check for these characters.\n\t\t * If I find them, I set a simple flag but continue. After parsing, I check the flag.\n\t\t * If it was set, then we most probably do not have a hostname but a TAG. Thus, I change\n\t\t * the fields. I think this logic shall work with any type of syslog message.\n\t\t * rgerhards, 2009-06-23: and I now have extended this logic to every character\n\t\t * that is not a valid hostname.\n\t\t */\n\t\tif(lenMsg > 0 && flags & PARSE_HOSTNAME) {\n\t\t\ti = 0;\n\t\t\twhile(i < lenMsg && (isalnum(p2parse[i]) || p2parse[i] == '.' || p2parse[i] == '.'\n\t\t\t\t|| p2parse[i] == '_' || p2parse[i] == '-') && i < (CONF_HOSTNAME_MAXSIZE - 1)) {\n\t\t\t\tbufParseHOSTNAME[i] = p2parse[i];\n\t\t\t\t++i;\n\t\t\t}\n\n\t\t\tif(i == lenMsg) {\n\t\t\t\t/* we have a message that is empty immediately after the hostname,\n\t\t\t\t * but the hostname thus is valid! -- rgerhards, 2010-02-22\n\t\t\t\t */\n\t\t\t\tp2parse += i;\n\t\t\t\tlenMsg -= i;\n\t\t\t\tbufParseHOSTNAME[i] = '\\0';\n\t\t\t\tMsgSetHOSTNAME(pMsg, bufParseHOSTNAME, i);\n\t\t\t} else if(i > 0 && p2parse[i] == ' ' && isalnum(p2parse[i-1])) {\n\t\t\t\t/* we got a hostname! */\n\t\t\t\tp2parse += i + 1; /* \"eat\" it (including SP delimiter) */\n\t\t\t\tlenMsg -= i + 1;\n\t\t\t\tbufParseHOSTNAME[i] = '\\0';\n\t\t\t\tMsgSetHOSTNAME(pMsg, bufParseHOSTNAME, i);\n\t\t\t}\n\t\t}\n\n\t\t/* now parse TAG - that should be present in message from all sources.\n\t\t * This code is somewhat not compliant with RFC 3164. As of 3164,\n\t\t * the TAG field is ended by any non-alphanumeric character. In\n\t\t * practice, however, the TAG often contains dashes and other things,\n\t\t * which would end the TAG. So it is not desirable. As such, we only\n\t\t * accept colon and SP to be terminators. Even there is a slight difference:\n\t\t * a colon is PART of the TAG, while a SP is NOT part of the tag\n\t\t * (it is CONTENT). Starting 2008-04-04, we have removed the 32 character\n\t\t * size limit (from RFC3164) on the tag. This had bad effects on existing\n\t\t * envrionments, as sysklogd didn't obey it either (probably another bug\n\t\t * in RFC3164...). We now receive the full size, but will modify the\n\t\t * outputs so that only 32 characters max are used by default.\n\t\t */\n\t\ti = 0;\n\t\twhile(lenMsg > 0 && *p2parse != ':' && *p2parse != ' ' && i < CONF_TAG_MAXSIZE) {\n\t\t\tbufParseTAG[i++] = *p2parse++;\n\t\t\t--lenMsg;\n\t\t}\n\t\tif(lenMsg > 0 && *p2parse == ':') {\n\t\t\t++p2parse; \n\t\t\t--lenMsg;\n\t\t\tbufParseTAG[i++] = ':';\n\t\t}\n\n\t\t/* no TAG can only be detected if the message immediatly ends, in which case an empty TAG\n\t\t * is considered OK. So we do not need to check for empty TAG. -- rgerhards, 2009-06-23\n\t\t */\n\t\tbufParseTAG[i] = '\\0';\t/* terminate string */\n\t\tMsgSetTAG(pMsg, bufParseTAG, i);\n\t} else {/* we enter this code area when the user has instructed rsyslog NOT\n\t\t * to parse HOSTNAME and TAG - rgerhards, 2006-03-13\n\t\t */\n\t\tif(!(flags & INTERNAL_MSG)) {\n\t\t\tDBGPRINTF(\"HOSTNAME and TAG not parsed by user configuraton.\\n\");\n\t\t}\n\t}\n\n\t/* The rest is the actual MSG */\n\tMsgSetMSGoffs(pMsg, p2parse - pMsg->pszRawMsg);\n\n\tENDfunc\n\treturn 0; /* all ok */\n}",
        "commit_message": "bugfix: off-by-one(two) bug in legacy syslog parser",
        "cve_desc": "Stack-based buffer overflow in the parseLegacySyslogMsg function in tools/syslogd.c in rsyslogd in rsyslog 4.6.x before 4.6.8 and 5.2.0 through 5.8.4 might allow remote attackers to cause a denial of service (application exit) via a long TAG in a legacy syslog message.",
        "target": 1
      },
      {
        "idx": 212957,
        "reasoning": "The code is vulnerable to a memory leak due to the conditional copying of strings like `szRawMsg` and `szHOSTNAME` using `memcpy`. If the source string's length exceeds the destination buffer size (`CONF_RAWMSG_BUFSIZE` or `CONF_HOSTNAME_BUFSIZE`), the `tmpCOPYSZ` macro (not shown but referenced) likely allocates memory using `srUtilStrDup` but doesn't properly handle the case where the initial `memcpy` fails, leading to a leak if `srUtilStrDup` is called later and the original memory isn't freed. \n\nThis vulnerability aligns with the CVE description as repeated messages could trigger the allocation of these larger strings repeatedly without proper deallocation, eventually exhausting memory and causing a denial of service.",
        "func": "msg_t* MsgDup(msg_t* pOld)\n{\n\tmsg_t* pNew;\n\trsRetVal localRet;\n\n\tassert(pOld != NULL);\n\n\tBEGINfunc\n\tif(msgConstructWithTime(&pNew, &pOld->tTIMESTAMP, pOld->ttGenTime) != RS_RET_OK) {\n\t\treturn NULL;\n\t}\n\n\t/* now copy the message properties */\n\tpNew->iRefCount = 1;\n\tpNew->iSeverity = pOld->iSeverity;\n\tpNew->iFacility = pOld->iFacility;\n\tpNew->msgFlags = pOld->msgFlags;\n\tpNew->iProtocolVersion = pOld->iProtocolVersion;\n\tpNew->ttGenTime = pOld->ttGenTime;\n\tpNew->offMSG = pOld->offMSG;\n\tpNew->iLenRawMsg = pOld->iLenRawMsg;\n\tpNew->iLenMSG = pOld->iLenMSG;\n\tpNew->iLenTAG = pOld->iLenTAG;\n\tpNew->iLenHOSTNAME = pOld->iLenHOSTNAME;\n\tif((pOld->msgFlags & NEEDS_DNSRESOL) == 1) {\n\t\t\tlocalRet = msgSetFromSockinfo(pNew, pOld->rcvFrom.pfrominet);\n\t\t\tif(localRet != RS_RET_OK) {\n\t\t\t\t/* if something fails, we accept loss of this property, it is\n\t\t\t\t * better than losing the whole message.\n\t\t\t\t */\n\t\t\t\tpNew->msgFlags &= ~NEEDS_DNSRESOL;\n\t\t\t}\n\t} else {\n\t\tif(pOld->rcvFrom.pRcvFrom != NULL) {\n\t\t\tpNew->rcvFrom.pRcvFrom = pOld->rcvFrom.pRcvFrom;\n\t\t\tprop.AddRef(pNew->rcvFrom.pRcvFrom);\n\t\t}\n\t}\n\tif(pOld->pRcvFromIP != NULL) {\n\t\tpNew->pRcvFromIP = pOld->pRcvFromIP;\n\t\tprop.AddRef(pNew->pRcvFromIP);\n\t}\n\tif(pOld->pInputName != NULL) {\n\t\tpNew->pInputName = pOld->pInputName;\n\t\tprop.AddRef(pNew->pInputName);\n\t}\n\t/* enable this, if someone actually uses UxTradMsg, delete after some time has\n\t * passed and nobody complained -- rgerhards, 2009-06-16\n\tpNew->offAfterPRI = pOld->offAfterPRI;\n\t*/\n\tif(pOld->iLenTAG > 0) {\n\t\tif(pOld->iLenTAG < CONF_TAG_BUFSIZE) {\n\t\t\tmemcpy(pNew->TAG.szBuf, pOld->TAG.szBuf, pOld->iLenTAG);\n\t\t} else {\n\t\t\tif((pNew->TAG.pszTAG = srUtilStrDup(pOld->TAG.pszTAG, pOld->iLenTAG)) == NULL) {\n\t\t\t\tmsgDestruct(&pNew);\n\t\t\t\treturn NULL;\n\t\t\t}\n\t\t\tpNew->iLenTAG = pOld->iLenTAG;\n\t\t}\n\t}\n\tif(pOld->iLenRawMsg < CONF_RAWMSG_BUFSIZE) {\n\t\tmemcpy(pNew->szRawMsg, pOld->szRawMsg, pOld->iLenRawMsg + 1);\n\t\tpNew->pszRawMsg = pNew->szRawMsg;\n\t} else {\n\t\ttmpCOPYSZ(RawMsg);\n\t}\n\tif(pOld->iLenHOSTNAME < CONF_HOSTNAME_BUFSIZE) {\n\t\tmemcpy(pNew->szHOSTNAME, pOld->szHOSTNAME, pOld->iLenHOSTNAME + 1);\n\t\tpNew->pszHOSTNAME = pNew->szHOSTNAME;\n\t} else {\n\t\ttmpCOPYSZ(HOSTNAME);\n\t}\n\n\ttmpCOPYCSTR(ProgName);\n\ttmpCOPYCSTR(StrucData);\n\ttmpCOPYCSTR(APPNAME);\n\ttmpCOPYCSTR(PROCID);\n\ttmpCOPYCSTR(MSGID);\n\n\t/* we do not copy all other cache properties, as we do not even know\n\t * if they are needed once again. So we let them re-create if needed.\n\t */\n\n\tENDfunc\n\treturn pNew;\n}",
        "commit_message": "backporting abort condition fix from 5.7.7",
        "cve_desc": "A memory leak in rsyslog before 5.7.6 was found in the way deamon processed log messages are logged when $RepeatedMsgReduction was enabled. A local attacker could use this flaw to cause a denial of the rsyslogd daemon service by crashing the service via a sequence of repeated log messages sent within short periods of time.",
        "target": 1
      },
      {
        "idx": 213053,
        "reasoning": "The `rsCStrExtendBuf` function is vulnerable to an integer overflow because the calculation of `iNewSize` can wrap around to a smaller value when `iMinNeeded` is large, leading to an insufficient buffer allocation. This insufficient allocation results in a heap-based buffer overflow when `realloc` is called, as a file line exceeding 64KiB can trigger this overflow and cause a denial of service.",
        "func": "rsCStrExtendBuf(cstr_t *pThis, size_t iMinNeeded)\n{\n\tuchar *pNewBuf;\n\tunsigned short iNewSize;\n\tDEFiRet;\n\n\t/* first compute the new size needed */\n\tif(iMinNeeded > RS_STRINGBUF_ALLOC_INCREMENT) {\n\t\t/* we allocate \"n\" ALLOC_INCREMENTs. Usually, that should\n\t\t * leave some room after the absolutely needed one. It also\n\t\t * reduces memory fragmentation. Note that all of this are\n\t\t * integer operations (very important to understand what is\n\t\t * going on)! Parenthesis are for better readibility.\n\t\t */\n\t\tiNewSize = (iMinNeeded / RS_STRINGBUF_ALLOC_INCREMENT + 1) * RS_STRINGBUF_ALLOC_INCREMENT;\n\t} else {\n\t\tiNewSize = pThis->iBufSize + RS_STRINGBUF_ALLOC_INCREMENT;\n\t}\n\tiNewSize += pThis->iBufSize; /* add current size */\n\n\t/* DEV debugging only: dbgprintf(\"extending string buffer, old %d, new %d\\n\", pThis->iBufSize, iNewSize); */\n\tCHKmalloc(pNewBuf = (uchar*) realloc(pThis->pBuf, iNewSize * sizeof(uchar)));\n\tpThis->iBufSize = iNewSize;\n\tpThis->pBuf = pNewBuf;\n\nfinalize_it:\n\tRETiRet;\n}",
        "commit_message": "bugfix: abort if imfile reads file line of more than 64KiB\n\nThanks to Peter Eisentraut for reporting and analysing this problem.\nbug tracker: http://bugzilla.adiscon.com/show_bug.cgi?id=221",
        "cve_desc": "Integer overflow in the rsCStrExtendBuf function in runtime/stringbuf.c in the imfile module in rsyslog 4.x before 4.6.6, 5.x before 5.7.4, and 6.x before 6.1.4 allows local users to cause a denial of service (daemon hang) via a large file, which triggers a heap-based buffer overflow.",
        "target": 1
      }
    ]
  },
  "ruby": {
    "0": [
      {
        "idx": 309784,
        "reasoning": "This code snippet is not inherently vulnerable based on the provided information. The commit message indicates a *fix* for abstract namespace handling on Linux, suggesting the previous code had an issue that was addressed\u2014not that the current version introduces a new vulnerability\u2014and the code itself simply retrieves and returns socket address information without apparent dangerous operations.\n\n\n\n",
        "func": "unix_addr(VALUE sock)\n{\n    rb_io_t *fptr;\n    struct sockaddr_un addr;\n    socklen_t len = (socklen_t)sizeof addr;\n    socklen_t len0 = len;\n\n    GetOpenFile(sock, fptr);\n\n    if (getsockname(fptr->fd, (struct sockaddr*)&addr, &len) < 0)\n        rsock_sys_fail_path(\"getsockname(2)\", fptr->pathv);\n    if (len0 < len) len = len0;\n    return rsock_unixaddr(&addr, len);\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 0
      },
      {
        "idx": 309785,
        "reasoning": "This code is likely safe as the commit message indicates a fix for abstract namespace support on Linux, not a security vulnerability. The code handles file descriptor passing via `sendmsg` using either `msg_control` (for systems supporting it) or `msg_accrights`, and appears to correctly manage buffer sizes and data copying, without obvious flaws that would lead to exploitable issues.",
        "func": "unix_send_io(VALUE sock, VALUE val)\n{\n    int fd;\n    rb_io_t *fptr;\n    struct iomsg_arg arg;\n    struct iovec vec[1];\n    char buf[1];\n\n#if FD_PASSING_BY_MSG_CONTROL\n    union {\n\tstruct cmsghdr hdr;\n\tchar pad[sizeof(struct cmsghdr)+8+sizeof(int)+8];\n    } cmsg;\n#endif\n\n    if (rb_obj_is_kind_of(val, rb_cIO)) {\n        rb_io_t *valfptr;\n\tGetOpenFile(val, valfptr);\n\tfd = valfptr->fd;\n    }\n    else if (FIXNUM_P(val)) {\n        fd = FIX2INT(val);\n    }\n    else {\n\trb_raise(rb_eTypeError, \"neither IO nor file descriptor\");\n    }\n\n    GetOpenFile(sock, fptr);\n\n    arg.msg.msg_name = NULL;\n    arg.msg.msg_namelen = 0;\n\n    /* Linux and Solaris doesn't work if msg_iov is NULL. */\n    buf[0] = '\\0';\n    vec[0].iov_base = buf;\n    vec[0].iov_len = 1;\n    arg.msg.msg_iov = vec;\n    arg.msg.msg_iovlen = 1;\n\n#if FD_PASSING_BY_MSG_CONTROL\n    arg.msg.msg_control = (caddr_t)&cmsg;\n    arg.msg.msg_controllen = (socklen_t)CMSG_LEN(sizeof(int));\n    arg.msg.msg_flags = 0;\n    MEMZERO((char*)&cmsg, char, sizeof(cmsg));\n    cmsg.hdr.cmsg_len = (socklen_t)CMSG_LEN(sizeof(int));\n    cmsg.hdr.cmsg_level = SOL_SOCKET;\n    cmsg.hdr.cmsg_type = SCM_RIGHTS;\n    memcpy(CMSG_DATA(&cmsg.hdr), &fd, sizeof(int));\n#else\n    arg.msg.msg_accrights = (caddr_t)&fd;\n    arg.msg.msg_accrightslen = sizeof(fd);\n#endif\n\n    arg.fd = fptr->fd;\n    while ((int)BLOCKING_REGION_FD(sendmsg_blocking, &arg) == -1) {\n\tif (!rb_io_wait_writable(arg.fd))\n\t    rsock_sys_fail_path(\"sendmsg(2)\", fptr->pathv);\n    }\n\n    return Qnil;\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 0
      },
      {
        "idx": 309786,
        "reasoning": "This code snippet appears safe as it retrieves the socket path using `getsockname` and stores it for later use, without directly manipulating user-supplied input in a way that could lead to vulnerabilities like path traversal or command injection. The commit message indicates a fix related to abstract namespaces, suggesting it addresses a specific functionality concern rather than a security flaw.\n\n\n\n",
        "func": "unix_path(VALUE sock)\n{\n    rb_io_t *fptr;\n\n    GetOpenFile(sock, fptr);\n    if (NIL_P(fptr->pathv)) {\n\tstruct sockaddr_un addr;\n\tsocklen_t len = (socklen_t)sizeof(addr);\n\tsocklen_t len0 = len;\n\tif (getsockname(fptr->fd, (struct sockaddr*)&addr, &len) < 0)\n            rsock_sys_fail_path(\"getsockname(2)\", fptr->pathv);\n        if (len0 < len) len = len0;\n\tfptr->pathv = rb_obj_freeze(rsock_unixpath_str(&addr, len));\n    }\n    return rb_str_dup(fptr->pathv);\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 0
      },
      {
        "idx": 309787,
        "reasoning": "This code snippet focuses on establishing a connection via a file descriptor and sockaddr structure, and doesn't directly handle user-provided input that could lead to vulnerabilities like injection or buffer overflows. The commit message indicates a fix related to abstract namespaces on Linux, suggesting the change addresses a specific system-level behavior rather than introducing or mitigating a security flaw *within this function itself*.\n\n\n\n",
        "func": "unixsock_connect_internal(VALUE a)\n{\n    struct unixsock_arg *arg = (struct unixsock_arg *)a;\n    return (VALUE)rsock_connect(arg->fd, (struct sockaddr*)arg->sockaddr,\n\t\t\t        arg->sockaddrlen, 0);\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 0
      },
      {
        "idx": 309788,
        "reasoning": "This code snippet appears safe as it simply calls another function (`rsock_s_recvfrom`) with a flag indicating a UNIX socket. The commit message focuses on changes to abstract namespace handling in a different function (`unixsock_path_value`) and doesn't suggest any vulnerabilities are introduced in `unix_recvfrom` itself.\n\n\n\n",
        "func": "unix_recvfrom(int argc, VALUE *argv, VALUE sock)\n{\n    return rsock_s_recvfrom(sock, argc, argv, RECV_UNIX);\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200774,
        "reasoning": "This code is vulnerable because it copies the provided socket path directly into a `sockaddr_un` structure without validating for null bytes, as described in the CVE. This allows an attacker to craft a path containing null characters, potentially leading to a connection to an unintended socket and a denial-of-service or other malicious behavior.",
        "func": "rsock_init_unixsock(VALUE sock, VALUE path, int server)\n{\n    struct sockaddr_un sockaddr;\n    socklen_t sockaddrlen;\n    int fd, status;\n    rb_io_t *fptr;\n\n    FilePathValue(path);\n\n    INIT_SOCKADDR_UN(&sockaddr, sizeof(struct sockaddr_un));\n    if (sizeof(sockaddr.sun_path) < (size_t)RSTRING_LEN(path)) {\n        rb_raise(rb_eArgError, \"too long unix socket path (%ldbytes given but %dbytes max)\",\n            RSTRING_LEN(path), (int)sizeof(sockaddr.sun_path));\n    }\n    memcpy(sockaddr.sun_path, RSTRING_PTR(path), RSTRING_LEN(path));\n    sockaddrlen = rsock_unix_sockaddr_len(path);\n\n    fd = rsock_socket(AF_UNIX, SOCK_STREAM, 0);\n    if (fd < 0) {\n\trsock_sys_fail_path(\"socket(2)\", path);\n    }\n\n    if (server) {\n        status = bind(fd, (struct sockaddr*)&sockaddr, sockaddrlen);\n    }\n    else {\n\tint prot;\n\tstruct unixsock_arg arg;\n\targ.sockaddr = &sockaddr;\n\targ.sockaddrlen = sockaddrlen;\n\targ.fd = fd;\n        status = (int)rb_protect(unixsock_connect_internal, (VALUE)&arg, &prot);\n\tif (prot) {\n\t    close(fd);\n\t    rb_jump_tag(prot);\n\t}\n    }\n\n    if (status < 0) {\n\tint e = errno;\n\tclose(fd);\n\trsock_syserr_fail_path(e, \"connect(2)\", path);\n    }\n\n    if (server) {\n\tif (listen(fd, SOMAXCONN) < 0) {\n\t    int e = errno;\n\t    close(fd);\n\t    rsock_syserr_fail_path(e, \"listen(2)\", path);\n\t}\n    }\n\n    rsock_init_sock(sock, fd);\n    if (server) {\n\tGetOpenFile(sock, fptr);\n        fptr->pathv = rb_str_new_frozen(path);\n    }\n\n    return sock;\n}",
        "commit_message": "unixsocket.c: abstract namespace\n\n* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@63000 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 1
      },
      {
        "idx": 202627,
        "reasoning": "This code is vulnerable because it doesn't check for tainted data when `$SAFE > 0` before passing arguments to the native function via `ffi_call`. This allows an attacker to bypass Ruby's security mechanisms intended to restrict operations based on the `$SAFE` level, potentially executing arbitrary code with elevated privileges.",
        "func": "function_call(int argc, VALUE argv[], VALUE self)\n{\n    ffi_cif * cif;\n    fiddle_generic retval;\n    fiddle_generic *generic_args;\n    void **values;\n    VALUE cfunc, types, cPointer;\n    int i;\n\n    cfunc    = rb_iv_get(self, \"@ptr\");\n    types    = rb_iv_get(self, \"@args\");\n    cPointer = rb_const_get(mFiddle, rb_intern(\"Pointer\"));\n\n    if(argc != RARRAY_LENINT(types)) {\n\trb_raise(rb_eArgError, \"wrong number of arguments (%d for %d)\",\n\t\targc, RARRAY_LENINT(types));\n    }\n\n    TypedData_Get_Struct(self, ffi_cif, &function_data_type, cif);\n\n    values = xcalloc((size_t)argc + 1, (size_t)sizeof(void *));\n    generic_args = xcalloc((size_t)argc, (size_t)sizeof(fiddle_generic));\n\n    for (i = 0; i < argc; i++) {\n\tVALUE type = RARRAY_PTR(types)[i];\n\tVALUE src = argv[i];\n\n\tif(NUM2INT(type) == TYPE_VOIDP) {\n\t    if(NIL_P(src)) {\n\t\tsrc = INT2FIX(0);\n\t    } else if(cPointer != CLASS_OF(src)) {\n\t\tsrc = rb_funcall(cPointer, rb_intern(\"[]\"), 1, src);\n\t    }\n\t    src = rb_Integer(src);\n\t}\n\n\tVALUE2GENERIC(NUM2INT(type), src, &generic_args[i]);\n\tvalues[i] = (void *)&generic_args[i];\n    }\n    values[argc] = NULL;\n\n    ffi_call(cif, NUM2PTR(rb_Integer(cfunc)), &retval, values);\n\n    rb_funcall(mFiddle, rb_intern(\"last_error=\"), 1, INT2NUM(errno));\n#if defined(_WIN32)\n    rb_funcall(mFiddle, rb_intern(\"win32_last_error=\"), 1, INT2NUM(errno));\n#endif\n\n    xfree(values);\n    xfree(generic_args);\n\n    return GENERIC2VALUE(rb_iv_get(self, \"@return_type\"), retval);\n}",
        "commit_message": "* ext/dl/lib/dl/func.rb (DL::Function#call): check tainted when\n  $SAFE > 0.\n* ext/fiddle/function.c (function_call): check tainted when $SAFE > 0.\n* test/fiddle/test_func.rb (module Fiddle): add test for above.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@40728 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "(1) DL and (2) Fiddle in Ruby 1.9 before 1.9.3 patchlevel 426, and 2.0 before 2.0.0 patchlevel 195, do not perform taint checking for native functions, which allows context-dependent attackers to bypass intended $SAFE level restrictions.",
        "target": 1
      },
      {
        "idx": 206259,
        "reasoning": "This code is vulnerable because it copies the provided socket path directly into a `sockaddr_un` structure without validating for null bytes, as highlighted by the HackerOne report. This allows an attacker to craft a path containing null bytes, potentially leading to a connection to an unintended socket and a denial-of-service or other malicious behavior, aligning with the CVE description.",
        "func": "rsock_init_unixsock(VALUE sock, VALUE path, int server)\n{\n    struct sockaddr_un sockaddr;\n    socklen_t sockaddrlen;\n    int fd, status;\n    rb_io_t *fptr;\n\n    SafeStringValue(path);\n\n    INIT_SOCKADDR_UN(&sockaddr, sizeof(struct sockaddr_un));\n    if (sizeof(sockaddr.sun_path) < (size_t)RSTRING_LEN(path)) {\n        rb_raise(rb_eArgError, \"too long unix socket path (%ldbytes given but %dbytes max)\",\n            RSTRING_LEN(path), (int)sizeof(sockaddr.sun_path));\n    }\n    memcpy(sockaddr.sun_path, RSTRING_PTR(path), RSTRING_LEN(path));\n    sockaddrlen = rsock_unix_sockaddr_len(path);\n\n    fd = rsock_socket(AF_UNIX, SOCK_STREAM, 0);\n    if (fd < 0) {\n\trsock_sys_fail_path(\"socket(2)\", path);\n    }\n\n    if (server) {\n        status = bind(fd, (struct sockaddr*)&sockaddr, sockaddrlen);\n    }\n    else {\n\tint prot;\n\tstruct unixsock_arg arg;\n\targ.sockaddr = &sockaddr;\n\targ.sockaddrlen = sockaddrlen;\n\targ.fd = fd;\n        status = (int)rb_protect(unixsock_connect_internal, (VALUE)&arg, &prot);\n\tif (prot) {\n\t    close(fd);\n\t    rb_jump_tag(prot);\n\t}\n    }\n\n    if (status < 0) {\n\tint e = errno;\n\tclose(fd);\n\trsock_syserr_fail_path(e, \"connect(2)\", path);\n    }\n\n    if (server) {\n\tif (listen(fd, SOMAXCONN) < 0) {\n\t    int e = errno;\n\t    close(fd);\n\t    rsock_syserr_fail_path(e, \"listen(2)\", path);\n\t}\n    }\n\n    rsock_init_sock(sock, fd);\n    if (server) {\n\tGetOpenFile(sock, fptr);\n        fptr->pathv = rb_str_new_frozen(path);\n    }\n\n    return sock;\n}",
        "commit_message": "unixsocket.c: check NUL bytes\n\n* ext/socket/unixsocket.c (rsock_init_unixsock): check NUL bytes.\n  https://hackerone.com/reports/302997\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@62991 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 1
      },
      {
        "idx": 206903,
        "reasoning": "This code is vulnerable because it copies the provided `path` directly into the `sun_path` field of the `sockaddr_un` structure without properly sanitizing for null bytes, as highlighted by the HackerOne report.  This allows an attacker to craft a path containing null bytes, potentially leading to connections to unintended sockets due to the way the kernel interprets the socket path.",
        "func": "rsock_init_unixsock(VALUE sock, VALUE path, int server)\n{\n    struct sockaddr_un sockaddr;\n    socklen_t sockaddrlen;\n    int fd, status;\n    rb_io_t *fptr;\n\n    SafeStringValue(path);\n\n    INIT_SOCKADDR_UN(&sockaddr, sizeof(struct sockaddr_un));\n    if (sizeof(sockaddr.sun_path) < (size_t)RSTRING_LEN(path)) {\n        rb_raise(rb_eArgError, \"too long unix socket path (%ldbytes given but %dbytes max)\",\n            RSTRING_LEN(path), (int)sizeof(sockaddr.sun_path));\n    }\n    memcpy(sockaddr.sun_path, RSTRING_PTR(path), RSTRING_LEN(path));\n    sockaddrlen = rsock_unix_sockaddr_len(path);\n\n    fd = rsock_socket(AF_UNIX, SOCK_STREAM, 0);\n    if (fd < 0) {\n\trsock_sys_fail_path(\"socket(2)\", path);\n    }\n\n    if (server) {\n        status = bind(fd, (struct sockaddr*)&sockaddr, sockaddrlen);\n    }\n    else {\n\tint prot;\n\tstruct unixsock_arg arg;\n\targ.sockaddr = &sockaddr;\n\targ.sockaddrlen = sockaddrlen;\n\targ.fd = fd;\n        status = (int)rb_protect(unixsock_connect_internal, (VALUE)&arg, &prot);\n\tif (prot) {\n\t    close(fd);\n\t    rb_jump_tag(prot);\n\t}\n    }\n\n    if (status < 0) {\n\tclose(fd);\n        rsock_sys_fail_path(\"connect(2)\", path);\n    }\n\n    if (server) {\n\tif (listen(fd, SOMAXCONN) < 0) {\n\t    close(fd);\n            rsock_sys_fail_path(\"listen(2)\", path);\n\t}\n    }\n\n    rsock_init_sock(sock, fd);\n    if (server) {\n\tGetOpenFile(sock, fptr);\n        fptr->pathv = rb_str_new_frozen(path);\n    }\n\n    return sock;\n}",
        "commit_message": "merge revision(s) 62991,63000:\n\n\tunixsocket.c: check NUL bytes\n\n\t* ext/socket/unixsocket.c (rsock_init_unixsock): check NUL bytes.\n\t  https://hackerone.com/reports/302997\n\n\tunixsocket.c: abstract namespace\n\n\t* ext/socket/unixsocket.c (unixsock_path_value): fix r62991 for\n\t  Linux abstract namespace.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/branches/ruby_2_2@63018 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "In Ruby before 2.2.10, 2.3.x before 2.3.7, 2.4.x before 2.4.4, 2.5.x before 2.5.1, and 2.6.0-preview1, the UNIXServer.open and UNIXSocket.open methods are not checked for null characters. It may be connected to an unintended socket.",
        "target": 1
      },
      {
        "idx": 209855,
        "reasoning": "This code is vulnerable to a heap overflow because the size of the `arg_types` buffer is determined by the length of the `args` array *at the time of allocation*. However, objects within the `args` array could be manipulated *after* allocation but *before* being used, potentially increasing the effective size of the array and leading to a write beyond the bounds of the `arg_types` buffer.",
        "func": "initialize(int argc, VALUE argv[], VALUE self)\n{\n    ffi_cif * cif;\n    ffi_type **arg_types;\n    ffi_status result;\n    VALUE ptr, args, ret_type, abi, kwds;\n    long i;\n\n    rb_scan_args(argc, argv, \"31:\", &ptr, &args, &ret_type, &abi, &kwds);\n    if(NIL_P(abi)) abi = INT2NUM(FFI_DEFAULT_ABI);\n\n    Check_Type(args, T_ARRAY);\n    Check_Max_Args(\"args\", RARRAY_LENINT(args));\n\n    rb_iv_set(self, \"@ptr\", ptr);\n    rb_iv_set(self, \"@args\", args);\n    rb_iv_set(self, \"@return_type\", ret_type);\n    rb_iv_set(self, \"@abi\", abi);\n\n    if (!NIL_P(kwds)) rb_hash_foreach(kwds, parse_keyword_arg_i, self);\n\n    TypedData_Get_Struct(self, ffi_cif, &function_data_type, cif);\n\n    arg_types = xcalloc(RARRAY_LEN(args) + 1, sizeof(ffi_type *));\n\n    for (i = 0; i < RARRAY_LEN(args); i++) {\n\tint type = NUM2INT(RARRAY_AREF(args, i));\n\targ_types[i] = INT2FFI_TYPE(type);\n    }\n    arg_types[RARRAY_LEN(args)] = NULL;\n\n    result = ffi_prep_cif (\n\t    cif,\n\t    NUM2INT(abi),\n\t    RARRAY_LENINT(args),\n\t    INT2FFI_TYPE(NUM2INT(ret_type)),\n\t    arg_types);\n\n    if (result)\n\trb_raise(rb_eRuntimeError, \"error creating CIF %d\", result);\n\n    return self;\n}",
        "commit_message": "function.c: check arguments\n\n* ext/fiddle/function.c (initialize): check all arguments first.\n  reported by Marcin 'Icewall' Noga of Cisco Talos.\n\ngit-svn-id: svn+ssh://ci.ruby-lang.org/ruby/trunk@53082 b2dd03c8-39d4-4d8f-98ff-823fe69b080e",
        "cve_desc": "An exploitable heap overflow vulnerability exists in the Fiddle::Function.new \"initialize\" function functionality of Ruby. In Fiddle::Function.new \"initialize\" heap buffer \"arg_types\" allocation is made based on args array length. Specially constructed object passed as element of args array can increase this array size after mentioned allocation and cause heap overflow.",
        "target": 1
      }
    ]
  },
  "samba": {
    "0": [
      {
        "idx": 10842,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message and code address restricting account type swapping to match Microsoft's security update MS15-096, specifically focusing on critical attributes and read-only domain controller filtering \u2013 it *implements* a security measure, rather than introducing a flaw.\n\n\n\n",
        "func": "static bool check_rodc_critical_attribute(struct ldb_message *msg)\n{\n\tuint32_t schemaFlagsEx, searchFlags, rodc_filtered_flags;\n\n\tschemaFlagsEx = ldb_msg_find_attr_as_uint(msg, \"schemaFlagsEx\", 0);\n\tsearchFlags = ldb_msg_find_attr_as_uint(msg, \"searchFlags\", 0);\n\trodc_filtered_flags = (SEARCH_FLAG_RODC_ATTRIBUTE\n\t\t\t      | SEARCH_FLAG_CONFIDENTIAL);\n\n\tif ((schemaFlagsEx & SCHEMA_FLAG_ATTR_IS_CRITICAL) &&\n\t\t((searchFlags & rodc_filtered_flags) == rodc_filtered_flags)) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}\n",
        "commit_message": "CVE-2015-8467: samdb: Match MS15-096 behaviour for userAccountControl\n\nSwapping between account types is now restricted\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11552\n\nSigned-off-by: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "The samldb_check_user_account_control_acl function in dsdb/samdb/ldb_modules/samldb.c in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3 does not properly check for administrative privileges during creation of machine accounts, which allows remote authenticated users to bypass intended access restrictions by leveraging the existence of a domain with both a Samba DC and a Windows DC, a similar issue to CVE-2015-2535.",
        "target": 0
      },
      {
        "idx": 10843,
        "reasoning": "This code snippet focuses on adding entries to the Samba database and doesn't directly handle user account control modifications that are the root cause of CVE-2015-8467. The commit message explicitly states the change *restricts* swapping between account types, addressing the vulnerability described in MS15-096, therefore this code is not vulnerable and implements the fix.",
        "func": "static int samldb_add_entry(struct samldb_ctx *ac)\n{\n\tstruct ldb_context *ldb;\n\tstruct ldb_request *req;\n\tint ret;\n\n\tldb = ldb_module_get_ctx(ac->module);\n\n\tret = ldb_build_add_req(&req, ldb, ac,\n\t\t\t\tac->msg,\n\t\t\t\tac->req->controls,\n\t\t\t\tac, samldb_add_entry_callback,\n\t\t\t\tac->req);\n\tLDB_REQ_SET_LOCATION(req);\n\tif (ret != LDB_SUCCESS) {\n\t\treturn ret;\n\t}\n\n\treturn ldb_next_request(ac->module, req);\n}\n",
        "commit_message": "CVE-2015-8467: samdb: Match MS15-096 behaviour for userAccountControl\n\nSwapping between account types is now restricted\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11552\n\nSigned-off-by: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "The samldb_check_user_account_control_acl function in dsdb/samdb/ldb_modules/samldb.c in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3 does not properly check for administrative privileges during creation of machine accounts, which allows remote authenticated users to bypass intended access restrictions by leveraging the existence of a domain with both a Samba DC and a Windows DC, a similar issue to CVE-2015-2535.",
        "target": 0
      },
      {
        "idx": 10844,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message explicitly states the code addresses CVE-2015-8467 by restricting account type swapping to match MS15-096, indicating a *fix* for a potential vulnerability rather than introducing a new one, and the code itself appears to be handling standard LDB reply processing.",
        "func": "static int samldb_add_entry_callback(struct ldb_request *req,\n\t\t\t\t\tstruct ldb_reply *ares)\n{\n\tstruct ldb_context *ldb;\n\tstruct samldb_ctx *ac;\n\tint ret;\n\n\tac = talloc_get_type(req->context, struct samldb_ctx);\n\tldb = ldb_module_get_ctx(ac->module);\n\n\tif (!ares) {\n\t\treturn ldb_module_done(ac->req, NULL, NULL,\n\t\t\t\t\tLDB_ERR_OPERATIONS_ERROR);\n\t}\n\n\tif (ares->type == LDB_REPLY_REFERRAL) {\n\t\treturn ldb_module_send_referral(ac->req, ares->referral);\n\t}\n\n\tif (ares->error != LDB_SUCCESS) {\n\t\treturn ldb_module_done(ac->req, ares->controls,\n\t\t\t\t\tares->response, ares->error);\n\t}\n\tif (ares->type != LDB_REPLY_DONE) {\n\t\tldb_asprintf_errstring(ldb, \"Invalid LDB reply type %d\", ares->type);\n\t\treturn ldb_module_done(ac->req, NULL, NULL,\n\t\t\t\t\tLDB_ERR_OPERATIONS_ERROR);\n\t}\n\n\t/* The caller may wish to get controls back from the add */\n\tac->ares = talloc_steal(ac, ares);\n\n\tret = samldb_next_step(ac);\n\tif (ret != LDB_SUCCESS) {\n\t\treturn ldb_module_done(ac->req, NULL, NULL, ret);\n\t}\n\treturn ret;\n}\n",
        "commit_message": "CVE-2015-8467: samdb: Match MS15-096 behaviour for userAccountControl\n\nSwapping between account types is now restricted\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11552\n\nSigned-off-by: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "The samldb_check_user_account_control_acl function in dsdb/samdb/ldb_modules/samldb.c in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3 does not properly check for administrative privileges during creation of machine accounts, which allows remote authenticated users to bypass intended access restrictions by leveraging the existence of a domain with both a Samba DC and a Windows DC, a similar issue to CVE-2015-2535.",
        "target": 0
      },
      {
        "idx": 10845,
        "reasoning": "This code addresses a vulnerability (CVE-2015-8467) related to restricting swaps between account types and ensuring proper handling of `msDS-IntId`. The commit implements checks and restrictions to prevent clients from directly setting `msDS-IntId` and ensures uniqueness, mitigating the original vulnerability by aligning with MS15-096 behavior.",
        "func": "static int samldb_add_handle_msDS_IntId(struct samldb_ctx *ac)\n{\n\tint ret;\n\tbool id_exists;\n\tuint32_t msds_intid;\n\tint32_t system_flags;\n\tstruct ldb_context *ldb;\n\tstruct ldb_result *ldb_res;\n\tstruct ldb_dn *schema_dn;\n\tstruct samldb_msds_intid_persistant *msds_intid_struct;\n\tstruct dsdb_schema *schema;\n\n\tldb = ldb_module_get_ctx(ac->module);\n\tschema_dn = ldb_get_schema_basedn(ldb);\n\n\t/* replicated update should always go through */\n\tif (ldb_request_get_control(ac->req,\n\t\t\t\t    DSDB_CONTROL_REPLICATED_UPDATE_OID)) {\n\t\treturn LDB_SUCCESS;\n\t}\n\n\t/* msDS-IntId is handled by system and should never be\n\t * passed by clients */\n\tif (ldb_msg_find_element(ac->msg, \"msDS-IntId\")) {\n\t\treturn LDB_ERR_UNWILLING_TO_PERFORM;\n\t}\n\n\t/* do not generate msDS-IntId if Relax control is passed */\n\tif (ldb_request_get_control(ac->req, LDB_CONTROL_RELAX_OID)) {\n\t\treturn LDB_SUCCESS;\n\t}\n\n\t/* check Functional Level */\n\tif (dsdb_functional_level(ldb) < DS_DOMAIN_FUNCTION_2003) {\n\t\treturn LDB_SUCCESS;\n\t}\n\n\t/* check systemFlags for SCHEMA_BASE_OBJECT flag */\n\tsystem_flags = ldb_msg_find_attr_as_int(ac->msg, \"systemFlags\", 0);\n\tif (system_flags & SYSTEM_FLAG_SCHEMA_BASE_OBJECT) {\n\t\treturn LDB_SUCCESS;\n\t}\n\tschema = dsdb_get_schema(ldb, NULL);\n\tif (!schema) {\n\t\tldb_debug_set(ldb, LDB_DEBUG_FATAL,\n\t\t\t      \"samldb_schema_info_update: no dsdb_schema loaded\");\n\t\tDEBUG(0,(__location__ \": %s\\n\", ldb_errstring(ldb)));\n\t\treturn ldb_operr(ldb);\n\t}\n\n\tmsds_intid_struct = (struct samldb_msds_intid_persistant*) ldb_get_opaque(ldb, SAMLDB_MSDS_INTID_OPAQUE);\n\tif (!msds_intid_struct) {\n\t\tmsds_intid_struct = talloc(ldb, struct samldb_msds_intid_persistant);\n\t\t/* Generate new value for msDs-IntId\n\t\t* Value should be in 0x80000000..0xBFFFFFFF range */\n\t\tmsds_intid = generate_random() % 0X3FFFFFFF;\n\t\tmsds_intid += 0x80000000;\n\t\tmsds_intid_struct->msds_intid = msds_intid;\n\t\tmsds_intid_struct->usn = schema->loaded_usn;\n\t\tDEBUG(2, (\"No samldb_msds_intid_persistant struct, allocating a new one\\n\"));\n\t} else {\n\t\tmsds_intid = msds_intid_struct->msds_intid;\n\t}\n\n\t/* probe id values until unique one is found */\n\tdo {\n\t\tuint64_t current_usn;\n\t\tmsds_intid++;\n\t\tif (msds_intid > 0xBFFFFFFF) {\n\t\t\tmsds_intid = 0x80000001;\n\t\t}\n\t\t/*\n\t\t * Alternative strategy to a costly (even indexed search) to the\n\t\t * database.\n\t\t * We search in the schema if we have already this intid (using dsdb_attribute_by_attributeID_id because\n\t\t * in the range 0x80000000 0xBFFFFFFFF, attributeID is a DSDB_ATTID_TYPE_INTID).\n\t\t * If so generate another random value.\n\t\t * If not check if the highest USN in the database for the schema partition is the\n\t\t * one that we know.\n\t\t * If so it means that's only this ldb context that is touching the schema in the database.\n\t\t * If not it means that's someone else has modified the database while we are doing our changes too\n\t\t * (this case should be very bery rare) in order to be sure do the search in the database.\n\t\t */\n\t\tif (dsdb_attribute_by_attributeID_id(schema, msds_intid)) {\n\t\t\tmsds_intid = generate_random() % 0X3FFFFFFF;\n\t\t\tmsds_intid += 0x80000000;\n\t\t\tcontinue;\n\t\t}\n\n\t\tret = dsdb_module_load_partition_usn(ac->module, schema_dn,\n\t\t\t\t\t\t     &current_usn, NULL, NULL);\n\t\tif (ret != LDB_SUCCESS) {\n\t\t\tldb_debug_set(ldb, LDB_DEBUG_ERROR,\n\t\t\t\t      __location__\": Searching for schema USN failed: %s\\n\",\n\t\t\t\t      ldb_errstring(ldb));\n\t\t\treturn ldb_operr(ldb);\n\t\t}\n\n\t\t/* current_usn can be lesser than msds_intid_struct-> if there is\n\t\t * uncommited changes.\n\t\t */\n\t\tif (current_usn > msds_intid_struct->usn) {\n\t\t\t/* oups something has changed, someone/something\n\t\t\t * else is modifying or has modified the schema\n\t\t\t * we'd better check this intid is the database directly\n\t\t\t */\n\n\t\t\tDEBUG(2, (\"Schema has changed, searching the database for the unicity of %d\\n\",\n\t\t\t\t\tmsds_intid));\n\n\t\t\tret = dsdb_module_search(ac->module, ac,\n\t\t\t\t\t\t&ldb_res,\n\t\t\t\t\t\tschema_dn, LDB_SCOPE_ONELEVEL, NULL,\n\t\t\t\t\t\tDSDB_FLAG_NEXT_MODULE,\n\t\t\t\t\t\tac->req,\n\t\t\t\t\t\t\"(msDS-IntId=%d)\", msds_intid);\n\t\t\tif (ret != LDB_SUCCESS) {\n\t\t\t\tldb_debug_set(ldb, LDB_DEBUG_ERROR,\n\t\t\t\t\t__location__\": Searching for msDS-IntId=%d failed - %s\\n\",\n\t\t\t\t\tmsds_intid,\n\t\t\t\t\tldb_errstring(ldb));\n\t\t\t\treturn ldb_operr(ldb);\n\t\t\t}\n\t\t\tid_exists = (ldb_res->count > 0);\n\t\t\ttalloc_free(ldb_res);\n\t\t} else {\n\t\t\tid_exists = 0;\n\t\t}\n\n\t} while(id_exists);\n\tmsds_intid_struct->msds_intid = msds_intid;\n\tldb_set_opaque(ldb, SAMLDB_MSDS_INTID_OPAQUE, msds_intid_struct);\n\n\treturn samdb_msg_add_int(ldb, ac->msg, ac->msg, \"msDS-IntId\",\n\t\t\t\t msds_intid);\n}\n",
        "commit_message": "CVE-2015-8467: samdb: Match MS15-096 behaviour for userAccountControl\n\nSwapping between account types is now restricted\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11552\n\nSigned-off-by: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "The samldb_check_user_account_control_acl function in dsdb/samdb/ldb_modules/samldb.c in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3 does not properly check for administrative privileges during creation of machine accounts, which allows remote authenticated users to bypass intended access restrictions by leveraging the existence of a domain with both a Samba DC and a Windows DC, a similar issue to CVE-2015-2535.",
        "target": 0
      },
      {
        "idx": 10846,
        "reasoning": "This code snippet manages a linked list of steps within the Samba database operations and doesn't directly handle user authentication or authorization logic. The commit message explicitly addresses restrictions on swapping account types to mitigate a vulnerability (CVE-2015-8467), but this code appears to be a supporting function for managing database operations *related* to that fix, not the vulnerable code itself\u2014therefore, it's not directly vulnerable.\n\n\n\n",
        "func": "static int samldb_add_step(struct samldb_ctx *ac, samldb_step_fn_t fn)\n{\n\tstruct samldb_step *step, *stepper;\n\n\tstep = talloc_zero(ac, struct samldb_step);\n\tif (step == NULL) {\n\t\treturn ldb_oom(ldb_module_get_ctx(ac->module));\n\t}\n\n\tstep->fn = fn;\n\n\tif (ac->steps == NULL) {\n\t\tac->steps = step;\n\t\tac->curstep = step;\n\t} else {\n\t\tif (ac->curstep == NULL)\n\t\t\treturn ldb_operr(ldb_module_get_ctx(ac->module));\n\t\tfor (stepper = ac->curstep; stepper->next != NULL;\n\t\t\tstepper = stepper->next);\n\t\tstepper->next = step;\n\t}\n\n\treturn LDB_SUCCESS;\n}\n",
        "commit_message": "CVE-2015-8467: samdb: Match MS15-096 behaviour for userAccountControl\n\nSwapping between account types is now restricted\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11552\n\nSigned-off-by: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Jeremy Allison <jra@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "The samldb_check_user_account_control_acl function in dsdb/samdb/ldb_modules/samldb.c in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3 does not properly check for administrative privileges during creation of machine accounts, which allows remote authenticated users to bypass intended access restrictions by leveraging the existence of a domain with both a Samba DC and a Windows DC, a similar issue to CVE-2015-2535.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 54,
        "reasoning": "This code is vulnerable to a buffer overflow due to the `memcpy` operations when handling `CSUM_MD4` variants, specifically when `len + sumresidue < CSUM_CHUNK` and subsequently when filling `md.buffer`. The vulnerability, as highlighted by the CVE, stems from mishandling of checksums and potentially allows an attacker to craft input that overflows the `md.buffer`, leading to arbitrary code execution or denial of service.",
        "func": "void sum_update(const char *p, int32 len)\n{\n\tswitch (cursum_type) {\n\t  case CSUM_MD5:\n\t\tmd5_update(&md, (uchar *)p, len);\n\t\tbreak;\n          case CSUM_MD4:\n          case CSUM_MD4_OLD:\n          case CSUM_MD4_BUSTED:\n                if (len + sumresidue < CSUM_CHUNK) {\n                        memcpy(md.buffer + sumresidue, p, len);\n                        sumresidue += len;\n\t\t}\n\n\t\tif (sumresidue) {\n\t\t\tint32 i = CSUM_CHUNK - sumresidue;\n\t\t\tmemcpy(md.buffer + sumresidue, p, i);\n\t\t\tmdfour_update(&md, (uchar *)md.buffer, CSUM_CHUNK);\n\t\t\tlen -= i;\n\t\t\tp += i;\n\t\t}\n\n\t\twhile (len >= CSUM_CHUNK) {\n\t\t\tmdfour_update(&md, (uchar *)p, CSUM_CHUNK);\n\t\t\tlen -= CSUM_CHUNK;\n\t\t\tp += CSUM_CHUNK;\n\t\t}\n\n\t\tsumresidue = len;\n\t\tif (sumresidue)\n\t\t\tmemcpy(md.buffer, p, sumresidue);\n\t\tbreak;\n\t  case CSUM_NONE:\n\t\tbreak;\n\t}\n}\n",
        "commit_message": "None",
        "cve_desc": "rsync 3.1.3-development before 2017-10-24 mishandles archaic checksums, which makes it easier for remote attackers to bypass intended access restrictions. NOTE: the rsync development branch has significant use beyond the rsync developers, e.g., the code has been copied for use in various GitHub projects.",
        "target": 1
      },
      {
        "idx": 55,
        "reasoning": "The code has a redundant check `if (!users || !*users) if (!users || !*users)` which, while not directly exploitable, indicates a potential logic error and lack of thorough code review. More critically, the code unconditionally returns `NULL` after sending a challenge, regardless of whether the authentication succeeds or fails, potentially allowing unauthenticated access if the subsequent authentication steps are bypassed or ignored\u2014a vulnerability similar to the CVE's bypass of access restrictions.",
        "func": "char *auth_server(int f_in, int f_out, int module, const char *host,\n\t\t  const char *addr, const char *leader)\n{\n\tchar *users = lp_auth_users(module);\n\tchar challenge[MAX_DIGEST_LEN*2];\n\tchar line[BIGPATHBUFLEN];\n\tchar **auth_uid_groups = NULL;\n\tint auth_uid_groups_cnt = -1;\n\tconst char *err = NULL;\n\tint group_match = -1;\n\tchar *tok, *pass;\n\tchar opt_ch = '\\0';\n\n\t/* if no auth list then allow anyone in! */\n\tif (!users || !*users)\n        if (!users || !*users)\n                return \"\";\n \n        gen_challenge(addr, challenge);\n \n        io_printf(f_out, \"%s%s\\n\", leader, challenge);\n\t\treturn NULL;\n\t}\n",
        "commit_message": "None",
        "cve_desc": "rsync 3.1.3-development before 2017-10-24 mishandles archaic checksums, which makes it easier for remote attackers to bypass intended access restrictions. NOTE: the rsync development branch has significant use beyond the rsync developers, e.g., the code has been copied for use in various GitHub projects.",
        "target": 1
      },
      {
        "idx": 74,
        "reasoning": "The code is vulnerable because the initial check `(str[0] & 0x80) == 0` incorrectly assumes a single-byte encoding if the most significant bit is not set, failing to account for UTF-16 encoding where ASCII characters are represented with zero bytes. This can lead to incorrect parsing of strings, potentially causing a buffer over-read or other memory corruption issues as described in the CVE, allowing attackers to read sensitive information from the daemon heap.",
        "func": "_PUBLIC_ codepoint_t next_codepoint_handle_ext(\n\t\t\tstruct smb_iconv_handle *ic,\n\t\t\tconst char *str, size_t len,\n\t\t\tcharset_t src_charset,\n\t\t\tsize_t *bytes_consumed)\n{\n\t/* it cannot occupy more than 4 bytes in UTF16 format */\n\tuint8_t buf[4];\n\tsmb_iconv_t descriptor;\n\tsize_t ilen_orig;\n\tsize_t ilen;\n        size_t olen;\n        char *outbuf;\n \n       if ((str[0] & 0x80) == 0) {\n                *bytes_consumed = 1;\n                return (codepoint_t)str[0];\n        }\n\t * This is OK as we only support codepoints up to 1M (U+100000)\n\t */\n\tilen_orig = MIN(len, 5);\n\tilen = ilen_orig;\n\n\tdescriptor = get_conv_handle(ic, src_charset, CH_UTF16);\n\tif (descriptor == (smb_iconv_t)-1) {\n\t\t*bytes_consumed = 1;\n\t\treturn INVALID_CODEPOINT;\n\t}\n\n\t/*\n\t * this looks a little strange, but it is needed to cope with\n\t * codepoints above 64k (U+1000) which are encoded as per RFC2781.\n\t */\n\tolen = 2;\n\toutbuf = (char *)buf;\n\tsmb_iconv(descriptor, &str, &ilen, &outbuf, &olen);\n\tif (olen == 2) {\n\t\tolen = 4;\n\t\toutbuf = (char *)buf;\n\t\tsmb_iconv(descriptor,  &str, &ilen, &outbuf, &olen);\n\t\tif (olen == 4) {\n\t\t\t/* we didn't convert any bytes */\n\t\t\t*bytes_consumed = 1;\n\t\t\treturn INVALID_CODEPOINT;\n\t\t}\n\t\tolen = 4 - olen;\n\t} else {\n\t\tolen = 2 - olen;\n\t}\n\n\t*bytes_consumed = ilen_orig - ilen;\n\n\tif (olen == 2) {\n\t\treturn (codepoint_t)SVAL(buf, 0);\n\t}\n\tif (olen == 4) {\n\t\t/* decode a 4 byte UTF16 character manually */\n\t\treturn (codepoint_t)0x10000 +\n\t\t\t(buf[2] | ((buf[3] & 0x3)<<8) |\n\t\t\t (buf[0]<<10) | ((buf[1] & 0x3)<<18));\n\t}\n\n\t/* no other length is valid */\n\treturn INVALID_CODEPOINT;\n}\n",
        "commit_message": "CVE-2015-5330: next_codepoint_handle_ext: don't short-circuit UTF16 low bytes\n\nUTF16 contains zero bytes when it is encoding ASCII (for example), so we\ncan't assume the absense of the 0x80 bit means a one byte encoding. No\ncurrent callers use UTF16.\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11599\n\nSigned-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>\nPair-programmed-with: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "ldb before 1.1.24, as used in the AD LDAP server in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3, mishandles string lengths, which allows remote attackers to obtain sensitive information from daemon heap memory by sending crafted packets and then reading (1) an error message or (2) a database value.",
        "target": 1
      },
      {
        "idx": 75,
        "reasoning": "The code is vulnerable due to insufficient bounds checking when copying data into the `dst` buffer, potentially leading to a buffer overflow if the input `src` string contains characters requiring escaping. This overflow can allow an attacker to overwrite heap memory, potentially exposing sensitive information as described in the CVE, by crafting a malicious input string that triggers excessive escaping and copying.",
        "func": " static int ldb_dn_escape_internal(char *dst, const char *src, int len)\n {\n       const char *p, *s;\n        char *d;\n       size_t l;\n       p = s = src;\n        d = dst;\n \n       while (p - src < len) {\n               p += strcspn(p, \",=\\n\\r+<>#;\\\\\\\" \");\n               if (p - src == len) /* found no escapable chars */\n                       break;\n               /* copy the part of the string before the stop */\n               memcpy(d, s, p - s);\n               d += (p - s); /* move to current position */\n               switch (*p) {\n                case ' ':\n                       if (p == src || (p-src)==(len-1)) {\n                                /* if at the beginning or end\n                                 * of the string then escape */\n                                *d++ = '\\\\';\n                               *d++ = *p++;                                     \n                        } else {\n                                /* otherwise don't escape */\n                               *d++ = *p++;\n                        }\n                        break;\n \n\t\t\t\t/* if at the beginning or end\n\t\t\t\t * of the string then escape */\n\t\t\t\t*d++ = '\\\\';\n\t\t\t\t*d++ = *p++;\t\t\t\t\t \n\t\t\t} else {\n\t\t\t\t/* otherwise don't escape */\n\t\t\t\t*d++ = *p++;\n\t\t\t}\n\t\t\tbreak;\n                case '?':\n                        /* these must be escaped using \\c form */\n                        *d++ = '\\\\';\n                       *d++ = *p++;\n                        break;\n \n               default: {\n                        /* any others get \\XX form */\n                        unsigned char v;\n                        const char *hexbytes = \"0123456789ABCDEF\";\n                       v = *(const unsigned char *)p;\n                        *d++ = '\\\\';\n                        *d++ = hexbytes[v>>4];\n                        *d++ = hexbytes[v&0xF];\n                       p++;\n                        break;\n                }\n                }\n               s = p; /* move forward */\n        }\n",
        "commit_message": "CVE-2015-5330: ldb_dn: simplify and fix ldb_dn_escape_internal()\n\nPreviously we relied on NUL terminated strings and jumped back and\nforth between copying escaped bytes and memcpy()ing un-escaped chunks.\nThis simple version is easier to reason about and works with\nunterminated strings. It may also be faster as it avoids reading the\nstring twice (first with strcspn, then with memcpy).\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11599\n\nSigned-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>\nPair-programmed-with: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "ldb before 1.1.24, as used in the AD LDAP server in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3, mishandles string lengths, which allows remote attackers to obtain sensitive information from daemon heap memory by sending crafted packets and then reading (1) an error message or (2) a database value.",
        "target": 1
      },
      {
        "idx": 76,
        "reasoning": "This code is vulnerable because the initial allocation for `dest` is `2*(n+1)`, assuming each character will expand by at most one byte when uppercased, but `next_codepoint_handle_ext` can return `c_size` greater than 1 for multi-byte characters. Consequently, `size` can exceed the allocated buffer size leading to a heap buffer overflow when writing to `dest`, potentially exposing sensitive information as described in the CVE.",
        "func": "_PUBLIC_ char *strupper_talloc_n_handle(struct smb_iconv_handle *iconv_handle,\n\t\t\t\t\tTALLOC_CTX *ctx, const char *src, size_t n)\n{\n\tsize_t size=0;\n\tchar *dest;\n\n\tif (!src) {\n\t\treturn NULL;\n\t}\n\n\t/* this takes advantage of the fact that upper/lower can't\n\t   change the length of a character by more than 1 byte */\n\tdest = talloc_array(ctx, char, 2*(n+1));\n\tif (dest == NULL) {\n                return NULL;\n        }\n \n       while (n-- && *src) {\n                size_t c_size;\n                codepoint_t c = next_codepoint_handle_ext(iconv_handle, src, n,\n                                                          CH_UNIX, &c_size);\n                src += c_size;\n \n                c = toupper_m(c);\n\t\tif (c_size == -1) {\n\t\t\ttalloc_free(dest);\n\t\t\treturn NULL;\n\t\t}\n\t\tsize += c_size;\n\t}\n\n\tdest[size] = 0;\n\n\t/* trim it so talloc_append_string() works */\n\tdest = talloc_realloc(ctx, dest, char, size+1);\n\n\ttalloc_set_name_const(dest, dest);\n\n\treturn dest;\n}\n",
        "commit_message": "CVE-2015-5330: strupper_talloc_n_handle(): properly count characters\n\nWhen a codepoint eats more than one byte we really want to know,\nespecially if the string is not NUL terminated.\n\nBug: https://bugzilla.samba.org/show_bug.cgi?id=11599\n\nSigned-off-by: Douglas Bagnall <douglas.bagnall@catalyst.net.nz>\nPair-programmed-with: Andrew Bartlett <abartlet@samba.org>\nReviewed-by: Ralph Boehme <slow@samba.org>",
        "cve_desc": "ldb before 1.1.24, as used in the AD LDAP server in Samba 4.x before 4.1.22, 4.2.x before 4.2.7, and 4.3.x before 4.3.3, mishandles string lengths, which allows remote attackers to obtain sensitive information from daemon heap memory by sending crafted packets and then reading (1) an error message or (2) a database value.",
        "target": 1
      }
    ]
  },
  "samurai": {
    "0": [
      {
        "idx": 304387,
        "reasoning": "This code snippet for `bufadd` is not directly vulnerable based on the provided information. The commit message discusses a vulnerability related to handling potentially null strings in a `writefile` function, and this snippet only concerns buffer management\u2014specifically, resizing a buffer when it's full\u2014and doesn't appear to directly handle external input that could lead to a null pointer dereference or other exploits.\n\n\n\n",
        "func": "bufadd(struct buffer *buf, char c)\n{\n\tif (buf->len >= buf->cap) {\n\t\tbuf->cap = buf->cap ? buf->cap * 2 : 1 << 8;\n\t\tbuf->data = realloc(buf->data, buf->cap);\n\t\tif (!buf->data)\n\t\t\tfatal(\"realloc:\");\n\t}\n\tbuf->data[buf->len++] = c;\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 0
      },
      {
        "idx": 304388,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message describes a logic error related to handling potentially unset environment variables that *could* lead to a vulnerability elsewhere in the `samurai` project, but the `xasprintf` function itself includes robust error handling and bounds checking to prevent buffer overflows or other memory corruption issues. \n\n\n\n",
        "func": "xasprintf(char **s, const char *fmt, ...)\n{\n\tva_list ap;\n\tint ret;\n\tsize_t n;\n\n\tva_start(ap, fmt);\n\tret = vsnprintf(NULL, 0, fmt, ap);\n\tva_end(ap);\n\tif (ret < 0)\n\t\tfatal(\"vsnprintf:\");\n\tn = ret + 1;\n\t*s = xmalloc(n);\n\tva_start(ap, fmt);\n\tret = vsnprintf(*s, n, fmt, ap);\n\tva_end(ap);\n\tif (ret < 0 || (size_t)ret >= n)\n\t\tfatal(\"vsnprintf:\");\n\n\treturn ret;\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 0
      },
      {
        "idx": 304389,
        "reasoning": "This code snippet for `xmalloc` is not directly vulnerable. It simply allocates memory using `malloc` and includes a fatal error check if the allocation fails, preventing potential crashes due to null pointers\u2014the commit message addresses a vulnerability in a different part of the `samurai` project related to string handling and environment variables, not memory allocation itself.\n\n\n\n",
        "func": "xmalloc(size_t n)\n{\n\tvoid *p;\n\n\tp = malloc(n);\n\tif (!p)\n\t\tfatal(\"malloc:\");\n\n\treturn p;\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 0
      },
      {
        "idx": 304390,
        "reasoning": "This code snippet for the `warn` function itself is not directly vulnerable. The commit message details a vulnerability fix in a `writefile` function, addressing a potential NULL pointer dereference related to environment variables influencing rule file processing \u2013 this `warn` function is simply a logging utility and doesn't handle external data in a way that introduces risk.\n\n\n\n",
        "func": "warn(const char *fmt, ...)\n{\n\tva_list ap;\n\n\tva_start(ap, fmt);\n\tvwarn(fmt, ap);\n\tva_end(ap);\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 0
      },
      {
        "idx": 304391,
        "reasoning": "This code snippet focuses on path canonicalization and doesn't directly handle file writing or external input that could lead to vulnerabilities like format string bugs or buffer overflows. The commit message describes a vulnerability related to `writefile` and environment variables, but the provided `canonpath` function doesn't interact with those elements, making it safe based on the given context.\n\n\n\n",
        "func": "canonpath(struct string *path)\n{\n\tchar *component[60];\n\tint n;\n\tchar *s, *d, *end;\n\n\tif (path->n == 0)\n\t\tfatal(\"empty path\");\n\ts = d = path->s;\n\tend = path->s + path->n;\n\tn = 0;\n\tif (*s == '/') {\n\t\t++s;\n\t\t++d;\n\t}\n\twhile (s < end) {\n\t\tswitch (s[0]) {\n\t\tcase '/':\n\t\t\t++s;\n\t\t\tcontinue;\n\t\tcase '.':\n\t\t\tswitch (s[1]) {\n\t\t\tcase '\\0': case '/':\n\t\t\t\ts += 2;\n\t\t\t\tcontinue;\n\t\t\tcase '.':\n\t\t\t\tif (s[2] != '/' && s[2] != '\\0')\n\t\t\t\t\tbreak;\n\t\t\t\tif (n > 0) {\n\t\t\t\t\td = component[--n];\n\t\t\t\t} else {\n\t\t\t\t\t*d++ = s[0];\n\t\t\t\t\t*d++ = s[1];\n\t\t\t\t\t*d++ = s[2];\n\t\t\t\t}\n\t\t\t\ts += 3;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\t\tif (n == LEN(component))\n\t\t\tfatal(\"path has too many components: %s\", path->s);\n\t\tcomponent[n++] = d;\n\t\twhile (*s != '/' && *s != '\\0')\n\t\t\t*d++ = *s++;\n\t\t*d++ = *s++;\n\t}\n\tif (d == path->s) {\n\t\t*d++ = '.';\n\t\t*d = '\\0';\n\t} else {\n\t\t*--d = '\\0';\n\t}\n\tpath->n = d - path->s;\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200502,
        "reasoning": "The `writefile` function is vulnerable to a NULL pointer dereference because it directly uses `s->s` and `s->n` without verifying that the `struct string *s` pointer itself is not NULL. Although the commit message discusses checks for `rspfile` and `rspfile_content`, it highlights a scenario where `s` could originate from an untrusted source (edge or global environment) and therefore be NULL, leading to a crash when attempting to access its members.",
        "func": "writefile(const char *name, struct string *s)\n{\n\tFILE *f;\n\tint ret;\n\n\tf = fopen(name, \"w\");\n\tif (!f) {\n\t\twarn(\"open %s:\", name);\n\t\treturn -1;\n\t}\n\tret = 0;\n\tif (fwrite(s->s, 1, s->n, f) != s->n || fflush(f) != 0) {\n\t\twarn(\"write %s:\", name);\n\t\tret = -1;\n\t}\n\tfclose(f);\n\n\treturn ret;\n}",
        "commit_message": "util: Check for NULL string in writefile\n\nThis check was there previously, but was removed in f549b757 with\nthe addition of a check during parse that every rule has rspfile\nif and only if it has rspfile_content. However, this fails to\nconsider the possibility of those variables coming from the edge\nor global environment. So, re-add the check.\n\nFixes #67.",
        "cve_desc": "samurai 1.2 has a NULL pointer dereference in writefile() in util.c via a crafted build file.",
        "target": 1
      }
    ]
  },
  "selinux": {
    "0": [],
    "1": [
      {
        "idx": 211171,
        "reasoning": "This code is vulnerable to a use-after-free because the `cil_reset_classperms_list` function likely frees the memory associated with `cp->classperms` without informing other parts of the code that rely on it. Subsequently, the `__cil_verify_classperms` function (and others) attempts to access this freed memory, leading to the observed heap-use-after-free error as described in the CVE.",
        "func": "static void cil_reset_classpermission(struct cil_classpermission *cp)\n{\n\tif (cp == NULL) {\n\t\treturn;\n\t}\n\n\tcil_reset_classperms_list(cp->classperms);\n}",
        "commit_message": "libsepol/cil: Destroy classperms list when resetting classpermission\n\nNicolas Iooss reports:\n  A few months ago, OSS-Fuzz found a crash in the CIL compiler, which\n  got reported as\n  https://bugs.chromium.org/p/oss-fuzz/issues/detail?id=28648 (the title\n  is misleading, or is caused by another issue that conflicts with the\n  one I report in this message). Here is a minimized CIL policy which\n  reproduces the issue:\n\n  (class CLASS (PERM))\n  (classorder (CLASS))\n  (sid SID)\n  (sidorder (SID))\n  (user USER)\n  (role ROLE)\n  (type TYPE)\n  (category CAT)\n  (categoryorder (CAT))\n  (sensitivity SENS)\n  (sensitivityorder (SENS))\n  (sensitivitycategory SENS (CAT))\n  (allow TYPE self (CLASS (PERM)))\n  (roletype ROLE TYPE)\n  (userrole USER ROLE)\n  (userlevel USER (SENS))\n  (userrange USER ((SENS)(SENS (CAT))))\n  (sidcontext SID (USER ROLE TYPE ((SENS)(SENS))))\n\n  (classpermission CLAPERM)\n\n  (optional OPT\n      (roletype nonexistingrole nonexistingtype)\n      (classpermissionset CLAPERM (CLASS (PERM)))\n  )\n\n  The CIL policy fuzzer (which mimics secilc built with clang Address\n  Sanitizer) reports:\n\n  ==36541==ERROR: AddressSanitizer: heap-use-after-free on address\n  0x603000004f98 at pc 0x56445134c842 bp 0x7ffe2a256590 sp\n  0x7ffe2a256588\n  READ of size 8 at 0x603000004f98 thread T0\n      #0 0x56445134c841 in __cil_verify_classperms\n  /selinux/libsepol/src/../cil/src/cil_verify.c:1620:8\n      #1 0x56445134a43e in __cil_verify_classpermission\n  /selinux/libsepol/src/../cil/src/cil_verify.c:1650:9\n      #2 0x56445134a43e in __cil_pre_verify_helper\n  /selinux/libsepol/src/../cil/src/cil_verify.c:1715:8\n      #3 0x5644513225ac in cil_tree_walk_core\n  /selinux/libsepol/src/../cil/src/cil_tree.c:272:9\n      #4 0x564451322ab1 in cil_tree_walk\n  /selinux/libsepol/src/../cil/src/cil_tree.c:316:7\n      #5 0x5644513226af in cil_tree_walk_core\n  /selinux/libsepol/src/../cil/src/cil_tree.c:284:9\n      #6 0x564451322ab1 in cil_tree_walk\n  /selinux/libsepol/src/../cil/src/cil_tree.c:316:7\n      #7 0x5644512b88fd in cil_pre_verify\n  /selinux/libsepol/src/../cil/src/cil_post.c:2510:7\n      #8 0x5644512b88fd in cil_post_process\n  /selinux/libsepol/src/../cil/src/cil_post.c:2524:7\n      #9 0x5644511856ff in cil_compile\n  /selinux/libsepol/src/../cil/src/cil.c:564:7\n\nThe classperms list of a classpermission rule is created and filled\nin when classpermissionset rules are processed, so it doesn't own any\npart of the list and shouldn't retain any of it when it is reset.\n\nDestroy the classperms list (without destroying the data in it)  when\nresetting a classpermission rule.\n\nReported-by: Nicolas Iooss <nicolas.iooss@m4x.org>\nSigned-off-by: James Carter <jwcart2@gmail.com>",
        "cve_desc": "The CIL compiler in SELinux 3.2 has a use-after-free in __cil_verify_classperms (called from __cil_verify_classpermission and __cil_pre_verify_helper).",
        "target": 1
      },
      {
        "idx": 214915,
        "reasoning": "This code is vulnerable because it destroys the `classperms` list within `cil_reset_perm` without ensuring no other part of the SELinux system is still referencing or using the data *pointed to* by that list\u2014a classic use-after-free scenario.  Given the CVE description, specifically mentioning `__cil_verify_classperms` and `hashtab_map`, it's highly probable these functions (or others) continue to access the freed `classperms` data, leading to a crash or potential security compromise.\n\n\n\n",
        "func": "static void cil_reset_perm(struct cil_perm *perm)\n{\n\tcil_reset_classperms_list(perm->classperms);\n}",
        "commit_message": "libsepol/cil: Destroy classperm list when resetting map perms\n\nMap perms share the same struct as regular perms, but only the\nmap perms use the classperms field. This field is a pointer to a\nlist of classperms that is created and added to when resolving\nclassmapping rules, so the map permission doesn't own any of the\ndata in the list and this list should be destroyed when the AST is\nreset.\n\nWhen resetting a perm, destroy the classperms list without destroying\nthe data in the list.\n\nSigned-off-by: James Carter <jwcart2@gmail.com>",
        "cve_desc": "The CIL compiler in SELinux 3.2 has a use-after-free in __cil_verify_classperms (called from __verify_map_perm_classperms and hashtab_map).",
        "target": 1
      }
    ]
  },
  "serenity": {
    "0": [],
    "1": []
  },
  "server": {
    "0": [
      {
        "idx": 503114,
        "reasoning": "This code snippet is not related to the commit message describing an SSL hostname validation issue. The provided code focuses on closing a MySQL connection and doesn't involve any SSL/TLS certificate verification processes, therefore it's not vulnerable to the described bug.\n\n\n\n",
        "func": "void STDCALL mysql_close_slow_part(MYSQL *mysql)\n{\n  /* If connection is still up, send a QUIT message */\n  if (mysql->net.vio != 0)\n  {\n    free_old_query(mysql);\n    mysql->status=MYSQL_STATUS_READY; /* Force command */\n    mysql->reconnect=0;\n    simple_command(mysql,COM_QUIT,(uchar*) 0,0,1);\n    end_server(mysql);\t\t\t/* Sets mysql->net.vio= 0 */\n  }\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 0
      },
      {
        "idx": 503115,
        "reasoning": "This code snippet is not vulnerable because it simply retrieves error messages associated with a MySQL connection and doesn't handle SSL certificate validation or hostname checking\u2014the focus of the commit message's fix. The commit message details a fix for `ssl_verify_server_cert()`, a function not present in the provided code, indicating this snippet is unrelated to the identified vulnerability.\n\n\n\n",
        "func": "const char * STDCALL mysql_error(MYSQL *mysql)\n{\n  return mysql ? mysql->net.last_error : mysql_server_last_error;\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 0
      },
      {
        "idx": 503116,
        "reasoning": "This code snippet is not vulnerable because it simply retrieves a socket descriptor and doesn't handle any SSL/TLS or certificate validation logic. The commit message and description relate to changes in `ssl_verify_server_cert()`, a function not present in the provided code, indicating the vulnerability fix is elsewhere in the codebase.\n\n\n\n",
        "func": "mysql_get_socket(const MYSQL *mysql)\n{\n  if (mysql->net.vio)\n    return mysql->net.vio->sd;\n  return INVALID_SOCKET;\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 0
      },
      {
        "idx": 503117,
        "reasoning": "This code snippet is not related to the commit message regarding SSL certificate hostname validation, and focuses on fetching lengths of strings within a MySQL result set. Therefore, it doesn't present any vulnerabilities related to the described SSL issue and is not flagged as vulnerable based on the provided context.\n\n\n\n",
        "func": "static void cli_fetch_lengths(ulong *to, MYSQL_ROW column,\n\t\t\t      unsigned int field_count)\n{ \n  ulong *prev_length;\n  char *start=0;\n  MYSQL_ROW end;\n\n  prev_length=0;\t\t\t\t/* Keep gcc happy */\n  for (end=column + field_count + 1 ; column != end ; column++, to++)\n  {\n    if (!*column)\n    {\n      *to= 0;\t\t\t\t\t/* Null */\n      continue;\n    }\n    if (start)\t\t\t\t\t/* Found end of prev string */\n      *prev_length= (ulong) (*column-start-1);\n    start= *column;\n    prev_length= to;\n  }\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 0
      },
      {
        "idx": 503118,
        "reasoning": "This code is likely safe with respect to the described fix. The commit message explicitly states the bug was in `ssl_verify_server_cert()` and the code snippet shows that function is called *after* the SSL connection is established, utilizing the updated hostname validation logic from OpenSSL's wiki, addressing the original vulnerability reported by Alex Gaynor.",
        "func": "static int send_client_reply_packet(MCPVIO_EXT *mpvio,\n                                    const uchar *data, int data_len)\n{\n  MYSQL *mysql= mpvio->mysql;\n  NET *net= &mysql->net;\n  char *buff, *end;\n\n  /* see end= buff+32 below, fixed size of the packet is 32 bytes */\n  buff= my_alloca(33 + USERNAME_LENGTH + data_len + NAME_LEN + NAME_LEN);\n  \n  mysql->client_flag|= mysql->options.client_flag;\n  mysql->client_flag|= CLIENT_CAPABILITIES;\n\n  if (mysql->client_flag & CLIENT_MULTI_STATEMENTS)\n    mysql->client_flag|= CLIENT_MULTI_RESULTS;\n\n#if defined(HAVE_OPENSSL) && !defined(EMBEDDED_LIBRARY)\n  if (mysql->options.use_ssl)\n    mysql->client_flag|= CLIENT_SSL;\n#endif /* HAVE_OPENSSL && !EMBEDDED_LIBRARY*/\n\n  if (mpvio->db)\n    mysql->client_flag|= CLIENT_CONNECT_WITH_DB;\n\n  /* Remove options that server doesn't support */\n  mysql->client_flag= mysql->client_flag &\n                       (~(CLIENT_COMPRESS | CLIENT_SSL | CLIENT_PROTOCOL_41) \n                       | mysql->server_capabilities);\n\n#ifndef HAVE_COMPRESS\n  mysql->client_flag&= ~CLIENT_COMPRESS;\n#endif\n\n  if (mysql->client_flag & CLIENT_PROTOCOL_41)\n  {\n    /* 4.1 server and 4.1 client has a 32 byte option flag */\n    int4store(buff,mysql->client_flag);\n    int4store(buff+4, net->max_packet_size);\n    buff[8]= (char) mysql->charset->number;\n    bzero(buff+9, 32-9);\n    end= buff+32;\n  }\n  else\n  {\n    int2store(buff, mysql->client_flag);\n    int3store(buff+2, net->max_packet_size);\n    end= buff+5;\n  }\n#ifdef HAVE_OPENSSL\n\n  /*\n     If client uses ssl and client also has to verify the server\n     certificate, a ssl connection is required.\n     If the server does not support ssl, we abort the connection.\n  */\n  if (mysql->options.use_ssl &&\n      (mysql->client_flag & CLIENT_SSL_VERIFY_SERVER_CERT) &&\n      !(mysql->server_capabilities & CLIENT_SSL))\n  {\n    set_mysql_extended_error(mysql, CR_SSL_CONNECTION_ERROR, unknown_sqlstate,\n                             ER(CR_SSL_CONNECTION_ERROR),\n                             \"SSL is required, but the server does not \"\n                             \"support it\");\n    goto error;\n  }\n\n  if (mysql->client_flag & CLIENT_SSL)\n  {\n    /* Do the SSL layering. */\n    struct st_mysql_options *options= &mysql->options;\n    struct st_VioSSLFd *ssl_fd;\n    enum enum_ssl_init_error ssl_init_error;\n    const char *cert_error;\n    unsigned long ssl_error;\n\n    /*\n      Send mysql->client_flag, max_packet_size - unencrypted otherwise\n      the server does not know we want to do SSL\n    */\n    if (my_net_write(net, (uchar*)buff, (size_t) (end-buff)) || net_flush(net))\n    {\n      set_mysql_extended_error(mysql, CR_SERVER_LOST, unknown_sqlstate,\n                               ER(CR_SERVER_LOST_EXTENDED),\n                               \"sending connection information to server\",\n                               errno);\n      goto error;\n    }\n\n    /* Create the VioSSLConnectorFd - init SSL and load certs */\n    if (!(ssl_fd= new_VioSSLConnectorFd(options->ssl_key,\n                                        options->ssl_cert,\n                                        options->ssl_ca,\n                                        options->ssl_capath,\n                                        options->ssl_cipher,\n                                        &ssl_init_error)))\n    {\n      set_mysql_extended_error(mysql, CR_SSL_CONNECTION_ERROR, unknown_sqlstate,\n                               ER(CR_SSL_CONNECTION_ERROR), sslGetErrString(ssl_init_error));\n      goto error;\n    }\n    mysql->connector_fd= (unsigned char *) ssl_fd;\n\n    /* Connect to the server */\n    DBUG_PRINT(\"info\", (\"IO layer change in progress...\"));\n    if (sslconnect(ssl_fd, net->vio,\n                   (long) (mysql->options.connect_timeout), &ssl_error))\n    {    \n      char buf[512];\n      ERR_error_string_n(ssl_error, buf, 512);\n      buf[511]= 0;\n      set_mysql_extended_error(mysql, CR_SSL_CONNECTION_ERROR, unknown_sqlstate,\n                               ER(CR_SSL_CONNECTION_ERROR),\n                               buf);\n      goto error;\n    }\n    DBUG_PRINT(\"info\", (\"IO layer change done!\"));\n\n    /* Verify server cert */\n    if ((mysql->client_flag & CLIENT_SSL_VERIFY_SERVER_CERT) &&\n        ssl_verify_server_cert(net->vio, mysql->host, &cert_error))\n    {\n      set_mysql_extended_error(mysql, CR_SSL_CONNECTION_ERROR, unknown_sqlstate,\n                               ER(CR_SSL_CONNECTION_ERROR), cert_error);\n      goto error;\n    }\n  }\n#endif /* HAVE_OPENSSL */\n\n  DBUG_PRINT(\"info\",(\"Server version = '%s'  capabilites: %lu  status: %u  client_flag: %lu\",\n\t\t     mysql->server_version, mysql->server_capabilities,\n\t\t     mysql->server_status, mysql->client_flag));\n\n  /* This needs to be changed as it's not useful with big packets */\n  if (mysql->user[0])\n    strmake(end, mysql->user, USERNAME_LENGTH);\n  else\n    read_user_name(end);\n\n  /* We have to handle different version of handshake here */\n  DBUG_PRINT(\"info\",(\"user: %s\",end));\n  end= strend(end) + 1;\n  if (data_len)\n  {\n    if (mysql->server_capabilities & CLIENT_SECURE_CONNECTION)\n    {\n      *end++= data_len;\n      memcpy(end, data, data_len);\n      end+= data_len;\n    }\n    else\n    {\n      DBUG_ASSERT(data_len == SCRAMBLE_LENGTH_323 + 1); /* incl. \\0 at the end */\n      memcpy(end, data, data_len);\n      end+= data_len;\n    }\n  }\n  else\n    *end++= 0;\n\n  /* Add database if needed */\n  if (mpvio->db && (mysql->server_capabilities & CLIENT_CONNECT_WITH_DB))\n  {\n    end= strmake(end, mpvio->db, NAME_LEN) + 1;\n    mysql->db= my_strdup(mpvio->db, MYF(MY_WME));\n  }\n\n  if (mysql->server_capabilities & CLIENT_PLUGIN_AUTH)\n    end= strmake(end, mpvio->plugin->name, NAME_LEN) + 1;\n\n  /* Write authentication package */\n  if (my_net_write(net, (uchar*) buff, (size_t) (end-buff)) || net_flush(net))\n  {\n    set_mysql_extended_error(mysql, CR_SERVER_LOST, unknown_sqlstate,\n                             ER(CR_SERVER_LOST_EXTENDED),\n                             \"sending authentication information\",\n                             errno);\n    goto error;\n  }\n  my_afree(buff);\n  return 0;\n  \nerror:\n  my_afree(buff);\n  return 1;\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 216567,
        "reasoning": "This code is vulnerable to a man-in-the-middle attack because it only checks the Common Name (CN) field within the certificate's subject, and specifically searches for `/CN=`, failing to properly validate against the subjectAltName field or handle maliciously crafted CNs like `/OU=/CN=bar.com/CN=foo.com`. This allows an attacker to present a certificate with a crafted CN that bypasses the hostname check, effectively spoofing the server.",
        "func": "static int ssl_verify_server_cert(Vio *vio, const char* server_hostname, const char **errptr)\n{\n  SSL *ssl;\n  X509 *server_cert;\n  char *cp1, *cp2;\n  char *buf;\n  DBUG_ENTER(\"ssl_verify_server_cert\");\n  DBUG_PRINT(\"enter\", (\"server_hostname: %s\", server_hostname));\n\n  if (!(ssl= (SSL*)vio->ssl_arg))\n  {\n    *errptr= \"No SSL pointer found\";\n    DBUG_RETURN(1);\n  }\n\n  if (!server_hostname)\n  {\n    *errptr= \"No server hostname supplied\";\n    DBUG_RETURN(1);\n  }\n\n  if (!(server_cert= SSL_get_peer_certificate(ssl)))\n  {\n    *errptr= \"Could not get server certificate\";\n    DBUG_RETURN(1);\n  }\n\n  if (X509_V_OK != SSL_get_verify_result(ssl))\n  {\n    *errptr= \"Failed to verify the server certificate\";\n    X509_free(server_cert);\n    DBUG_RETURN(1);\n  }\n  /*\n    We already know that the certificate exchanged was valid; the SSL library\n    handled that. Now we need to verify that the contents of the certificate\n    are what we expect.\n  */\n\n  buf= X509_NAME_oneline(X509_get_subject_name(server_cert), 0, 0);\n  X509_free (server_cert);\n\n  if (!buf)\n  {\n    *errptr= \"Out of memory\";\n    DBUG_RETURN(1);\n  }\n\n  DBUG_PRINT(\"info\", (\"hostname in cert: %s\", buf));\n  cp1= strstr(buf, \"/CN=\");\n  if (cp1)\n  {\n    cp1+= 4; /* Skip the \"/CN=\" that we found */\n    /* Search for next / which might be the delimiter for email */\n    cp2= strchr(cp1, '/');\n    if (cp2)\n      *cp2= '\\0';\n    DBUG_PRINT(\"info\", (\"Server hostname in cert: %s\", cp1));\n    if (!strcmp(cp1, server_hostname))\n    {\n      free(buf);\n      /* Success */\n      DBUG_RETURN(0);\n    }\n  }\n  *errptr= \"SSL certificate validation failure\";\n  free(buf);\n  DBUG_RETURN(1);\n}",
        "commit_message": "MDEV-9212 ssl-validate-cert incorrect hostname check\n\nReimplement ssl_verify_server_cert() using the logic\nfrom https://wiki.openssl.org/index.php/Hostname_validation\n\nThe bug was discovered by Alex Gaynor.",
        "cve_desc": "The ssl_verify_server_cert function in sql-common/client.c in MariaDB before 5.5.47, 10.0.x before 10.0.23, and 10.1.x before 10.1.10; Oracle MySQL 5.5.48 and earlier, 5.6.29 and earlier, and 5.7.11 and earlier; and Percona Server do not properly verify that the server hostname matches a domain name in the subject's Common Name (CN) or subjectAltName field of the X.509 certificate, which allows man-in-the-middle attackers to spoof SSL servers via a \"/CN=\" string in a field in a certificate, as demonstrated by \"/OU=/CN=bar.com/CN=foo.com.\"",
        "target": 1
      },
      {
        "idx": 216666,
        "reasoning": "The code is vulnerable because `list_add` modifies the `element->next` pointer within the loop while the loop is simultaneously iterating using `element->next`, leading to skipped elements and potential invalid memory access. This can result in a crash, as described in the CVE, because some `MYSQL` structures are left with dangling pointers, ultimately causing issues when those structures are later accessed.",
        "func": "static void mysql_prune_stmt_list(MYSQL *mysql)\n{\n  LIST *element= mysql->stmts;\n  LIST *pruned_list= 0;\n\n  for (; element; element= element->next)\n  {\n    MYSQL_STMT *stmt= (MYSQL_STMT *) element->data;\n    if (stmt->state != MYSQL_STMT_INIT_DONE)\n    {\n      stmt->mysql= 0;\n      stmt->last_errno= CR_SERVER_LOST;\n      strmov(stmt->last_error, ER(CR_SERVER_LOST));\n      strmov(stmt->sqlstate, unknown_sqlstate);\n    }\n    else\n    {\n      pruned_list= list_add(pruned_list, element);\n    }\n  }\n\n  mysql->stmts= pruned_list;\n}",
        "commit_message": "MDEV-11933 Wrong usage of linked list in mysql_prune_stmt_list\n\nmysql_prune_stmt_list() was walking the list following\nelement->next pointers, but inside the loop it was invoking\nlist_add(element) that modified element->next. So, mysql_prune_stmt_list()\nfailed to visit and reset all elements, and some of them were left\nwith pointers to invalid MYSQL.",
        "cve_desc": "Crash in libmysqlclient.so in Oracle MySQL before 5.6.21 and 5.7.x before 5.7.5 and MariaDB through 5.5.54, 10.0.x through 10.0.29, 10.1.x through 10.1.21, and 10.2.x through 10.2.3.",
        "target": 1
      },
      {
        "idx": 216708,
        "reasoning": "The code is vulnerable because the `WSREP_TO_ISOLATION_BEGIN` call is made within the `drop` block, specifically when dropping an event, potentially leading to DDL replication occurring *before* access control checks are fully enforced. This allows a malicious user with sufficient privileges to replicate DDL statements to cluster nodes even if they lack the necessary permissions, as highlighted in the CVE description regarding incorrect ordering of DDL replication and ACL checking.",
        "func": "Event_job_data::execute(THD *thd, bool drop)\n{\n  String sp_sql;\n#ifndef NO_EMBEDDED_ACCESS_CHECKS\n  Security_context event_sctx, *save_sctx= NULL;\n#endif\n  List<Item> empty_item_list;\n  bool ret= TRUE;\n\n  DBUG_ENTER(\"Event_job_data::execute\");\n\n  thd->reset_for_next_command();\n\n  /*\n    MySQL parser currently assumes that current database is either\n    present in THD or all names in all statements are fully specified.\n    And yet not fully specified names inside stored programs must be \n    be supported, even if the current database is not set:\n    CREATE PROCEDURE db1.p1() BEGIN CREATE TABLE t1; END//\n    -- in this example t1 should be always created in db1 and the statement\n    must parse even if there is no current database.\n\n    To support this feature and still address the parser limitation,\n    we need to set the current database here.\n    We don't have to call mysql_change_db, since the checks performed\n    in it are unnecessary for the purpose of parsing, and\n    mysql_change_db will be invoked anyway later, to activate the\n    procedure database before it's executed.\n  */\n  thd->set_db(dbname.str, dbname.length);\n\n  lex_start(thd);\n\n#ifndef NO_EMBEDDED_ACCESS_CHECKS\n  if (event_sctx.change_security_context(thd,\n                                         &definer_user, &definer_host,\n                                         &dbname, &save_sctx))\n  {\n    sql_print_error(\"Event Scheduler: \"\n                    \"[%s].[%s.%s] execution failed, \"\n                    \"failed to authenticate the user.\",\n                    definer.str, dbname.str, name.str);\n    goto end;\n  }\n#endif\n\n  if (check_access(thd, EVENT_ACL, dbname.str, NULL, NULL, 0, 0))\n  {\n    /*\n      This aspect of behavior is defined in the worklog,\n      and this is how triggers work too: if TRIGGER\n      privilege is revoked from trigger definer,\n      triggers are not executed.\n    */\n    sql_print_error(\"Event Scheduler: \"\n                    \"[%s].[%s.%s] execution failed, \"\n                    \"user no longer has EVENT privilege.\",\n                    definer.str, dbname.str, name.str);\n    goto end;\n  }\n\n  if (construct_sp_sql(thd, &sp_sql))\n    goto end;\n\n  /*\n    Set up global thread attributes to reflect the properties of\n    this Event. We can simply reset these instead of usual\n    backup/restore employed in stored programs since we know that\n    this is a top level statement and the worker thread is\n    allocated exclusively to execute this event.\n  */\n\n  thd->variables.sql_mode= sql_mode;\n  thd->variables.time_zone= time_zone;\n\n  thd->set_query(sp_sql.c_ptr_safe(), sp_sql.length());\n\n  {\n    Parser_state parser_state;\n    if (parser_state.init(thd, thd->query(), thd->query_length()))\n      goto end;\n\n    if (parse_sql(thd, & parser_state, creation_ctx))\n    {\n      sql_print_error(\"Event Scheduler: \"\n                      \"%serror during compilation of %s.%s\",\n                      thd->is_fatal_error ? \"fatal \" : \"\",\n                      (const char *) dbname.str, (const char *) name.str);\n      goto end;\n    }\n  }\n\n  {\n    sp_head *sphead= thd->lex->sphead;\n\n    DBUG_ASSERT(sphead);\n\n    sphead->m_flags|= sp_head::LOG_SLOW_STATEMENTS;\n    sphead->m_flags|= sp_head::LOG_GENERAL_LOG;\n\n    sphead->set_info(0, 0, &thd->lex->sp_chistics, sql_mode);\n    sphead->set_creation_ctx(creation_ctx);\n    sphead->optimize();\n\n    ret= sphead->execute_procedure(thd, &empty_item_list);\n    /*\n      There is no pre-locking and therefore there should be no\n      tables open and locked left after execute_procedure.\n    */\n  }\n\nend:\n  if (drop && !thd->is_fatal_error)\n  {\n    /*\n      We must do it here since here we're under the right authentication\n      ID of the event definer.\n    */\n    sql_print_information(\"Event Scheduler: Dropping %s.%s\",\n                          (const char *) dbname.str, (const char *) name.str);\n    /*\n      Construct a query for the binary log, to ensure the event is dropped\n      on the slave\n    */\n    if (construct_drop_event_sql(thd, &sp_sql))\n      ret= 1;\n    else\n    {\n      ulong saved_master_access;\n\n      thd->set_query(sp_sql.c_ptr_safe(), sp_sql.length());\n\n      /*\n        NOTE: even if we run in read-only mode, we should be able to lock\n        the mysql.event table for writing. In order to achieve this, we\n        should call mysql_lock_tables() under the super-user.\n\n        Same goes for transaction access mode.\n        Temporarily reset it to read-write.\n      */\n\n      saved_master_access= thd->security_ctx->master_access;\n      thd->security_ctx->master_access |= SUPER_ACL;\n      bool save_tx_read_only= thd->tx_read_only;\n      thd->tx_read_only= false;\n\n      if (WSREP(thd))\n      {\n        thd->lex->sql_command = SQLCOM_DROP_EVENT;\n        WSREP_TO_ISOLATION_BEGIN(WSREP_MYSQL_DB, NULL, NULL);\n      }\n\n      ret= Events::drop_event(thd, dbname, name, FALSE);\n\n      WSREP_TO_ISOLATION_END;\n\n#ifdef WITH_WSREP\n  error:\n#endif\n      thd->tx_read_only= save_tx_read_only;\n      thd->security_ctx->master_access= saved_master_access;\n    }\n  }\n#ifndef NO_EMBEDDED_ACCESS_CHECKS\n  if (save_sctx)\n    event_sctx.restore_security_context(thd, save_sctx);\n#endif\n  thd->lex->unit.cleanup();\n  thd->end_statement();\n  thd->cleanup_after_query();\n  /* Avoid races with SHOW PROCESSLIST */\n  thd->reset_query();\n\n  DBUG_PRINT(\"info\", (\"EXECUTED %s.%s  ret: %d\", dbname.str, name.str, ret));\n\n  DBUG_RETURN(ret);\n}",
        "commit_message": "MW-416 DDL replication moved after acl checking\n\ngalera_events test shows a regression with the original fix for MW-416\nReason was that Events::drop_event() can be called also from inside event\nexecution, and there we have a speacial treatment for event, which executes\n\"DROP EVENT\" statement, and runs TOI replication inside the event processing body.\nThis resulted in executing WSREP_TO_ISOLATION two times for such DROP EVENT statement.\nFix is to call WSREP_TO_ISOLATION_BEGIN only in Events::drop_event()",
        "cve_desc": "sql/event_data_objects.cc in MariaDB before 10.1.30 and 10.2.x before 10.2.10 and Percona XtraDB Cluster before 5.6.37-26.21-3 and 5.7.x before 5.7.19-29.22-3 allows remote authenticated users with SQL access to bypass intended access restrictions and replicate data definition language (DDL) statements to cluster nodes by leveraging incorrect ordering of DDL replication and ACL checking.",
        "target": 1
      },
      {
        "idx": 216943,
        "reasoning": "This code is vulnerable because returning `0` (a null pointer) from `get_tmp_table_field()` when a temporary field is expected can lead to a crash in `Create_tmp_table::finalize` as described in the CVE. The commit message explicitly states the removal of a prohibition related to temporary field creation, reintroducing a condition that previously caused a server crash when handling specific SQL statements\u2014effectively reverting a fix for MDEV-10780/MDEV-11265 and recreating the DoS vulnerability.",
        "func": "  Field *get_tmp_table_field() { return 0; }",
        "commit_message": "MDEV-26423 MariaDB server crash in Create_tmp_table::finalize\n\nRemoved prohibition of creating temporary field of Item_default_value\n(added by mistake by 1d9b043a1f5db7ff229d5200652cff7a78ea6266 fix of\nMDEV-10780 and MDEV-11265).",
        "cve_desc": "An issue in the component Create_tmp_table::finalize of MariaDB Server v10.7 and below was discovered to allow attackers to cause a Denial of Service (DoS) via specially crafted SQL statements.",
        "target": 1
      },
      {
        "idx": 216944,
        "reasoning": "The vulnerability lies in the discrepancy between `maybe_null` being set to 0 for table-less subqueries and the potential for these subqueries to actually return NULL, leading to a crash in `Type_handler_decimal_result::make_sort_key_part()` as described in the commit message. This crash, triggered by specially crafted SQL statements involving `ORDER BY` with such subqueries, aligns with the CVE description of a Denial of Service due to improper handling of `my_decimal` types.\n\n\n\n",
        "func": "bool Item_singlerow_subselect::fix_length_and_dec()\n{\n  if ((max_columns= engine->cols()) == 1)\n  {\n    if (engine->fix_length_and_dec(row= &value))\n      return TRUE;\n  }\n  else\n  {\n    if (!(row= (Item_cache**) current_thd->alloc(sizeof(Item_cache*) *\n                                                 max_columns)) ||\n        engine->fix_length_and_dec(row))\n      return TRUE;\n    value= *row;\n  }\n  unsigned_flag= value->unsigned_flag;\n  /*\n    If there are not tables in subquery then ability to have NULL value\n    depends on SELECT list (if single row subquery have tables then it\n    always can be NULL if there are not records fetched).\n  */\n  if (engine->no_tables())\n    maybe_null= engine->may_be_null();\n  else\n  {\n    for (uint i= 0; i < max_columns; i++)\n      row[i]->maybe_null= TRUE;\n  }\n  return FALSE;\n}",
        "commit_message": "MDEV-25994: Crash with union of my_decimal type in ORDER BY clause\n\nWhen single-row subquery fails with \"Subquery reutrns more than 1 row\"\nerror, it will raise an error and return NULL.\n\nOn the other hand, Item_singlerow_subselect sets item->maybe_null=0\nfor table-less subqueries like \"(SELECT not_null_value)\"  (*)\n\nThis discrepancy (item with maybe_null=0 returning NULL) causes the\ncode in Type_handler_decimal_result::make_sort_key_part() to crash.\n\nFixed this by allowing inference (*) only when the subquery is NOT a\nUNION.",
        "cve_desc": "An issue in the component my_decimal::operator= of MariaDB Server v10.6.3 and below was discovered to allow attackers to cause a Denial of Service (DoS) via specially crafted SQL statements.",
        "target": 1
      }
    ]
  },
  "skiboot": {
    "0": [],
    "1": []
  },
  "sleuthkit": {
    "0": [
      {
        "idx": 69927,
        "reasoning": "This code snippet addresses a fix for CVE-2018-19497, indicating a previous vulnerability was mitigated. The code safely closes a file and frees allocated memory associated with an attribute file structure, with null checks to prevent crashes, and doesn't introduce any new obvious vulnerabilities based on the provided context.\n\n\n\n",
        "func": "close_attr_file(ATTR_FILE_T * attr_file)\n{\n    if (attr_file == NULL) {\n        tsk_error_set_errno(TSK_ERR_FS_READ);\n        tsk_error_set_errstr(\"close_attr_file: NULL attr_file arg\");\n        return 1;\n    }\n\n    if (attr_file->file != NULL) {\n        tsk_fs_file_close(attr_file->file);\n        attr_file->file = NULL;\n    }\n\n    free(attr_file->header);\n    attr_file->header = NULL;\n\n    attr_file->rootNode = 0;\n    attr_file->nodeSize = 0;\n    return 0;\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 0
      },
      {
        "idx": 69928,
        "reasoning": "This code snippet is safe and addresses a known vulnerability (CVE-2018-19497) by correctly converting a 32-bit integer (`cnid`) into a byte array in network byte order (big-endian). The commit message explicitly states it *fixes* the CVE, indicating the previous implementation was likely vulnerable to issues stemming from incorrect byte ordering when handling network data, and this code resolves that.",
        "func": "cnid_to_array(uint32_t cnid, uint8_t array[4])\n{\n    array[3] = (cnid >> 0) & 0xff;\n    array[2] = (cnid >> 8) & 0xff;\n    array[1] = (cnid >> 16) & 0xff;\n    array[0] = (cnid >> 24) & 0xff;\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 0
      },
      {
        "idx": 69929,
        "reasoning": "This code addresses CVE-2018-19497 by attempting to safely append error information to a fixed-size buffer (`TSK_ERROR_STRING_MAX_LENGTH`). The `snprintf` and `vsnprintf` calls with length limiting arguments prevent buffer overflows, mitigating the vulnerability described in the CVE, therefore the code is not vulnerable.",
        "func": "error_detected(uint32_t errnum, char *errstr, ...)\n{\n    va_list args;\n\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr = errInfo->errstr;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = errnum;\n        else {\n            size_t sl = strlen(errstr);\n            snprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                \" Next errnum: 0x%x \", errnum);\n        }\n        if (errstr != NULL) {\n            size_t sl = strlen(loc_errstr);\n            vsnprintf(loc_errstr + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n\n    va_end(args);\n\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 0
      },
      {
        "idx": 69930,
        "reasoning": "This code addresses CVE-2018-19497 by ensuring `vsnprintf` doesn't write beyond the bounds of `errInfo->errstr2` through careful length calculation (`TSK_ERROR_STRING_MAX_LENGTH - sl`). The check `if (errstr != NULL)` prevents a potential null pointer dereference and ensures `vsnprintf` is only called when a custom error message is provided, further enhancing safety.",
        "func": "error_returned(char *errstr, ...)\n{\n    va_list args;\n    va_start(args, errstr);\n\n    {\n        TSK_ERROR_INFO *errInfo = tsk_error_get_info();\n        char *loc_errstr2 = errInfo->errstr2;\n\n        if (errInfo->t_errno == 0)\n            errInfo->t_errno = TSK_ERR_AUX_GENERIC;\n        if (errstr != NULL) {\n            size_t sl = strlen(loc_errstr2);\n            vsnprintf(loc_errstr2 + sl, TSK_ERROR_STRING_MAX_LENGTH - sl,\n                errstr, args);\n        }\n    }\n    va_end(args);\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 0
      },
      {
        "idx": 69931,
        "reasoning": "This code is likely safe and the fix addresses a previously identified vulnerability (CVE-2018-19497) rather than introducing a new one. The function correctly frees allocated memory for a resource descriptor and recursively calls itself to handle the remaining descriptors, preventing memory leaks and ensuring proper cleanup\u2014a common mitigation for the addressed CVE.\n\n\n\n",
        "func": "free_res_descriptor(RES_DESCRIPTOR * rd)\n{\n    RES_DESCRIPTOR *nxt;\n\n    if (rd == NULL)\n        return;\n    nxt = rd->next;\n    free(rd->name);\n    free(rd);\n    free_res_descriptor(nxt);   // tail recursive\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3495,
        "reasoning": "The code is vulnerable because it doesn't sufficiently validate the `keylen` calculated from `tsk_getu16` within the B-tree traversal, potentially allowing an attacker to craft a file system image with a maliciously large key length. This oversized `keylen` can lead to an out-of-bounds read when accessing `node[rec_off + keylen]` as described in the CVE, ultimately causing a denial of service via a segmentation fault.",
        "func": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                 key = (hfs_btree_key_cat *) & node[rec_off];\n \n                 keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                     tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                     tsk_error_set_errstr\n                         (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                     free(node);\n                     return 1;\n                 }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    break;\n                }\n            }\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                int keylen;\n\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}\n",
        "commit_message": "Merge pull request #1374 from JordyZomer/develop\n\nFix CVE-2018-19497.",
        "cve_desc": "In The Sleuth Kit (TSK) through 4.6.4, hfs_cat_traverse in tsk/fs/hfs.c does not properly determine when a key length is too large, which allows attackers to cause a denial of service (SEGV on unknown address with READ memory access in a tsk_getu16 call in hfs_dir_open_meta_cb in tsk/fs/hfs_dent.c).",
        "target": 1
      },
      {
        "idx": 10691,
        "reasoning": "This code is vulnerable to an integer overflow when calculating `keylen` because `tsk_getu16` returns an unsigned 16-bit integer, and if `key->key_len` is a large value (like 65535), adding 2 to it can wrap around, resulting in a smaller value than expected. This smaller `keylen` bypasses a crucial size check (`if (keylen > nodesize)`), leading to a subsequent out-of-bounds read when accessing memory based on this incorrect length, ultimately causing a crash as demonstrated by the AddressSanitizer report.",
        "func": "hfs_cat_traverse(HFS_INFO * hfs,\n    TSK_HFS_BTREE_CB a_cb, void *ptr)\n{\n    TSK_FS_INFO *fs = &(hfs->fs_info);\n    uint32_t cur_node;          /* node id of the current node */\n    char *node;\n\n    uint16_t nodesize;\n    uint8_t is_done = 0;\n\n    tsk_error_reset();\n\n    nodesize = tsk_getu16(fs->endian, hfs->catalog_header.nodesize);\n    if ((node = (char *) tsk_malloc(nodesize)) == NULL)\n        return 1;\n\n    /* start at root node */\n    cur_node = tsk_getu32(fs->endian, hfs->catalog_header.rootNode);\n\n    /* if the root node is zero, then the extents btree is empty */\n    /* if no files have overflow extents, the Extents B-tree still\n       exists on disk, but is an empty B-tree containing only\n       the header node */\n    if (cur_node == 0) {\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: \"\n                \"empty extents btree\\n\");\n        free(node);\n        return 1;\n    }\n\n    if (tsk_verbose)\n        tsk_fprintf(stderr, \"hfs_cat_traverse: starting at \"\n            \"root node %\" PRIu32 \"; nodesize = %\"\n            PRIu16 \"\\n\", cur_node, nodesize);\n\n    /* Recurse down to the needed leaf nodes and then go forward */\n    is_done = 0;\n    while (is_done == 0) {\n        TSK_OFF_T cur_off;      /* start address of cur_node */\n        uint16_t num_rec;       /* number of records in this node */\n        ssize_t cnt;\n        hfs_btree_node *node_desc;\n\n        // sanity check\n        if (cur_node > tsk_getu32(fs->endian,\n                hfs->catalog_header.totalNodes)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n                (\"hfs_cat_traverse: Node %d too large for file\", cur_node);\n            free(node);\n            return 1;\n        }\n\n        // read the current node\n        cur_off = cur_node * nodesize;\n        cnt = tsk_fs_attr_read(hfs->catalog_attr, cur_off,\n            node, nodesize, 0);\n        if (cnt != nodesize) {\n            if (cnt >= 0) {\n                tsk_error_reset();\n                tsk_error_set_errno(TSK_ERR_FS_READ);\n            }\n            tsk_error_set_errstr2\n                (\"hfs_cat_traverse: Error reading node %d at offset %\"\n                PRIuOFF, cur_node, cur_off);\n            free(node);\n            return 1;\n        }\n\n        // process the header / descriptor\n        if (nodesize < sizeof(hfs_btree_node)) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr\n            (\"hfs_cat_traverse: Node size %d is too small to be valid\", nodesize);\n            free(node);\n            return 1;\n        }\n        node_desc = (hfs_btree_node *) node;\n        num_rec = tsk_getu16(fs->endian, node_desc->num_rec);\n\n        if (tsk_verbose)\n            tsk_fprintf(stderr, \"hfs_cat_traverse: node %\" PRIu32\n                \" @ %\" PRIu64 \" has %\" PRIu16 \" records\\n\",\n                cur_node, cur_off, num_rec);\n\n        if (num_rec == 0) {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: zero records in node %\"\n                PRIu32, cur_node);\n            free(node);\n            return 1;\n        }\n\n        /* With an index node, find the record with the largest key that is smaller\n         * to or equal to cnid */\n        if (node_desc->type == HFS_BT_NODE_TYPE_IDX) {\n            uint32_t next_node = 0;\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in index node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \" ; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n\n\n                /* save the info from this record unless it is too big */\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_IDX, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n                // record the closest entry\n                else if ((retval == HFS_BTREE_CB_IDX_LT)\n                    || (next_node == 0)) {\n                    hfs_btree_index_record *idx_rec;\n                    int keylen =\n                        2 + hfs_get_idxkeylen(hfs, tsk_getu16(fs->endian,\n                            key->key_len), &(hfs->catalog_header));\n                    if (rec_off + keylen > nodesize) {\n                        tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                        tsk_error_set_errstr\n                            (\"hfs_cat_traverse: offset of record and keylength %d in index node %d too large (%d vs %\"\n                            PRIu16 \")\", rec, cur_node,\n                            (int) rec_off + keylen, nodesize);\n                        free(node);\n                        return 1;\n                    }\n                    idx_rec =\n                        (hfs_btree_index_record *) & node[rec_off +\n                        keylen];\n                    next_node = tsk_getu32(fs->endian, idx_rec->childNode);\n                }\n                if (retval == HFS_BTREE_CB_IDX_EQGT) {\n                    // move down to the next node\n                    break;\n                }\n            }\n            // check if we found a relevant node\n            if (next_node == 0) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: did not find any keys in index node %d\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            // TODO: Handle multinode loops\n            if (next_node == cur_node) {\n                tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                tsk_error_set_errstr\n                    (\"hfs_cat_traverse: node %d references itself as next node\",\n                    cur_node);\n                is_done = 1;\n                break;\n            }\n            cur_node = next_node;\n        }\n\n        /* With a leaf, we look for the specific record. */\n        else if (node_desc->type == HFS_BT_NODE_TYPE_LEAF) {\n            int rec;\n\n            for (rec = 0; rec < num_rec; ++rec) {\n                size_t rec_off;\n                hfs_btree_key_cat *key;\n                uint8_t retval;\n                uint16_t keylen;\n\n                // get the record offset in the node\n                rec_off =\n                    tsk_getu16(fs->endian,\n                    &node[nodesize - (rec + 1) * 2]);\n                if (rec_off > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: offset of record %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, (int) rec_off,\n                        nodesize);\n                    free(node);\n                    return 1;\n                }\n                key = (hfs_btree_key_cat *) & node[rec_off];\n\n                keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len);\n                if ((keylen) > nodesize) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr\n                        (\"hfs_cat_traverse: length of key %d in leaf node %d too large (%d vs %\"\n                        PRIu16 \")\", rec, cur_node, keylen, nodesize);\n                    free(node);\n                    return 1;\n                }\n\n                /*\n                   if (tsk_verbose)\n                   tsk_fprintf(stderr,\n                   \"hfs_cat_traverse: record %\" PRIu16\n                   \"; keylen %\" PRIu16 \" (%\" PRIu32 \")\\n\", rec,\n                   tsk_getu16(fs->endian, key->key_len),\n                   tsk_getu32(fs->endian, key->parent_cnid));\n                 */\n                //                rec_cnid = tsk_getu32(fs->endian, key->file_id);\n\n                retval =\n                    a_cb(hfs, HFS_BT_NODE_TYPE_LEAF, key,\n                    cur_off + rec_off, ptr);\n                if (retval == HFS_BTREE_CB_LEAF_STOP) {\n                    is_done = 1;\n                    break;\n                }\n                else if (retval == HFS_BTREE_CB_ERR) {\n                    tsk_error_set_errno(TSK_ERR_FS_GENFS);\n                    tsk_error_set_errstr2\n                        (\"hfs_cat_traverse: Callback returned error\");\n                    free(node);\n                    return 1;\n                }\n            }\n\n            // move right to the next node if we got this far\n            if (is_done == 0) {\n                cur_node = tsk_getu32(fs->endian, node_desc->flink);\n                if (cur_node == 0) {\n                    is_done = 1;\n                }\n                if (tsk_verbose)\n                    tsk_fprintf(stderr,\n                        \"hfs_cat_traverse: moving forward to next leaf\");\n            }\n        }\n        else {\n            tsk_error_set_errno(TSK_ERR_FS_GENFS);\n            tsk_error_set_errstr(\"hfs_cat_traverse: btree node %\" PRIu32\n                \" (%\" PRIu64 \") is neither index nor leaf (%\" PRIu8 \")\",\n                cur_node, cur_off, node_desc->type);\n            free(node);\n            return 1;\n        }\n    }\n    free(node);\n    return 0;\n}",
        "commit_message": "hfs: fix keylen check in hfs_cat_traverse()\n\nIf key->key_len is 65535, calculating \"uint16_t keylen' would\ncause an overflow:\n\n   uint16_t keylen;\n   ...\n   keylen = 2 + tsk_getu16(hfs->fs_info.endian, key->key_len)\n\nso the code bypasses the sanity check \"if (keylen > nodesize)\"\nwhich results in crash later:\n\n    ./toolfs/fstools/fls -b 512 -f hfs <image>\n    =================================================================\n    ==16==ERROR: AddressSanitizer: SEGV on unknown address 0x6210000256a4 (pc 0x00000054812b bp 0x7ffca548a8f0 sp 0x7ffca548a480 T0)\n    ==16==The signal is caused by a READ memory access.\n        #0 0x54812a in hfs_dir_open_meta_cb /fuzzing/sleuthkit/tsk/fs/hfs_dent.c:237:20\n        #1 0x51a96c in hfs_cat_traverse /fuzzing/sleuthkit/tsk/fs/hfs.c:1082:21\n        #2 0x547785 in hfs_dir_open_meta /fuzzing/sleuthkit/tsk/fs/hfs_dent.c:480:9\n        #3 0x50f57d in tsk_fs_dir_open_meta /fuzzing/sleuthkit/tsk/fs/fs_dir.c:290:14\n        #4 0x54af17 in tsk_fs_path2inum /fuzzing/sleuthkit/tsk/fs/ifind_lib.c:237:23\n        #5 0x522266 in hfs_open /fuzzing/sleuthkit/tsk/fs/hfs.c:6579:9\n        #6 0x508e89 in main /fuzzing/sleuthkit/tools/fstools/fls.cpp:267:19\n        #7 0x7f9daf67c2b0 in __libc_start_main (/lib/x86_64-linux-gnu/libc.so.6+0x202b0)\n        #8 0x41d679 in _start (/fuzzing/sleuthkit/tools/fstools/fls+0x41d679)\n\nMake 'keylen' int type to prevent the overflow and fix that.\nNow, I get proper error message instead of crash:\n    ./toolfs/fstools/fls -b 512 -f hfs <image>\n    General file system error (hfs_cat_traverse: length of key 3 in leaf node 1 too large (65537 vs 4096))",
        "cve_desc": "The Sleuth Kit 4.6.0 and earlier is affected by: Integer Overflow. The impact is: Opening crafted disk image triggers crash in tsk/fs/hfs_dent.c:237. The component is: Overflow in fls tool used on HFS image. Bug is in tsk/fs/hfs.c file in function hfs_cat_traverse() in lines: 952, 1062. The attack vector is: Victim must open a crafted HFS filesystem image.",
        "target": 1
      }
    ]
  },
  "slurm": {
    "0": [
      {
        "idx": 67010,
        "reasoning": "This code snippet is not directly related to the described vulnerability regarding insecure file path handling in `_prolog_error()`. The provided code simply allocates memory for a group ID list and doesn't involve any file path manipulation or interaction with potentially untrusted data that could lead to a security issue as described in the commit message and CVE.\n\n\n\n",
        "func": "_alloc_gids(int n, gid_t *gids)\n{\n\tgids_t *new;\n\n\tnew = (gids_t *)xmalloc(sizeof(gids_t));\n\tnew->ngids = n;\n\tnew->gids = gids;\n\treturn new;\n}\n",
        "commit_message": "Fix security issue in _prolog_error().\n\nFix security issue caused by insecure file path handling triggered by\nthe failure of a Prolog script. To exploit this a user needs to\nanticipate or cause the Prolog to fail for their job.\n\n(This commit is slightly different from the fix to the 15.08 branch.)\n\nCVE-2016-10030.",
        "cve_desc": "The _prolog_error function in slurmd/req.c in Slurm before 15.08.13, 16.x before 16.05.7, and 17.x before 17.02.0-pre4 has a vulnerability in how the slurmd daemon informs users of a Prolog failure on a compute node. That vulnerability could allow a user to assume control of an arbitrary file on the system. Any exploitation of this is dependent on the user being able to cause or anticipate the failure (non-zero return code) of a Prolog script that their job would run on. This issue affects all Slurm versions from 0.6.0 (September 2005) to present. Workarounds to prevent exploitation of this are to either disable your Prolog script, or modify it such that it always returns 0 (\"success\") and adjust it to set the node as down using scontrol instead of relying on the slurmd to handle that automatically. If you do not have a Prolog set you are unaffected by this issue.",
        "target": 0
      },
      {
        "idx": 67011,
        "reasoning": "This code snippet is not directly related to the described vulnerability regarding insecure file path handling in `_prolog_error()`. The provided code focuses on managing a cache of group IDs and doesn't exhibit any obvious flaws that would allow for path manipulation or exploitation based on Prolog script failures.",
        "func": "_alloc_gids_cache(char *user, gid_t gid, gids_t *gids, gids_cache_t *next)\n{\n\tgids_cache_t *p;\n\n\tp = (gids_cache_t *)xmalloc(sizeof(gids_cache_t));\n\tp->user = xstrdup(user);\n\tp->timestamp = time(NULL);\n\tp->gid = gid;\n\tp->gids = gids;\n\tp->next = next;\n\treturn p;\n}\n",
        "commit_message": "Fix security issue in _prolog_error().\n\nFix security issue caused by insecure file path handling triggered by\nthe failure of a Prolog script. To exploit this a user needs to\nanticipate or cause the Prolog to fail for their job.\n\n(This commit is slightly different from the fix to the 15.08 branch.)\n\nCVE-2016-10030.",
        "cve_desc": "The _prolog_error function in slurmd/req.c in Slurm before 15.08.13, 16.x before 16.05.7, and 17.x before 17.02.0-pre4 has a vulnerability in how the slurmd daemon informs users of a Prolog failure on a compute node. That vulnerability could allow a user to assume control of an arbitrary file on the system. Any exploitation of this is dependent on the user being able to cause or anticipate the failure (non-zero return code) of a Prolog script that their job would run on. This issue affects all Slurm versions from 0.6.0 (September 2005) to present. Workarounds to prevent exploitation of this are to either disable your Prolog script, or modify it such that it always returns 0 (\"success\") and adjust it to set the node as down using scontrol instead of relying on the slurmd to handle that automatically. If you do not have a Prolog set you are unaffected by this issue.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 3219,
        "reasoning": "This code is vulnerable to arbitrary file control because the `_prolog_error` function constructs a file path based on user-supplied data (`req->std_err` or `req->std_out`) without proper sanitization, potentially allowing a malicious user to specify a path outside of the intended working directory. Specifically, if `err_name` contains a leading `/` or if `req->work_dir` is not set, the code can create files in arbitrary locations on the system, leading to potential overwrites or unauthorized access.",
        "func": " _prolog_error(batch_job_launch_msg_t *req, int rc)\n {\n\tchar *err_name_ptr, err_name[256], path_name[MAXPATHLEN];\n\tchar *fmt_char;\n\tint fd;\n\n\tif (req->std_err || req->std_out) {\n\t\tif (req->std_err)\n\t\t\tstrncpy(err_name, req->std_err, sizeof(err_name));\n\t\telse\n\t\t\tstrncpy(err_name, req->std_out, sizeof(err_name));\n\t\tif ((fmt_char = strchr(err_name, (int) '%')) &&\n\t\t    (fmt_char[1] == 'j') && !strchr(fmt_char+1, (int) '%')) {\n\t\t\tchar tmp_name[256];\n\t\t\tfmt_char[1] = 'u';\n\t\t\tsnprintf(tmp_name, sizeof(tmp_name), err_name,\n\t\t\t\t req->job_id);\n\t\t\tstrncpy(err_name, tmp_name, sizeof(err_name));\n\t\t}\n\t} else {\n\t\tsnprintf(err_name, sizeof(err_name), \"slurm-%u.out\",\n\t\t\t req->job_id);\n\t}\n\terr_name_ptr = err_name;\n\tif (err_name_ptr[0] == '/')\n\t\tsnprintf(path_name, MAXPATHLEN, \"%s\", err_name_ptr);\n\telse if (req->work_dir)\n\t\tsnprintf(path_name, MAXPATHLEN, \"%s/%s\",\n \t\t\treq->work_dir, err_name_ptr);\n \telse\n \t\tsnprintf(path_name, MAXPATHLEN, \"/%s\", err_name_ptr);\n\tif ((fd = open(path_name, (O_CREAT|O_APPEND|O_WRONLY), 0644)) == -1) {\n\t\terror(\"Unable to open %s: %s\", path_name,\n\t\t      slurm_strerror(errno));\n \t\treturn;\n \t}\n \tsnprintf(err_name, sizeof(err_name),\n\t\t \"Error running slurm prolog: %d\\n\", WEXITSTATUS(rc));\n\tsafe_write(fd, err_name, strlen(err_name));\n\tif (fchown(fd, (uid_t) req->uid, (gid_t) req->gid) == -1) {\n\t\tsnprintf(err_name, sizeof(err_name),\n\t\t\t \"Couldn't change fd owner to %u:%u: %m\\n\",\n\t\t\t req->uid, req->gid);\n\t}\nrwfail:\n\tclose(fd);\n}\n",
        "commit_message": "Fix security issue in _prolog_error().\n\nFix security issue caused by insecure file path handling triggered by\nthe failure of a Prolog script. To exploit this a user needs to\nanticipate or cause the Prolog to fail for their job.\n\n(This commit is slightly different from the fix to the 15.08 branch.)\n\nCVE-2016-10030.",
        "cve_desc": "The _prolog_error function in slurmd/req.c in Slurm before 15.08.13, 16.x before 16.05.7, and 17.x before 17.02.0-pre4 has a vulnerability in how the slurmd daemon informs users of a Prolog failure on a compute node. That vulnerability could allow a user to assume control of an arbitrary file on the system. Any exploitation of this is dependent on the user being able to cause or anticipate the failure (non-zero return code) of a Prolog script that their job would run on. This issue affects all Slurm versions from 0.6.0 (September 2005) to present. Workarounds to prevent exploitation of this are to either disable your Prolog script, or modify it such that it always returns 0 (\"success\") and adjust it to set the node as down using scontrol instead of relying on the slurmd to handle that automatically. If you do not have a Prolog set you are unaffected by this issue.",
        "target": 1
      }
    ]
  },
  "soundtouch": {
    "0": [
      {
        "idx": 332575,
        "reasoning": "This code snippet simply closes a file pointer and sets it to NULL within a destructor, representing standard resource cleanup. There are no apparent vulnerabilities like buffer overflows, format string bugs, or improper error handling present in this concise code; the commit message relates to a different part of the `soundtouch` project and doesn't impact this function's safety.\n\n\n\n",
        "func": "WavInFile::~WavInFile()\r\n{\r\n    if (fptr) fclose(fptr);\r\n    fptr = NULL;\r\n}\r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 0
      },
      {
        "idx": 332576,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. It simply rewinds a file pointer and re-reads WAV headers, with an assertion to ensure header reading is successful \u2013 there's no apparent input validation issue or potential for exploitation in this specific function's logic.",
        "func": "void WavInFile::rewind()\r\n{\r\n    int hdrsOk;\r\n\r\n    fseek(fptr, 0, SEEK_SET);\r\n    hdrsOk = readWavHeaders();\r\n    assert(hdrsOk == 0);\r\n    dataRead = 0;\r\n}\r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 0
      },
      {
        "idx": 332577,
        "reasoning": "This code snippet performs a simple byte-swapping operation on a 32-bit integer, and doesn't directly handle any external input or perform operations that could lead to vulnerabilities like buffer overflows or format string bugs. The commit message regarding WAV header length checks suggests a separate, likely input validation, improvement elsewhere in the codebase, but this function itself appears safe.\n\n\n\n",
        "func": "    static inline int _swap32(int &dwData)\r\n    {\r\n        dwData = ((dwData >> 24) & 0x000000FF) | \r\n               ((dwData >> 8)  & 0x0000FF00) | \r\n               ((dwData << 8)  & 0x00FF0000) | \r\n               ((dwData << 24) & 0xFF000000);\r\n        return dwData;\r\n    }   \r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 0
      },
      {
        "idx": 332578,
        "reasoning": "This code snippet is not vulnerable because it simply checks if all data has been read or the end of the file has been reached, utilizing standard file stream functions (`feof`) and comparing against a header-defined data length. The added minimum size check in the commit message, while relevant to overall WAV parsing robustness, doesn't directly impact the safety of this specific `eof()` function.\n\n\n\n",
        "func": "int WavInFile::eof() const\r\n{\r\n    // return true if all data has been read or file eof has reached\r\n    return (dataRead == header.data.data_len || feof(fptr));\r\n}\r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 0
      },
      {
        "idx": 332579,
        "reasoning": "This code snippet is not vulnerable because it simply deallocates memory (`convBuff`) and resets a size variable (`convBuffSize`) within a destructor. There are no apparent issues related to memory management, input validation, or potential exploits present in this straightforward cleanup operation.\n\n\n\n",
        "func": "WavFileBase::~WavFileBase()\r\n{\r\n    delete[] convBuff;\r\n    convBuffSize = 0;\r\n}\r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 202291,
        "reasoning": "The code is vulnerable to a buffer overflow because it calculates `nDump` as the difference between the reported block length (`nLen`) and the expected size, but then only limits the *read* size to the expected size, not the initial `nLen` value used for `fseek`. This allows a malicious WAV file to report a large `nLen` value, causing `fseek` to advance the file pointer beyond the intended block, potentially leading to out-of-bounds reads in subsequent operations or when processing later blocks.",
        "func": "int WavInFile::readHeaderBlock()\r\n{\r\n    char label[5];\r\n    string sLabel;\r\n\r\n    // lead label string\r\n    if (fread(label, 1, 4, fptr) !=4) return -1;\r\n    label[4] = 0;\r\n\r\n    if (isAlphaStr(label) == 0) return -1;    // not a valid label\r\n\r\n    // Decode blocks according to their label\r\n    if (strcmp(label, fmtStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fmt ' block \r\n        memcpy(header.format.fmt, fmtStr, 4);\r\n\r\n        // read length of the format field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen); // int format_len;\r\n        header.format.format_len = nLen;\r\n\r\n        // calculate how much length differs from expected\r\n        nDump = nLen - ((int)sizeof(header.format) - 8);\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.format) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.format.fixed), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap16((short &)header.format.fixed);            // short int fixed;\r\n        _swap16((short &)header.format.channel_number);   // short int channel_number;\r\n        _swap32((int &)header.format.sample_rate);        // int sample_rate;\r\n        _swap32((int &)header.format.byte_rate);          // int byte_rate;\r\n        _swap16((short &)header.format.byte_per_sample);  // short int byte_per_sample;\r\n        _swap16((short &)header.format.bits_per_sample);  // short int bits_per_sample;\r\n\r\n        // if format_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, factStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fact' block \r\n        memcpy(header.fact.fact_field, factStr, 4);\r\n\r\n        // read length of the fact field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen); // int fact_len;\r\n        header.fact.fact_len = nLen;\r\n\r\n        // calculate how much length differs from expected\r\n        nDump = nLen - ((int)sizeof(header.fact) - 8);\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.fact) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.fact.fact_sample_len), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.fact.fact_sample_len);    // int sample_length;\r\n\r\n        // if fact_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, dataStr) == 0)\r\n    {\r\n        // 'data' block\r\n        memcpy(header.data.data_field, dataStr, 4);\r\n        if (fread(&(header.data.data_len), sizeof(uint), 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.data.data_len);\r\n\r\n        return 1;\r\n    }\r\n    else\r\n    {\r\n        uint len, i;\r\n        uint temp;\r\n        // unknown block\r\n\r\n        // read length\r\n        if (fread(&len, sizeof(len), 1, fptr) != 1) return -1;\r\n        // scan through the block\r\n        for (i = 0; i < len; i ++)\r\n        {\r\n            if (fread(&temp, 1, 1, fptr) != 1) return -1;\r\n            if (feof(fptr)) return -1;   // unexpected eof\r\n        }\r\n    }\r\n    return 0;\r\n}\r",
        "commit_message": "Added minimum size check for WAV header block lengh values",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 1
      },
      {
        "idx": 210136,
        "reasoning": "This code is vulnerable to a double-free due to the `getConvBuffer` function likely allocating a buffer that is later freed, and then potentially being called again with a size that doesn't account for proper alignment before the original buffer is released\u2014the commit message addresses alignment, hinting at this issue. The CVE description explicitly states SoundTouch 2.0 is susceptible to a double-free, and this `write` function is a key component of WAV file handling where such a vulnerability could manifest.",
        "func": "void WavOutFile::write(const float *buffer, int numElems)\r\n{\r\n    int numBytes;\r\n    int bytesPerSample;\r\n\r\n    if (numElems == 0) return;\r\n\r\n    bytesPerSample = header.format.bits_per_sample / 8;\r\n    numBytes = numElems * bytesPerSample;\r\n    short *temp = (short*)getConvBuffer(numBytes);\r\n\r\n    switch (bytesPerSample)\r\n    {\r\n        case 1:\r\n        {\r\n            unsigned char *temp2 = (unsigned char *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                temp2[i] = (unsigned char)saturate(buffer[i] * 128.0f + 128.0f, 0.0f, 255.0f);\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 2:\r\n        {\r\n            short *temp2 = (short *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                short value = (short)saturate(buffer[i] * 32768.0f, -32768.0f, 32767.0f);\r\n                temp2[i] = _swap16(value);\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 3:\r\n        {\r\n            char *temp2 = (char *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                int value = saturate(buffer[i] * 8388608.0f, -8388608.0f, 8388607.0f);\r\n                *((int*)temp2) = _swap32(value);\r\n                temp2 += 3;\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 4:\r\n        {\r\n            int *temp2 = (int *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                int value = saturate(buffer[i] * 2147483648.0f, -2147483648.0f, 2147483647.0f);\r\n                temp2[i] = _swap32(value);\r\n            }\r\n            break;\r\n        }\r\n\r\n        default:\r\n            assert(false);\r\n    }\r\n\r\n    int res = (int)fwrite(temp, 1, numBytes, fptr);\r\n\r\n    if (res != numBytes) \r\n    {\r\n        ST_THROW_RT_ERROR(\"Error while writing to a wav file.\");\r\n    }\r\n    bytesWritten += numBytes;\r\n}\r",
        "commit_message": "Fix CVE-2018-17097 by rounding working buffer size up to nearest 4-byte boundary. Replaced also tab characters with spaces in indentation.",
        "cve_desc": "The WavFileBase class in WavFile.cpp in Olli Parviainen SoundTouch 2.0 allows remote attackers to cause a denial of service (double free) or possibly have unspecified other impact, as demonstrated by SoundStretch.",
        "target": 1
      },
      {
        "idx": 210773,
        "reasoning": "The code is vulnerable to a buffer overflow because the `nDump` calculation, while intended to prevent reading beyond the allocated buffer size, can be bypassed if a crafted WAV file provides a `nLen` value significantly larger than expected, leading to an out-of-bounds read during the `fread` operation. Specifically, the check `if (nDump < 0) return -1;` only prevents reading *less* than the expected structure size, not *more*, allowing a malicious file to overflow the `header.format` or `header.fact` buffers.",
        "func": "int WavInFile::readHeaderBlock()\r\n{\r\n    char label[5];\r\n    string sLabel;\r\n\r\n    // lead label string\r\n    if (fread(label, 1, 4, fptr) !=4) return -1;\r\n    label[4] = 0;\r\n\r\n    if (isAlphaStr(label) == 0) return -1;    // not a valid label\r\n\r\n    // Decode blocks according to their label\r\n    if (strcmp(label, fmtStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fmt ' block \r\n        memcpy(header.format.fmt, fmtStr, 4);\r\n\r\n        // read length of the format field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen);\r\n\r\n        // calculate how much length differs from expected \r\n        nDump = nLen - ((int)sizeof(header.format) - 8);\r\n\r\n        // verify that header length isn't smaller than expected structure\r\n        if (nDump < 0) return -1;\r\n\r\n        header.format.format_len = nLen;\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.format) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.format.fixed), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap16((short &)header.format.fixed);            // short int fixed;\r\n        _swap16((short &)header.format.channel_number);   // short int channel_number;\r\n        _swap32((int &)header.format.sample_rate);        // int sample_rate;\r\n        _swap32((int &)header.format.byte_rate);          // int byte_rate;\r\n        _swap16((short &)header.format.byte_per_sample);  // short int byte_per_sample;\r\n        _swap16((short &)header.format.bits_per_sample);  // short int bits_per_sample;\r\n\r\n        // if format_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, factStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fact' block \r\n        memcpy(header.fact.fact_field, factStr, 4);\r\n\r\n        // read length of the fact field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen);\r\n\r\n        // calculate how much length differs from expected\r\n        nDump = nLen - ((int)sizeof(header.fact) - 8);\r\n\r\n        // verify that fact length isn't smaller than expected structure\r\n        if (nDump < 0) return -1;\r\n\r\n        header.fact.fact_len = nLen;\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.fact) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.fact.fact_sample_len), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.fact.fact_sample_len);    // int sample_length;\r\n\r\n        // if fact_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, dataStr) == 0)\r\n    {\r\n        // 'data' block\r\n        memcpy(header.data.data_field, dataStr, 4);\r\n        if (fread(&(header.data.data_len), sizeof(uint), 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.data.data_len);\r\n\r\n        return 1;\r\n    }\r\n    else\r\n    {\r\n        uint len, i;\r\n        uint temp;\r\n        // unknown block\r\n\r\n        // read length\r\n        if (fread(&len, sizeof(len), 1, fptr) != 1) return -1;\r\n        // scan through the block\r\n        for (i = 0; i < len; i ++)\r\n        {\r\n            if (fread(&temp, 1, 1, fptr) != 1) return -1;\r\n            if (feof(fptr)) return -1;   // unexpected eof\r\n        }\r\n    }\r\n    return 0;\r\n}\r",
        "commit_message": "Improved WavFile header/fact not-too-small check",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 1
      },
      {
        "idx": 210876,
        "reasoning": "The code is vulnerable because the `temp2 += 3` increment in the 3-byte sample case doesn't account for potential alignment issues, leading to writing outside the allocated `temp` buffer if `numElems` is large enough. This out-of-bounds write could lead to a crash (denial of service) or potentially allow for arbitrary code execution, aligning with the CVE's description of memory corruption issues within the WavFileBase class.",
        "func": "void WavOutFile::write(const float *buffer, int numElems)\r\n{\r\n    int numBytes;\r\n    int bytesPerSample;\r\n\r\n    if (numElems == 0) return;\r\n\r\n    bytesPerSample = header.format.bits_per_sample / 8;\r\n    numBytes = numElems * bytesPerSample;\r\n    int confBufBytes = (numBytes + 3) & -4; // round up to nearest multiple of four to avoid overflow with 24bit-value assignment\r\n    void *temp = getConvBuffer(confBufBytes);\r\n\r\n    switch (bytesPerSample)\r\n    {\r\n        case 1:\r\n        {\r\n            unsigned char *temp2 = (unsigned char *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                temp2[i] = (unsigned char)saturate(buffer[i] * 128.0f + 128.0f, 0.0f, 255.0f);\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 2:\r\n        {\r\n            short *temp2 = (short *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                short value = (short)saturate(buffer[i] * 32768.0f, -32768.0f, 32767.0f);\r\n                temp2[i] = _swap16(value);\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 3:\r\n        {\r\n            char *temp2 = (char *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                int value = saturate(buffer[i] * 8388608.0f, -8388608.0f, 8388607.0f);\r\n                *((int*)temp2) = _swap32(value);\r\n                temp2 += 3;\r\n            }\r\n            break;\r\n        }\r\n\r\n        case 4:\r\n        {\r\n            int *temp2 = (int *)temp;\r\n            for (int i = 0; i < numElems; i ++)\r\n            {\r\n                int value = saturate(buffer[i] * 2147483648.0f, -2147483648.0f, 2147483647.0f);\r\n                temp2[i] = _swap32(value);\r\n            }\r\n            break;\r\n        }\r\n\r\n        default:\r\n            assert(false);\r\n    }\r\n\r\n    int res = (int)fwrite(temp, 1, numBytes, fptr);\r\n\r\n    if (res != numBytes) \r\n    {\r\n        ST_THROW_RT_ERROR(\"Error while writing to a wav file.\");\r\n    }\r\n    bytesWritten += numBytes;\r\n}\r",
        "commit_message": "New take on CVE-2018-17097 i.e. avoiding writing beyond end of buffer in case of 24-bit samples",
        "cve_desc": "The WavFileBase class in WavFile.cpp in Olli Parviainen SoundTouch 2.0 allows remote attackers to cause a denial of service (double free) or possibly have unspecified other impact, as demonstrated by SoundStretch.",
        "target": 1
      },
      {
        "idx": 212026,
        "reasoning": "The code is vulnerable to a buffer overflow because it calculates `nDump` based on the provided `nLen` (length of the 'fmt' or 'fact' block) and uses this value to determine how much data to read, but doesn't adequately validate that `nLen` isn't excessively large, potentially leading to an out-of-bounds read when `fread` is called. Specifically, while it limits the read size to `sizeof(header.format) - 8` or `sizeof(header.fact) - 8` when `nDump > 0`, the initial `nLen` value itself isn't bounded, allowing a crafted WAV file to potentially cause a read beyond allocated memory before the size limiting logic is applied.",
        "func": "int WavInFile::readHeaderBlock()\r\n{\r\n    char label[5];\r\n    string sLabel;\r\n\r\n    // lead label string\r\n    if (fread(label, 1, 4, fptr) !=4) return -1;\r\n    label[4] = 0;\r\n\r\n    if (isAlphaStr(label) == 0) return -1;    // not a valid label\r\n\r\n    // Decode blocks according to their label\r\n    if (strcmp(label, fmtStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fmt ' block \r\n        memcpy(header.format.fmt, fmtStr, 4);\r\n\r\n        // read length of the format field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen);\r\n\r\n        // verify that header length isn't smaller than expected\r\n        if (nLen < sizeof(header.format) - 8) return -1;\r\n\r\n        header.format.format_len = nLen;\r\n\r\n        // calculate how much length differs from expected\r\n        nDump = nLen - ((int)sizeof(header.format) - 8);\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.format) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.format.fixed), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap16((short &)header.format.fixed);            // short int fixed;\r\n        _swap16((short &)header.format.channel_number);   // short int channel_number;\r\n        _swap32((int &)header.format.sample_rate);        // int sample_rate;\r\n        _swap32((int &)header.format.byte_rate);          // int byte_rate;\r\n        _swap16((short &)header.format.byte_per_sample);  // short int byte_per_sample;\r\n        _swap16((short &)header.format.bits_per_sample);  // short int bits_per_sample;\r\n\r\n        // if format_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, factStr) == 0)\r\n    {\r\n        int nLen, nDump;\r\n\r\n        // 'fact' block \r\n        memcpy(header.fact.fact_field, factStr, 4);\r\n\r\n        // read length of the fact field\r\n        if (fread(&nLen, sizeof(int), 1, fptr) != 1) return -1;\r\n        // swap byte order if necessary\r\n        _swap32(nLen); // int fact_len;\r\n\r\n        // verify that fact length isn't smaller than expected\r\n        if (nLen < sizeof(header.fact) - 8) return -1;\r\n\r\n        header.fact.fact_len = nLen;\r\n\r\n        // calculate how much length differs from expected\r\n        nDump = nLen - ((int)sizeof(header.fact) - 8);\r\n\r\n        // if format_len is larger than expected, read only as much data as we've space for\r\n        if (nDump > 0)\r\n        {\r\n            nLen = sizeof(header.fact) - 8;\r\n        }\r\n\r\n        // read data\r\n        if (fread(&(header.fact.fact_sample_len), nLen, 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.fact.fact_sample_len);    // int sample_length;\r\n\r\n        // if fact_len is larger than expected, skip the extra data\r\n        if (nDump > 0)\r\n        {\r\n            fseek(fptr, nDump, SEEK_CUR);\r\n        }\r\n\r\n        return 0;\r\n    }\r\n    else if (strcmp(label, dataStr) == 0)\r\n    {\r\n        // 'data' block\r\n        memcpy(header.data.data_field, dataStr, 4);\r\n        if (fread(&(header.data.data_len), sizeof(uint), 1, fptr) != 1) return -1;\r\n\r\n        // swap byte order if necessary\r\n        _swap32((int &)header.data.data_len);\r\n\r\n        return 1;\r\n    }\r\n    else\r\n    {\r\n        uint len, i;\r\n        uint temp;\r\n        // unknown block\r\n\r\n        // read length\r\n        if (fread(&len, sizeof(len), 1, fptr) != 1) return -1;\r\n        // scan through the block\r\n        for (i = 0; i < len; i ++)\r\n        {\r\n            if (fread(&temp, 1, 1, fptr) != 1) return -1;\r\n            if (feof(fptr)) return -1;   // unexpected eof\r\n        }\r\n    }\r\n    return 0;\r\n}\r",
        "commit_message": "Fixed WavFile header/fact not-too-small check",
        "cve_desc": "soundtouch version up to and including 2.0.0 contains a Buffer Overflow vulnerability in SoundStretch/WavFile.cpp:WavInFile::readHeaderBlock() that can result in arbitrary code execution. This attack appear to be exploitable via victim must open maliocius file in soundstretch utility.",
        "target": 1
      }
    ]
  },
  "spnego-http-auth-nginx-module": {
    "0": [],
    "1": []
  },
  "sqlite": {
    "0": [
      {
        "idx": 290458,
        "reasoning": "This code snippet appears safe as it primarily focuses on query optimization and statistical gathering within the FTS3/4 module, without directly handling external inputs that could lead to vulnerabilities like SQL injection or buffer overflows. The code allocates memory using `sqlite3_malloc` and checks for allocation failures, mitigating potential denial-of-service risks, and the logic seems contained within the FTS query evaluation process.",
        "func": "static int fts3EvalGatherStats(\n  Fts3Cursor *pCsr,               /* Cursor object */\n  Fts3Expr *pExpr                 /* FTSQUERY_PHRASE expression */\n){\n  int rc = SQLITE_OK;             /* Return code */\n\n  assert( pExpr->eType==FTSQUERY_PHRASE );\n  if( pExpr->aMI==0 ){\n    Fts3Table *pTab = (Fts3Table *)pCsr->base.pVtab;\n    Fts3Expr *pRoot;                /* Root of NEAR expression */\n    Fts3Expr *p;                    /* Iterator used for several purposes */\n\n    sqlite3_int64 iPrevId = pCsr->iPrevId;\n    sqlite3_int64 iDocid;\n    u8 bEof;\n\n    /* Find the root of the NEAR expression */\n    pRoot = pExpr;\n    while( pRoot->pParent && pRoot->pParent->eType==FTSQUERY_NEAR ){\n      pRoot = pRoot->pParent;\n    }\n    iDocid = pRoot->iDocid;\n    bEof = pRoot->bEof;\n    assert( pRoot->bStart );\n\n    /* Allocate space for the aMSI[] array of each FTSQUERY_PHRASE node */\n    for(p=pRoot; p; p=p->pLeft){\n      Fts3Expr *pE = (p->eType==FTSQUERY_PHRASE?p:p->pRight);\n      assert( pE->aMI==0 );\n      pE->aMI = (u32 *)sqlite3_malloc(pTab->nColumn * 3 * sizeof(u32));\n      if( !pE->aMI ) return SQLITE_NOMEM;\n      memset(pE->aMI, 0, pTab->nColumn * 3 * sizeof(u32));\n    }\n\n    fts3EvalRestart(pCsr, pRoot, &rc);\n\n    while( pCsr->isEof==0 && rc==SQLITE_OK ){\n\n      do {\n        /* Ensure the %_content statement is reset. */\n        if( pCsr->isRequireSeek==0 ) sqlite3_reset(pCsr->pStmt);\n        assert( sqlite3_data_count(pCsr->pStmt)==0 );\n\n        /* Advance to the next document */\n        fts3EvalNextRow(pCsr, pRoot, &rc);\n        pCsr->isEof = pRoot->bEof;\n        pCsr->isRequireSeek = 1;\n        pCsr->isMatchinfoNeeded = 1;\n        pCsr->iPrevId = pRoot->iDocid;\n      }while( pCsr->isEof==0 \n           && pRoot->eType==FTSQUERY_NEAR \n           && fts3EvalTestDeferredAndNear(pCsr, &rc) \n      );\n\n      if( rc==SQLITE_OK && pCsr->isEof==0 ){\n        fts3EvalUpdateCounts(pRoot);\n      }\n    }\n\n    pCsr->isEof = 0;\n    pCsr->iPrevId = iPrevId;\n\n    if( bEof ){\n      pRoot->bEof = bEof;\n    }else{\n      /* Caution: pRoot may iterate through docids in ascending or descending\n      ** order. For this reason, even though it seems more defensive, the \n      ** do loop can not be written:\n      **\n      **   do {...} while( pRoot->iDocid<iDocid && rc==SQLITE_OK );\n      */\n      fts3EvalRestart(pCsr, pRoot, &rc);\n      do {\n        fts3EvalNextRow(pCsr, pRoot, &rc);\n        assert( pRoot->bEof==0 );\n      }while( pRoot->iDocid!=iDocid && rc==SQLITE_OK );\n      fts3EvalTestDeferredAndNear(pCsr, &rc);\n    }\n  }\n  return rc;\n}",
        "commit_message": "Improve the performance of fts3/4 queries that use the OR operator and at least one auxiliary fts function.\n\nFossilOrigin-Name: 245e8730451fbdc1c729beff7295c452df604009",
        "cve_desc": "ext/fts3/fts3.c in SQLite before 3.32.0 has a use-after-free in fts3EvalNextRow, related to the snippet feature.",
        "target": 0
      },
      {
        "idx": 290459,
        "reasoning": "This code snippet focuses on efficiently storing delta-encoded varints, a common optimization technique, and doesn't appear to handle any external input directly. There are no immediately obvious vulnerabilities like buffer overflows, format string bugs, or injection flaws present in this isolated function, and the commit message doesn't suggest any security-relevant changes were made.",
        "func": "static void fts3PutDeltaVarint(\n  char **pp,                      /* IN/OUT: Output pointer */\n  sqlite3_int64 *piPrev,          /* IN/OUT: Previous value written to list */\n  sqlite3_int64 iVal              /* Write this value to the list */\n){\n  assert( iVal-*piPrev > 0 || (*piPrev==0 && iVal==0) );\n  *pp += sqlite3Fts3PutVarint(*pp, iVal-*piPrev);\n  *piPrev = iVal;\n}",
        "commit_message": "Improve the performance of fts3/4 queries that use the OR operator and at least one auxiliary fts function.\n\nFossilOrigin-Name: 245e8730451fbdc1c729beff7295c452df604009",
        "cve_desc": "ext/fts3/fts3.c in SQLite before 3.32.0 has a use-after-free in fts3EvalNextRow, related to the snippet feature.",
        "target": 0
      },
      {
        "idx": 290460,
        "reasoning": "This code snippet appears safe as it simply parses an integer from a string and includes a basic check to ensure at least one digit was present. There are no apparent issues related to buffer overflows, format string vulnerabilities, or other common security concerns within this focused integer parsing function, and the commit message doesn't suggest any related changes that would introduce vulnerabilities.",
        "func": "static int fts3GobbleInt(const char **pp, int *pnOut){\n  const char *p;                  /* Iterator pointer */\n  int nInt = 0;                   /* Output value */\n\n  for(p=*pp; p[0]>='0' && p[0]<='9'; p++){\n    nInt = nInt * 10 + (p[0] - '0');\n  }\n  if( p==*pp ) return SQLITE_ERROR;\n  *pnOut = nInt;\n  *pp = p;\n  return SQLITE_OK;\n}",
        "commit_message": "Improve the performance of fts3/4 queries that use the OR operator and at least one auxiliary fts function.\n\nFossilOrigin-Name: 245e8730451fbdc1c729beff7295c452df604009",
        "cve_desc": "ext/fts3/fts3.c in SQLite before 3.32.0 has a use-after-free in fts3EvalNextRow, related to the snippet feature.",
        "target": 0
      },
      {
        "idx": 290461,
        "reasoning": "This code snippet appears safe as it primarily focuses on constructing a string for an FTS query expression list and utilizes `fts3QuoteId` to properly quote identifiers, mitigating potential injection risks. While string formatting is involved with `fts3Appendf`, the inputs appear controlled within the context of the FTS table structure and function names, and doesn't directly handle user-supplied data without sanitization.\n\n\n\n",
        "func": "static char *fts3WriteExprList(Fts3Table *p, const char *zFunc, int *pRc){\n  char *zRet = 0;\n  char *zFree = 0;\n  char *zFunction;\n  int i;\n\n  if( !zFunc ){\n    zFunction = \"\";\n  }else{\n    zFree = zFunction = fts3QuoteId(zFunc);\n  }\n  fts3Appendf(pRc, &zRet, \"?\");\n  for(i=0; i<p->nColumn; i++){\n    fts3Appendf(pRc, &zRet, \",%s(?)\", zFunction);\n  }\n  if( p->zLanguageid ){\n    fts3Appendf(pRc, &zRet, \", ?\");\n  }\n  sqlite3_free(zFree);\n  return zRet;\n}",
        "commit_message": "Improve the performance of fts3/4 queries that use the OR operator and at least one auxiliary fts function.\n\nFossilOrigin-Name: 245e8730451fbdc1c729beff7295c452df604009",
        "cve_desc": "ext/fts3/fts3.c in SQLite before 3.32.0 has a use-after-free in fts3EvalNextRow, related to the snippet feature.",
        "target": 0
      },
      {
        "idx": 290462,
        "reasoning": "This code snippet appears safe as it focuses on performance improvements within the FTS3/4 query processing and doesn't introduce any obvious vulnerabilities like buffer overflows, SQL injection, or improper input validation. The code manages memory correctly by freeing allocated buffers in case of errors and utilizes existing, presumably vetted, FTS3 functions for segment reading and merging.\n\n\n\n",
        "func": "static int fts3TermSelect(\n  Fts3Table *p,                   /* Virtual table handle */\n  Fts3PhraseToken *pTok,          /* Token to query for */\n  int iColumn,                    /* Column to query (or -ve for all columns) */\n  int *pnOut,                     /* OUT: Size of buffer at *ppOut */\n  char **ppOut                    /* OUT: Malloced result buffer */\n){\n  int rc;                         /* Return code */\n  Fts3MultiSegReader *pSegcsr;    /* Seg-reader cursor for this term */\n  TermSelect tsc;                 /* Object for pair-wise doclist merging */\n  Fts3SegFilter filter;           /* Segment term filter configuration */\n\n  pSegcsr = pTok->pSegcsr;\n  memset(&tsc, 0, sizeof(TermSelect));\n\n  filter.flags = FTS3_SEGMENT_IGNORE_EMPTY | FTS3_SEGMENT_REQUIRE_POS\n        | (pTok->isPrefix ? FTS3_SEGMENT_PREFIX : 0)\n        | (pTok->bFirst ? FTS3_SEGMENT_FIRST : 0)\n        | (iColumn<p->nColumn ? FTS3_SEGMENT_COLUMN_FILTER : 0);\n  filter.iCol = iColumn;\n  filter.zTerm = pTok->z;\n  filter.nTerm = pTok->n;\n\n  rc = sqlite3Fts3SegReaderStart(p, pSegcsr, &filter);\n  while( SQLITE_OK==rc\n      && SQLITE_ROW==(rc = sqlite3Fts3SegReaderStep(p, pSegcsr)) \n  ){\n    rc = fts3TermSelectMerge(p, &tsc, pSegcsr->aDoclist, pSegcsr->nDoclist);\n  }\n\n  if( rc==SQLITE_OK ){\n    rc = fts3TermSelectFinishMerge(p, &tsc);\n  }\n  if( rc==SQLITE_OK ){\n    *ppOut = tsc.aaOutput[0];\n    *pnOut = tsc.anOutput[0];\n  }else{\n    int i;\n    for(i=0; i<SizeofArray(tsc.aaOutput); i++){\n      sqlite3_free(tsc.aaOutput[i]);\n    }\n  }\n\n  fts3SegReaderCursorFree(pSegcsr);\n  pTok->pSegcsr = 0;\n  return rc;\n}",
        "commit_message": "Improve the performance of fts3/4 queries that use the OR operator and at least one auxiliary fts function.\n\nFossilOrigin-Name: 245e8730451fbdc1c729beff7295c452df604009",
        "cve_desc": "ext/fts3/fts3.c in SQLite before 3.32.0 has a use-after-free in fts3EvalNextRow, related to the snippet feature.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 200977,
        "reasoning": "The code is vulnerable to an integer overflow in the calculation of `iSample` as `pIdx->nSample * nField` could result in a value exceeding the maximum integer size, leading to unexpected behavior during the binary search. This overflow, combined with the subsequent array indexing using `iTest = (iMin+iSample)/2` and accessing `aSample[iSamp]`, could lead to an out-of-bounds read, potentially allowing an attacker to leak sensitive information or cause a denial-of-service, aligning with the CVE description of excessive memory usage due to large string arguments.",
        "func": "static int whereKeyStats(\n  Parse *pParse,              /* Database connection */\n  Index *pIdx,                /* Index to consider domain of */\n  UnpackedRecord *pRec,       /* Vector of values to consider */\n  int roundUp,                /* Round up if true.  Round down if false */\n  tRowcnt *aStat              /* OUT: stats written here */\n){\n  IndexSample *aSample = pIdx->aSample;\n  int iCol;                   /* Index of required stats in anEq[] etc. */\n  int i;                      /* Index of first sample >= pRec */\n  int iSample;                /* Smallest sample larger than or equal to pRec */\n  int iMin = 0;               /* Smallest sample not yet tested */\n  int iTest;                  /* Next sample to test */\n  int res;                    /* Result of comparison operation */\n  int nField;                 /* Number of fields in pRec */\n  tRowcnt iLower = 0;         /* anLt[] + anEq[] of largest sample pRec is > */\n\n#ifndef SQLITE_DEBUG\n  UNUSED_PARAMETER( pParse );\n#endif\n  assert( pRec!=0 );\n  assert( pIdx->nSample>0 );\n  assert( pRec->nField>0 && pRec->nField<=pIdx->nSampleCol );\n\n  /* Do a binary search to find the first sample greater than or equal\n  ** to pRec. If pRec contains a single field, the set of samples to search\n  ** is simply the aSample[] array. If the samples in aSample[] contain more\n  ** than one fields, all fields following the first are ignored.\n  **\n  ** If pRec contains N fields, where N is more than one, then as well as the\n  ** samples in aSample[] (truncated to N fields), the search also has to\n  ** consider prefixes of those samples. For example, if the set of samples\n  ** in aSample is:\n  **\n  **     aSample[0] = (a, 5) \n  **     aSample[1] = (a, 10) \n  **     aSample[2] = (b, 5) \n  **     aSample[3] = (c, 100) \n  **     aSample[4] = (c, 105)\n  **\n  ** Then the search space should ideally be the samples above and the \n  ** unique prefixes [a], [b] and [c]. But since that is hard to organize, \n  ** the code actually searches this set:\n  **\n  **     0: (a) \n  **     1: (a, 5) \n  **     2: (a, 10) \n  **     3: (a, 10) \n  **     4: (b) \n  **     5: (b, 5) \n  **     6: (c) \n  **     7: (c, 100) \n  **     8: (c, 105)\n  **     9: (c, 105)\n  **\n  ** For each sample in the aSample[] array, N samples are present in the\n  ** effective sample array. In the above, samples 0 and 1 are based on \n  ** sample aSample[0]. Samples 2 and 3 on aSample[1] etc.\n  **\n  ** Often, sample i of each block of N effective samples has (i+1) fields.\n  ** Except, each sample may be extended to ensure that it is greater than or\n  ** equal to the previous sample in the array. For example, in the above, \n  ** sample 2 is the first sample of a block of N samples, so at first it \n  ** appears that it should be 1 field in size. However, that would make it \n  ** smaller than sample 1, so the binary search would not work. As a result, \n  ** it is extended to two fields. The duplicates that this creates do not \n  ** cause any problems.\n  */\n  nField = pRec->nField;\n  iCol = 0;\n  iSample = pIdx->nSample * nField;\n  do{\n    int iSamp;                    /* Index in aSample[] of test sample */\n    int n;                        /* Number of fields in test sample */\n\n    iTest = (iMin+iSample)/2;\n    iSamp = iTest / nField;\n    if( iSamp>0 ){\n      /* The proposed effective sample is a prefix of sample aSample[iSamp].\n      ** Specifically, the shortest prefix of at least (1 + iTest%nField) \n      ** fields that is greater than the previous effective sample.  */\n      for(n=(iTest % nField) + 1; n<nField; n++){\n        if( aSample[iSamp-1].anLt[n-1]!=aSample[iSamp].anLt[n-1] ) break;\n      }\n    }else{\n      n = iTest + 1;\n    }\n\n    pRec->nField = n;\n    res = sqlite3VdbeRecordCompare(aSample[iSamp].n, aSample[iSamp].p, pRec);\n    if( res<0 ){\n      iLower = aSample[iSamp].anLt[n-1] + aSample[iSamp].anEq[n-1];\n      iMin = iTest+1;\n    }else if( res==0 && n<nField ){\n      iLower = aSample[iSamp].anLt[n-1];\n      iMin = iTest+1;\n      res = -1;\n    }else{\n      iSample = iTest;\n      iCol = n-1;\n    }\n  }while( res && iMin<iSample );\n  i = iSample / nField;\n\n#ifdef SQLITE_DEBUG\n  /* The following assert statements check that the binary search code\n  ** above found the right answer. This block serves no purpose other\n  ** than to invoke the asserts.  */\n  if( pParse->db->mallocFailed==0 ){\n    if( res==0 ){\n      /* If (res==0) is true, then pRec must be equal to sample i. */\n      assert( i<pIdx->nSample );\n      assert( iCol==nField-1 );\n      pRec->nField = nField;\n      assert( 0==sqlite3VdbeRecordCompare(aSample[i].n, aSample[i].p, pRec) \n           || pParse->db->mallocFailed \n      );\n    }else{\n      /* Unless i==pIdx->nSample, indicating that pRec is larger than\n      ** all samples in the aSample[] array, pRec must be smaller than the\n      ** (iCol+1) field prefix of sample i.  */\n      assert( i<=pIdx->nSample && i>=0 );\n      pRec->nField = iCol+1;\n      assert( i==pIdx->nSample \n           || sqlite3VdbeRecordCompare(aSample[i].n, aSample[i].p, pRec)>0\n           || pParse->db->mallocFailed );\n\n      /* if i==0 and iCol==0, then record pRec is smaller than all samples\n      ** in the aSample[] array. Otherwise, if (iCol>0) then pRec must\n      ** be greater than or equal to the (iCol) field prefix of sample i.\n      ** If (i>0), then pRec must also be greater than sample (i-1).  */\n      if( iCol>0 ){\n        pRec->nField = iCol;\n        assert( sqlite3VdbeRecordCompare(aSample[i].n, aSample[i].p, pRec)<=0\n             || pParse->db->mallocFailed );\n      }\n      if( i>0 ){\n        pRec->nField = nField;\n        assert( sqlite3VdbeRecordCompare(aSample[i-1].n, aSample[i-1].p, pRec)<0\n             || pParse->db->mallocFailed );\n      }\n    }\n  }\n#endif /* ifdef SQLITE_DEBUG */\n\n  if( res==0 ){\n    /* Record pRec is equal to sample i */\n    assert( iCol==nField-1 );\n    aStat[0] = aSample[i].anLt[iCol];\n    aStat[1] = aSample[i].anEq[iCol];\n  }else{\n    /* At this point, the (iCol+1) field prefix of aSample[i] is the first \n    ** sample that is greater than pRec. Or, if i==pIdx->nSample then pRec\n    ** is larger than all samples in the array. */\n    tRowcnt iUpper, iGap;\n    if( i>=pIdx->nSample ){\n      iUpper = sqlite3LogEstToInt(pIdx->aiRowLogEst[0]);\n    }else{\n      iUpper = aSample[i].anLt[iCol];\n    }\n\n    if( iLower>=iUpper ){\n      iGap = 0;\n    }else{\n      iGap = iUpper - iLower;\n    }\n    if( roundUp ){\n      iGap = (iGap*2)/3;\n    }else{\n      iGap = iGap/3;\n    }\n    aStat[0] = iLower + iGap;\n    aStat[1] = pIdx->aAvgEq[nField-1];\n  }\n\n  /* Restore the pRec->nField value before returning.  */\n  pRec->nField = nField;\n  return i;\n}",
        "commit_message": "Fix the whereKeyStats() routine (part of STAT4 processing only) so that it\nis able to cope with row-value comparisons against the primary key index\nof a WITHOUT ROWID table.\n[forum:/forumpost/3607259d3c|Forum post 3607259d3c].\n\nFossilOrigin-Name: 2a6f761864a462de5c2d5bc666b82fb0b7e124a03443cd1482620dde344b34bb",
        "cve_desc": "SQLite 1.0.12 through 3.39.x before 3.39.2 sometimes allows an array-bounds overflow if billions of bytes are used in a string argument to a C API.",
        "target": 1
      },
      {
        "idx": 203991,
        "reasoning": "The vulnerability lies within the `TK_COLUMN` case where the code doesn't properly validate `pExpr->y.pTab` when handling generated columns, potentially leading to incorrect table access. Specifically, the code allows access to generated columns without sufficient checks, as highlighted by the CVE, which can be exploited when these columns are used in joins, resulting in unexpected behavior or crashes.",
        "func": "int sqlite3ExprCodeTarget(Parse *pParse, Expr *pExpr, int target){\n  Vdbe *v = pParse->pVdbe;  /* The VM under construction */\n  int op;                   /* The opcode being coded */\n  int inReg = target;       /* Results stored in register inReg */\n  int regFree1 = 0;         /* If non-zero free this temporary register */\n  int regFree2 = 0;         /* If non-zero free this temporary register */\n  int r1, r2;               /* Various register numbers */\n  Expr tempX;               /* Temporary expression node */\n  int p5 = 0;\n\n  assert( target>0 && target<=pParse->nMem );\n  if( v==0 ){\n    assert( pParse->db->mallocFailed );\n    return 0;\n  }\n\nexpr_code_doover:\n  if( pExpr==0 ){\n    op = TK_NULL;\n  }else{\n    op = pExpr->op;\n  }\n  switch( op ){\n    case TK_AGG_COLUMN: {\n      AggInfo *pAggInfo = pExpr->pAggInfo;\n      struct AggInfo_col *pCol = &pAggInfo->aCol[pExpr->iAgg];\n      if( !pAggInfo->directMode ){\n        assert( pCol->iMem>0 );\n        return pCol->iMem;\n      }else if( pAggInfo->useSortingIdx ){\n        sqlite3VdbeAddOp3(v, OP_Column, pAggInfo->sortingIdxPTab,\n                              pCol->iSorterColumn, target);\n        return target;\n      }\n      /* Otherwise, fall thru into the TK_COLUMN case */\n    }\n    case TK_COLUMN: {\n      int iTab = pExpr->iTable;\n      if( ExprHasProperty(pExpr, EP_FixedCol) ){\n        /* This COLUMN expression is really a constant due to WHERE clause\n        ** constraints, and that constant is coded by the pExpr->pLeft\n        ** expresssion.  However, make sure the constant has the correct\n        ** datatype by applying the Affinity of the table column to the\n        ** constant.\n        */\n        int iReg = sqlite3ExprCodeTarget(pParse, pExpr->pLeft,target);\n        int aff = sqlite3TableColumnAffinity(pExpr->y.pTab, pExpr->iColumn);\n        if( aff>SQLITE_AFF_BLOB ){\n          static const char zAff[] = \"B\\000C\\000D\\000E\";\n          assert( SQLITE_AFF_BLOB=='A' );\n          assert( SQLITE_AFF_TEXT=='B' );\n          if( iReg!=target ){\n            sqlite3VdbeAddOp2(v, OP_SCopy, iReg, target);\n            iReg = target;\n          }\n          sqlite3VdbeAddOp4(v, OP_Affinity, iReg, 1, 0,\n                            &zAff[(aff-'B')*2], P4_STATIC);\n        }\n        return iReg;\n      }\n      if( iTab<0 ){\n        if( pParse->iSelfTab<0 ){\n          /* Other columns in the same row for CHECK constraints or\n          ** generated columns or for inserting into partial index.\n          ** The row is unpacked into registers beginning at\n          ** 0-(pParse->iSelfTab).  The rowid (if any) is in a register\n          ** immediately prior to the first column.\n          */\n          Column *pCol;\n          Table *pTab = pExpr->y.pTab;\n          int iSrc;\n          int iCol = pExpr->iColumn;\n          assert( pTab!=0 );\n          assert( iCol>=XN_ROWID );\n          assert( iCol<pExpr->y.pTab->nCol );\n          if( iCol<0 ){\n            return -1-pParse->iSelfTab;\n          }\n          pCol = pTab->aCol + iCol;\n          testcase( iCol!=sqlite3TableColumnToStorage(pTab,iCol) );\n          iSrc = sqlite3TableColumnToStorage(pTab, iCol) - pParse->iSelfTab;\n#ifndef SQLITE_OMIT_GENERATED_COLUMNS\n          if( pCol->colFlags & COLFLAG_GENERATED ){\n            if( pCol->colFlags & COLFLAG_BUSY ){\n              sqlite3ErrorMsg(pParse, \"generated column loop on \\\"%s\\\"\",\n                              pCol->zName);\n              return 0;\n            }\n            pCol->colFlags |= COLFLAG_BUSY;\n            if( pCol->colFlags & COLFLAG_NOTAVAIL ){\n              sqlite3ExprCodeGeneratedColumn(pParse, pCol, iSrc);\n            }\n            pCol->colFlags &= ~(COLFLAG_BUSY|COLFLAG_NOTAVAIL);\n            return iSrc;\n          }else\n#endif /* SQLITE_OMIT_GENERATED_COLUMNS */\n          if( pCol->affinity==SQLITE_AFF_REAL ){\n            sqlite3VdbeAddOp2(v, OP_SCopy, iSrc, target);\n            sqlite3VdbeAddOp1(v, OP_RealAffinity, target);\n            return target;\n          }else{\n            return iSrc;\n          }\n        }else{\n          /* Coding an expression that is part of an index where column names\n          ** in the index refer to the table to which the index belongs */\n          iTab = pParse->iSelfTab - 1;\n        }\n      }\n      return sqlite3ExprCodeGetColumn(pParse, pExpr->y.pTab,\n                               pExpr->iColumn, iTab, target,\n                               pExpr->op2);\n    }\n    case TK_INTEGER: {\n      codeInteger(pParse, pExpr, 0, target);\n      return target;\n    }\n    case TK_TRUEFALSE: {\n      sqlite3VdbeAddOp2(v, OP_Integer, sqlite3ExprTruthValue(pExpr), target);\n      return target;\n    }\n#ifndef SQLITE_OMIT_FLOATING_POINT\n    case TK_FLOAT: {\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      codeReal(v, pExpr->u.zToken, 0, target);\n      return target;\n    }\n#endif\n    case TK_STRING: {\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      sqlite3VdbeLoadString(v, target, pExpr->u.zToken);\n      return target;\n    }\n    case TK_NULL: {\n      sqlite3VdbeAddOp2(v, OP_Null, 0, target);\n      return target;\n    }\n#ifndef SQLITE_OMIT_BLOB_LITERAL\n    case TK_BLOB: {\n      int n;\n      const char *z;\n      char *zBlob;\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      assert( pExpr->u.zToken[0]=='x' || pExpr->u.zToken[0]=='X' );\n      assert( pExpr->u.zToken[1]=='\\'' );\n      z = &pExpr->u.zToken[2];\n      n = sqlite3Strlen30(z) - 1;\n      assert( z[n]=='\\'' );\n      zBlob = sqlite3HexToBlob(sqlite3VdbeDb(v), z, n);\n      sqlite3VdbeAddOp4(v, OP_Blob, n/2, target, 0, zBlob, P4_DYNAMIC);\n      return target;\n    }\n#endif\n    case TK_VARIABLE: {\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      assert( pExpr->u.zToken!=0 );\n      assert( pExpr->u.zToken[0]!=0 );\n      sqlite3VdbeAddOp2(v, OP_Variable, pExpr->iColumn, target);\n      if( pExpr->u.zToken[1]!=0 ){\n        const char *z = sqlite3VListNumToName(pParse->pVList, pExpr->iColumn);\n        assert( pExpr->u.zToken[0]=='?' || strcmp(pExpr->u.zToken, z)==0 );\n        pParse->pVList[0] = 0; /* Indicate VList may no longer be enlarged */\n        sqlite3VdbeAppendP4(v, (char*)z, P4_STATIC);\n      }\n      return target;\n    }\n    case TK_REGISTER: {\n      return pExpr->iTable;\n    }\n#ifndef SQLITE_OMIT_CAST\n    case TK_CAST: {\n      /* Expressions of the form:   CAST(pLeft AS token) */\n      inReg = sqlite3ExprCodeTarget(pParse, pExpr->pLeft, target);\n      if( inReg!=target ){\n        sqlite3VdbeAddOp2(v, OP_SCopy, inReg, target);\n        inReg = target;\n      }\n      sqlite3VdbeAddOp2(v, OP_Cast, target,\n                        sqlite3AffinityType(pExpr->u.zToken, 0));\n      return inReg;\n    }\n#endif /* SQLITE_OMIT_CAST */\n    case TK_IS:\n    case TK_ISNOT:\n      op = (op==TK_IS) ? TK_EQ : TK_NE;\n      p5 = SQLITE_NULLEQ;\n      /* fall-through */\n    case TK_LT:\n    case TK_LE:\n    case TK_GT:\n    case TK_GE:\n    case TK_NE:\n    case TK_EQ: {\n      Expr *pLeft = pExpr->pLeft;\n      if( sqlite3ExprIsVector(pLeft) ){\n        codeVectorCompare(pParse, pExpr, target, op, p5);\n      }else{\n        r1 = sqlite3ExprCodeTemp(pParse, pLeft, &regFree1);\n        r2 = sqlite3ExprCodeTemp(pParse, pExpr->pRight, &regFree2);\n        codeCompare(pParse, pLeft, pExpr->pRight, op,\n            r1, r2, inReg, SQLITE_STOREP2 | p5,\n            ExprHasProperty(pExpr,EP_Commuted));\n        assert(TK_LT==OP_Lt); testcase(op==OP_Lt); VdbeCoverageIf(v,op==OP_Lt);\n        assert(TK_LE==OP_Le); testcase(op==OP_Le); VdbeCoverageIf(v,op==OP_Le);\n        assert(TK_GT==OP_Gt); testcase(op==OP_Gt); VdbeCoverageIf(v,op==OP_Gt);\n        assert(TK_GE==OP_Ge); testcase(op==OP_Ge); VdbeCoverageIf(v,op==OP_Ge);\n        assert(TK_EQ==OP_Eq); testcase(op==OP_Eq); VdbeCoverageIf(v,op==OP_Eq);\n        assert(TK_NE==OP_Ne); testcase(op==OP_Ne); VdbeCoverageIf(v,op==OP_Ne);\n        testcase( regFree1==0 );\n        testcase( regFree2==0 );\n      }\n      break;\n    }\n    case TK_AND:\n    case TK_OR:\n    case TK_PLUS:\n    case TK_STAR:\n    case TK_MINUS:\n    case TK_REM:\n    case TK_BITAND:\n    case TK_BITOR:\n    case TK_SLASH:\n    case TK_LSHIFT:\n    case TK_RSHIFT: \n    case TK_CONCAT: {\n      assert( TK_AND==OP_And );            testcase( op==TK_AND );\n      assert( TK_OR==OP_Or );              testcase( op==TK_OR );\n      assert( TK_PLUS==OP_Add );           testcase( op==TK_PLUS );\n      assert( TK_MINUS==OP_Subtract );     testcase( op==TK_MINUS );\n      assert( TK_REM==OP_Remainder );      testcase( op==TK_REM );\n      assert( TK_BITAND==OP_BitAnd );      testcase( op==TK_BITAND );\n      assert( TK_BITOR==OP_BitOr );        testcase( op==TK_BITOR );\n      assert( TK_SLASH==OP_Divide );       testcase( op==TK_SLASH );\n      assert( TK_LSHIFT==OP_ShiftLeft );   testcase( op==TK_LSHIFT );\n      assert( TK_RSHIFT==OP_ShiftRight );  testcase( op==TK_RSHIFT );\n      assert( TK_CONCAT==OP_Concat );      testcase( op==TK_CONCAT );\n      r1 = sqlite3ExprCodeTemp(pParse, pExpr->pLeft, &regFree1);\n      r2 = sqlite3ExprCodeTemp(pParse, pExpr->pRight, &regFree2);\n      sqlite3VdbeAddOp3(v, op, r2, r1, target);\n      testcase( regFree1==0 );\n      testcase( regFree2==0 );\n      break;\n    }\n    case TK_UMINUS: {\n      Expr *pLeft = pExpr->pLeft;\n      assert( pLeft );\n      if( pLeft->op==TK_INTEGER ){\n        codeInteger(pParse, pLeft, 1, target);\n        return target;\n#ifndef SQLITE_OMIT_FLOATING_POINT\n      }else if( pLeft->op==TK_FLOAT ){\n        assert( !ExprHasProperty(pExpr, EP_IntValue) );\n        codeReal(v, pLeft->u.zToken, 1, target);\n        return target;\n#endif\n      }else{\n        tempX.op = TK_INTEGER;\n        tempX.flags = EP_IntValue|EP_TokenOnly;\n        tempX.u.iValue = 0;\n        r1 = sqlite3ExprCodeTemp(pParse, &tempX, &regFree1);\n        r2 = sqlite3ExprCodeTemp(pParse, pExpr->pLeft, &regFree2);\n        sqlite3VdbeAddOp3(v, OP_Subtract, r2, r1, target);\n        testcase( regFree2==0 );\n      }\n      break;\n    }\n    case TK_BITNOT:\n    case TK_NOT: {\n      assert( TK_BITNOT==OP_BitNot );   testcase( op==TK_BITNOT );\n      assert( TK_NOT==OP_Not );         testcase( op==TK_NOT );\n      r1 = sqlite3ExprCodeTemp(pParse, pExpr->pLeft, &regFree1);\n      testcase( regFree1==0 );\n      sqlite3VdbeAddOp2(v, op, r1, inReg);\n      break;\n    }\n    case TK_TRUTH: {\n      int isTrue;    /* IS TRUE or IS NOT TRUE */\n      int bNormal;   /* IS TRUE or IS FALSE */\n      r1 = sqlite3ExprCodeTemp(pParse, pExpr->pLeft, &regFree1);\n      testcase( regFree1==0 );\n      isTrue = sqlite3ExprTruthValue(pExpr->pRight);\n      bNormal = pExpr->op2==TK_IS;\n      testcase( isTrue && bNormal);\n      testcase( !isTrue && bNormal);\n      sqlite3VdbeAddOp4Int(v, OP_IsTrue, r1, inReg, !isTrue, isTrue ^ bNormal);\n      break;\n    }\n    case TK_ISNULL:\n    case TK_NOTNULL: {\n      int addr;\n      assert( TK_ISNULL==OP_IsNull );   testcase( op==TK_ISNULL );\n      assert( TK_NOTNULL==OP_NotNull ); testcase( op==TK_NOTNULL );\n      sqlite3VdbeAddOp2(v, OP_Integer, 1, target);\n      r1 = sqlite3ExprCodeTemp(pParse, pExpr->pLeft, &regFree1);\n      testcase( regFree1==0 );\n      addr = sqlite3VdbeAddOp1(v, op, r1);\n      VdbeCoverageIf(v, op==TK_ISNULL);\n      VdbeCoverageIf(v, op==TK_NOTNULL);\n      sqlite3VdbeAddOp2(v, OP_Integer, 0, target);\n      sqlite3VdbeJumpHere(v, addr);\n      break;\n    }\n    case TK_AGG_FUNCTION: {\n      AggInfo *pInfo = pExpr->pAggInfo;\n      if( pInfo==0 ){\n        assert( !ExprHasProperty(pExpr, EP_IntValue) );\n        sqlite3ErrorMsg(pParse, \"misuse of aggregate: %s()\", pExpr->u.zToken);\n      }else{\n        return pInfo->aFunc[pExpr->iAgg].iMem;\n      }\n      break;\n    }\n    case TK_FUNCTION: {\n      ExprList *pFarg;       /* List of function arguments */\n      int nFarg;             /* Number of function arguments */\n      FuncDef *pDef;         /* The function definition object */\n      const char *zId;       /* The function name */\n      u32 constMask = 0;     /* Mask of function arguments that are constant */\n      int i;                 /* Loop counter */\n      sqlite3 *db = pParse->db;  /* The database connection */\n      u8 enc = ENC(db);      /* The text encoding used by this database */\n      CollSeq *pColl = 0;    /* A collating sequence */\n\n#ifndef SQLITE_OMIT_WINDOWFUNC\n      if( ExprHasProperty(pExpr, EP_WinFunc) ){\n        return pExpr->y.pWin->regResult;\n      }\n#endif\n\n      if( ConstFactorOk(pParse) && sqlite3ExprIsConstantNotJoin(pExpr) ){\n        /* SQL functions can be expensive. So try to move constant functions\n        ** out of the inner loop, even if that means an extra OP_Copy. */\n        return sqlite3ExprCodeAtInit(pParse, pExpr, -1);\n      }\n      assert( !ExprHasProperty(pExpr, EP_xIsSelect) );\n      if( ExprHasProperty(pExpr, EP_TokenOnly) ){\n        pFarg = 0;\n      }else{\n        pFarg = pExpr->x.pList;\n      }\n      nFarg = pFarg ? pFarg->nExpr : 0;\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      zId = pExpr->u.zToken;\n      pDef = sqlite3FindFunction(db, zId, nFarg, enc, 0);\n#ifdef SQLITE_ENABLE_UNKNOWN_SQL_FUNCTION\n      if( pDef==0 && pParse->explain ){\n        pDef = sqlite3FindFunction(db, \"unknown\", nFarg, enc, 0);\n      }\n#endif\n      if( pDef==0 || pDef->xFinalize!=0 ){\n        sqlite3ErrorMsg(pParse, \"unknown function: %s()\", zId);\n        break;\n      }\n\n      /* Attempt a direct implementation of the built-in COALESCE() and\n      ** IFNULL() functions.  This avoids unnecessary evaluation of\n      ** arguments past the first non-NULL argument.\n      */\n      if( pDef->funcFlags & SQLITE_FUNC_COALESCE ){\n        int endCoalesce = sqlite3VdbeMakeLabel(pParse);\n        assert( nFarg>=2 );\n        sqlite3ExprCode(pParse, pFarg->a[0].pExpr, target);\n        for(i=1; i<nFarg; i++){\n          sqlite3VdbeAddOp2(v, OP_NotNull, target, endCoalesce);\n          VdbeCoverage(v);\n          sqlite3ExprCode(pParse, pFarg->a[i].pExpr, target);\n        }\n        sqlite3VdbeResolveLabel(v, endCoalesce);\n        break;\n      }\n\n      /* The UNLIKELY() function is a no-op.  The result is the value\n      ** of the first argument.\n      */\n      if( pDef->funcFlags & SQLITE_FUNC_UNLIKELY ){\n        assert( nFarg>=1 );\n        return sqlite3ExprCodeTarget(pParse, pFarg->a[0].pExpr, target);\n      }\n\n#ifdef SQLITE_DEBUG\n      /* The AFFINITY() function evaluates to a string that describes\n      ** the type affinity of the argument.  This is used for testing of\n      ** the SQLite type logic.\n      */\n      if( pDef->funcFlags & SQLITE_FUNC_AFFINITY ){\n        const char *azAff[] = { \"blob\", \"text\", \"numeric\", \"integer\", \"real\" };\n        char aff;\n        assert( nFarg==1 );\n        aff = sqlite3ExprAffinity(pFarg->a[0].pExpr);\n        sqlite3VdbeLoadString(v, target, \n                (aff<=SQLITE_AFF_NONE) ? \"none\" : azAff[aff-SQLITE_AFF_BLOB]);\n        return target;\n      }\n#endif\n\n      for(i=0; i<nFarg; i++){\n        if( i<32 && sqlite3ExprIsConstant(pFarg->a[i].pExpr) ){\n          testcase( i==31 );\n          constMask |= MASKBIT32(i);\n        }\n        if( (pDef->funcFlags & SQLITE_FUNC_NEEDCOLL)!=0 && !pColl ){\n          pColl = sqlite3ExprCollSeq(pParse, pFarg->a[i].pExpr);\n        }\n      }\n      if( pFarg ){\n        if( constMask ){\n          r1 = pParse->nMem+1;\n          pParse->nMem += nFarg;\n        }else{\n          r1 = sqlite3GetTempRange(pParse, nFarg);\n        }\n\n        /* For length() and typeof() functions with a column argument,\n        ** set the P5 parameter to the OP_Column opcode to OPFLAG_LENGTHARG\n        ** or OPFLAG_TYPEOFARG respectively, to avoid unnecessary data\n        ** loading.\n        */\n        if( (pDef->funcFlags & (SQLITE_FUNC_LENGTH|SQLITE_FUNC_TYPEOF))!=0 ){\n          u8 exprOp;\n          assert( nFarg==1 );\n          assert( pFarg->a[0].pExpr!=0 );\n          exprOp = pFarg->a[0].pExpr->op;\n          if( exprOp==TK_COLUMN || exprOp==TK_AGG_COLUMN ){\n            assert( SQLITE_FUNC_LENGTH==OPFLAG_LENGTHARG );\n            assert( SQLITE_FUNC_TYPEOF==OPFLAG_TYPEOFARG );\n            testcase( pDef->funcFlags & OPFLAG_LENGTHARG );\n            pFarg->a[0].pExpr->op2 = \n                  pDef->funcFlags & (OPFLAG_LENGTHARG|OPFLAG_TYPEOFARG);\n          }\n        }\n\n        sqlite3ExprCodeExprList(pParse, pFarg, r1, 0,\n                                SQLITE_ECEL_DUP|SQLITE_ECEL_FACTOR);\n      }else{\n        r1 = 0;\n      }\n#ifndef SQLITE_OMIT_VIRTUALTABLE\n      /* Possibly overload the function if the first argument is\n      ** a virtual table column.\n      **\n      ** For infix functions (LIKE, GLOB, REGEXP, and MATCH) use the\n      ** second argument, not the first, as the argument to test to\n      ** see if it is a column in a virtual table.  This is done because\n      ** the left operand of infix functions (the operand we want to\n      ** control overloading) ends up as the second argument to the\n      ** function.  The expression \"A glob B\" is equivalent to \n      ** \"glob(B,A).  We want to use the A in \"A glob B\" to test\n      ** for function overloading.  But we use the B term in \"glob(B,A)\".\n      */\n      if( nFarg>=2 && ExprHasProperty(pExpr, EP_InfixFunc) ){\n        pDef = sqlite3VtabOverloadFunction(db, pDef, nFarg, pFarg->a[1].pExpr);\n      }else if( nFarg>0 ){\n        pDef = sqlite3VtabOverloadFunction(db, pDef, nFarg, pFarg->a[0].pExpr);\n      }\n#endif\n      if( pDef->funcFlags & SQLITE_FUNC_NEEDCOLL ){\n        if( !pColl ) pColl = db->pDfltColl; \n        sqlite3VdbeAddOp4(v, OP_CollSeq, 0, 0, 0, (char *)pColl, P4_COLLSEQ);\n      }\n#ifdef SQLITE_ENABLE_OFFSET_SQL_FUNC\n      if( pDef->funcFlags & SQLITE_FUNC_OFFSET ){\n        Expr *pArg = pFarg->a[0].pExpr;\n        if( pArg->op==TK_COLUMN ){\n          sqlite3VdbeAddOp3(v, OP_Offset, pArg->iTable, pArg->iColumn, target);\n        }else{\n          sqlite3VdbeAddOp2(v, OP_Null, 0, target);\n        }\n      }else\n#endif\n      {\n        sqlite3VdbeAddFunctionCall(pParse, constMask, r1, target, nFarg,\n                                   pDef, pExpr->op2);\n      }\n      if( nFarg && constMask==0 ){\n        sqlite3ReleaseTempRange(pParse, r1, nFarg);\n      }\n      return target;\n    }\n#ifndef SQLITE_OMIT_SUBQUERY\n    case TK_EXISTS:\n    case TK_SELECT: {\n      int nCol;\n      testcase( op==TK_EXISTS );\n      testcase( op==TK_SELECT );\n      if( op==TK_SELECT && (nCol = pExpr->x.pSelect->pEList->nExpr)!=1 ){\n        sqlite3SubselectError(pParse, nCol, 1);\n      }else{\n        return sqlite3CodeSubselect(pParse, pExpr);\n      }\n      break;\n    }\n    case TK_SELECT_COLUMN: {\n      int n;\n      if( pExpr->pLeft->iTable==0 ){\n        pExpr->pLeft->iTable = sqlite3CodeSubselect(pParse, pExpr->pLeft);\n      }\n      assert( pExpr->iTable==0 || pExpr->pLeft->op==TK_SELECT );\n      if( pExpr->iTable!=0\n       && pExpr->iTable!=(n = sqlite3ExprVectorSize(pExpr->pLeft))\n      ){\n        sqlite3ErrorMsg(pParse, \"%d columns assigned %d values\",\n                                pExpr->iTable, n);\n      }\n      return pExpr->pLeft->iTable + pExpr->iColumn;\n    }\n    case TK_IN: {\n      int destIfFalse = sqlite3VdbeMakeLabel(pParse);\n      int destIfNull = sqlite3VdbeMakeLabel(pParse);\n      sqlite3VdbeAddOp2(v, OP_Null, 0, target);\n      sqlite3ExprCodeIN(pParse, pExpr, destIfFalse, destIfNull);\n      sqlite3VdbeAddOp2(v, OP_Integer, 1, target);\n      sqlite3VdbeResolveLabel(v, destIfFalse);\n      sqlite3VdbeAddOp2(v, OP_AddImm, target, 0);\n      sqlite3VdbeResolveLabel(v, destIfNull);\n      return target;\n    }\n#endif /* SQLITE_OMIT_SUBQUERY */\n\n\n    /*\n    **    x BETWEEN y AND z\n    **\n    ** This is equivalent to\n    **\n    **    x>=y AND x<=z\n    **\n    ** X is stored in pExpr->pLeft.\n    ** Y is stored in pExpr->pList->a[0].pExpr.\n    ** Z is stored in pExpr->pList->a[1].pExpr.\n    */\n    case TK_BETWEEN: {\n      exprCodeBetween(pParse, pExpr, target, 0, 0);\n      return target;\n    }\n    case TK_SPAN:\n    case TK_COLLATE: \n    case TK_UPLUS: {\n      pExpr = pExpr->pLeft;\n      goto expr_code_doover; /* 2018-04-28: Prevent deep recursion. OSSFuzz. */\n    }\n\n    case TK_TRIGGER: {\n      /* If the opcode is TK_TRIGGER, then the expression is a reference\n      ** to a column in the new.* or old.* pseudo-tables available to\n      ** trigger programs. In this case Expr.iTable is set to 1 for the\n      ** new.* pseudo-table, or 0 for the old.* pseudo-table. Expr.iColumn\n      ** is set to the column of the pseudo-table to read, or to -1 to\n      ** read the rowid field.\n      **\n      ** The expression is implemented using an OP_Param opcode. The p1\n      ** parameter is set to 0 for an old.rowid reference, or to (i+1)\n      ** to reference another column of the old.* pseudo-table, where \n      ** i is the index of the column. For a new.rowid reference, p1 is\n      ** set to (n+1), where n is the number of columns in each pseudo-table.\n      ** For a reference to any other column in the new.* pseudo-table, p1\n      ** is set to (n+2+i), where n and i are as defined previously. For\n      ** example, if the table on which triggers are being fired is\n      ** declared as:\n      **\n      **   CREATE TABLE t1(a, b);\n      **\n      ** Then p1 is interpreted as follows:\n      **\n      **   p1==0   ->    old.rowid     p1==3   ->    new.rowid\n      **   p1==1   ->    old.a         p1==4   ->    new.a\n      **   p1==2   ->    old.b         p1==5   ->    new.b       \n      */\n      Table *pTab = pExpr->y.pTab;\n      int iCol = pExpr->iColumn;\n      int p1 = pExpr->iTable * (pTab->nCol+1) + 1 \n                     + (iCol>=0 ? sqlite3TableColumnToStorage(pTab, iCol) : -1);\n\n      assert( pExpr->iTable==0 || pExpr->iTable==1 );\n      assert( iCol>=-1 && iCol<pTab->nCol );\n      assert( pTab->iPKey<0 || iCol!=pTab->iPKey );\n      assert( p1>=0 && p1<(pTab->nCol*2+2) );\n\n      sqlite3VdbeAddOp2(v, OP_Param, p1, target);\n      VdbeComment((v, \"r[%d]=%s.%s\", target,\n        (pExpr->iTable ? \"new\" : \"old\"),\n        (pExpr->iColumn<0 ? \"rowid\" : pExpr->y.pTab->aCol[iCol].zName)\n      ));\n\n#ifndef SQLITE_OMIT_FLOATING_POINT\n      /* If the column has REAL affinity, it may currently be stored as an\n      ** integer. Use OP_RealAffinity to make sure it is really real.\n      **\n      ** EVIDENCE-OF: R-60985-57662 SQLite will convert the value back to\n      ** floating point when extracting it from the record.  */\n      if( iCol>=0 && pTab->aCol[iCol].affinity==SQLITE_AFF_REAL ){\n        sqlite3VdbeAddOp1(v, OP_RealAffinity, target);\n      }\n#endif\n      break;\n    }\n\n    case TK_VECTOR: {\n      sqlite3ErrorMsg(pParse, \"row value misused\");\n      break;\n    }\n\n    /* TK_IF_NULL_ROW Expr nodes are inserted ahead of expressions\n    ** that derive from the right-hand table of a LEFT JOIN.  The\n    ** Expr.iTable value is the table number for the right-hand table.\n    ** The expression is only evaluated if that table is not currently\n    ** on a LEFT JOIN NULL row.\n    */\n    case TK_IF_NULL_ROW: {\n      int addrINR;\n      u8 okConstFactor = pParse->okConstFactor;\n      addrINR = sqlite3VdbeAddOp1(v, OP_IfNullRow, pExpr->iTable);\n      /* Temporarily disable factoring of constant expressions, since\n      ** even though expressions may appear to be constant, they are not\n      ** really constant because they originate from the right-hand side\n      ** of a LEFT JOIN. */\n      pParse->okConstFactor = 0;\n      inReg = sqlite3ExprCodeTarget(pParse, pExpr->pLeft, target);\n      pParse->okConstFactor = okConstFactor;\n      sqlite3VdbeJumpHere(v, addrINR);\n      sqlite3VdbeChangeP3(v, addrINR, inReg);\n      break;\n    }\n\n    /*\n    ** Form A:\n    **   CASE x WHEN e1 THEN r1 WHEN e2 THEN r2 ... WHEN eN THEN rN ELSE y END\n    **\n    ** Form B:\n    **   CASE WHEN e1 THEN r1 WHEN e2 THEN r2 ... WHEN eN THEN rN ELSE y END\n    **\n    ** Form A is can be transformed into the equivalent form B as follows:\n    **   CASE WHEN x=e1 THEN r1 WHEN x=e2 THEN r2 ...\n    **        WHEN x=eN THEN rN ELSE y END\n    **\n    ** X (if it exists) is in pExpr->pLeft.\n    ** Y is in the last element of pExpr->x.pList if pExpr->x.pList->nExpr is\n    ** odd.  The Y is also optional.  If the number of elements in x.pList\n    ** is even, then Y is omitted and the \"otherwise\" result is NULL.\n    ** Ei is in pExpr->pList->a[i*2] and Ri is pExpr->pList->a[i*2+1].\n    **\n    ** The result of the expression is the Ri for the first matching Ei,\n    ** or if there is no matching Ei, the ELSE term Y, or if there is\n    ** no ELSE term, NULL.\n    */\n    default: assert( op==TK_CASE ); {\n      int endLabel;                     /* GOTO label for end of CASE stmt */\n      int nextCase;                     /* GOTO label for next WHEN clause */\n      int nExpr;                        /* 2x number of WHEN terms */\n      int i;                            /* Loop counter */\n      ExprList *pEList;                 /* List of WHEN terms */\n      struct ExprList_item *aListelem;  /* Array of WHEN terms */\n      Expr opCompare;                   /* The X==Ei expression */\n      Expr *pX;                         /* The X expression */\n      Expr *pTest = 0;                  /* X==Ei (form A) or just Ei (form B) */\n      Expr *pDel = 0;\n      sqlite3 *db = pParse->db;\n\n      assert( !ExprHasProperty(pExpr, EP_xIsSelect) && pExpr->x.pList );\n      assert(pExpr->x.pList->nExpr > 0);\n      pEList = pExpr->x.pList;\n      aListelem = pEList->a;\n      nExpr = pEList->nExpr;\n      endLabel = sqlite3VdbeMakeLabel(pParse);\n      if( (pX = pExpr->pLeft)!=0 ){\n        pDel = sqlite3ExprDup(db, pX, 0);\n        if( db->mallocFailed ){\n          sqlite3ExprDelete(db, pDel);\n          break;\n        }\n        testcase( pX->op==TK_COLUMN );\n        exprToRegister(pDel, exprCodeVector(pParse, pDel, &regFree1));\n        testcase( regFree1==0 );\n        memset(&opCompare, 0, sizeof(opCompare));\n        opCompare.op = TK_EQ;\n        opCompare.pLeft = pDel;\n        pTest = &opCompare;\n        /* Ticket b351d95f9cd5ef17e9d9dbae18f5ca8611190001:\n        ** The value in regFree1 might get SCopy-ed into the file result.\n        ** So make sure that the regFree1 register is not reused for other\n        ** purposes and possibly overwritten.  */\n        regFree1 = 0;\n      }\n      for(i=0; i<nExpr-1; i=i+2){\n        if( pX ){\n          assert( pTest!=0 );\n          opCompare.pRight = aListelem[i].pExpr;\n        }else{\n          pTest = aListelem[i].pExpr;\n        }\n        nextCase = sqlite3VdbeMakeLabel(pParse);\n        testcase( pTest->op==TK_COLUMN );\n        sqlite3ExprIfFalse(pParse, pTest, nextCase, SQLITE_JUMPIFNULL);\n        testcase( aListelem[i+1].pExpr->op==TK_COLUMN );\n        sqlite3ExprCode(pParse, aListelem[i+1].pExpr, target);\n        sqlite3VdbeGoto(v, endLabel);\n        sqlite3VdbeResolveLabel(v, nextCase);\n      }\n      if( (nExpr&1)!=0 ){\n        sqlite3ExprCode(pParse, pEList->a[nExpr-1].pExpr, target);\n      }else{\n        sqlite3VdbeAddOp2(v, OP_Null, 0, target);\n      }\n      sqlite3ExprDelete(db, pDel);\n      sqlite3VdbeResolveLabel(v, endLabel);\n      break;\n    }\n#ifndef SQLITE_OMIT_TRIGGER\n    case TK_RAISE: {\n      assert( pExpr->affExpr==OE_Rollback \n           || pExpr->affExpr==OE_Abort\n           || pExpr->affExpr==OE_Fail\n           || pExpr->affExpr==OE_Ignore\n      );\n      if( !pParse->pTriggerTab ){\n        sqlite3ErrorMsg(pParse,\n                       \"RAISE() may only be used within a trigger-program\");\n        return 0;\n      }\n      if( pExpr->affExpr==OE_Abort ){\n        sqlite3MayAbort(pParse);\n      }\n      assert( !ExprHasProperty(pExpr, EP_IntValue) );\n      if( pExpr->affExpr==OE_Ignore ){\n        sqlite3VdbeAddOp4(\n            v, OP_Halt, SQLITE_OK, OE_Ignore, 0, pExpr->u.zToken,0);\n        VdbeCoverage(v);\n      }else{\n        sqlite3HaltConstraint(pParse, SQLITE_CONSTRAINT_TRIGGER,\n                              pExpr->affExpr, pExpr->u.zToken, 0, 0);\n      }\n\n      break;\n    }\n#endif\n  }\n  sqlite3ReleaseTempReg(pParse, regFree1);\n  sqlite3ReleaseTempReg(pParse, regFree2);\n  return inReg;\n}",
        "commit_message": "Fix a problem that comes up when using generated columns that evaluate to a\nconstant in an index and then making use of that index in a join.\n\nFossilOrigin-Name: 8b12e95fec7ce6e0de82a04ca3dfcf1a8e62e233b7382aa28a8a9be6e862b1af",
        "cve_desc": "SQLite 3.30.1 mishandles pExpr->y.pTab, as demonstrated by the TK_COLUMN case in sqlite3ExprCodeTarget in expr.c.",
        "target": 1
      },
      {
        "idx": 204820,
        "reasoning": "This code is vulnerable because the `pItem->colUsed` bitmask is incorrectly updated when a generated column is involved in a join's `USING` clause, potentially leading to inaccurate tracking of column usage. Specifically, the bit shift `((Bitmask)1)<<(iCol>=BMS ? BMS-1 : iCol)` can cause an out-of-bounds write if `iCol` is greater than or equal to `BMS`, as it attempts to shift by an amount exceeding the bitmask's size, aligning with the CVE's description of issues arising from generated columns impacting integrity checks.",
        "func": "Expr *sqlite3CreateColumnExpr(sqlite3 *db, SrcList *pSrc, int iSrc, int iCol){\n  Expr *p = sqlite3ExprAlloc(db, TK_COLUMN, 0, 0);\n  if( p ){\n    struct SrcList_item *pItem = &pSrc->a[iSrc];\n    p->y.pTab = pItem->pTab;\n    p->iTable = pItem->iCursor;\n    if( p->y.pTab->iPKey==iCol ){\n      p->iColumn = -1;\n    }else{\n      p->iColumn = (ynVar)iCol;\n      testcase( iCol==BMS );\n      testcase( iCol==BMS-1 );\n      pItem->colUsed |= ((Bitmask)1)<<(iCol>=BMS ? BMS-1 : iCol);\n    }\n  }\n  return p;\n}",
        "commit_message": "Ensure that the SrcList_item.colUsed field is set correctly (set to have a\n1 for all columns of the table) when a generated column appears in the USING\nclause of a join.\n\nFossilOrigin-Name: 1923efb283e8840fa7436eb20b9d2174ef7cace1690d3b97b572a0db2048b8e3",
        "cve_desc": "pragma.c in SQLite through 3.30.1 mishandles NOT NULL in an integrity_check PRAGMA command in certain cases of generated columns.",
        "target": 1
      }
    ]
  },
  "squid": {
    "0": [
      {
        "idx": 330558,
        "reasoning": "This code addresses a previously identified memory leak related to SNMP packet parsing, specifically when queries are denied or use unsupported commands. The fix involves ensuring proper freeing of allocated memory (`snmp_var_free`) within error handling and response construction paths, preventing the accumulation of leaked bytes as reported in the `cache.log` warnings \u2013 therefore, it resolves a known issue rather than introducing a new vulnerability.",
        "func": "snmpAgentResponse(struct snmp_pdu *PDU) {\n\n    struct snmp_pdu *Answer = NULL;\n\n    debugs(49, 5, \"snmpAgentResponse: Called.\");\n\n    if ((Answer = snmp_pdu_create(SNMP_PDU_RESPONSE))) {\n        Answer->reqid = PDU->reqid;\n        Answer->errindex = 0;\n\n        if (PDU->command == SNMP_PDU_GET || PDU->command == SNMP_PDU_GETNEXT) {\n            /* Indirect way */\n            int get_next = (PDU->command == SNMP_PDU_GETNEXT);\n            variable_list *VarPtr_;\n            variable_list **RespVars = &(Answer->variables);\n            oid_ParseFn *ParseFn;\n            int index = 0;\n            /* Loop through all variables */\n\n            for (VarPtr_ = PDU->variables; VarPtr_; VarPtr_ = VarPtr_->next_variable) {\n                variable_list *VarPtr = VarPtr_;\n                variable_list *VarNew = NULL;\n                oid *NextOidName = NULL;\n                snint NextOidNameLen = 0;\n\n                ++index;\n\n                if (get_next)\n                    ParseFn = snmpTreeNext(VarPtr->name, VarPtr->name_length, &NextOidName, &NextOidNameLen);\n                else\n                    ParseFn = snmpTreeGet(VarPtr->name, VarPtr->name_length);\n\n                if (ParseFn == NULL) {\n                    Answer->errstat = SNMP_ERR_NOSUCHNAME;\n                    debugs(49, 5, \"snmpAgentResponse: No such oid. \");\n                } else {\n                    if (get_next) {\n                        VarPtr = snmp_var_new(NextOidName, NextOidNameLen);\n                        xfree(NextOidName);\n                    }\n\n                    int * errstatTmp =  &(Answer->errstat);\n\n                    VarNew = (*ParseFn) (VarPtr, (snint *) errstatTmp);\n\n                    if (get_next)\n                        snmp_var_free(VarPtr);\n                }\n\n                if ((Answer->errstat != SNMP_ERR_NOERROR) || (VarNew == NULL)) {\n                    Answer->errindex = index;\n                    debugs(49, 5, \"snmpAgentResponse: error.\");\n\n                    if (VarNew)\n                        snmp_var_free(VarNew);\n\n                    while ((VarPtr = Answer->variables) != NULL) {\n                        Answer->variables = VarPtr->next_variable;\n                        snmp_var_free(VarPtr);\n                    }\n\n                    /* Steal the original PDU list of variables for the error response */\n                    Answer->variables = PDU->variables;\n\n                    PDU->variables = NULL;\n\n                    return (Answer);\n                }\n\n                /* No error.  Insert this var at the end, and move on to the next.\n                 */\n                *RespVars = VarNew;\n\n                RespVars = &(VarNew->next_variable);\n            }\n        }\n    }\n\n    return (Answer);\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 0
      },
      {
        "idx": 330559,
        "reasoning": "This code is not directly vulnerable to the memory leak described in the commit message. The commit addresses leaks stemming from SNMP packet *parsing* and denial handling, while this code snippet focuses solely on allocating and initializing a `mib_tree_entry` structure \u2013 it doesn't handle SNMP requests or access control decisions directly.\n\n\n\n",
        "func": "snmpAddNode(oid * name, int len, oid_ParseFn * parsefunction, instance_Fn * instancefunction, AggrType aggrType, int children,...)\n{\n    va_list args;\n    int loop;\n    mib_tree_entry *entry = NULL;\n    va_start(args, children);\n\n    MemBuf tmp;\n    debugs(49, 6, \"snmpAddNode: Children : \" << children << \", Oid : \" << snmpDebugOid(name, len, tmp));\n\n    va_start(args, children);\n    entry = (mib_tree_entry *)xmalloc(sizeof(mib_tree_entry));\n    entry->name = name;\n    entry->len = len;\n    entry->parsefunction = parsefunction;\n    entry->instancefunction = instancefunction;\n    entry->children = children;\n    entry->leaves = NULL;\n    entry->aggrType = aggrType;\n\n    if (children > 0) {\n        entry->leaves = (mib_tree_entry **)xmalloc(sizeof(mib_tree_entry *) * children);\n\n        for (loop = 0; loop < children; ++loop) {\n            entry->leaves[loop] = va_arg(args, mib_tree_entry *);\n            entry->leaves[loop]->parent = entry;\n        }\n    }\n\n    va_end(args);\n    return (entry);\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 0
      },
      {
        "idx": 330560,
        "reasoning": "This code addresses a previously identified memory leak related to denied SNMP queries and unsupported commands by explicitly freeing the `PDU` structures (`rq->PDU` and `RespPDU`) using `snmp_free_pdu`. The fix ensures that memory allocated for these packets is released even when a response isn't fully constructed or sent, resolving the leak described in the commit message and thus isn't introducing new vulnerabilities.\n\n\n\n",
        "func": "snmpConstructReponse(SnmpRequest * rq)\n{\n\n    struct snmp_pdu *RespPDU;\n\n    debugs(49, 5, \"snmpConstructReponse: Called.\");\n\n    if (UsingSmp() && IamWorkerProcess()) {\n        AsyncJob::Start(new Snmp::Forwarder(static_cast<Snmp::Pdu&>(*rq->PDU),\n                                            static_cast<Snmp::Session&>(rq->session), rq->sock, rq->from));\n        snmp_free_pdu(rq->PDU);\n        return;\n    }\n\n    RespPDU = snmpAgentResponse(rq->PDU);\n    snmp_free_pdu(rq->PDU);\n\n    if (RespPDU != NULL) {\n        snmp_build(&rq->session, RespPDU, rq->outbuf, &rq->outlen);\n        comm_udp_sendto(rq->sock, rq->from, rq->outbuf, rq->outlen);\n        snmp_free_pdu(RespPDU);\n    }\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 0
      },
      {
        "idx": 330561,
        "reasoning": "This code snippet simply provides access to a singleton instance and doesn't directly handle any network input or memory management related to the SNMP packet parsing described in the commit message. Therefore, it's not vulnerable to the memory leak being addressed and is safe based on the provided context.\n\n\n\n",
        "func": "ACLSNMPCommunityStrategy::Instance()\n{\n    return &Instance_;\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 0
      },
      {
        "idx": 330562,
        "reasoning": "This code snippet is not directly vulnerable to the memory leak fixed in the commit. The commit addresses leaks stemming from denied SNMP queries and unsupported commands *before* reaching this `oid2addr` function, which simply copies data into statically allocated structures\u2014it doesn't dynamically allocate or free memory itself. \n\n\n\n",
        "func": "oid2addr(oid * id, Ip::Address &addr, u_int size)\n{\n    struct in_addr i4addr;\n    struct in6_addr i6addr;\n    u_int i;\n    u_char *cp;\n    if ( size == sizeof(struct in_addr) )\n        cp = (u_char *) &(i4addr.s_addr);\n    else\n        cp = (u_char *) &(i6addr);\n    MemBuf tmp;\n    debugs(49, 7, \"oid2addr: id : \" << snmpDebugOid(id, size, tmp) );\n    for (i=0 ; i<size; ++i) {\n        cp[i] = id[i];\n    }\n    if ( size == sizeof(struct in_addr) )\n        addr = i4addr;\n    else\n        addr = i6addr;\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 202147,
        "reasoning": "The code is vulnerable to a memory leak because `snmp_pdu_create(0)` allocates memory for `PDU` which is then freed only within the `else` block when `Community` is null; if access is denied (`allow == ACCESS_DENIED`) or `snmp_coexist_V2toV1` fails, the allocated `PDU` is never freed, leading to a gradual exhaustion of memory with repeated denied requests. This directly aligns with the CVE description of a denial of service via memory leak triggered by SNMP packets, specifically those denied by access rules or unsupported commands.",
        "func": "snmpDecodePacket(SnmpRequest * rq)\n{\n    struct snmp_pdu *PDU;\n    u_char *Community;\n    u_char *buf = rq->buf;\n    int len = rq->len;\n    allow_t allow = ACCESS_DENIED;\n\n    if (!Config.accessList.snmp) {\n        debugs(49, DBG_IMPORTANT, \"WARNING: snmp_access not configured. agent query DENIED from : \" << rq->from);\n        return;\n    }\n\n    debugs(49, 5, HERE << \"Called.\");\n    PDU = snmp_pdu_create(0);\n    /* Allways answer on SNMPv1 */\n    rq->session.Version = SNMP_VERSION_1;\n    Community = snmp_parse(&rq->session, PDU, buf, len);\n\n    /* Check if we have explicit permission to access SNMP data.\n     * default (set above) is to deny all */\n    if (Community) {\n        ACLFilledChecklist checklist(Config.accessList.snmp, NULL, NULL);\n        checklist.src_addr = rq->from;\n        checklist.snmp_community = (char *) Community;\n        allow = checklist.fastCheck();\n\n        if (allow == ACCESS_ALLOWED && (snmp_coexist_V2toV1(PDU))) {\n            rq->community = Community;\n            rq->PDU = PDU;\n            debugs(49, 5, \"snmpAgentParse: reqid=[\" << PDU->reqid << \"]\");\n            snmpConstructReponse(rq);\n        } else {\n            debugs(49, DBG_IMPORTANT, \"WARNING: SNMP agent query DENIED from : \" << rq->from);\n        }\n        xfree(Community);\n\n    } else {\n        debugs(49, DBG_IMPORTANT, \"WARNING: Failed SNMP agent query from : \" << rq->from);\n        snmp_free_pdu(PDU);\n    }\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 1
      },
      {
        "idx": 202669,
        "reasoning": "The code is vulnerable to a memory leak because `snmp_pdu_create(0)` allocates memory for `PDU` which is then freed only within the `else` block when `Community` is null; if access is denied via the ACL check, `PDU` is never freed, leading to a leak with each denied query. This aligns with the CVE description indicating a denial of service via memory exhaustion caused by SNMP packets triggering the \"SNMP agent query DENIED\" warning.",
        "func": "snmpDecodePacket(SnmpRequest * rq)\n{\n    struct snmp_pdu *PDU;\n    u_char *Community;\n    u_char *buf = rq->buf;\n    int len = rq->len;\n\n    if (!Config.accessList.snmp) {\n        debugs(49, DBG_IMPORTANT, \"WARNING: snmp_access not configured. agent query DENIED from : \" << rq->from);\n        return;\n    }\n\n    debugs(49, 5, HERE << \"Called.\");\n    PDU = snmp_pdu_create(0);\n    /* Allways answer on SNMPv1 */\n    rq->session.Version = SNMP_VERSION_1;\n    Community = snmp_parse(&rq->session, PDU, buf, len);\n\n    /* Check if we have explicit permission to access SNMP data.\n     * default (set above) is to deny all */\n    if (Community) {\n        ACLFilledChecklist checklist(Config.accessList.snmp, NULL, NULL);\n        checklist.src_addr = rq->from;\n        checklist.snmp_community = (char *) Community;\n\n        if (checklist.fastCheck().allowed() && (snmp_coexist_V2toV1(PDU))) {\n            rq->community = Community;\n            rq->PDU = PDU;\n            debugs(49, 5, \"snmpAgentParse: reqid=[\" << PDU->reqid << \"]\");\n            snmpConstructReponse(rq);\n        } else {\n            debugs(49, DBG_IMPORTANT, \"WARNING: SNMP agent query DENIED from : \" << rq->from);\n        }\n        xfree(Community);\n\n    } else {\n        debugs(49, DBG_IMPORTANT, \"WARNING: Failed SNMP agent query from : \" << rq->from);\n        snmp_free_pdu(PDU);\n    }\n}",
        "commit_message": "Fix memory leak when parsing SNMP packet (#313)\n\nSNMP queries denied by snmp_access rules and queries with certain\nunsupported SNMPv2 commands were leaking a few hundred bytes each. Such\nqueries trigger \"SNMP agent query DENIED from...\" WARNINGs in cache.log.",
        "cve_desc": "Squid before 4.4, when SNMP is enabled, allows a denial of service (Memory Leak) via an SNMP packet.",
        "target": 1
      }
    ]
  },
  "src": {
    "0": [
      {
        "idx": 57389,
        "reasoning": "This code snippet is not vulnerable because it simply converts file attributes (access and modification times) into a `timeval` structure. The commit message indicates a fix related to file *creation* in read-only mode, which this code doesn't handle\u2014it only *reads* existing attributes, not create or modify files. \n\n\n\n",
        "func": "attrib_to_tv(const Attrib *a)\n{\n\tstatic struct timeval tv[2];\n\n\ttv[0].tv_sec = a->atime;\n\ttv[0].tv_usec = 0;\n\ttv[1].tv_sec = a->mtime;\n\ttv[1].tv_usec = 0;\n\treturn tv;\n}\n",
        "commit_message": "disallow creation (of empty files) in read-only mode; reported by\nMichal Zalewski, feedback & ok deraadt@",
        "cve_desc": "The process_open function in sftp-server.c in OpenSSH before 7.6 does not properly prevent write operations in readonly mode, which allows attackers to create zero-length files.",
        "target": 0
      },
      {
        "idx": 57390,
        "reasoning": "This code snippet focuses on converting Unix error codes to SSH-specific return codes and doesn't directly handle file creation or modification operations. The commit message indicates a change to *prevent* creation in read-only mode, suggesting a security improvement rather than introducing a vulnerability; this code simply reflects how existing errors are mapped, not the prevention logic itself.\n\n\n\n",
        "func": "errno_to_portable(int unixerrno)\n{\n\tint ret = 0;\n\n\tswitch (unixerrno) {\n\tcase 0:\n\t\tret = SSH2_FX_OK;\n\t\tbreak;\n\tcase ENOENT:\n\tcase ENOTDIR:\n\tcase EBADF:\n\tcase ELOOP:\n\t\tret = SSH2_FX_NO_SUCH_FILE;\n\t\tbreak;\n\tcase EPERM:\n\tcase EACCES:\n\tcase EFAULT:\n\t\tret = SSH2_FX_PERMISSION_DENIED;\n\t\tbreak;\n\tcase ENAMETOOLONG:\n\tcase EINVAL:\n\t\tret = SSH2_FX_BAD_MESSAGE;\n\t\tbreak;\n\tcase ENOSYS:\n\t\tret = SSH2_FX_OP_UNSUPPORTED;\n\t\tbreak;\n\tdefault:\n\t\tret = SSH2_FX_FAILURE;\n\t\tbreak;\n\t}\n\treturn ret;\n}\n",
        "commit_message": "disallow creation (of empty files) in read-only mode; reported by\nMichal Zalewski, feedback & ok deraadt@",
        "cve_desc": "The process_open function in sftp-server.c in OpenSSH before 7.6 does not properly prevent write operations in readonly mode, which allows attackers to create zero-length files.",
        "target": 0
      },
      {
        "idx": 57391,
        "reasoning": "This code snippet is addressing a security concern reported by Michal Zalewski regarding file creation in read-only mode. The commit message explicitly states the change *disallows* creation of files when in read-only mode, mitigating a potential vulnerability where unexpected file creation could occur, thus making the code safe with respect to this specific issue.",
        "func": "flags_from_portable(int pflags)\n{\n\tint flags = 0;\n\n\tif ((pflags & SSH2_FXF_READ) &&\n\t    (pflags & SSH2_FXF_WRITE)) {\n\t\tflags = O_RDWR;\n\t} else if (pflags & SSH2_FXF_READ) {\n\t\tflags = O_RDONLY;\n\t} else if (pflags & SSH2_FXF_WRITE) {\n\t\tflags = O_WRONLY;\n\t}\n\tif (pflags & SSH2_FXF_APPEND)\n\t\tflags |= O_APPEND;\n\tif (pflags & SSH2_FXF_CREAT)\n\t\tflags |= O_CREAT;\n\tif (pflags & SSH2_FXF_TRUNC)\n\t\tflags |= O_TRUNC;\n\tif (pflags & SSH2_FXF_EXCL)\n\t\tflags |= O_EXCL;\n\treturn flags;\n}\n",
        "commit_message": "disallow creation (of empty files) in read-only mode; reported by\nMichal Zalewski, feedback & ok deraadt@",
        "cve_desc": "The process_open function in sftp-server.c in OpenSSH before 7.6 does not properly prevent write operations in readonly mode, which allows attackers to create zero-length files.",
        "target": 0
      },
      {
        "idx": 57393,
        "reasoning": "This code snippet is not vulnerable because it simply returns the number of bytes read from a file handle, or 0 if the handle is invalid. The commit message indicates a fix related to file *creation* in read-only mode, which this function doesn't handle\u2014it only *reads* from existing handles, and safely returns a value regardless of handle validity.\n\n\n\n",
        "func": "handle_bytes_read(int handle)\n{\n\tif (handle_is_ok(handle, HANDLE_FILE))\n\t\treturn (handles[handle].bytes_read);\n\treturn 0;\n}\n",
        "commit_message": "disallow creation (of empty files) in read-only mode; reported by\nMichal Zalewski, feedback & ok deraadt@",
        "cve_desc": "The process_open function in sftp-server.c in OpenSSH before 7.6 does not properly prevent write operations in readonly mode, which allows attackers to create zero-length files.",
        "target": 0
      }
    ],
    "1": []
  },
  "sudo": {
    "0": [],
    "1": [
      {
        "idx": 211727,
        "reasoning": "This code is vulnerable to a heap-based buffer overflow in `sudoedit` mode due to insufficient handling of backslashes within command-line arguments. Specifically, the code attempts to quote meta-characters (including backslashes) when constructing a command for shell execution, but fails to account for the added backslash itself, leading to an overestimation of the required buffer size and a potential overflow when copying the command.",
        "func": "parse_args(int argc, char **argv, int *old_optind, int *nargc, char ***nargv,\n    struct sudo_settings **settingsp, char ***env_addp)\n{\n    struct environment extra_env;\n    int mode = 0;\t\t/* what mode is sudo to be run in? */\n    int flags = 0;\t\t/* mode flags */\n    int valid_flags = DEFAULT_VALID_FLAGS;\n    int ch, i;\n    char *cp;\n    const char *progname;\n    int proglen;\n    debug_decl(parse_args, SUDO_DEBUG_ARGS);\n\n    /* Is someone trying something funny? */\n    if (argc <= 0)\n\tusage();\n\n    /* Pass progname to plugin so it can call initprogname() */\n    progname = getprogname();\n    sudo_settings[ARG_PROGNAME].value = progname;\n\n    /* First, check to see if we were invoked as \"sudoedit\". */\n    proglen = strlen(progname);\n    if (proglen > 4 && strcmp(progname + proglen - 4, \"edit\") == 0) {\n\tprogname = \"sudoedit\";\n\tmode = MODE_EDIT;\n\tsudo_settings[ARG_SUDOEDIT].value = \"true\";\n    }\n\n    /* Load local IP addresses and masks. */\n    if (get_net_ifs(&cp) > 0)\n\tsudo_settings[ARG_NET_ADDRS].value = cp;\n\n    /* Set max_groups from sudo.conf. */\n    i = sudo_conf_max_groups();\n    if (i != -1) {\n\tif (asprintf(&cp, \"%d\", i) == -1)\n\t    sudo_fatalx(U_(\"%s: %s\"), __func__, U_(\"unable to allocate memory\"));\n\tsudo_settings[ARG_MAX_GROUPS].value = cp;\n    }\n\n    /* Returns true if the last option string was \"-h\" */\n#define got_host_flag\t(optind > 1 && argv[optind - 1][0] == '-' && \\\n\t    argv[optind - 1][1] == 'h' && argv[optind - 1][2] == '\\0')\n\n    /* Returns true if the last option string was \"--\" */\n#define got_end_of_args\t(optind > 1 && argv[optind - 1][0] == '-' && \\\n\t    argv[optind - 1][1] == '-' && argv[optind - 1][2] == '\\0')\n\n    /* Returns true if next option is an environment variable */\n#define is_envar (optind < argc && argv[optind][0] != '/' && \\\n\t    strchr(argv[optind], '=') != NULL)\n\n    /* Space for environment variables is lazy allocated. */\n    memset(&extra_env, 0, sizeof(extra_env));\n\n    /* XXX - should fill in settings at the end to avoid dupes */\n    for (;;) {\n\t/*\n\t * Some trickiness is required to allow environment variables\n\t * to be interspersed with command line options.\n\t */\n\tif ((ch = getopt_long(argc, argv, short_opts, long_opts, NULL)) != -1) {\n\t    switch (ch) {\n\t\tcase 'A':\n\t\t    SET(tgetpass_flags, TGP_ASKPASS);\n\t\t    break;\n#ifdef HAVE_BSD_AUTH_H\n\t\tcase 'a':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_BSDAUTH_TYPE].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_BSDAUTH_TYPE].value = optarg;\n\t\t    break;\n#endif\n\t\tcase 'b':\n\t\t    SET(flags, MODE_BACKGROUND);\n\t\t    break;\n\t\tcase 'B':\n\t\t    SET(tgetpass_flags, TGP_BELL);\n\t\t    break;\n\t\tcase 'C':\n\t\t    assert(optarg != NULL);\n\t\t    if (sudo_strtonum(optarg, 3, INT_MAX, NULL) == 0) {\n\t\t\tsudo_warnx(\"%s\",\n\t\t\t    U_(\"the argument to -C must be a number greater than or equal to 3\"));\n\t\t\tusage();\n\t\t    }\n\t\t    if (sudo_settings[ARG_CLOSEFROM].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_CLOSEFROM].value = optarg;\n\t\t    break;\n#ifdef HAVE_LOGIN_CAP_H\n\t\tcase 'c':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_LOGIN_CLASS].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_LOGIN_CLASS].value = optarg;\n\t\t    break;\n#endif\n\t\tcase 'D':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_CWD].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_CWD].value = optarg;\n\t\t    break;\n\t\tcase 'E':\n\t\t    /*\n\t\t     * Optional argument is a comma-separated list of\n\t\t     * environment variables to preserve.\n\t\t     * If not present, preserve everything.\n\t\t     */\n\t\t    if (optarg == NULL) {\n\t\t\tsudo_settings[ARG_PRESERVE_ENVIRONMENT].value = \"true\";\n\t\t\tSET(flags, MODE_PRESERVE_ENV);\n\t\t    } else {\n\t\t\tparse_env_list(&extra_env, optarg);\n\t\t    }\n\t\t    break;\n\t\tcase 'e':\n\t\t    if (mode && mode != MODE_EDIT)\n\t\t\tusage_excl();\n\t\t    mode = MODE_EDIT;\n\t\t    sudo_settings[ARG_SUDOEDIT].value = \"true\";\n\t\t    valid_flags = MODE_NONINTERACTIVE;\n\t\t    break;\n\t\tcase 'g':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_RUNAS_GROUP].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_RUNAS_GROUP].value = optarg;\n\t\t    break;\n\t\tcase 'H':\n\t\t    sudo_settings[ARG_SET_HOME].value = \"true\";\n\t\t    break;\n\t\tcase 'h':\n\t\t    if (optarg == NULL) {\n\t\t\t/*\n\t\t\t * Optional args support -hhostname, not -h hostname.\n\t\t\t * If we see a non-option after the -h flag, treat as\n\t\t\t * remote host and bump optind to skip over it.\n\t\t\t */\n\t\t\tif (got_host_flag && argv[optind] != NULL &&\n\t\t\t    argv[optind][0] != '-' && !is_envar) {\n\t\t\t    if (sudo_settings[ARG_REMOTE_HOST].value != NULL)\n\t\t\t\tusage();\n\t\t\t    sudo_settings[ARG_REMOTE_HOST].value = argv[optind++];\n\t\t\t    continue;\n\t\t\t}\n\t\t\tif (mode && mode != MODE_HELP) {\n\t\t\t    if (strcmp(progname, \"sudoedit\") != 0)\n\t\t\t\tusage_excl();\n\t\t\t}\n\t\t\tmode = MODE_HELP;\n\t\t\tvalid_flags = 0;\n\t\t\tbreak;\n\t\t    }\n\t\t    FALLTHROUGH;\n\t\tcase OPT_HOSTNAME:\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_REMOTE_HOST].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_REMOTE_HOST].value = optarg;\n\t\t    break;\n\t\tcase 'i':\n\t\t    sudo_settings[ARG_LOGIN_SHELL].value = \"true\";\n\t\t    SET(flags, MODE_LOGIN_SHELL);\n\t\t    break;\n\t\tcase 'k':\n\t\t    sudo_settings[ARG_IGNORE_TICKET].value = \"true\";\n\t\t    break;\n\t\tcase 'K':\n\t\t    sudo_settings[ARG_IGNORE_TICKET].value = \"true\";\n\t\t    if (mode && mode != MODE_KILL)\n\t\t\tusage_excl();\n\t\t    mode = MODE_KILL;\n\t\t    valid_flags = 0;\n\t\t    break;\n\t\tcase 'l':\n\t\t    if (mode) {\n\t\t\tif (mode == MODE_LIST)\n\t\t\t    SET(flags, MODE_LONG_LIST);\n\t\t\telse\n\t\t\t    usage_excl();\n\t\t    }\n\t\t    mode = MODE_LIST;\n\t\t    valid_flags = MODE_NONINTERACTIVE|MODE_LONG_LIST;\n\t\t    break;\n\t\tcase 'n':\n\t\t    SET(flags, MODE_NONINTERACTIVE);\n\t\t    sudo_settings[ARG_NONINTERACTIVE].value = \"true\";\n\t\t    break;\n\t\tcase 'P':\n\t\t    sudo_settings[ARG_PRESERVE_GROUPS].value = \"true\";\n\t\t    break;\n\t\tcase 'p':\n\t\t    /* An empty prompt is allowed. */\n\t\t    assert(optarg != NULL);\n\t\t    if (sudo_settings[ARG_PROMPT].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_PROMPT].value = optarg;\n\t\t    break;\n\t\tcase 'R':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_CHROOT].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_CHROOT].value = optarg;\n\t\t    break;\n#ifdef HAVE_SELINUX\n\t\tcase 'r':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_SELINUX_ROLE].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_SELINUX_ROLE].value = optarg;\n\t\t    break;\n\t\tcase 't':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_SELINUX_TYPE].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_SELINUX_TYPE].value = optarg;\n\t\t    break;\n#endif\n\t\tcase 'T':\n\t\t    /* Plugin determines whether empty timeout is allowed. */\n\t\t    assert(optarg != NULL);\n\t\t    if (sudo_settings[ARG_TIMEOUT].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_TIMEOUT].value = optarg;\n\t\t    break;\n\t\tcase 'S':\n\t\t    SET(tgetpass_flags, TGP_STDIN);\n\t\t    break;\n\t\tcase 's':\n\t\t    sudo_settings[ARG_USER_SHELL].value = \"true\";\n\t\t    SET(flags, MODE_SHELL);\n\t\t    break;\n\t\tcase 'U':\n\t\t    assert(optarg != NULL);\n\t\t    if (list_user != NULL || *optarg == '\\0')\n\t\t\tusage();\n\t\t    list_user = optarg;\n\t\t    break;\n\t\tcase 'u':\n\t\t    assert(optarg != NULL);\n\t\t    if (*optarg == '\\0')\n\t\t\tusage();\n\t\t    if (sudo_settings[ARG_RUNAS_USER].value != NULL)\n\t\t\tusage();\n\t\t    sudo_settings[ARG_RUNAS_USER].value = optarg;\n\t\t    break;\n\t\tcase 'v':\n\t\t    if (mode && mode != MODE_VALIDATE)\n\t\t\tusage_excl();\n\t\t    mode = MODE_VALIDATE;\n\t\t    valid_flags = MODE_NONINTERACTIVE;\n\t\t    break;\n\t\tcase 'V':\n\t\t    if (mode && mode != MODE_VERSION)\n\t\t\tusage_excl();\n\t\t    mode = MODE_VERSION;\n\t\t    valid_flags = 0;\n\t\t    break;\n\t\tdefault:\n\t\t    usage();\n\t    }\n\t} else if (!got_end_of_args && is_envar) {\n\t    /* Insert key=value pair, crank optind and resume getopt. */\n\t    env_insert(&extra_env, argv[optind]);\n\t    optind++;\n\t} else {\n\t    /* Not an option or an environment variable -- we're done. */\n\t    break;\n\t}\n    }\n\n    argc -= optind;\n    argv += optind;\n    *old_optind = optind;\n\n    if (!mode) {\n\t/* Defer -k mode setting until we know whether it is a flag or not */\n\tif (sudo_settings[ARG_IGNORE_TICKET].value != NULL) {\n\t    if (argc == 0 && !(flags & (MODE_SHELL|MODE_LOGIN_SHELL))) {\n\t\tmode = MODE_INVALIDATE;\t/* -k by itself */\n\t\tsudo_settings[ARG_IGNORE_TICKET].value = NULL;\n\t\tvalid_flags = 0;\n\t    }\n\t}\n\tif (!mode)\n\t    mode = MODE_RUN;\t\t/* running a command */\n    }\n\n    if (argc > 0 && mode == MODE_LIST)\n\tmode = MODE_CHECK;\n\n    if (ISSET(flags, MODE_LOGIN_SHELL)) {\n\tif (ISSET(flags, MODE_SHELL)) {\n\t    sudo_warnx(\"%s\",\n\t\tU_(\"you may not specify both the -i and -s options\"));\n\t    usage();\n\t}\n\tif (ISSET(flags, MODE_PRESERVE_ENV)) {\n\t    sudo_warnx(\"%s\",\n\t\tU_(\"you may not specify both the -i and -E options\"));\n\t    usage();\n\t}\n\tSET(flags, MODE_SHELL);\n    }\n    if ((flags & valid_flags) != flags)\n\tusage();\n    if (mode == MODE_EDIT &&\n       (ISSET(flags, MODE_PRESERVE_ENV) || extra_env.env_len != 0)) {\n\tif (ISSET(mode, MODE_PRESERVE_ENV))\n\t    sudo_warnx(\"%s\", U_(\"the -E option is not valid in edit mode\"));\n\tif (extra_env.env_len != 0)\n\t    sudo_warnx(\"%s\",\n\t\tU_(\"you may not specify environment variables in edit mode\"));\n\tusage();\n    }\n    if ((sudo_settings[ARG_RUNAS_USER].value != NULL ||\n\t sudo_settings[ARG_RUNAS_GROUP].value != NULL) &&\n\t!ISSET(mode, MODE_EDIT | MODE_RUN | MODE_CHECK | MODE_VALIDATE)) {\n\tusage();\n    }\n    if (list_user != NULL && mode != MODE_LIST && mode != MODE_CHECK) {\n\tsudo_warnx(\"%s\",\n\t    U_(\"the -U option may only be used with the -l option\"));\n\tusage();\n    }\n    if (ISSET(tgetpass_flags, TGP_STDIN) && ISSET(tgetpass_flags, TGP_ASKPASS)) {\n\tsudo_warnx(\"%s\", U_(\"the -A and -S options may not be used together\"));\n\tusage();\n    }\n    if ((argc == 0 && mode == MODE_EDIT) ||\n\t(argc > 0 && !ISSET(mode, MODE_RUN | MODE_EDIT | MODE_CHECK)))\n\tusage();\n    if (argc == 0 && mode == MODE_RUN && !ISSET(flags, MODE_SHELL)) {\n\tSET(flags, (MODE_IMPLIED_SHELL | MODE_SHELL));\n\tsudo_settings[ARG_IMPLIED_SHELL].value = \"true\";\n    }\n#ifdef ENABLE_SUDO_PLUGIN_API\n    sudo_settings[ARG_PLUGIN_DIR].value = sudo_conf_plugin_dir_path();\n#endif\n\n    if (mode == MODE_HELP)\n\thelp();\n\n    /*\n     * For shell mode we need to rewrite argv\n     */\n    if (ISSET(mode, MODE_RUN) && ISSET(flags, MODE_SHELL)) {\n\tchar **av, *cmnd = NULL;\n\tint ac = 1;\n\n\tif (argc != 0) {\n\t    /* shell -c \"command\" */\n\t    char *src, *dst;\n\t    size_t cmnd_size = (size_t) (argv[argc - 1] - argv[0]) +\n\t\tstrlen(argv[argc - 1]) + 1;\n\n\t    cmnd = dst = reallocarray(NULL, cmnd_size, 2);\n\t    if (cmnd == NULL)\n\t\tsudo_fatalx(U_(\"%s: %s\"), __func__, U_(\"unable to allocate memory\"));\n\t    if (!gc_add(GC_PTR, cmnd))\n\t\texit(EXIT_FAILURE);\n\n\t    for (av = argv; *av != NULL; av++) {\n\t\tfor (src = *av; *src != '\\0'; src++) {\n\t\t    /* quote potential meta characters */\n\t\t    if (!isalnum((unsigned char)*src) && *src != '_' && *src != '-' && *src != '$')\n\t\t\t*dst++ = '\\\\';\n\t\t    *dst++ = *src;\n\t\t}\n\t\t*dst++ = ' ';\n\t    }\n\t    if (cmnd != dst)\n\t\tdst--;  /* replace last space with a NUL */\n\t    *dst = '\\0';\n\n\t    ac += 2; /* -c cmnd */\n\t}\n\n\tav = reallocarray(NULL, ac + 1, sizeof(char *));\n\tif (av == NULL)\n\t    sudo_fatalx(U_(\"%s: %s\"), __func__, U_(\"unable to allocate memory\"));\n\tif (!gc_add(GC_PTR, av))\n\t    exit(EXIT_FAILURE);\n\n\tav[0] = (char *)user_details.shell; /* plugin may override shell */\n\tif (cmnd != NULL) {\n\t    av[1] = \"-c\";\n\t    av[2] = cmnd;\n\t}\n\tav[ac] = NULL;\n\n\targv = av;\n\targc = ac;\n    }\n\n    /*\n     * For sudoedit we need to rewrite argv\n     */\n    if (mode == MODE_EDIT) {\n#if defined(HAVE_SETRESUID) || defined(HAVE_SETREUID) || defined(HAVE_SETEUID)\n\tchar **av;\n\tint ac;\n\n\tav = reallocarray(NULL, argc + 2, sizeof(char *));\n\tif (av == NULL)\n\t    sudo_fatalx(U_(\"%s: %s\"), __func__, U_(\"unable to allocate memory\"));\n\tif (!gc_add(GC_PTR, av))\n\t    exit(EXIT_FAILURE);\n\n\t/* Must have the command in argv[0]. */\n\tav[0] = \"sudoedit\";\n\tfor (ac = 0; argv[ac] != NULL; ac++) {\n\t    av[ac + 1] = argv[ac];\n\t}\n\tav[++ac] = NULL;\n\n\targv = av;\n\targc = ac;\n#else\n\tsudo_fatalx(\"%s\", U_(\"sudoedit is not supported on this platform\"));\n#endif\n    }\n\n    *settingsp = sudo_settings;\n    *env_addp = extra_env.envp;\n    *nargc = argc;\n    *nargv = argv;\n    debug_return_int(mode | flags);\n}",
        "commit_message": "Reset valid_flags to MODE_NONINTERACTIVE for sudoedit.\nThis is consistent with how the -e option is handled.\nAlso reject -H and -P flags for sudoedit as was done in sudo 1.7.\nFound by Qualys, this is part of the fix for CVE-2021-3156.",
        "cve_desc": "Sudo before 1.9.5p2 contains an off-by-one error that can result in a heap-based buffer overflow, which allows privilege escalation to root via \"sudoedit -s\" and a command-line argument that ends with a single backslash character.",
        "target": 1
      }
    ]
  },
  "swtpm": {
    "0": [],
    "1": []
  },
  "tcpdump": {
    "0": [
      {
        "idx": 36424,
        "reasoning": "This code snippet is not vulnerable because it's an empty function stub with unused parameters, indicating it doesn't currently perform any operations that could be exploited. The commit message references changes elsewhere in the codebase (PPP unescaping and const correctness) but doesn't suggest this specific function `handle_bap` was the target of those fixes or contained any vulnerabilities itself.\n\n\n\n",
        "func": "handle_bap(netdissect_options *ndo _U_,\n           const u_char *p _U_, int length _U_)\n{\n\t/* XXX: to be supported!! */\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 0
      },
      {
        "idx": 36425,
        "reasoning": "This code appears safe as the commit message explicitly addresses bounds checking when unescaping PPP, and the snippet demonstrates checks like `length - (p - p0) < val_size` and `length - (p - p0) < 1` before accessing data, preventing potential buffer overflows. The `ND_TCHECK` macro also likely performs bounds checking, further mitigating risks associated with reading beyond the allocated buffer.",
        "func": "handle_chap(netdissect_options *ndo,\n            const u_char *p, int length)\n{\n\tu_int code, len;\n\tint val_size, name_size, msg_size;\n\tconst u_char *p0;\n\tint i;\n\n\tp0 = p;\n\tif (length < 1) {\n\t\tND_PRINT((ndo, \"[|chap]\"));\n\t\treturn;\n\t} else if (length < 4) {\n\t\tND_TCHECK(*p);\n\t\tND_PRINT((ndo, \"[|chap 0x%02x]\", *p));\n\t\treturn;\n\t}\n\n\tND_TCHECK(*p);\n\tcode = *p;\n\tND_PRINT((ndo, \"CHAP, %s (0x%02x)\",\n               tok2str(chapcode_values,\"unknown\",code),\n               code));\n\tp++;\n\n\tND_TCHECK(*p);\n\tND_PRINT((ndo, \", id %u\", *p));\t\t/* ID */\n\tp++;\n\n\tND_TCHECK2(*p, 2);\n\tlen = EXTRACT_16BITS(p);\n\tp += 2;\n\n\t/*\n\t * Note that this is a generic CHAP decoding routine. Since we\n\t * don't know which flavor of CHAP (i.e. CHAP-MD5, MS-CHAPv1,\n\t * MS-CHAPv2) is used at this point, we can't decode packet\n\t * specifically to each algorithms. Instead, we simply decode\n\t * the GCD (Gratest Common Denominator) for all algorithms.\n\t */\n\tswitch (code) {\n\tcase CHAP_CHAL:\n\tcase CHAP_RESP:\n\t\tif (length - (p - p0) < 1)\n\t\t\treturn;\n\t\tND_TCHECK(*p);\n\t\tval_size = *p;\t\t/* value size */\n\t\tp++;\n\t\tif (length - (p - p0) < val_size)\n\t\t\treturn;\n\t\tND_PRINT((ndo, \", Value \"));\n\t\tfor (i = 0; i < val_size; i++) {\n\t\t\tND_TCHECK(*p);\n\t\t\tND_PRINT((ndo, \"%02x\", *p++));\n\t\t}\n\t\tname_size = len - (p - p0);\n\t\tND_PRINT((ndo, \", Name \"));\n\t\tfor (i = 0; i < name_size; i++) {\n\t\t\tND_TCHECK(*p);\n\t\t\tsafeputchar(ndo, *p++);\n\t\t}\n\t\tbreak;\n\tcase CHAP_SUCC:\n\tcase CHAP_FAIL:\n\t\tmsg_size = len - (p - p0);\n\t\tND_PRINT((ndo, \", Msg \"));\n\t\tfor (i = 0; i< msg_size; i++) {\n\t\t\tND_TCHECK(*p);\n\t\t\tsafeputchar(ndo, *p++);\n\t\t}\n\t\tbreak;\n\t}\n\treturn;\n\ntrunc:\n\tND_PRINT((ndo, \"[|chap]\"));\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 0
      },
      {
        "idx": 36426,
        "reasoning": "This code addresses potential buffer over-read vulnerabilities by adding bounds checking (`if (length < 4)`, `if (length < 11)`, etc.) before accessing data within the `pptr` buffer. While the original commit message mentions fixing a \"weak boundary checking\" issue, the added checks mitigate the risk of reading beyond the allocated buffer, making it safe from the identified vulnerability.",
        "func": "handle_ctrl_proto(netdissect_options *ndo,\n                  u_int proto, const u_char *pptr, int length)\n{\n\tconst char *typestr;\n\tu_int code, len;\n\tint (*pfunc)(netdissect_options *, const u_char *, int);\n\tint x, j;\n        const u_char *tptr;\n\n        tptr=pptr;\n\n        typestr = tok2str(ppptype2str, \"unknown ctrl-proto (0x%04x)\", proto);\n\tND_PRINT((ndo, \"%s, \", typestr));\n\n\tif (length < 4) /* FIXME weak boundary checking */\n\t\tgoto trunc;\n\tND_TCHECK2(*tptr, 2);\n\n\tcode = *tptr++;\n\n\tND_PRINT((ndo, \"%s (0x%02x), id %u, length %u\",\n\t          tok2str(cpcodes, \"Unknown Opcode\",code),\n\t          code,\n\t          *tptr++, /* ID */\n\t          length + 2));\n\n\tif (!ndo->ndo_vflag)\n\t\treturn;\n\n\tif (length <= 4)\n\t\treturn;    /* there may be a NULL confreq etc. */\n\n\tND_TCHECK2(*tptr, 2);\n\tlen = EXTRACT_16BITS(tptr);\n\ttptr += 2;\n\n\tND_PRINT((ndo, \"\\n\\tencoded length %u (=Option(s) length %u)\", len, len - 4));\n\n\tif (ndo->ndo_vflag > 1)\n\t\tprint_unknown_data(ndo, pptr - 2, \"\\n\\t\", 6);\n\n\n\tswitch (code) {\n\tcase CPCODES_VEXT:\n\t\tif (length < 11)\n\t\t\tbreak;\n\t\tND_TCHECK2(*tptr, 4);\n\t\tND_PRINT((ndo, \"\\n\\t  Magic-Num 0x%08x\", EXTRACT_32BITS(tptr)));\n\t\ttptr += 4;\n\t\tND_TCHECK2(*tptr, 3);\n\t\tND_PRINT((ndo, \" Vendor: %s (%u)\",\n                       tok2str(oui_values,\"Unknown\",EXTRACT_24BITS(tptr)),\n                       EXTRACT_24BITS(tptr)));\n\t\t/* XXX: need to decode Kind and Value(s)? */\n\t\tbreak;\n\tcase CPCODES_CONF_REQ:\n\tcase CPCODES_CONF_ACK:\n\tcase CPCODES_CONF_NAK:\n\tcase CPCODES_CONF_REJ:\n\t\tx = len - 4;\t/* Code(1), Identifier(1) and Length(2) */\n\t\tdo {\n\t\t\tswitch (proto) {\n\t\t\tcase PPP_LCP:\n\t\t\t\tpfunc = print_lcp_config_options;\n\t\t\t\tbreak;\n\t\t\tcase PPP_IPCP:\n\t\t\t\tpfunc = print_ipcp_config_options;\n\t\t\t\tbreak;\n\t\t\tcase PPP_IPV6CP:\n\t\t\t\tpfunc = print_ip6cp_config_options;\n\t\t\t\tbreak;\n\t\t\tcase PPP_CCP:\n\t\t\t\tpfunc = print_ccp_config_options;\n\t\t\t\tbreak;\n\t\t\tcase PPP_BACP:\n\t\t\t\tpfunc = print_bacp_config_options;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\t/*\n\t\t\t\t * No print routine for the options for\n\t\t\t\t * this protocol.\n\t\t\t\t */\n\t\t\t\tpfunc = NULL;\n\t\t\t\tbreak;\n\t\t\t}\n\n\t\t\tif (pfunc == NULL) /* catch the above null pointer if unknown CP */\n\t\t\t\tbreak;\n\n\t\t\tif ((j = (*pfunc)(ndo, tptr, len)) == 0)\n\t\t\t\tbreak;\n\t\t\tx -= j;\n\t\t\ttptr += j;\n\t\t} while (x > 0);\n\t\tbreak;\n\n\tcase CPCODES_TERM_REQ:\n\tcase CPCODES_TERM_ACK:\n\t\t/* XXX: need to decode Data? */\n\t\tbreak;\n\tcase CPCODES_CODE_REJ:\n\t\t/* XXX: need to decode Rejected-Packet? */\n\t\tbreak;\n\tcase CPCODES_PROT_REJ:\n\t\tif (length < 6)\n\t\t\tbreak;\n\t\tND_TCHECK2(*tptr, 2);\n\t\tND_PRINT((ndo, \"\\n\\t  Rejected %s Protocol (0x%04x)\",\n\t\t       tok2str(ppptype2str,\"unknown\", EXTRACT_16BITS(tptr)),\n\t\t       EXTRACT_16BITS(tptr)));\n\t\t/* XXX: need to decode Rejected-Information? - hexdump for now */\n\t\tif (len > 6) {\n\t\t\tND_PRINT((ndo, \"\\n\\t  Rejected Packet\"));\n\t\t\tprint_unknown_data(ndo, tptr + 2, \"\\n\\t    \", len - 2);\n\t\t}\n\t\tbreak;\n\tcase CPCODES_ECHO_REQ:\n\tcase CPCODES_ECHO_RPL:\n\tcase CPCODES_DISC_REQ:\n\t\tif (length < 8)\n\t\t\tbreak;\n\t\tND_TCHECK2(*tptr, 4);\n\t\tND_PRINT((ndo, \"\\n\\t  Magic-Num 0x%08x\", EXTRACT_32BITS(tptr)));\n\t\t/* XXX: need to decode Data? - hexdump for now */\n\t\tif (len > 8) {\n\t\t\tND_PRINT((ndo, \"\\n\\t  -----trailing data-----\"));\n\t\t\tND_TCHECK2(tptr[4], len - 8);\n\t\t\tprint_unknown_data(ndo, tptr + 4, \"\\n\\t  \", len - 8);\n\t\t}\n\t\tbreak;\n\tcase CPCODES_ID:\n\t\tif (length < 8)\n\t\t\tbreak;\n\t\tND_TCHECK2(*tptr, 4);\n\t\tND_PRINT((ndo, \"\\n\\t  Magic-Num 0x%08x\", EXTRACT_32BITS(tptr)));\n\t\t/* RFC 1661 says this is intended to be human readable */\n\t\tif (len > 8) {\n\t\t\tND_PRINT((ndo, \"\\n\\t  Message\\n\\t    \"));\n\t\t\tif (fn_printn(ndo, tptr + 4, len - 4, ndo->ndo_snapend))\n\t\t\t\tgoto trunc;\n\t\t}\n\t\tbreak;\n\tcase CPCODES_TIME_REM:\n\t\tif (length < 12)\n\t\t\tbreak;\n\t\tND_TCHECK2(*tptr, 4);\n\t\tND_PRINT((ndo, \"\\n\\t  Magic-Num 0x%08x\", EXTRACT_32BITS(tptr)));\n\t\tND_TCHECK2(*(tptr + 4), 4);\n\t\tND_PRINT((ndo, \", Seconds-Remaining %us\", EXTRACT_32BITS(tptr + 4)));\n\t\t/* XXX: need to decode Message? */\n\t\tbreak;\n\tdefault:\n\t\t/* XXX this is dirty but we do not get the\n\t\t * original pointer passed to the begin\n\t\t * the PPP packet */\n\t\tif (ndo->ndo_vflag <= 1)\n\t\t\tprint_unknown_data(ndo, pptr - 2, \"\\n\\t  \", length + 2);\n\t\tbreak;\n\t}\n\treturn;\n\ntrunc:\n\tND_PRINT((ndo, \"[|%s]\", typestr));\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 0
      },
      {
        "idx": 36427,
        "reasoning": "This code is flagged as safe because the commit message explicitly states it adds bounds checking when unescaping PPP, addressing a potential vulnerability related to accessing memory outside of allocated boundaries. Additionally, the code snippet demonstrates calculations of `hdrlength` and subsequent pointer arithmetic (`p += hdrlength`) to ensure data is processed within the valid packet capture length, preventing buffer overflows.",
        "func": "ppp_bsdos_if_print(netdissect_options *ndo _U_,\n                   const struct pcap_pkthdr *h _U_, register const u_char *p _U_)\n{\n\tregister int hdrlength;\n#ifdef __bsdi__\n\tregister u_int length = h->len;\n\tregister u_int caplen = h->caplen;\n\tuint16_t ptype;\n\tconst u_char *q;\n\tint i;\n\n\tif (caplen < PPP_BSDI_HDRLEN) {\n\t\tND_PRINT((ndo, \"[|ppp]\"));\n\t\treturn (caplen)\n\t}\n\n\thdrlength = 0;\n\n#if 0\n\tif (p[0] == PPP_ADDRESS && p[1] == PPP_CONTROL) {\n\t\tif (ndo->ndo_eflag)\n\t\t\tND_PRINT((ndo, \"%02x %02x \", p[0], p[1]));\n\t\tp += 2;\n\t\thdrlength = 2;\n\t}\n\n\tif (ndo->ndo_eflag)\n\t\tND_PRINT((ndo, \"%d \", length));\n\t/* Retrieve the protocol type */\n\tif (*p & 01) {\n\t\t/* Compressed protocol field */\n\t\tptype = *p;\n\t\tif (ndo->ndo_eflag)\n\t\t\tND_PRINT((ndo, \"%02x \", ptype));\n\t\tp++;\n\t\thdrlength += 1;\n\t} else {\n\t\t/* Un-compressed protocol field */\n\t\tptype = EXTRACT_16BITS(p);\n\t\tif (ndo->ndo_eflag)\n\t\t\tND_PRINT((ndo, \"%04x \", ptype));\n\t\tp += 2;\n\t\thdrlength += 2;\n\t}\n#else\n\tptype = 0;\t/*XXX*/\n\tif (ndo->ndo_eflag)\n\t\tND_PRINT((ndo, \"%c \", p[SLC_DIR] ? 'O' : 'I'));\n\tif (p[SLC_LLHL]) {\n\t\t/* link level header */\n\t\tstruct ppp_header *ph;\n\n\t\tq = p + SLC_BPFHDRLEN;\n\t\tph = (struct ppp_header *)q;\n\t\tif (ph->phdr_addr == PPP_ADDRESS\n\t\t && ph->phdr_ctl == PPP_CONTROL) {\n\t\t\tif (ndo->ndo_eflag)\n\t\t\t\tND_PRINT((ndo, \"%02x %02x \", q[0], q[1]));\n\t\t\tptype = EXTRACT_16BITS(&ph->phdr_type);\n\t\t\tif (ndo->ndo_eflag && (ptype == PPP_VJC || ptype == PPP_VJNC)) {\n\t\t\t\tND_PRINT((ndo, \"%s \", tok2str(ppptype2str,\n\t\t\t\t\t\t\"proto-#%d\", ptype)));\n\t\t\t}\n\t\t} else {\n\t\t\tif (ndo->ndo_eflag) {\n\t\t\t\tND_PRINT((ndo, \"LLH=[\"));\n\t\t\t\tfor (i = 0; i < p[SLC_LLHL]; i++)\n\t\t\t\t\tND_PRINT((ndo, \"%02x\", q[i]));\n\t\t\t\tND_PRINT((ndo, \"] \"));\n\t\t\t}\n\t\t}\n\t}\n\tif (ndo->ndo_eflag)\n\t\tND_PRINT((ndo, \"%d \", length));\n\tif (p[SLC_CHL]) {\n\t\tq = p + SLC_BPFHDRLEN + p[SLC_LLHL];\n\n\t\tswitch (ptype) {\n\t\tcase PPP_VJC:\n\t\t\tptype = vjc_print(ndo, q, ptype);\n\t\t\thdrlength = PPP_BSDI_HDRLEN;\n\t\t\tp += hdrlength;\n\t\t\tswitch (ptype) {\n\t\t\tcase PPP_IP:\n\t\t\t\tip_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\tcase PPP_IPV6:\n\t\t\t\tip6_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\tcase PPP_MPLS_UCAST:\n\t\t\tcase PPP_MPLS_MCAST:\n\t\t\t\tmpls_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tgoto printx;\n\t\tcase PPP_VJNC:\n\t\t\tptype = vjc_print(ndo, q, ptype);\n\t\t\thdrlength = PPP_BSDI_HDRLEN;\n\t\t\tp += hdrlength;\n\t\t\tswitch (ptype) {\n\t\t\tcase PPP_IP:\n\t\t\t\tip_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\tcase PPP_IPV6:\n\t\t\t\tip6_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\tcase PPP_MPLS_UCAST:\n\t\t\tcase PPP_MPLS_MCAST:\n\t\t\t\tmpls_print(ndo, p, length);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tgoto printx;\n\t\tdefault:\n\t\t\tif (ndo->ndo_eflag) {\n\t\t\t\tND_PRINT((ndo, \"CH=[\"));\n\t\t\t\tfor (i = 0; i < p[SLC_LLHL]; i++)\n\t\t\t\t\tND_PRINT((ndo, \"%02x\", q[i]));\n\t\t\t\tND_PRINT((ndo, \"] \"));\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n\n\thdrlength = PPP_BSDI_HDRLEN;\n#endif\n\n\tlength -= hdrlength;\n\tp += hdrlength;\n\n\tswitch (ptype) {\n\tcase PPP_IP:\n\t\tip_print(p, length);\n\t\tbreak;\n\tcase PPP_IPV6:\n\t\tip6_print(ndo, p, length);\n\t\tbreak;\n\tcase PPP_MPLS_UCAST:\n\tcase PPP_MPLS_MCAST:\n\t\tmpls_print(ndo, p, length);\n\t\tbreak;\n\tdefault:\n\t\tND_PRINT((ndo, \"%s \", tok2str(ppptype2str, \"unknown PPP protocol (0x%04x)\", ptype)));\n\t}\n\nprintx:\n#else /* __bsdi */\n\thdrlength = 0;\n#endif /* __bsdi__ */\n\treturn (hdrlength);\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 0
      },
      {
        "idx": 36428,
        "reasoning": "This code addresses a potential bounds checking issue when unescaping PPP data, indicating a proactive security measure rather than a vulnerability. The commit message explicitly states the purpose is to *add* bounds checking, and the code snippet demonstrates checks for `caplen` before accessing packet data, preventing potential reads beyond the buffer's allocated size.",
        "func": "ppp_hdlc_if_print(netdissect_options *ndo,\n                  const struct pcap_pkthdr *h, register const u_char *p)\n{\n\tregister u_int length = h->len;\n\tregister u_int caplen = h->caplen;\n\tu_int proto;\n\tu_int hdrlen = 0;\n\n\tif (caplen < 2) {\n\t\tND_PRINT((ndo, \"[|ppp]\"));\n\t\treturn (caplen);\n\t}\n\n\tswitch (p[0]) {\n\n\tcase PPP_ADDRESS:\n\t\tif (caplen < 4) {\n\t\t\tND_PRINT((ndo, \"[|ppp]\"));\n\t\t\treturn (caplen);\n\t\t}\n\n\t\tif (ndo->ndo_eflag)\n\t\t\tND_PRINT((ndo, \"%02x %02x %d \", p[0], p[1], length));\n\t\tp += 2;\n\t\tlength -= 2;\n\t\thdrlen += 2;\n\n\t\tproto = EXTRACT_16BITS(p);\n\t\tp += 2;\n\t\tlength -= 2;\n\t\thdrlen += 2;\n\t\tND_PRINT((ndo, \"%s: \", tok2str(ppptype2str, \"unknown PPP protocol (0x%04x)\", proto)));\n\n\t\thandle_ppp(ndo, proto, p, length);\n\t\tbreak;\n\n\tcase CHDLC_UNICAST:\n\tcase CHDLC_BCAST:\n\t\treturn (chdlc_if_print(ndo, h, p));\n\n\tdefault:\n\t\tif (ndo->ndo_eflag)\n\t\t\tND_PRINT((ndo, \"%02x %02x %d \", p[0], p[1], length));\n\t\tp += 2;\n\t\thdrlen += 2;\n\n\t\t/*\n\t\t * XXX - NetBSD's \"ppp_netbsd_serial_if_print()\" treats\n\t\t * the next two octets as an Ethernet type; does that\n\t\t * ever happen?\n\t\t */\n\t\tND_PRINT((ndo, \"unknown addr %02x; ctrl %02x\", p[0], p[1]));\n\t\tbreak;\n\t}\n\n\treturn (hdrlen);\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1183,
        "reasoning": "The code is vulnerable to a buffer overflow because the `malloc` call allocates a buffer of size `length` based on the original packet length, but the unescaping process within the `for` loop can *increase* the size of the data being written to this buffer if many `0x7d` escape sequences are present. Specifically, if the input contains many escaped characters, the `i--` decrement within the `if (c == 0x7d)` block doesn't account for the additional byte written, leading to a write beyond the allocated buffer's bounds and ultimately a crash.",
        "func": " ppp_hdlc(netdissect_options *ndo,\n          const u_char *p, int length)\n {\n\tu_char *b, *s, *t, c;\n \tint i, proto;\n \tconst void *se;\n \n         if (length <= 0)\n                 return;\n \n\tb = (uint8_t *)malloc(length);\n \tif (b == NULL)\n \t\treturn;\n \n\t/*\n\t * Unescape all the data into a temporary, private, buffer.\n \t * Do this so that we dont overwrite the original packet\n \t * contents.\n \t */\n\tfor (s = (u_char *)p, t = b, i = length; i > 0; i--) {\n \t\tc = *s++;\n \t\tif (c == 0x7d) {\n\t\t\tif (i > 1) {\n\t\t\t\ti--;\n\t\t\t\tc = *s++ ^ 0x20;\n\t\t\t} else\n\t\t\t\tcontinue;\n \t\t}\n \t\t*t++ = c;\n \t}\n\n\tse = ndo->ndo_snapend;\n\tndo->ndo_snapend = t;\n\tlength = t - b;\n\n        /* now lets guess about the payload codepoint format */\n        if (length < 1)\n                goto trunc;\n        proto = *b; /* start with a one-octet codepoint guess */\n\n        switch (proto) {\n        case PPP_IP:\n\t\tip_print(ndo, b + 1, length - 1);\n\t\tgoto cleanup;\n        case PPP_IPV6:\n\t\tip6_print(ndo, b + 1, length - 1);\n\t\tgoto cleanup;\n        default: /* no luck - try next guess */\n\t\tbreak;\n        }\n\n        if (length < 2)\n                goto trunc;\n        proto = EXTRACT_16BITS(b); /* next guess - load two octets */\n\n        switch (proto) {\n        case (PPP_ADDRESS << 8 | PPP_CONTROL): /* looks like a PPP frame */\n            if (length < 4)\n                goto trunc;\n            proto = EXTRACT_16BITS(b+2); /* load the PPP proto-id */\n            handle_ppp(ndo, proto, b + 4, length - 4);\n            break;\n        default: /* last guess - proto must be a PPP proto-id */\n            handle_ppp(ndo, proto, b + 2, length - 2);\n            break;\n        }\n\ncleanup:\n\tndo->ndo_snapend = se;\n\tfree(b);\n        return;\n\ntrunc:\n\tndo->ndo_snapend = se;\n\tfree(b);\n\tND_PRINT((ndo, \"[|ppp]\"));\n}\n",
        "commit_message": "Do bounds checking when unescaping PPP.\n\nClean up a const issue while we're at it.",
        "cve_desc": "Buffer overflow in the ppp_hdlc function in print-ppp.c in tcpdump 4.6.2 and earlier allows remote attackers to cause a denial of service (crash) cia a crafted PPP packet.",
        "target": 1
      },
      {
        "idx": 2491,
        "reasoning": "This code is vulnerable to a buffer over-read because it accesses `dp->ip6r_segleft` and other fields without first verifying that the `ip6_rthdr` structure itself is fully contained within the captured packet data. Specifically, the code proceeds to read fields like `dp0->ip6r0_reserved` and iterate through addresses based on `len` without ensuring there's enough data remaining in the packet buffer (`ndo->ndo_snapend`) to safely access them, leading to a potential read beyond the buffer's bounds.",
        "func": "rt6_print(netdissect_options *ndo, register const u_char *bp, const u_char *bp2 _U_)\n{\n\tregister const struct ip6_rthdr *dp;\n\tregister const struct ip6_rthdr0 *dp0;\n\tregister const u_char *ep;\n\tint i, len;\n \tregister const struct in6_addr *addr;\n \n \tdp = (const struct ip6_rthdr *)bp;\n\tlen = dp->ip6r_len;\n \n \t/* 'ep' points to the end of available data. */\n \tep = ndo->ndo_snapend;\n \n \tND_TCHECK(dp->ip6r_segleft);\n \n \tND_PRINT((ndo, \"srcrt (len=%d\", dp->ip6r_len));\t/*)*/\n \tND_PRINT((ndo, \", type=%d\", dp->ip6r_type));\n \tND_PRINT((ndo, \", segleft=%d\", dp->ip6r_segleft));\n\n\tswitch (dp->ip6r_type) {\n\tcase IPV6_RTHDR_TYPE_0:\n\tcase IPV6_RTHDR_TYPE_2:\t\t\t/* Mobile IPv6 ID-20 */\n\t\tdp0 = (const struct ip6_rthdr0 *)dp;\n\n\t\tND_TCHECK(dp0->ip6r0_reserved);\n\t\tif (dp0->ip6r0_reserved || ndo->ndo_vflag) {\n\t\t\tND_PRINT((ndo, \", rsv=0x%0x\",\n\t\t\t    EXTRACT_32BITS(&dp0->ip6r0_reserved)));\n\t\t}\n\n\t\tif (len % 2 == 1)\n\t\t\tgoto trunc;\n\t\tlen >>= 1;\n\t\taddr = &dp0->ip6r0_addr[0];\n\t\tfor (i = 0; i < len; i++) {\n\t\t\tif ((const u_char *)(addr + 1) > ep)\n\t\t\t\tgoto trunc;\n\n\t\t\tND_PRINT((ndo, \", [%d]%s\", i, ip6addr_string(ndo, addr)));\n\t\t\taddr++;\n\t\t}\n\t\t/*(*/\n\t\tND_PRINT((ndo, \") \"));\n\t\treturn((dp0->ip6r0_len + 1) << 3);\n\t\tbreak;\n\tdefault:\n\t\tgoto trunc;\n\t\tbreak;\n\t}\n\n trunc:\n\tND_PRINT((ndo, \"[|srcrt]\"));\n\treturn -1;\n}\n",
        "commit_message": "CVE-2017-13725/IPv6 R.H.: Check for the existence of all fields before fetching them.\n\nDon't fetch the length field from the header until after we've checked\nfor the existence of a field at or after that field.\n\n(Found by code inspection, not by a capture.)",
        "cve_desc": "The IPv6 routing header parser in tcpdump before 4.9.2 has a buffer over-read in print-rt6.c:rt6_print().",
        "target": 1
      },
      {
        "idx": 2505,
        "reasoning": "This code is vulnerable to a buffer over-read because it incorrectly calculates the length of the IPv6 address and subnet mask combination, expecting 20 bytes instead of the correct 32 bytes. This leads to reading beyond the allocated buffer when processing `IPSECDOI_ID_IPV6_ADDR_SUBNET`, potentially exposing sensitive information or causing a crash.",
        "func": "ikev1_id_print(netdissect_options *ndo, u_char tpay _U_,\n\t       const struct isakmp_gen *ext, u_int item_len,\n\t       const u_char *ep _U_, uint32_t phase, uint32_t doi _U_,\n\t       uint32_t proto _U_, int depth _U_)\n{\n#define USE_IPSECDOI_IN_PHASE1\t1\n\tconst struct ikev1_pl_id *p;\n\tstruct ikev1_pl_id id;\n\tstatic const char *idtypestr[] = {\n\t\t\"IPv4\", \"IPv4net\", \"IPv6\", \"IPv6net\",\n\t};\n\tstatic const char *ipsecidtypestr[] = {\n\t\tNULL, \"IPv4\", \"FQDN\", \"user FQDN\", \"IPv4net\", \"IPv6\",\n\t\t\"IPv6net\", \"IPv4range\", \"IPv6range\", \"ASN1 DN\", \"ASN1 GN\",\n\t\t\"keyid\",\n\t};\n\tint len;\n\tconst u_char *data;\n\n\tND_PRINT((ndo,\"%s:\", NPSTR(ISAKMP_NPTYPE_ID)));\n\n\tp = (const struct ikev1_pl_id *)ext;\n\tND_TCHECK(*p);\n\tUNALIGNED_MEMCPY(&id, ext, sizeof(id));\n\tif (sizeof(*p) < item_len) {\n\t\tdata = (const u_char *)(p + 1);\n\t\tlen = item_len - sizeof(*p);\n\t} else {\n\t\tdata = NULL;\n\t\tlen = 0;\n\t}\n\n#if 0 /*debug*/\n\tND_PRINT((ndo,\" [phase=%d doi=%d proto=%d]\", phase, doi, proto));\n#endif\n\tswitch (phase) {\n#ifndef USE_IPSECDOI_IN_PHASE1\n\tcase 1:\n#endif\n\tdefault:\n\t\tND_PRINT((ndo,\" idtype=%s\", STR_OR_ID(id.d.id_type, idtypestr)));\n\t\tND_PRINT((ndo,\" doi_data=%u\",\n\t\t\t  (uint32_t)(ntohl(id.d.doi_data) & 0xffffff)));\n\t\tbreak;\n\n#ifdef USE_IPSECDOI_IN_PHASE1\n\tcase 1:\n#endif\n\tcase 2:\n\t    {\n\t\tconst struct ipsecdoi_id *doi_p;\n\t\tstruct ipsecdoi_id doi_id;\n\t\tconst char *p_name;\n\n\t\tdoi_p = (const struct ipsecdoi_id *)ext;\n\t\tND_TCHECK(*doi_p);\n\t\tUNALIGNED_MEMCPY(&doi_id, ext, sizeof(doi_id));\n\t\tND_PRINT((ndo,\" idtype=%s\", STR_OR_ID(doi_id.type, ipsecidtypestr)));\n\t\t/* A protocol ID of 0 DOES NOT mean IPPROTO_IP! */\n\t\tif (!ndo->ndo_nflag && doi_id.proto_id && (p_name = netdb_protoname(doi_id.proto_id)) != NULL)\n\t\t\tND_PRINT((ndo,\" protoid=%s\", p_name));\n\t\telse\n\t\t\tND_PRINT((ndo,\" protoid=%u\", doi_id.proto_id));\n\t\tND_PRINT((ndo,\" port=%d\", ntohs(doi_id.port)));\n\t\tif (!len)\n\t\t\tbreak;\n\t\tif (data == NULL)\n\t\t\tgoto trunc;\n\t\tND_TCHECK2(*data, len);\n\t\tswitch (doi_id.type) {\n\t\tcase IPSECDOI_ID_IPV4_ADDR:\n\t\t\tif (len < 4)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 4]\", len));\n\t\t\telse\n\t\t\t\tND_PRINT((ndo,\" len=%d %s\", len, ipaddr_string(ndo, data)));\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\tcase IPSECDOI_ID_FQDN:\n\t\tcase IPSECDOI_ID_USER_FQDN:\n\t\t    {\n\t\t\tint i;\n\t\t\tND_PRINT((ndo,\" len=%d \", len));\n\t\t\tfor (i = 0; i < len; i++)\n\t\t\t\tsafeputchar(ndo, data[i]);\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\t    }\n\t\tcase IPSECDOI_ID_IPV4_ADDR_SUBNET:\n\t\t    {\n\t\t\tconst u_char *mask;\n\t\t\tif (len < 8)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 8]\", len));\n\t\t\telse {\n\t\t\t\tmask = data + sizeof(struct in_addr);\n\t\t\t\tND_PRINT((ndo,\" len=%d %s/%u.%u.%u.%u\", len,\n\t\t\t\t\t  ipaddr_string(ndo, data),\n\t\t\t\t\t  mask[0], mask[1], mask[2], mask[3]));\n\t\t\t}\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\t    }\n\t\tcase IPSECDOI_ID_IPV6_ADDR:\n\t\t\tif (len < 16)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 16]\", len));\n\t\t\telse\n\t\t\t\tND_PRINT((ndo,\" len=%d %s\", len, ip6addr_string(ndo, data)));\n\t\t\tlen = 0;\n\t\t\tbreak;\n \t\tcase IPSECDOI_ID_IPV6_ADDR_SUBNET:\n \t\t    {\n \t\t\tconst u_char *mask;\n\t\t\tif (len < 20)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 20]\", len));\n \t\t\telse {\n \t\t\t\tmask = (const u_char *)(data + sizeof(struct in6_addr));\n \t\t\t\t/*XXX*/\n\t\t\t\tND_PRINT((ndo,\" len=%d %s/0x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x%02x\", len,\n\t\t\t\t\t  ip6addr_string(ndo, data),\n\t\t\t\t\t  mask[0], mask[1], mask[2], mask[3],\n\t\t\t\t\t  mask[4], mask[5], mask[6], mask[7],\n\t\t\t\t\t  mask[8], mask[9], mask[10], mask[11],\n\t\t\t\t\t  mask[12], mask[13], mask[14], mask[15]));\n\t\t\t}\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\t    }\n\t\tcase IPSECDOI_ID_IPV4_ADDR_RANGE:\n\t\t\tif (len < 8)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 8]\", len));\n\t\t\telse {\n\t\t\t\tND_PRINT((ndo,\" len=%d %s-%s\", len,\n\t\t\t\t\t  ipaddr_string(ndo, data),\n\t\t\t\t\t  ipaddr_string(ndo, data + sizeof(struct in_addr))));\n\t\t\t}\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\tcase IPSECDOI_ID_IPV6_ADDR_RANGE:\n\t\t\tif (len < 32)\n\t\t\t\tND_PRINT((ndo,\" len=%d [bad: < 32]\", len));\n\t\t\telse {\n\t\t\t\tND_PRINT((ndo,\" len=%d %s-%s\", len,\n\t\t\t\t\t  ip6addr_string(ndo, data),\n\t\t\t\t\t  ip6addr_string(ndo, data + sizeof(struct in6_addr))));\n\t\t\t}\n\t\t\tlen = 0;\n\t\t\tbreak;\n\t\tcase IPSECDOI_ID_DER_ASN1_DN:\n\t\tcase IPSECDOI_ID_DER_ASN1_GN:\n\t\tcase IPSECDOI_ID_KEY_ID:\n\t\t\tbreak;\n\t\t}\n\t\tbreak;\n\t    }\n\t}\n\tif (data && len) {\n\t\tND_PRINT((ndo,\" len=%d\", len));\n\t\tif (2 < ndo->ndo_vflag) {\n\t\t\tND_PRINT((ndo,\" \"));\n\t\t\tif (!rawprint(ndo, (const uint8_t *)data, len))\n\t\t\t\tgoto trunc;\n\t\t}\n\t}\n\treturn (const u_char *)ext + item_len;\ntrunc:\n\tND_PRINT((ndo,\" [|%s]\", NPSTR(ISAKMP_NPTYPE_ID)));\n\treturn NULL;\n}\n",
        "commit_message": "CVE-2017-13689/IKEv1: Fix addr+subnet length check.\n\nAn IPv6 address plus subnet mask is 32 bytes, not 20 bytes.\n16 bytes of IPv6 address, 16 bytes of subnet mask.\n\nThis fixes a buffer over-read discovered by Bhargava Shastry,\nSecT/TU Berlin.\n\nAdd a test using the capture file supplied by the reporter(s).",
        "cve_desc": "The IKEv1 parser in tcpdump before 4.9.2 has a buffer over-read in print-isakmp.c:ikev1_id_print().",
        "target": 1
      }
    ]
  },
  "teeworlds": {
    "0": [
      {
        "idx": 437726,
        "reasoning": "This code snippet is not inherently vulnerable based on the provided information. It simply calls another function (`SendMsgEx`) with additional parameters, and without knowing the implementation of `SendMsgEx` or the context of `CMsgPacker` and `Flags`, there's no immediately obvious security flaw present in this forwarding function itself.\n\n\n\n",
        "func": "int CClient::SendMsg(CMsgPacker *pMsg, int Flags)\n{\n\treturn SendMsgEx(pMsg, Flags, false);\n}",
        "commit_message": "added some checks to snap handling",
        "cve_desc": "The CClient::ProcessServerPacket method in engine/client/client.cpp in Teeworlds before 0.6.4 allows remote servers to write to arbitrary physical memory locations and possibly execute arbitrary code via vectors involving snap handling.",
        "target": 0
      },
      {
        "idx": 437727,
        "reasoning": "This code snippet is not inherently vulnerable because it simply calls a method on another object (`m_SnapshotDelta`) to set a static size based on input parameters. There's no direct manipulation of potentially dangerous data like user input or memory addresses within this function itself, and without further context about `m_SnapshotDelta` and its `SetStaticsize` method, no vulnerabilities are apparent.",
        "func": "void CClient::SnapSetStaticsize(int ItemType, int Size)\n{\n\tm_SnapshotDelta.SetStaticsize(ItemType, Size);\n}",
        "commit_message": "added some checks to snap handling",
        "cve_desc": "The CClient::ProcessServerPacket method in engine/client/client.cpp in Teeworlds before 0.6.4 allows remote servers to write to arbitrary physical memory locations and possibly execute arbitrary code via vectors involving snap handling.",
        "target": 0
      },
      {
        "idx": 437728,
        "reasoning": "This code snippet is not inherently vulnerable. It simply manages the client's state during game entry and initiates the connection process by sending a signal and calling a handler \u2013 there's no obvious input validation missing or dangerous operation performed that would lead to a security issue based on this small excerpt.",
        "func": "void CClient::EnterGame()\n{\n\tif(State() == IClient::STATE_DEMOPLAYBACK)\n\t\treturn;\n\n\t// now we will wait for two snapshots\n\t// to finish the connection\n\tSendEnterGame();\n\tOnEnterGame();\n}",
        "commit_message": "added some checks to snap handling",
        "cve_desc": "The CClient::ProcessServerPacket method in engine/client/client.cpp in Teeworlds before 0.6.4 allows remote servers to write to arbitrary physical memory locations and possibly execute arbitrary code via vectors involving snap handling.",
        "target": 0
      },
      {
        "idx": 437729,
        "reasoning": "This code snippet is not vulnerable because it simply calls another function (`DisconnectWithReason`) with a predefined value. There's no input handling, memory manipulation, or other operations present that would introduce a security risk based on this isolated view of the code.",
        "func": "void CClient::Disconnect()\n{\n\tDisconnectWithReason(0);\n}",
        "commit_message": "added some checks to snap handling",
        "cve_desc": "The CClient::ProcessServerPacket method in engine/client/client.cpp in Teeworlds before 0.6.4 allows remote servers to write to arbitrary physical memory locations and possibly execute arbitrary code via vectors involving snap handling.",
        "target": 0
      },
      {
        "idx": 437730,
        "reasoning": "This code snippet is not vulnerable because it simply checks a flag (`GotProblems()`) returned by the networking client (`m_NetClient`) and returns a boolean value. There's no direct input handling, memory manipulation, or other operations typically associated with vulnerabilities present in this function.",
        "func": "bool CClient::ConnectionProblems()\n{\n\treturn m_NetClient.GotProblems() != 0;\n}",
        "commit_message": "added some checks to snap handling",
        "cve_desc": "The CClient::ProcessServerPacket method in engine/client/client.cpp in Teeworlds before 0.6.4 allows remote servers to write to arbitrary physical memory locations and possibly execute arbitrary code via vectors involving snap handling.",
        "target": 0
      }
    ],
    "1": []
  },
  "tensorflow": {
    "0": [
      {
        "idx": 218934,
        "reasoning": "This code snippet itself is not directly vulnerable. The commit message describes a fix for a potential denial-of-service vulnerability in `cwise ops` by validating argument types, and the provided code only shows a simple constructor\u2014it doesn\u2019t contain the vulnerable logic or the type validation being added/corrected.\n\n\n\n",
        "func": "  explicit UnaryVariantOp(OpKernelConstruction* ctx) : OpKernel(ctx) {}",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 0
      },
      {
        "idx": 218935,
        "reasoning": "This code is **not vulnerable** to the described denial-of-service. The commit message explicitly states the code *validates* argument types to prevent `CHECK`-fail errors, and the snippet demonstrates this validation using `ctx->MatchSignature` after converting types to enums, avoiding the previously problematic RTTI usage.\n\n\n\n",
        "func": "  explicit UnaryOp(OpKernelConstruction* ctx) : OpKernel(ctx) {\n    auto in = DataTypeToEnum<Tin>::v();\n    auto out = DataTypeToEnum<Tout>::v();\n    OP_REQUIRES_OK(ctx, ctx->MatchSignature({in}, {out}));\n  }",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 0
      },
      {
        "idx": 218936,
        "reasoning": "This code snippet is not directly related to the vulnerability described in the commit message, which concerns argument type validation in cwise operations. The provided code defines a helper function for creating an Eigen index list and doesn't involve any operations susceptible to the previously identified `CHECK`-fail denial of service triggered by invalid types.\n\n\n\n",
        "func": "  inline Eigen::IndexList<int, Eigen::type2index<1>> NByOne(int n) {\n    Eigen::IndexList<int, Eigen::type2index<1>> ret;\n    ret.set(0, n);\n    return ret;\n  }",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 0
      },
      {
        "idx": 218937,
        "reasoning": "This code is not vulnerable because the commit message explicitly addresses and mitigates a potential denial-of-service vulnerability by validating argument types to cwise operations. The fix replaces a problematic RTTI call with a safer alternative (`DataTypeString`), resolving the root cause of the previous `CHECK`-fail issue without introducing new vulnerabilities in the provided snippet.\n\n\n\n",
        "func": "  void operator()(const CPUDevice& d, typename Functor::tout_type out,\n                  typename Functor::tin_type in) {\n    Assign(d, out, in.unaryExpr(typename Functor::func()));\n  }",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 0
      },
      {
        "idx": 218938,
        "reasoning": "This code snippet is not directly vulnerable. The commit message describes a fix for a potential denial-of-service in *cwise ops* due to missing argument type validation, but the provided code focuses on setting a tolerance attribute for an `ApproximateEqualOp` and doesn't relate to the described vulnerability regarding argument types in cwise operations.\n\n\n\n",
        "func": "  explicit ApproximateEqualOp(OpKernelConstruction* context)\n      : OpKernel(context) {\n    float tolerance;\n    OP_REQUIRES_OK(context, context->GetAttr(\"tolerance\", &tolerance));\n    tolerance_ = T(tolerance);\n  }",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 194997,
        "reasoning": "This code is vulnerable to a denial-of-service attack because it doesn't adequately validate the data types of input tensors before performing operations, potentially leading to type confusion when calling templated binary operators. A malicious user could craft a `SavedModel` with mismatched data types, causing `CHECK` failures within the `flat<*>` calls and crashing the TensorFlow process.",
        "func": "  void Compute(OpKernelContext* ctx) override {\n    const Tensor& input_0 = ctx->input(0);\n    const Tensor& input_1 = ctx->input(1);\n    const Device& eigen_device = ctx->eigen_device<Device>();\n    bool error = false;\n    bool* const error_ptr = Functor::has_errors ? &error : nullptr;\n\n    // NOTE: Handle three simple cases before building the BinaryOpState, which\n    // is relatively expensive for small operations.\n    if (input_0.shape() == input_1.shape()) {\n      // tensor op tensor with no broadcasting.\n      Tensor* out;\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0, 1}, 0, input_0.shape(), &out));\n      functor::BinaryFunctor<Device, Functor, 1>()(\n          eigen_device, out->template flat<Tout>(),\n          input_0.template flat<Tin>(), input_1.template flat<Tin>(),\n          error_ptr);\n      if (Functor::has_errors && error) {\n        SetComputeError(ctx);\n      }\n      return;\n    } else if (input_0.shape().dims() == 0) {\n      // scalar op tensor.\n      Tensor* out;\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {1}, 0, input_1.shape(), &out));\n\n      functor::BinaryFunctor<Device, Functor, 1>().Left(\n          eigen_device, out->template flat<Tout>(),\n          input_0.template scalar<Tin>(), input_1.template flat<Tin>(),\n          error_ptr);\n      if (Functor::has_errors && error) {\n        SetComputeError(ctx);\n      }\n      return;\n    } else if (input_1.shape().dims() == 0) {\n      // tensor op scalar.\n      Tensor* out;\n      OP_REQUIRES_OK(ctx, ctx->forward_input_or_allocate_output(\n                              {0}, 0, input_0.shape(), &out));\n      functor::BinaryFunctor<Device, Functor, 1>().Right(\n          eigen_device, out->template flat<Tout>(),\n          input_0.template flat<Tin>(), input_1.template scalar<Tin>(),\n          error_ptr);\n      if (Functor::has_errors && error) {\n        SetComputeError(ctx);\n      }\n      return;\n    }\n\n    // 'state': Shared helper not dependent on T to reduce code size\n    BinaryOpState state(ctx);\n    if (ctx->status().code() == error::RESOURCE_EXHAUSTED) {\n      // Stop when BinaryOpState's constructor failed due to OOM.\n      return;\n    }\n    auto& bcast = state.bcast;\n    Tensor* out = state.out;\n    if (!bcast.IsValid()) {\n      if (ctx->status().ok()) {\n        if (state.result) {\n          functor::SetOneFunctor<Device, bool>()(eigen_device,\n                                                 out->flat<bool>());\n        } else {\n          functor::SetZeroFunctor<Device, bool>()(eigen_device,\n                                                  out->flat<bool>());\n        }\n      }\n      return;\n    }\n\n    auto& in0 = state.in0;\n    auto& in1 = state.in1;\n    if (state.out_num_elements == 0) {\n      return;\n    }\n\n    const int ndims = state.ndims;\n    if (ndims <= 1) {\n      auto out_flat = out->flat<Tout>();\n      if (state.in1_num_elements == 1) {\n        // tensor op scalar\n        functor::BinaryFunctor<Device, Functor, 1>().Right(\n            eigen_device, out_flat, in0.template flat<Tin>(),\n            in1.template scalar<Tin>(), error_ptr);\n      } else if (state.in0_num_elements == 1) {\n        // scalar op tensor\n        functor::BinaryFunctor<Device, Functor, 1>().Left(\n            eigen_device, out_flat, in0.template scalar<Tin>(),\n            in1.template flat<Tin>(), error_ptr);\n      } else {\n        functor::BinaryFunctor<Device, Functor, 1>()(\n            eigen_device, out_flat, in0.template flat<Tin>(),\n            in1.template flat<Tin>(), error_ptr);\n      }\n    } else if (ndims == 2) {\n      functor::BinaryFunctor<Device, Functor, 2>().BCast(\n          eigen_device, out->shaped<Tout, 2>(bcast.result_shape()),\n          in0.template shaped<Tin, 2>(bcast.x_reshape()),\n          BCast::ToIndexArray<2>(bcast.x_bcast()),\n          in1.template shaped<Tin, 2>(bcast.y_reshape()),\n          BCast::ToIndexArray<2>(bcast.y_bcast()), error_ptr);\n    } else if (ndims == 3) {\n      functor::BinaryFunctor<Device, Functor, 3>().BCast(\n          eigen_device, out->shaped<Tout, 3>(bcast.result_shape()),\n          in0.template shaped<Tin, 3>(bcast.x_reshape()),\n          BCast::ToIndexArray<3>(bcast.x_bcast()),\n          in1.template shaped<Tin, 3>(bcast.y_reshape()),\n          BCast::ToIndexArray<3>(bcast.y_bcast()), error_ptr);\n    } else if (ndims == 4) {\n      functor::BinaryFunctor<Device, Functor, 4>().BCast(\n          eigen_device, out->shaped<Tout, 4>(bcast.result_shape()),\n          in0.template shaped<Tin, 4>(bcast.x_reshape()),\n          BCast::ToIndexArray<4>(bcast.x_bcast()),\n          in1.template shaped<Tin, 4>(bcast.y_reshape()),\n          BCast::ToIndexArray<4>(bcast.y_bcast()), error_ptr);\n    } else if (ndims == 5) {\n      functor::BinaryFunctor<Device, Functor, 5>().BCast(\n          eigen_device, out->shaped<Tout, 5>(bcast.result_shape()),\n          in0.template shaped<Tin, 5>(bcast.x_reshape()),\n          BCast::ToIndexArray<5>(bcast.x_bcast()),\n          in1.template shaped<Tin, 5>(bcast.y_reshape()),\n          BCast::ToIndexArray<5>(bcast.y_bcast()), error_ptr);\n    } else {\n      SetUnimplementedError(ctx);\n    }\n    if (Functor::has_errors && error) {\n      SetComputeError(ctx);\n    }\n  }",
        "commit_message": "Validate real and expected type of arguments to cwise ops.\n\nWithout this validation, it is possible to trigger a `CHECK`-fail denial of service.\n\nThis is a rollforward of a previous commit which was rolled back as it was relying on RTTI. This time we don't use RTTI, we replace `typeid(Tin).name()` with a double function call, `DataTypeString(DataTypeToEnum<Tin>::v())`.\n\nPiperOrigin-RevId: 409340416\nChange-Id: I96080b2796729a3a9b65e7c68307ac276070f2f0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. A malicious user can cause a denial of service by altering a `SavedModel` such that any binary op would trigger `CHECK` failures. This occurs when the protobuf part corresponding to the tensor arguments is modified such that the `dtype` no longer matches the `dtype` expected by the op. In that case, calling the templated binary operator for the binary op would receive corrupted data, due to the type confusion involved. If `Tin` and `Tout` don't match the type of data in `out` and `input_*` tensors then `flat<*>` would interpret it wrongly. In most cases, this would be a silent failure, but we have noticed scenarios where this results in a `CHECK` crash, hence a denial of service. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 1
      },
      {
        "idx": 195025,
        "reasoning": "This code is vulnerable because it loads `TensorSliceProtos` from potentially malicious checkpoint files without sufficient validation, as highlighted by the CVE description. Specifically, the `ParseProtoUnlimited` function and subsequent processing of data within the `SavedSliceMeta` and `TensorSliceProto` structures are susceptible to crashes and undefined behavior if the checkpoint file contains invalid or maliciously crafted data, leading to the issues described in the CVE.",
        "func": "void TensorSliceReader::LoadShard(int shard) const {\n  CHECK_LT(shard, sss_.size());\n  if (sss_[shard] || !status_.ok()) {\n    return;  // Already loaded, or invalid.\n  }\n  string value;\n  SavedTensorSlices sts;\n  const string fname = fnames_[shard];\n  VLOG(1) << \"Reading meta data from file \" << fname << \"...\";\n  Table* table;\n  Status s = open_function_(fname, &table);\n  if (!s.ok()) {\n    status_ = errors::DataLoss(\"Unable to open table file \", fname, \": \",\n                               s.ToString());\n    return;\n  }\n  sss_[shard].reset(table);\n  if (!(table->Get(kSavedTensorSlicesKey, &value) &&\n        ParseProtoUnlimited(&sts, value))) {\n    status_ = errors::Internal(\n        \"Failed to find the saved tensor slices at the beginning of the \"\n        \"checkpoint file: \",\n        fname);\n    return;\n  }\n  status_ = CheckVersions(sts.meta().versions(), TF_CHECKPOINT_VERSION,\n                          TF_CHECKPOINT_VERSION_MIN_PRODUCER, \"Checkpoint\",\n                          \"checkpoint\");\n  if (!status_.ok()) return;\n  for (const SavedSliceMeta& ssm : sts.meta().tensor()) {\n    TensorShape ssm_shape;\n    status_ = TensorShape::BuildTensorShapeBase(ssm.shape(), &ssm_shape);\n    if (!status_.ok()) return;\n    for (const TensorSliceProto& tsp : ssm.slice()) {\n      TensorSlice ss_slice(tsp);\n      status_ = RegisterTensorSlice(ssm.name(), ssm_shape, ssm.type(), fname,\n                                    ss_slice, &tensors_);\n      if (!status_.ok()) return;\n    }\n  }\n}",
        "commit_message": "Add BuildTensorSlice for building from unvalidated TensorSliceProtos.\n\nThis avoids several sources of crashes and undefined behavior when loading\ninvalid checkpoints.\n\nPiperOrigin-RevId: 392785704\nChange-Id: Icd9713c768b882f3b58b427eddac376060696833",
        "cve_desc": "TensorFlow is an open source platform for machine learning. In affected versions an attacker can trigger undefined behavior, integer overflows, segfaults and `CHECK`-fail crashes if they can change saved checkpoints from outside of TensorFlow. This is because the checkpoints loading infrastructure is missing validation for invalid file formats. The fixes will be included in TensorFlow 2.7.0. We will also cherrypick these commits on TensorFlow 2.6.1, TensorFlow 2.5.2, and TensorFlow 2.4.4, as these are also affected and still in supported range.",
        "target": 1
      },
      {
        "idx": 195070,
        "reasoning": "This code is vulnerable because it validates `NodeDef`s within functions defined in a `FunctionDefLibrary` but doesn't explicitly check for or prevent self-recursive functions, as the `GraphDef` format doesn't support them. Consequently, loading a `GraphDef` with a self-recursive function will lead to a stack overflow during execution when the code attempts to resolve the function and its nodes indefinitely.",
        "func": "static Status ValidateSavedTensors(const GraphDef& graph_def) {\n  for (const auto& node : graph_def.node()) {\n    TF_RETURN_IF_ERROR(ValidateNode(node));\n  }\n\n  if (graph_def.has_library()) {\n    const FunctionDefLibrary& library = graph_def.library();\n    for (const auto& function : library.function()) {\n      for (const auto& node : function.node_def()) {\n        TF_RETURN_IF_ERROR(ValidateNode(node));\n      }\n    }\n  }\n\n  return Status::OK();\n}",
        "commit_message": "Prevent stack overflow when FunctionLib in GraphDef has a self-recursive function.\n\nIt is likely that no recursivity is supported, but we should handle this separately.\n\nPiperOrigin-RevId: 414860329\nChange-Id: I02a2270e86282b37362ddd485eeef16fb986a9e0",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. The `GraphDef` format in TensorFlow does not allow self recursive functions. The runtime assumes that this invariant is satisfied. However, a `GraphDef` containing a fragment such as the following can be consumed when loading a `SavedModel`. This would result in a stack overflow during execution as resolving each `NodeDef` means resolving the function itself and its nodes. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 1
      },
      {
        "idx": 195071,
        "reasoning": "This code is vulnerable to an integer overflow because `embedding_size` and `lookup_size` are calculated by multiplying dimensions from user-provided tensors (`value` and `dense_shape`). A malicious user could craft input tensors with large dimensions, causing these multiplications to overflow, potentially leading to a heap out-of-bounds read or write when `TfLiteTensorRealloc` is called with the resulting `output_size`.",
        "func": "TfLiteStatus Eval(TfLiteContext* context, TfLiteNode* node) {\n  auto* params =\n      reinterpret_cast<TfLiteEmbeddingLookupSparseParams*>(node->builtin_data);\n  TfLiteTensor* output;\n  TF_LITE_ENSURE_OK(context, GetOutputSafe(context, node, 0, &output));\n  const TfLiteTensor* ids;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 0, &ids));\n  const TfLiteTensor* indices;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 1, &indices));\n  const TfLiteTensor* dense_shape;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 2, &dense_shape));\n  const TfLiteTensor* weights;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 3, &weights));\n  const TfLiteTensor* value;\n  TF_LITE_ENSURE_OK(context, GetInputSafe(context, node, 4, &value));\n\n  const int lookup_rank = SizeOfDimension(indices, 1);\n  const int embedding_rank = NumDimensions(value);\n  const int num_lookups = SizeOfDimension(ids, 0);\n  const int num_rows = SizeOfDimension(value, 0);\n\n  // The last dimension gets replaced by the embedding.\n  const int output_rank = (lookup_rank - 1) + (embedding_rank - 1);\n\n  // Make sure that the actual dense shape of the sparse tensor represented by\n  // (loopkup, indices, dense_shape) is consistent.\n  TF_LITE_ENSURE_EQ(context, SizeOfDimension(dense_shape, 0), lookup_rank);\n\n  // Resize output tensor.\n  TfLiteIntArray* output_shape = TfLiteIntArrayCreate(output_rank);\n  TF_LITE_ENSURE(context, output_shape != nullptr);\n  int k = 0;\n  int embedding_size = 1;\n  int lookup_size = 1;\n  for (int i = 0; i < lookup_rank - 1; i++, k++) {\n    const int dim = dense_shape->data.i32[i];\n    lookup_size *= dim;\n    output_shape->data[k] = dim;\n  }\n  for (int i = 1; i < embedding_rank; i++, k++) {\n    const int dim = SizeOfDimension(value, i);\n    embedding_size *= dim;\n    output_shape->data[k] = dim;\n  }\n  TF_LITE_ENSURE_STATUS(context->ResizeTensor(context, output, output_shape));\n  const int output_size = lookup_size * embedding_size;\n  TfLiteTensorRealloc(output_size * sizeof(float), output);\n\n  float* output_ptr = GetTensorData<float>(output);\n  const float* weights_ptr = GetTensorData<float>(weights);\n  const float* value_ptr = GetTensorData<float>(value);\n\n  std::fill_n(output_ptr, output_size, 0.0f);\n\n  // Keep track of the current bucket for aggregation/combination.\n  int current_output_offset = 0;\n  float current_total_weight = 0.0;\n  float current_squares_weight = 0.0;\n  int num_elements = 0;\n\n  for (int i = 0; i < num_lookups; i++) {\n    int idx = ids->data.i32[i];\n    if (idx >= num_rows || idx < 0) {\n      context->ReportError(context,\n                           \"Embedding Lookup Sparse: index out of bounds. \"\n                           \"Got %d, and bounds are [0, %d]\",\n                           idx, num_rows - 1);\n      return kTfLiteError;\n    }\n\n    // Check where we need to aggregate.\n    const int example_indices_offset = i * lookup_rank;\n    int output_bucket = 0;\n    int stride = 1;\n    for (int k = (lookup_rank - 1) - 1; k >= 0; k--) {\n      output_bucket += indices->data.i32[example_indices_offset + k] * stride;\n      stride *= dense_shape->data.i32[k];\n    }\n    const int output_offset = output_bucket * embedding_size;\n\n    // If we are in a new aggregation bucket and the combiner is not the sum,\n    // go back and finalize the result of the previous bucket.\n    if (output_offset != current_output_offset) {\n      FinalizeAggregation(params->combiner, num_elements, current_total_weight,\n                          current_squares_weight, embedding_size,\n                          &output_ptr[current_output_offset]);\n\n      // Track next bucket.\n      num_elements = 0;\n      current_total_weight = 0.0;\n      current_squares_weight = 0.0;\n      current_output_offset = output_offset;\n    }\n\n    // Add element to aggregation.\n    ++num_elements;\n    const int example_embedding_offset = idx * embedding_size;\n    const float w = weights_ptr[i];\n    current_squares_weight += w * w;\n    current_total_weight += w;\n    for (int k = 0; k < embedding_size; k++) {\n      output_ptr[current_output_offset + k] +=\n          value_ptr[example_embedding_offset + k] * w;\n    }\n  }\n\n  // Finalize last bucket.\n  FinalizeAggregation(params->combiner, num_elements, current_total_weight,\n                      current_squares_weight, embedding_size,\n                      &GetTensorData<float>(output)[current_output_offset]);\n\n  return kTfLiteOk;\n}",
        "commit_message": "[lite] Check for overflow when creating required bytes.\n\nPiperOrigin-RevId: 417629001\nChange-Id: Ia7feb3ea8e988f4fd4b3c98c1a1fed4557d99fd7",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. An attacker can craft a TFLite model that would cause an integer overflow in embedding lookup operations. Both `embedding_size` and `lookup_size` are products of values provided by the user. Hence, a malicious user could trigger overflows in the multiplication. In certain scenarios, this can then result in heap OOB read/write. Users are advised to upgrade to a patched version.",
        "target": 1
      },
      {
        "idx": 195219,
        "reasoning": "This code is vulnerable to a potential denial-of-service (DoS) attack because it allocates a `std::vector<DimensionHandle>` named `dims` with a size determined by a value within a user-controlled tensor. An attacker could provide a tensor with a very large integer value, leading to excessive memory allocation and potentially crashing the TensorFlow process, as described in the CVE.",
        "func": "Status InferenceContext::InternalMakeShapeFromTensor(\n    bool treat_unknown_scalar_tensor_as_unknown_shape, const Tensor* t,\n    ShapeHandle tensor_shape, ShapeHandle* out) {\n  // Only callers who have set\n  if (!treat_unknown_scalar_tensor_as_unknown_shape) {\n    TF_RETURN_IF_ERROR(WithRank(tensor_shape, 1, &tensor_shape));\n  }\n  if (t == nullptr) {\n    // This is guarded by the check above.\n    if (Rank(tensor_shape) == 0) {\n      return ReturnUnknownShape(out);\n    }\n    // Shape tensor is not known, but if the shape of the shape tensor is then\n    // the right number of unknown dims can be created.\n    DimensionHandle shape_dim = Dim(tensor_shape, 0);\n    if (!ValueKnown(shape_dim)) {\n      return ReturnUnknownShape(out);\n    }\n    const auto num_dims = Value(shape_dim);\n    std::vector<DimensionHandle> dims;\n    dims.reserve(num_dims);\n    for (int i = 0; i < num_dims; i++) dims.push_back(UnknownDim());\n    return ReturnCreatedShape(dims, out);\n  }\n\n  if (t->shape().dims() == 0) {\n    if (t->dtype() == DataType::DT_INT32) {\n      auto flat_t = t->scalar<int32>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else if (t->dtype() == DataType::DT_INT64) {\n      auto flat_t = t->scalar<int64_t>();\n      if (flat_t() != -1) {\n        *out = nullptr;\n        return errors::InvalidArgument(\n            \"Input tensor must be rank 1, or if its rank 0 it must have value \"\n            \"-1 \"\n            \"(representing an unknown shape).  Saw value: \",\n            flat_t());\n      }\n      return ReturnUnknownShape(out);\n    } else {\n      *out = nullptr;\n      return errors::InvalidArgument(\n          \"Input tensor must be int32 or int64, but was \",\n          DataTypeString(t->dtype()));\n    }\n  }\n\n  if (t->shape().dims() != 1) {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be rank 1, but was rank \", t->shape().dims(), \".\",\n        ((t->shape().dims() == 0)\n             ? \"If it is rank 0 rank 0 it must have statically known value -1 \"\n               \"(representing an unknown shape). \"\n             : \" \"),\n        \"Saw tensor shape \", t->shape().DebugString());\n  }\n  std::vector<DimensionHandle> dims;\n  if (t->dtype() == DataType::DT_INT32) {\n    auto flat_t = t->flat<int32>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int32_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else if (t->dtype() == DataType::DT_INT64) {\n    auto flat_t = t->flat<int64_t>();\n    for (int i = 0; i < flat_t.size(); ++i) {\n      const int64_t val = flat_t(i);\n      if (val < -1) {\n        return errors::InvalidArgument(\n            \"Invalid value in tensor used for shape: \", val);\n      }\n      // -1 will become an unknown dim.\n      dims.push_back(MakeDim(val));\n    }\n  } else {\n    *out = nullptr;\n    return errors::InvalidArgument(\n        \"Input tensor must be int32 or int64, but was \",\n        DataTypeString(t->dtype()));\n  }\n\n  return ReturnCreatedShape(dims, out);\n}",
        "commit_message": "Fix abort caused by allocating a too large vector.\n\nWe need to make sure that the number of dimensions in a shape is within limits.\n\nPiperOrigin-RevId: 408997911\nChange-Id: If59e1c23f2ec9c2d4ff4d8632fd62b2a7773a4eb",
        "cve_desc": "Tensorflow is an Open Source Machine Learning Framework. During shape inference, TensorFlow can allocate a large vector based on a value from a tensor controlled by the user. The fix will be included in TensorFlow 2.8.0. We will also cherrypick this commit on TensorFlow 2.7.1, TensorFlow 2.6.3, and TensorFlow 2.5.3, as these are also affected and still in supported range.",
        "target": 1
      }
    ]
  },
  "tip": {
    "0": [
      {
        "idx": 352893,
        "reasoning": "This code is not vulnerable because it does *not* implement the suggested workaround for CVE-2013-6885, which involves setting MSR `C001_1020[15] = 1b`. The provided code snippet focuses on enabling SSE and adjusting `CLK_CTL` MSRs, unrelated to the erratum's described issue of locked instructions and write-combined memory.\n\n\n\n",
        "func": "static void init_amd_k7(struct cpuinfo_x86 *c)\n{\n\tu32 l, h;\n\n\t/*\n\t * Bit 15 of Athlon specific MSR 15, needs to be 0\n\t * to enable SSE on Palomino/Morgan/Barton CPU's.\n\t * If the BIOS didn't enable it already, enable it here.\n\t */\n\tif (c->x86_model >= 6 && c->x86_model <= 10) {\n\t\tif (!cpu_has(c, X86_FEATURE_XMM)) {\n\t\t\tprintk(KERN_INFO \"Enabling disabled K7/SSE Support.\\n\");\n\t\t\trdmsr(MSR_K7_HWCR, l, h);\n\t\t\tl &= ~0x00008000;\n\t\t\twrmsr(MSR_K7_HWCR, l, h);\n\t\t\tset_cpu_cap(c, X86_FEATURE_XMM);\n\t\t}\n\t}\n\n\t/*\n\t * It's been determined by AMD that Athlons since model 8 stepping 1\n\t * are more robust with CLK_CTL set to 200xxxxx instead of 600xxxxx\n\t * As per AMD technical note 27212 0.2\n\t */\n\tif ((c->x86_model == 8 && c->x86_mask >= 1) || (c->x86_model > 8)) {\n\t\trdmsr(MSR_K7_CLK_CTL, l, h);\n\t\tif ((l & 0xfff00000) != 0x20000000) {\n\t\t\tprintk(KERN_INFO\n\t\t\t    \"CPU: CLK_CTL MSR was %x. Reprogramming to %x\\n\",\n\t\t\t\t\tl, ((l & 0x000fffff)|0x20000000));\n\t\t\twrmsr(MSR_K7_CLK_CTL, (l & 0x000fffff)|0x20000000, h);\n\t\t}\n\t}\n\n\tset_cpu_cap(c, X86_FEATURE_K7);\n\n\tamd_k7_smp_check(c);\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 0
      },
      {
        "idx": 352894,
        "reasoning": "This code is **not vulnerable** because it implements the suggested workaround for CVE-2013-6885 by checking and setting the MSR `C001_1020[15]` to 1b for affected AMD Family 16h processors, thus mitigating the potential for core hangs described in the erratum. The code specifically targets the vulnerable processor family and model and applies the BIOS-recommended fix directly within the kernel as a precaution.\n\n\n\n",
        "func": "static void early_init_amd(struct cpuinfo_x86 *c)\n{\n\tearly_init_amd_mc(c);\n\n\t/*\n\t * c->x86_power is 8000_0007 edx. Bit 8 is TSC runs at constant rate\n\t * with P/T states and does not stop in deep C-states\n\t */\n\tif (c->x86_power & (1 << 8)) {\n\t\tset_cpu_cap(c, X86_FEATURE_CONSTANT_TSC);\n\t\tset_cpu_cap(c, X86_FEATURE_NONSTOP_TSC);\n\t\tif (!check_tsc_unstable())\n\t\t\tsched_clock_stable = 1;\n\t}\n\n#ifdef CONFIG_X86_64\n\tset_cpu_cap(c, X86_FEATURE_SYSCALL32);\n#else\n\t/*  Set MTRR capability flag if appropriate */\n\tif (c->x86 == 5)\n\t\tif (c->x86_model == 13 || c->x86_model == 9 ||\n\t\t    (c->x86_model == 8 && c->x86_mask >= 8))\n\t\t\tset_cpu_cap(c, X86_FEATURE_K6_MTRR);\n#endif\n#if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_PCI)\n\t/* check CPU config space for extended APIC ID */\n\tif (cpu_has_apic && c->x86 >= 0xf) {\n\t\tunsigned int val;\n\t\tval = read_pci_config(0, 24, 0, 0x68);\n\t\tif ((val & ((1 << 17) | (1 << 18))) == ((1 << 17) | (1 << 18)))\n\t\t\tset_cpu_cap(c, X86_FEATURE_EXTD_APICID);\n\t}\n#endif\n\n\t/* F16h erratum 793, CVE-2013-6885 */\n\tif (c->x86 == 0x16 && c->x86_model <= 0xf) {\n\t\tu64 val;\n\n\t\trdmsrl(MSR_AMD64_LS_CFG, val);\n\t\tif (!(val & BIT(15)))\n\t\t\twrmsrl(MSR_AMD64_LS_CFG, val | BIT(15));\n\t}\n\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 0
      },
      {
        "idx": 352895,
        "reasoning": "This code is **not vulnerable** to the described erratum. The code implements a check to determine if the CPU is susceptible to erratum 793 and applies a workaround by setting a specific MSR bit if necessary, effectively mitigating the potential for core hangs as outlined in the CVE description. \n\n\n\n",
        "func": "static bool cpu_has_amd_erratum(struct cpuinfo_x86 *cpu, const int *erratum)\n{\n\tint osvw_id = *erratum++;\n\tu32 range;\n\tu32 ms;\n\n\tif (osvw_id >= 0 && osvw_id < 65536 &&\n\t    cpu_has(cpu, X86_FEATURE_OSVW)) {\n\t\tu64 osvw_len;\n\n\t\trdmsrl(MSR_AMD64_OSVW_ID_LENGTH, osvw_len);\n\t\tif (osvw_id < osvw_len) {\n\t\t\tu64 osvw_bits;\n\n\t\t\trdmsrl(MSR_AMD64_OSVW_STATUS + (osvw_id >> 6),\n\t\t\t    osvw_bits);\n\t\t\treturn osvw_bits & (1ULL << (osvw_id & 0x3f));\n\t\t}\n\t}\n\n\t/* OSVW unavailable or ID unknown, match family-model-stepping range */\n\tms = (cpu->x86_model << 4) | cpu->x86_mask;\n\twhile ((range = *erratum++))\n\t\tif ((cpu->x86 == AMD_MODEL_RANGE_FAMILY(range)) &&\n\t\t    (ms >= AMD_MODEL_RANGE_START(range)) &&\n\t\t    (ms <= AMD_MODEL_RANGE_END(range)))\n\t\t\treturn true;\n\n\treturn false;\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 0
      },
      {
        "idx": 352896,
        "reasoning": "This code is not directly vulnerable to CVE-2013-6885 because it doesn't implement the suggested workaround (setting MSR C001_1020[15] = 1b). The commit message states the code *adds* the workaround as a precaution, but the provided snippet doesn't show that implementation; it focuses on TSC behavior and virtual address alignment, unrelated to the erratum's core hang issue.\n\n\n\n",
        "func": "static void bsp_init_amd(struct cpuinfo_x86 *c)\n{\n\tif (cpu_has(c, X86_FEATURE_CONSTANT_TSC)) {\n\n\t\tif (c->x86 > 0x10 ||\n\t\t    (c->x86 == 0x10 && c->x86_model >= 0x2)) {\n\t\t\tu64 val;\n\n\t\t\trdmsrl(MSR_K7_HWCR, val);\n\t\t\tif (!(val & BIT(24)))\n\t\t\t\tprintk(KERN_WARNING FW_BUG \"TSC doesn't count \"\n\t\t\t\t\t\"with P0 frequency!\\n\");\n\t\t}\n\t}\n\n\tif (c->x86 == 0x15) {\n\t\tunsigned long upperbit;\n\t\tu32 cpuid, assoc;\n\n\t\tcpuid\t = cpuid_edx(0x80000005);\n\t\tassoc\t = cpuid >> 16 & 0xff;\n\t\tupperbit = ((cpuid >> 24) << 10) / assoc;\n\n\t\tva_align.mask\t  = (upperbit - 1) & PAGE_MASK;\n\t\tva_align.flags    = ALIGN_VA_32 | ALIGN_VA_64;\n\t}\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 0
      },
      {
        "idx": 352897,
        "reasoning": "This code snippet is not directly vulnerable because it's a utility function (`rdmsrl_amd_safe`) for reading Model Specific Registers (MSRs) and doesn't directly implement the potentially problematic combination of write-combined memory access and locked instructions described in the erratum. The commit message indicates the workaround is applied via a BIOS setting (MSR C001_1020[15] = 1b), not within this specific code, mitigating the core hang issue.\n\n\n\n",
        "func": "static inline int rdmsrl_amd_safe(unsigned msr, unsigned long long *p)\n{\n\tu32 gprs[8] = { 0 };\n\tint err;\n\n\tWARN_ONCE((boot_cpu_data.x86 != 0xf),\n\t\t  \"%s should only be used on K8!\\n\", __func__);\n\n\tgprs[1] = msr;\n\tgprs[7] = 0x9c5a203a;\n\n\terr = rdmsr_safe_regs(gprs);\n\n\t*p = gprs[0] | ((u64)gprs[2] << 32);\n\n\treturn err;\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 204111,
        "reasoning": "This code is vulnerable because it doesn't implement the suggested workaround of setting MSR C001_1020[15] = 1b, leaving the system susceptible to a core hang when a locked instruction interacts with a write-combined memory type as described in erratum 793 (CVE-2013-6885). While the commit message states the workaround is *added*, the provided code snippet doesn't show any implementation of this MSR modification, meaning the vulnerability remains unmitigated.",
        "func": "static void early_init_amd(struct cpuinfo_x86 *c)\n{\n\tearly_init_amd_mc(c);\n\n\t/*\n\t * c->x86_power is 8000_0007 edx. Bit 8 is TSC runs at constant rate\n\t * with P/T states and does not stop in deep C-states\n\t */\n\tif (c->x86_power & (1 << 8)) {\n\t\tset_cpu_cap(c, X86_FEATURE_CONSTANT_TSC);\n\t\tset_cpu_cap(c, X86_FEATURE_NONSTOP_TSC);\n\t\tif (!check_tsc_unstable())\n\t\t\tsched_clock_stable = 1;\n\t}\n\n#ifdef CONFIG_X86_64\n\tset_cpu_cap(c, X86_FEATURE_SYSCALL32);\n#else\n\t/*  Set MTRR capability flag if appropriate */\n\tif (c->x86 == 5)\n\t\tif (c->x86_model == 13 || c->x86_model == 9 ||\n\t\t    (c->x86_model == 8 && c->x86_mask >= 8))\n\t\t\tset_cpu_cap(c, X86_FEATURE_K6_MTRR);\n#endif\n#if defined(CONFIG_X86_LOCAL_APIC) && defined(CONFIG_PCI)\n\t/* check CPU config space for extended APIC ID */\n\tif (cpu_has_apic && c->x86 >= 0xf) {\n\t\tunsigned int val;\n\t\tval = read_pci_config(0, 24, 0, 0x68);\n\t\tif ((val & ((1 << 17) | (1 << 18))) == ((1 << 17) | (1 << 18)))\n\t\t\tset_cpu_cap(c, X86_FEATURE_EXTD_APICID);\n\t}\n#endif\n}",
        "commit_message": "x86, cpu, amd: Add workaround for family 16h, erratum 793\n\nThis adds the workaround for erratum 793 as a precaution in case not\nevery BIOS implements it.  This addresses CVE-2013-6885.\n\nErratum text:\n\n[Revision Guide for AMD Family 16h Models 00h-0Fh Processors,\ndocument 51810 Rev. 3.04 November 2013]\n\n793 Specific Combination of Writes to Write Combined Memory Types and\nLocked Instructions May Cause Core Hang\n\nDescription\n\nUnder a highly specific and detailed set of internal timing\nconditions, a locked instruction may trigger a timing sequence whereby\nthe write to a write combined memory type is not flushed, causing the\nlocked instruction to stall indefinitely.\n\nPotential Effect on System\n\nProcessor core hang.\n\nSuggested Workaround\n\nBIOS should set MSR\nC001_1020[15] = 1b.\n\nFix Planned\n\nNo fix planned\n\n[ hpa: updated description, fixed typo in MSR name ]\n\nSigned-off-by: Borislav Petkov <bp@suse.de>\nLink: http://lkml.kernel.org/r/20140114230711.GS29865@pd.tnic\nTested-by: Aravind Gopalakrishnan <aravind.gopalakrishnan@amd.com>\nSigned-off-by: H. Peter Anvin <hpa@linux.intel.com>",
        "cve_desc": "The microcode on AMD 16h 00h through 0Fh processors does not properly handle the interaction between locked instructions and write-combined memory types, which allows local users to cause a denial of service (system hang) via a crafted application, aka the errata 793 issue.",
        "target": 1
      },
      {
        "idx": 205689,
        "reasoning": "This code is vulnerable because when `CONFIG_TIMER_STATS` is enabled, it leaks the real PID of a process via `/proc/timer_list`, potentially exposing information across namespaces. This allows a local user to discover PIDs outside of their own namespace, violating the intended isolation and potentially enabling privilege escalation or information gathering attacks as described in the CVE.",
        "func": "print_timer(struct seq_file *m, struct hrtimer *taddr, struct hrtimer *timer,\n\t    int idx, u64 now)\n{\n#ifdef CONFIG_TIMER_STATS\n\tchar tmp[TASK_COMM_LEN + 1];\n#endif\n\tSEQ_printf(m, \" #%d: \", idx);\n\tprint_name_offset(m, taddr);\n\tSEQ_printf(m, \", \");\n\tprint_name_offset(m, timer->function);\n\tSEQ_printf(m, \", S:%02x\", timer->state);\n#ifdef CONFIG_TIMER_STATS\n\tSEQ_printf(m, \", \");\n\tprint_name_offset(m, timer->start_site);\n\tmemcpy(tmp, timer->start_comm, TASK_COMM_LEN);\n\ttmp[TASK_COMM_LEN] = 0;\n\tSEQ_printf(m, \", %s/%d\", tmp, timer->start_pid);\n#endif\n\tSEQ_printf(m, \"\\n\");\n\tSEQ_printf(m, \" # expires at %Lu-%Lu nsecs [in %Ld to %Ld nsecs]\\n\",\n\t\t(unsigned long long)ktime_to_ns(hrtimer_get_softexpires(timer)),\n\t\t(unsigned long long)ktime_to_ns(hrtimer_get_expires(timer)),\n\t\t(long long)(ktime_to_ns(hrtimer_get_softexpires(timer)) - now),\n\t\t(long long)(ktime_to_ns(hrtimer_get_expires(timer)) - now));\n}",
        "commit_message": "time: Remove CONFIG_TIMER_STATS\n\nCurrently CONFIG_TIMER_STATS exposes process information across namespaces:\n\nkernel/time/timer_list.c print_timer():\n\n        SEQ_printf(m, \", %s/%d\", tmp, timer->start_pid);\n\n/proc/timer_list:\n\n #11: <0000000000000000>, hrtimer_wakeup, S:01, do_nanosleep, cron/2570\n\nGiven that the tracer can give the same information, this patch entirely\nremoves CONFIG_TIMER_STATS.\n\nSuggested-by: Thomas Gleixner <tglx@linutronix.de>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nAcked-by: John Stultz <john.stultz@linaro.org>\nCc: Nicolas Pitre <nicolas.pitre@linaro.org>\nCc: linux-doc@vger.kernel.org\nCc: Lai Jiangshan <jiangshanlai@gmail.com>\nCc: Shuah Khan <shuah@kernel.org>\nCc: Xing Gao <xgao01@email.wm.edu>\nCc: Jonathan Corbet <corbet@lwn.net>\nCc: Jessica Frazelle <me@jessfraz.com>\nCc: kernel-hardening@lists.openwall.com\nCc: Nicolas Iooss <nicolas.iooss_linux@m4x.org>\nCc: \"Paul E. McKenney\" <paulmck@linux.vnet.ibm.com>\nCc: Petr Mladek <pmladek@suse.com>\nCc: Richard Cochran <richardcochran@gmail.com>\nCc: Tejun Heo <tj@kernel.org>\nCc: Michal Marek <mmarek@suse.com>\nCc: Josh Poimboeuf <jpoimboe@redhat.com>\nCc: Dmitry Vyukov <dvyukov@google.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nCc: \"Eric W. Biederman\" <ebiederm@xmission.com>\nCc: Olof Johansson <olof@lixom.net>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: linux-api@vger.kernel.org\nCc: Arjan van de Ven <arjan@linux.intel.com>\nLink: http://lkml.kernel.org/r/20170208192659.GA32582@beast\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>",
        "cve_desc": "The time subsystem in the Linux kernel through 4.9.9, when CONFIG_TIMER_STATS is enabled, allows local users to discover real PID values (as distinguished from PID values inside a PID namespace) by reading the /proc/timer_list file, related to the print_timer function in kernel/time/timer_list.c and the __timer_stats_timer_set_start_info function in kernel/time/timer.c.",
        "target": 1
      },
      {
        "idx": 205703,
        "reasoning": "The code is vulnerable because it stores the actual PID (`current->pid`) of a process within the `timer_list` structure when `CONFIG_TIMER_STATS` is enabled. This allows a local user, by reading `/proc/timer_list`, to potentially discover PIDs outside of their own namespace, breaking the PID namespace isolation and revealing information about processes they shouldn't have access to.",
        "func": "void __timer_stats_timer_set_start_info(struct timer_list *timer, void *addr)\n{\n\tif (timer->start_site)\n\t\treturn;\n\n\ttimer->start_site = addr;\n\tmemcpy(timer->start_comm, current->comm, TASK_COMM_LEN);\n\ttimer->start_pid = current->pid;\n}",
        "commit_message": "time: Remove CONFIG_TIMER_STATS\n\nCurrently CONFIG_TIMER_STATS exposes process information across namespaces:\n\nkernel/time/timer_list.c print_timer():\n\n        SEQ_printf(m, \", %s/%d\", tmp, timer->start_pid);\n\n/proc/timer_list:\n\n #11: <0000000000000000>, hrtimer_wakeup, S:01, do_nanosleep, cron/2570\n\nGiven that the tracer can give the same information, this patch entirely\nremoves CONFIG_TIMER_STATS.\n\nSuggested-by: Thomas Gleixner <tglx@linutronix.de>\nSigned-off-by: Kees Cook <keescook@chromium.org>\nAcked-by: John Stultz <john.stultz@linaro.org>\nCc: Nicolas Pitre <nicolas.pitre@linaro.org>\nCc: linux-doc@vger.kernel.org\nCc: Lai Jiangshan <jiangshanlai@gmail.com>\nCc: Shuah Khan <shuah@kernel.org>\nCc: Xing Gao <xgao01@email.wm.edu>\nCc: Jonathan Corbet <corbet@lwn.net>\nCc: Jessica Frazelle <me@jessfraz.com>\nCc: kernel-hardening@lists.openwall.com\nCc: Nicolas Iooss <nicolas.iooss_linux@m4x.org>\nCc: \"Paul E. McKenney\" <paulmck@linux.vnet.ibm.com>\nCc: Petr Mladek <pmladek@suse.com>\nCc: Richard Cochran <richardcochran@gmail.com>\nCc: Tejun Heo <tj@kernel.org>\nCc: Michal Marek <mmarek@suse.com>\nCc: Josh Poimboeuf <jpoimboe@redhat.com>\nCc: Dmitry Vyukov <dvyukov@google.com>\nCc: Oleg Nesterov <oleg@redhat.com>\nCc: \"Eric W. Biederman\" <ebiederm@xmission.com>\nCc: Olof Johansson <olof@lixom.net>\nCc: Andrew Morton <akpm@linux-foundation.org>\nCc: linux-api@vger.kernel.org\nCc: Arjan van de Ven <arjan@linux.intel.com>\nLink: http://lkml.kernel.org/r/20170208192659.GA32582@beast\nSigned-off-by: Thomas Gleixner <tglx@linutronix.de>",
        "cve_desc": "The time subsystem in the Linux kernel through 4.9.9, when CONFIG_TIMER_STATS is enabled, allows local users to discover real PID values (as distinguished from PID values inside a PID namespace) by reading the /proc/timer_list file, related to the print_timer function in kernel/time/timer_list.c and the __timer_stats_timer_set_start_info function in kernel/time/timer.c.",
        "target": 1
      },
      {
        "idx": 205717,
        "reasoning": "The code is vulnerable because `efi_call_phys_prolog()` could fail to allocate memory and return NULL without properly cleaning up partially created page tables, potentially leading to a system crash or undefined behavior. While the commit message acknowledges a panic will likely occur two levels up, the lack of complete cleanup introduces a potential instability even before reaching that point, aligning with the CVE's description of mishandled memory allocation failures.",
        "func": "static efi_status_t __init phys_efi_set_virtual_address_map(\n\tunsigned long memory_map_size,\n\tunsigned long descriptor_size,\n\tu32 descriptor_version,\n\tefi_memory_desc_t *virtual_map)\n{\n\tefi_status_t status;\n\tunsigned long flags;\n\tpgd_t *save_pgd;\n\n\tsave_pgd = efi_call_phys_prolog();\n\n\t/* Disable interrupts around EFI calls: */\n\tlocal_irq_save(flags);\n\tstatus = efi_call_phys(efi_phys.set_virtual_address_map,\n\t\t\t       memory_map_size, descriptor_size,\n\t\t\t       descriptor_version, virtual_map);\n\tlocal_irq_restore(flags);\n\n\tefi_call_phys_epilog(save_pgd);\n\n\treturn status;\n}",
        "commit_message": "efi/x86/Add missing error handling to old_memmap 1:1 mapping code\n\nThe old_memmap flow in efi_call_phys_prolog() performs numerous memory\nallocations, and either does not check for failure at all, or it does\nbut fails to propagate it back to the caller, which may end up calling\ninto the firmware with an incomplete 1:1 mapping.\n\nSo let's fix this by returning NULL from efi_call_phys_prolog() on\nmemory allocation failures only, and by handling this condition in the\ncaller. Also, clean up any half baked sets of page tables that we may\nhave created before returning with a NULL return value.\n\nNote that any failure at this level will trigger a panic() two levels\nup, so none of this makes a huge difference, but it is a nice cleanup\nnonetheless.\n\n[ardb: update commit log, add efi_call_phys_epilog() call on error path]\n\nSigned-off-by: Gen Zhang <blackgod016574@gmail.com>\nSigned-off-by: Ard Biesheuvel <ard.biesheuvel@linaro.org>\nCc: Linus Torvalds <torvalds@linux-foundation.org>\nCc: Peter Zijlstra <peterz@infradead.org>\nCc: Rob Bradford <robert.bradford@intel.com>\nCc: Thomas Gleixner <tglx@linutronix.de>\nCc: linux-efi@vger.kernel.org\nLink: http://lkml.kernel.org/r/20190525112559.7917-2-ard.biesheuvel@linaro.org\nSigned-off-by: Ingo Molnar <mingo@kernel.org>",
        "cve_desc": "**DISPUTED** An issue was discovered in the efi subsystem in the Linux kernel through 5.1.5. phys_efi_set_virtual_address_map in arch/x86/platform/efi/efi.c and efi_call_phys_prolog in arch/x86/platform/efi/efi_64.c mishandle memory allocation failures. NOTE: This id is disputed as not being an issue because \u201cAll the code touched by the referenced commit runs only at boot, before any user processes are started. Therefore, there is no possibility for an unprivileged user to control it.\u201d.",
        "target": 1
      }
    ]
  },
  "tk": {
    "0": [],
    "1": []
  },
  "u-boot": {
    "0": [
      {
        "idx": 255876,
        "reasoning": "This code snippet is not directly related to the CVE-2019-14196 fix, which concerns an unbounded memcpy in `nfs_lookup_reply`. The provided code solely handles the construction of NFS authentication credentials and doesn't involve any data copying operations susceptible to length-related vulnerabilities.\n\n\n\n",
        "func": "static uint32_t *rpc_add_credentials(uint32_t *p)\n{\n\t/* Here's the executive summary on authentication requirements of the\n\t * various NFS server implementations:\tLinux accepts both AUTH_NONE\n\t * and AUTH_UNIX authentication (also accepts an empty hostname field\n\t * in the AUTH_UNIX scheme).  *BSD refuses AUTH_NONE, but accepts\n\t * AUTH_UNIX (also accepts an empty hostname field in the AUTH_UNIX\n\t * scheme).  To be safe, use AUTH_UNIX and pass the hostname if we have\n\t * it (if the BOOTP/DHCP reply didn't give one, just use an empty\n\t * hostname).  */\n\n\t/* Provide an AUTH_UNIX credential.  */\n\t*p++ = htonl(1);\t\t/* AUTH_UNIX */\n\t*p++ = htonl(20);\t\t/* auth length */\n\t*p++ = 0;\t\t\t/* stamp */\n\t*p++ = 0;\t\t\t/* hostname string */\n\t*p++ = 0;\t\t\t/* uid */\n\t*p++ = 0;\t\t\t/* gid */\n\t*p++ = 0;\t\t\t/* auxiliary gid list */\n\n\t/* Provide an AUTH_NONE verifier.  */\n\t*p++ = 0;\t\t\t/* AUTH_NONE */\n\t*p++ = 0;\t\t\t/* auth length */\n\n\treturn p;\n}",
        "commit_message": "CVE-2019-14196: nfs: fix unbounded memcpy with a failed length check at nfs_lookup_reply\n\nThis patch adds a check to rpc_pkt.u.reply.data at nfs_lookup_reply.\n\nSigned-off-by: Cheng Liu <liucheng32@huawei.com>\nReported-by: Ferm\u00edn Serna <fermin@semmle.com>\nAcked-by: Joe Hershberger <joe.hershberger@ni.com>",
        "cve_desc": "nfs_lookup_reply in net/nfs.c in Das U-Boot through 2022.04 (and through 2022.07-rc2) has an unbounded memcpy with a failed length check, leading to a buffer overflow. NOTE: this issue exists because of an incorrect fix for CVE-2019-14196.",
        "target": 0
      }
    ],
    "1": []
  },
  "udev": {
    "0": [],
    "1": []
  },
  "unbound": {
    "0": [
      {
        "idx": 296252,
        "reasoning": "This code snippet is not directly vulnerable to the reported \"Out of Bound Write Compressed Names in rdata_copy()\" issue. The `reply_find_rrset` function only *compares* name lengths and content; it doesn't perform any data copying or manipulation of the `dname` field where the vulnerability in `rdata_copy()` resides, thus it's not a point of exposure for that specific flaw.\n\n\n\n",
        "func": "struct ub_packed_rrset_key* reply_find_rrset(struct reply_info* rep,\n\tuint8_t* name, size_t namelen, uint16_t type, uint16_t dclass)\n{\n\tsize_t i;\n\tfor(i=0; i<rep->rrset_count; i++) {\n\t\tstruct ub_packed_rrset_key* s = rep->rrsets[i];\n\t\tif(ntohs(s->rk.type) == type && \n\t\t\tntohs(s->rk.rrset_class) == dclass && \n\t\t\tnamelen == s->rk.dname_len &&\n\t\t\tquery_dname_compare(name, s->rk.dname) == 0) {\n\t\t\treturn s;\n\t\t}\n\t}\n\treturn NULL;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 0
      },
      {
        "idx": 296253,
        "reasoning": "This code snippet is not directly vulnerable to the \"Fix Out of Bound Write Compressed Names in rdata_copy()\" issue described in the commit message. The function `reply_find_rrset_section_an` only *compares* name lengths and content; it doesn't perform any data copying or manipulation of the `dname` field where the vulnerability in `rdata_copy()` resided, thus it's not a point of exposure for that specific bug.\n\n\n\n",
        "func": "struct ub_packed_rrset_key* reply_find_rrset_section_an(struct reply_info* rep,\n\tuint8_t* name, size_t namelen, uint16_t type, uint16_t dclass)\n{\n\tsize_t i;\n\tfor(i=0; i<rep->an_numrrsets; i++) {\n\t\tstruct ub_packed_rrset_key* s = rep->rrsets[i];\n\t\tif(ntohs(s->rk.type) == type && \n\t\t\tntohs(s->rk.rrset_class) == dclass && \n\t\t\tnamelen == s->rk.dname_len &&\n\t\t\tquery_dname_compare(name, s->rk.dname) == 0) {\n\t\t\treturn s;\n\t\t}\n\t}\n\treturn NULL;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 0
      },
      {
        "idx": 296254,
        "reasoning": "This code snippet is not directly vulnerable to the \"Out of Bound Write Compressed Names in rdata_copy()\" issue reported by X41 D-Sec. The provided code focuses on copying `reply_info` structures and allocating/copying RRsets, while the vulnerability specifically relates to how `rdata_copy()` handles compressed names \u2013 a function *not* present in this snippet.\n\n\n\n",
        "func": "reply_info_copy(struct reply_info* rep, struct alloc_cache* alloc, \n\tstruct regional* region)\n{\n\tstruct reply_info* cp;\n\tcp = construct_reply_info_base(region, rep->flags, rep->qdcount, \n\t\trep->ttl, rep->prefetch_ttl, rep->serve_expired_ttl, \n\t\trep->an_numrrsets, rep->ns_numrrsets, rep->ar_numrrsets,\n\t\trep->rrset_count, rep->security);\n\tif(!cp)\n\t\treturn NULL;\n\t/* allocate ub_key structures special or not */\n\tif(!reply_info_alloc_rrset_keys(cp, alloc, region)) {\n\t\tif(!region)\n\t\t\treply_info_parsedelete(cp, alloc);\n\t\treturn NULL;\n\t}\n\tif(!repinfo_copy_rrsets(cp, rep, region)) {\n\t\tif(!region)\n\t\t\treply_info_parsedelete(cp, alloc);\n\t\treturn NULL;\n\t}\n\treturn cp;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 0
      },
      {
        "idx": 296255,
        "reasoning": "This code snippet is not directly related to the reported \"Out of Bound Write Compressed Names in rdata_copy()\" vulnerability. The commit message specifically mentions a fix in `rdata_copy()`, while this code focuses on calling registered callbacks after a reply is prepared \u2013 it doesn\u2019t handle DNS data copying or name compression directly, and therefore isn\u2019t flagged as vulnerable based on the provided context.\n\n\n\n",
        "func": "static int inplace_cb_reply_call_generic(\n    struct inplace_cb* callback_list, enum inplace_cb_list_type type,\n\tstruct query_info* qinfo, struct module_qstate* qstate,\n\tstruct reply_info* rep, int rcode, struct edns_data* edns,\n\tstruct comm_reply* repinfo, struct regional* region)\n{\n\tstruct inplace_cb* cb;\n\tstruct edns_option* opt_list_out = NULL;\n#if defined(EXPORT_ALL_SYMBOLS)\n\t(void)type; /* param not used when fptr_ok disabled */\n#endif\n\tif(qstate)\n\t\topt_list_out = qstate->edns_opts_front_out;\n\tfor(cb=callback_list; cb; cb=cb->next) {\n\t\tfptr_ok(fptr_whitelist_inplace_cb_reply_generic(\n\t\t\t(inplace_cb_reply_func_type*)cb->cb, type));\n\t\t(void)(*(inplace_cb_reply_func_type*)cb->cb)(qinfo, qstate, rep,\n\t\t\trcode, edns, &opt_list_out, repinfo, region, cb->id, cb->cb_arg);\n\t}\n\tedns->opt_list = opt_list_out;\n\treturn 1;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 0
      },
      {
        "idx": 296256,
        "reasoning": "This code snippet is not directly vulnerable to the \"Fix Out of Bound Write Compressed Names in rdata_copy()\" issue reported by X41 D-Sec. The commit message specifically targets `rdata_copy()`, while this code focuses on parsing the DNS packet and preparing data for further processing\u2014it doesn't appear to directly handle resource record data copying where the vulnerability lies.\n\n\n\n",
        "func": "int reply_info_parse(sldns_buffer* pkt, struct alloc_cache* alloc,\n        struct query_info* qinf, struct reply_info** rep, \n\tstruct regional* region, struct edns_data* edns)\n{\n\t/* use scratch pad region-allocator during parsing. */\n\tstruct msg_parse* msg;\n\tint ret;\n\t\n\tqinf->qname = NULL;\n\tqinf->local_alias = NULL;\n\t*rep = NULL;\n\tif(!(msg = regional_alloc(region, sizeof(*msg)))) {\n\t\treturn LDNS_RCODE_SERVFAIL;\n\t}\n\tmemset(msg, 0, sizeof(*msg));\n\t\n\tsldns_buffer_set_position(pkt, 0);\n\tif((ret = parse_packet(pkt, msg, region)) != 0) {\n\t\treturn ret;\n\t}\n\tif((ret = parse_extract_edns(msg, edns, region)) != 0)\n\t\treturn ret;\n\n\t/* parse OK, allocate return structures */\n\t/* this also performs dname decompression */\n\tif(!parse_create_msg(pkt, msg, alloc, qinf, rep, NULL)) {\n\t\tquery_info_clear(qinf);\n\t\treply_info_parsedelete(*rep, alloc);\n\t\t*rep = NULL;\n\t\treturn LDNS_RCODE_SERVFAIL;\n\t}\n\treturn 0;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 199229,
        "reasoning": "The code is vulnerable to an infinite loop because the pointer chasing in the `LABEL_IS_PTR` block doesn't properly validate the target of the pointer, potentially leading it to cycle back to previously visited labels. While the vendor disputes exploitability, a crafted DNS response with a circular reference in the compressed domain name can cause `dname` to repeatedly point to the same locations, triggering the infinite loop despite the length checks.",
        "func": "void dname_pkt_copy(sldns_buffer* pkt, uint8_t* to, uint8_t* dname)\n{\n\t/* copy over the dname and decompress it at the same time */\n\tsize_t len = 0;\n\tuint8_t lablen;\n\tlablen = *dname++;\n\twhile(lablen) {\n\t\tif(LABEL_IS_PTR(lablen)) {\n\t\t\t/* follow pointer */\n\t\t\tdname = sldns_buffer_at(pkt, PTR_OFFSET(lablen, *dname));\n\t\t\tlablen = *dname++;\n\t\t\tcontinue;\n\t\t}\n\t\tif(lablen > LDNS_MAX_LABELLEN) {\n\t\t\t*to = 0; /* end the result prematurely */\n\t\t\treturn;\n\t\t}\n\t\tlog_assert(lablen <= LDNS_MAX_LABELLEN);\n\t\tlen += (size_t)lablen+1;\n\t\tif(len >= LDNS_MAX_DOMAINLEN) {\n\t\t\t*to = 0; /* end the result prematurely */\n\t\t\tlog_err(\"bad dname in dname_pkt_copy\");\n\t\t\treturn;\n\t\t}\n\t\t*to++ = lablen;\n\t\tmemmove(to, dname, lablen);\n\t\tdname += lablen;\n\t\tto += lablen;\n\t\tlablen = *dname++;\n\t}\n\t/* copy last \\0 */\n\t*to = 0;\n}",
        "commit_message": "- Fix Insufficient Handling of Compressed Names in dname_pkt_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an infinite loop via a compressed name in dname_pkt_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 1
      },
      {
        "idx": 199986,
        "reasoning": "The code is vulnerable to an out-of-bounds write due to insufficient validation of `pkt_len` within the decompression loop, specifically when handling compressed domain names (`LDNS_RDF_TYPE_DNAME`). If a maliciously crafted DNS packet contains a compressed name with an incorrect length, `dname_pkt_copy` could write beyond the allocated buffer `to`, leading to a potential crash or arbitrary code execution, despite the vendor's dispute.",
        "func": "rdata_copy(sldns_buffer* pkt, struct packed_rrset_data* data, uint8_t* to, \n\tstruct rr_parse* rr, time_t* rr_ttl, uint16_t type,\n\tsldns_pkt_section section)\n{\n\tuint16_t pkt_len;\n\tconst sldns_rr_descriptor* desc;\n\n\t*rr_ttl = sldns_read_uint32(rr->ttl_data);\n\t/* RFC 2181 Section 8. if msb of ttl is set treat as if zero. */\n\tif(*rr_ttl & 0x80000000U)\n\t\t*rr_ttl = 0;\n\tif(type == LDNS_RR_TYPE_SOA && section == LDNS_SECTION_AUTHORITY) {\n\t\t/* negative response. see if TTL of SOA record larger than the\n\t\t * minimum-ttl in the rdata of the SOA record */\n\t\tif(*rr_ttl > soa_find_minttl(rr))\n\t\t\t*rr_ttl = soa_find_minttl(rr);\n\t\tif(*rr_ttl > MAX_NEG_TTL)\n\t\t\t*rr_ttl = MAX_NEG_TTL;\n\t}\n\tif(*rr_ttl < MIN_TTL)\n\t\t*rr_ttl = MIN_TTL;\n\tif(*rr_ttl > MAX_TTL)\n\t\t*rr_ttl = MAX_TTL;\n\tif(*rr_ttl < data->ttl)\n\t\tdata->ttl = *rr_ttl;\n\n\tif(rr->outside_packet) {\n\t\t/* uncompressed already, only needs copy */\n\t\tmemmove(to, rr->ttl_data+sizeof(uint32_t), rr->size);\n\t\treturn 1;\n\t}\n\n\tsldns_buffer_set_position(pkt, (size_t)\n\t\t(rr->ttl_data - sldns_buffer_begin(pkt) + sizeof(uint32_t)));\n\t/* insert decompressed size into rdata len stored in memory */\n\t/* -2 because rdatalen bytes are not included. */\n\tpkt_len = htons(rr->size - 2);\n\tmemmove(to, &pkt_len, sizeof(uint16_t));\n\tto += 2;\n\t/* read packet rdata len */\n\tpkt_len = sldns_buffer_read_u16(pkt);\n\tif(sldns_buffer_remaining(pkt) < pkt_len)\n\t\treturn 0;\n\tdesc = sldns_rr_descript(type);\n\tif(pkt_len > 0 && desc && desc->_dname_count > 0) {\n\t\tint count = (int)desc->_dname_count;\n\t\tint rdf = 0;\n\t\tsize_t len;\n\t\tsize_t oldpos;\n\t\t/* decompress dnames. */\n\t\twhile(pkt_len > 0 && count) {\n\t\t\tswitch(desc->_wireformat[rdf]) {\n\t\t\tcase LDNS_RDF_TYPE_DNAME:\n\t\t\t\toldpos = sldns_buffer_position(pkt);\n\t\t\t\tdname_pkt_copy(pkt, to, \n\t\t\t\t\tsldns_buffer_current(pkt));\n\t\t\t\tto += pkt_dname_len(pkt);\n\t\t\t\tpkt_len -= sldns_buffer_position(pkt)-oldpos;\n\t\t\t\tcount--;\n\t\t\t\tlen = 0;\n\t\t\t\tbreak;\n\t\t\tcase LDNS_RDF_TYPE_STR:\n\t\t\t\tlen = sldns_buffer_current(pkt)[0] + 1;\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tlen = get_rdf_size(desc->_wireformat[rdf]);\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tif(len) {\n\t\t\t\tmemmove(to, sldns_buffer_current(pkt), len);\n\t\t\t\tto += len;\n\t\t\t\tsldns_buffer_skip(pkt, (ssize_t)len);\n\t\t\t\tlog_assert(len <= pkt_len);\n\t\t\t\tpkt_len -= len;\n\t\t\t}\n\t\t\trdf++;\n\t\t}\n\t}\n\t/* copy remaining rdata */\n\tif(pkt_len >  0)\n\t\tmemmove(to, sldns_buffer_current(pkt), pkt_len);\n\t\n\treturn 1;\n}",
        "commit_message": "- Fix Out of Bound Write Compressed Names in rdata_copy(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write via a compressed name in rdata_copy. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 1
      },
      {
        "idx": 202222,
        "reasoning": "This code is vulnerable to command injection because it constructs a shell command string (`str`) using data directly from DNS responses (qname, TTL, A/AAAA records, IPSECKEY records) without proper sanitization, and then executes this string using `system()`. A malicious actor can craft DNS responses to include arbitrary shell commands within these fields, leading to remote code execution on the Unbound server.",
        "func": "call_hook(struct module_qstate* qstate, struct ipsecmod_qstate* iq,\n\tstruct ipsecmod_env* ATTR_UNUSED(ie))\n{\n\tsize_t slen, tempdata_len, tempstring_len, i;\n\tchar str[65535], *s, *tempstring;\n\tint w;\n\tstruct ub_packed_rrset_key* rrset_key;\n\tstruct packed_rrset_data* rrset_data;\n\tuint8_t *tempdata;\n\n\t/* Check if a shell is available */\n\tif(system(NULL) == 0) {\n\t\tlog_err(\"ipsecmod: no shell available for ipsecmod-hook\");\n\t\treturn 0;\n\t}\n\n\t/* Zero the buffer. */\n\ts = str;\n\tslen = sizeof(str);\n\tmemset(s, 0, slen);\n\n\t/* Copy the hook into the buffer. */\n\tsldns_str_print(&s, &slen, \"%s\", qstate->env->cfg->ipsecmod_hook);\n\t/* Put space into the buffer. */\n\tsldns_str_print(&s, &slen, \" \");\n\t/* Copy the qname into the buffer. */\n\ttempstring = sldns_wire2str_dname(qstate->qinfo.qname,\n\t\tqstate->qinfo.qname_len);\n\tif(!tempstring) {\n\t\tlog_err(\"ipsecmod: out of memory when calling the hook\");\n\t\treturn 0;\n\t}\n\tsldns_str_print(&s, &slen, \"\\\"%s\\\"\", tempstring);\n\tfree(tempstring);\n\t/* Put space into the buffer. */\n\tsldns_str_print(&s, &slen, \" \");\n\t/* Copy the IPSECKEY TTL into the buffer. */\n\trrset_data = (struct packed_rrset_data*)iq->ipseckey_rrset->entry.data;\n\tsldns_str_print(&s, &slen, \"\\\"%ld\\\"\", (long)rrset_data->ttl);\n\t/* Put space into the buffer. */\n\tsldns_str_print(&s, &slen, \" \");\n\t/* Copy the A/AAAA record(s) into the buffer. Start and end this section\n\t * with a double quote. */\n\trrset_key = reply_find_answer_rrset(&qstate->return_msg->qinfo,\n\t\tqstate->return_msg->rep);\n\trrset_data = (struct packed_rrset_data*)rrset_key->entry.data;\n\tsldns_str_print(&s, &slen, \"\\\"\");\n\tfor(i=0; i<rrset_data->count; i++) {\n\t\tif(i > 0) {\n\t\t\t/* Put space into the buffer. */\n\t\t\tsldns_str_print(&s, &slen, \" \");\n\t\t}\n\t\t/* Ignore the first two bytes, they are the rr_data len. */\n\t\tw = sldns_wire2str_rdata_buf(rrset_data->rr_data[i] + 2,\n\t\t\trrset_data->rr_len[i] - 2, s, slen, qstate->qinfo.qtype);\n\t\tif(w < 0) {\n\t\t\t/* Error in printout. */\n\t\t\treturn -1;\n\t\t} else if((size_t)w >= slen) {\n\t\t\ts = NULL; /* We do not want str to point outside of buffer. */\n\t\t\tslen = 0;\n\t\t\treturn -1;\n\t\t} else {\n\t\t\ts += w;\n\t\t\tslen -= w;\n\t\t}\n\t}\n\tsldns_str_print(&s, &slen, \"\\\"\");\n\t/* Put space into the buffer. */\n\tsldns_str_print(&s, &slen, \" \");\n\t/* Copy the IPSECKEY record(s) into the buffer. Start and end this section\n\t * with a double quote. */\n\tsldns_str_print(&s, &slen, \"\\\"\");\n\trrset_data = (struct packed_rrset_data*)iq->ipseckey_rrset->entry.data;\n\tfor(i=0; i<rrset_data->count; i++) {\n\t\tif(i > 0) {\n\t\t\t/* Put space into the buffer. */\n\t\t\tsldns_str_print(&s, &slen, \" \");\n\t\t}\n\t\t/* Ignore the first two bytes, they are the rr_data len. */\n\t\ttempdata = rrset_data->rr_data[i] + 2;\n\t\ttempdata_len = rrset_data->rr_len[i] - 2;\n\t\t/* Save the buffer pointers. */\n\t\ttempstring = s; tempstring_len = slen;\n\t\tw = sldns_wire2str_ipseckey_scan(&tempdata, &tempdata_len, &s, &slen,\n\t\t\tNULL, 0);\n\t\t/* There was an error when parsing the IPSECKEY; reset the buffer\n\t\t * pointers to their previous values. */\n\t\tif(w == -1){\n\t\t\ts = tempstring; slen = tempstring_len;\n\t\t}\n\t}\n\tsldns_str_print(&s, &slen, \"\\\"\");\n\tverbose(VERB_ALGO, \"ipsecmod: hook command: '%s'\", str);\n\t/* ipsecmod-hook should return 0 on success. */\n\tif(system(str) != 0)\n\t\treturn 0;\n\treturn 1;\n}",
        "commit_message": "Fix CVE-2019-18934, shell execution in ipsecmod.",
        "cve_desc": "Unbound 1.6.4 through 1.9.4 contain a vulnerability in the ipsec module that can cause shell code execution after receiving a specially crafted answer. This issue can only be triggered if unbound was compiled with `--enable-ipsecmod` support, and ipsecmod is enabled and used in the configuration.",
        "target": 1
      },
      {
        "idx": 206643,
        "reasoning": "The code is vulnerable to an integer overflow because the calculation `dlen + origin_len - 1` can exceed `LDNS_MAX_DOMAINLEN` and `*len` without being detected, leading to a subsequent out-of-bounds write in the `memmove` function. Despite the vendor's dispute, the overflow allows crafting a domain name that results in writing beyond the allocated buffer size, even if exploitation is difficult in a running Unbound instance.",
        "func": "int sldns_str2wire_dname_buf_origin(const char* str, uint8_t* buf, size_t* len,\n\tuint8_t* origin, size_t origin_len)\n{\n\tsize_t dlen = *len;\n\tint rel = 0;\n\tint s = sldns_str2wire_dname_buf_rel(str, buf, &dlen, &rel);\n\tif(s) return s;\n\n\tif(rel && origin && dlen > 0) {\n\t\tif(dlen + origin_len - 1 > LDNS_MAX_DOMAINLEN)\n\t\t\treturn RET_ERR(LDNS_WIREPARSE_ERR_DOMAINNAME_OVERFLOW,\n\t\t\t\tLDNS_MAX_DOMAINLEN);\n\t\tif(dlen + origin_len - 1 > *len)\n\t\t\treturn RET_ERR(LDNS_WIREPARSE_ERR_BUFFER_TOO_SMALL,\n\t\t\t\t*len);\n\t\tmemmove(buf+dlen-1, origin, origin_len);\n\t\t*len = dlen + origin_len - 1;\n\t} else\n\t\t*len = dlen;\n\treturn LDNS_WIREPARSE_ERR_OK;\n}",
        "commit_message": "- Fix Integer Overflow to Buffer Overflow in\n  sldns_str2wire_dname_buf_origin(), reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an integer overflow in sldns_str2wire_dname_buf_origin, leading to an out-of-bounds write. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 1
      },
      {
        "idx": 210821,
        "reasoning": "This code is vulnerable to an out-of-bounds write because the `limit` check `(size_t)(t-token) >= limit` is performed *after* potentially writing a character to `*t`, allowing a write past the allocated buffer size. Despite the vendor's dispute, the logic allows exceeding the `limit` if a character is processed before the check, leading to a potential buffer overflow.",
        "func": "sldns_bget_token_par(sldns_buffer *b, char *token, const char *delim,\n\tsize_t limit, int* par, const char* skipw)\n{\n\tint c, lc;\n\tint p; /* 0 -> no parentheses seen, >0 nr of ( seen */\n\tint com, quoted;\n\tchar *t;\n\tsize_t i;\n\tconst char *d;\n\tconst char *del;\n\n\t/* standard delimiters */\n\tif (!delim) {\n\t\t/* from isspace(3) */\n\t\tdel = LDNS_PARSE_NORMAL;\n\t} else {\n\t\tdel = delim;\n\t}\n\n\tp = (par?*par:0);\n\ti = 0;\n\tcom = 0;\n\tquoted = 0;\n\tt = token;\n\tlc = 0;\n\tif (del[0] == '\"') {\n\t\tquoted = 1;\n\t}\n\n\twhile ((c = sldns_bgetc(b)) != EOF) {\n\t\tif (c == '\\r') /* carriage return */\n\t\t\tc = ' ';\n\t\tif (c == '(' && lc != '\\\\' && !quoted) {\n\t\t\t/* this only counts for non-comments */\n\t\t\tif (com == 0) {\n\t\t\t\tif(par) (*par)++;\n\t\t\t\tp++;\n\t\t\t}\n\t\t\tlc = c;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (c == ')' && lc != '\\\\' && !quoted) {\n\t\t\t/* this only counts for non-comments */\n\t\t\tif (com == 0) {\n\t\t\t\tif(par) (*par)--;\n\t\t\t\tp--;\n\t\t\t}\n\t\t\tlc = c;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (p < 0) {\n\t\t\t/* more ) then ( */\n\t\t\t*t = '\\0';\n\t\t\treturn 0;\n\t\t}\n\n\t\t/* do something with comments ; */\n\t\tif (c == ';' && quoted == 0) {\n\t\t\tif (lc != '\\\\') {\n\t\t\t\tcom = 1;\n\t\t\t}\n\t\t}\n\t\tif (c == '\"' && com == 0 && lc != '\\\\') {\n\t\t\tquoted = 1 - quoted;\n\t\t}\n\n\t\tif (c == '\\n' && com != 0) {\n\t\t\t/* comments */\n\t\t\tcom = 0;\n\t\t\t*t = ' ';\n\t\t\tlc = c;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (com == 1) {\n\t\t\t*t = ' ';\n\t\t\tlc = c;\n\t\t\tcontinue;\n\t\t}\n\n\t\tif (c == '\\n' && p != 0) {\n\t\t\t/* in parentheses */\n\t\t\t/* do not write ' ' if we want to skip spaces */\n\t\t\tif(!(skipw && (strchr(skipw, c)||strchr(skipw, ' '))))\n\t\t\t\t*t++ = ' ';\n\t\t\tlc = c;\n\t\t\tcontinue;\n\t\t}\n\n\t\t/* check to skip whitespace at start, but also after ( */\n\t\tif(skipw && i==0 && !com && !quoted && lc != '\\\\') {\n\t\t\tif(strchr(skipw, c)) {\n\t\t\t\tlc = c;\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t}\n\n\t\t/* check if we hit the delim */\n\t\tfor (d = del; *d; d++) {\n\t\t\t/* we can only exit if no parens or user tracks them */\n                        if (c == *d && lc != '\\\\' && (p == 0 || par)) {\n\t\t\t\tgoto tokenread;\n                        }\n\t\t}\n\n\t\ti++;\n\t\tif (limit > 0 && (i >= limit || (size_t)(t-token) >= limit)) {\n\t\t\t*t = '\\0';\n\t\t\treturn -1;\n\t\t}\n\t\t*t++ = c;\n\n\t\tif (c == '\\\\' && lc == '\\\\') {\n\t\t\tlc = 0;\n\t\t} else {\n\t\t\tlc = c;\n\t\t}\n\t}\n\t*t = '\\0';\n\tif (i == 0) {\n\t\t/* nothing read */\n\t\treturn -1;\n\t}\n\tif (!par && p != 0) {\n\t\treturn -1;\n\t}\n\treturn (ssize_t)i;\n\ntokenread:\n\tif(*del == '\"')\n\t\t/* do not skip over quotes after the string, they are part\n\t\t * of the next string.  But skip over whitespace (if needed)*/\n\t\tsldns_bskipcs(b, del+1);\n\telse \tsldns_bskipcs(b, del);\n\t*t = '\\0';\n\n\tif (!par && p != 0) {\n\t\treturn -1;\n\t}\n\treturn (ssize_t)i;\n}",
        "commit_message": "- Fix Out of Bounds Write in sldns_bget_token_par(),\n  reported by X41 D-Sec.",
        "cve_desc": "Unbound before 1.9.5 allows an out-of-bounds write in sldns_bget_token_par. NOTE: The vendor disputes that this is a vulnerability. Although the code may be vulnerable, a running Unbound installation cannot be remotely or locally exploited",
        "target": 1
      }
    ]
  },
  "unicorn": {
    "0": [
      {
        "idx": 220937,
        "reasoning": "This code is safe and doesn't present any immediately obvious vulnerabilities. The `encode_sleb128` function correctly encodes a signed LEB128 value, and the commit message addresses an issue in a different function (`split_region`), indicating this code wasn't impacted by that fix.",
        "func": "static uint8_t *encode_sleb128(uint8_t *p, target_long val)\n{\n    int more, byte;\n\n    do {\n        byte = val & 0x7f;\n        val >>= 7;\n        more = !((val == 0 && (byte & 0x40) == 0)\n                 || (val == -1 && (byte & 0x40) != 0));\n        if (more) {\n            byte |= 0x80;\n        }\n        *p++ = byte;\n    } while (more);\n\n    return p;\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 0
      },
      {
        "idx": 220938,
        "reasoning": "This code snippet defines a function that always returns `false`, indicating a region is not locked. There's no discernible vulnerability here as it simply provides a constant return value and doesn't interact with any potentially unsafe operations or data\u2014the commit message regarding `split_region` doesn't relate to this function's logic.\n\n\n\n",
        "func": "static bool tb_exec_is_locked(TCGContext *tcg_ctx)\n{\n    return false;\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 0
      },
      {
        "idx": 220939,
        "reasoning": "This code snippet is not vulnerable because it simply calculates and returns the size of a context structure based on the size of its components. There's no external input, memory manipulation, or potential for buffer overflows or other common vulnerabilities present in this function.",
        "func": "size_t uc_context_size(uc_engine *uc)\n{\n    UC_INIT(uc);\n    // return the total size of struct uc_context\n    return sizeof(uc_context) + uc->cpu_context_size;\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 0
      },
      {
        "idx": 220940,
        "reasoning": "This code is not vulnerable because the fix addresses a simple offset error in calculating the position within a translation block, and doesn't introduce any new logic that could lead to memory safety issues or control flow manipulation. The core functionality of decoding instructions and restoring CPU state remains unchanged, and the bounds checks (`searched_pc < host_pc` and `host_pc > searched_pc`) prevent out-of-bounds access.\n\n\n\n",
        "func": "static int cpu_restore_state_from_tb(CPUState *cpu, TranslationBlock *tb,\n                                     uintptr_t searched_pc, bool reset_icount)\n{\n    target_ulong data[TARGET_INSN_START_WORDS] = { tb->pc };\n    uintptr_t host_pc = (uintptr_t)tb->tc.ptr;\n    CPUArchState *env = cpu->env_ptr;\n    uint8_t *p = (uint8_t *)tb->tc.ptr + tb->tc.size;\n    int i, j, num_insns = tb->icount;\n\n    searched_pc -= GETPC_ADJ;\n\n    if (searched_pc < host_pc) {\n        return -1;\n    }\n\n    /* Reconstruct the stored insn data while looking for the point at\n       which the end of the insn exceeds the searched_pc.  */\n    for (i = 0; i < num_insns; ++i) {\n        for (j = 0; j < TARGET_INSN_START_WORDS; ++j) {\n            data[j] += decode_sleb128(&p);\n        }\n        host_pc += decode_sleb128(&p);\n        if (host_pc > searched_pc) {\n            goto found;\n        }\n    }\n    return -1;\n\n found:\n    if (reset_icount && (tb_cflags(tb) & CF_USE_ICOUNT)) {\n        /* Reset the cycle counter to the start of the block\n           and shift if to the number of actually executed instructions */\n        cpu_neg(cpu)->icount_decr.u16.low += num_insns - i;\n    }\n    restore_state_to_opc(env, tb, data);\n\n    return 0;\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 0
      },
      {
        "idx": 220941,
        "reasoning": "This code snippet appears safe as it primarily focuses on updating data structures related to page table management and memory protection within a user-mode emulation context (\"unicorn\"). The fix addresses an offset issue, which, while important for correctness, doesn't inherently introduce any exploitable vulnerabilities like buffer overflows, format string bugs, or injection flaws based on the provided context.",
        "func": "static inline void tb_page_add(struct uc_struct *uc, PageDesc *p, TranslationBlock *tb,\n                               unsigned int n, tb_page_addr_t page_addr)\n{\n    bool page_already_protected;\n\n    assert_page_locked(p);\n\n    tb->page_addr[n] = page_addr;\n    tb->page_next[n] = p->first_tb;\n    page_already_protected = p->first_tb != (uintptr_t)NULL;\n    p->first_tb = (uintptr_t)tb | n;\n    invalidate_page_bitmap(p);\n\n    /* if some code is already present, then the pages are already\n       protected. So we handle the case where only the first TB is\n       allocated in a physical page */\n    if (!page_already_protected) {\n        tlb_protect_code(uc, page_addr);\n    }\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 195065,
        "reasoning": "This code is vulnerable to a sandbox escape due to a flawed comparison of Guest Virtual Address (GVA) and Guest Physical Address (GPA) when using `uc_mem_map_ptr`, allowing an attacker to map memory outside of the intended sandbox region. Specifically, the vulnerability arises when splitting a memory region, potentially leading to the mapping of host memory into the guest, enabling arbitrary code execution on the host machine.",
        "func": "static bool split_region(struct uc_struct *uc, MemoryRegion *mr,\n                         uint64_t address, size_t size, bool do_delete)\n{\n    uint8_t *backup;\n    uint32_t perms;\n    uint64_t begin, end, chunk_end;\n    size_t l_size, m_size, r_size;\n    RAMBlock *block = NULL;\n    bool prealloc = false;\n\n    chunk_end = address + size;\n\n    // if this region belongs to area [address, address+size],\n    // then there is no work to do.\n    if (address <= mr->addr && chunk_end >= mr->end) {\n        return true;\n    }\n\n    if (size == 0) {\n        // trivial case\n        return true;\n    }\n\n    if (address >= mr->end || chunk_end <= mr->addr) {\n        // impossible case\n        return false;\n    }\n\n    QLIST_FOREACH(block, &uc->ram_list.blocks, next)\n    {\n        if (block->offset <= mr->addr &&\n            block->used_length >= (mr->end - mr->addr)) {\n            break;\n        }\n    }\n\n    if (block == NULL) {\n        return false;\n    }\n\n    // RAM_PREALLOC is not defined outside exec.c and I didn't feel like\n    // moving it\n    prealloc = !!(block->flags & 1);\n\n    if (block->flags & 1) {\n        backup = block->host;\n    } else {\n        backup = copy_region(uc, mr);\n        if (backup == NULL) {\n            return false;\n        }\n    }\n\n    // save the essential information required for the split before mr gets\n    // deleted\n    perms = mr->perms;\n    begin = mr->addr;\n    end = mr->end;\n\n    // unmap this region first, then do split it later\n    if (uc_mem_unmap(uc, mr->addr, (size_t)int128_get64(mr->size)) !=\n        UC_ERR_OK) {\n        goto error;\n    }\n\n    /* overlapping cases\n     *               |------mr------|\n     * case 1    |---size--|\n     * case 2           |--size--|\n     * case 3                  |---size--|\n     */\n\n    // adjust some things\n    if (address < begin) {\n        address = begin;\n    }\n    if (chunk_end > end) {\n        chunk_end = end;\n    }\n\n    // compute sub region sizes\n    l_size = (size_t)(address - begin);\n    r_size = (size_t)(end - chunk_end);\n    m_size = (size_t)(chunk_end - address);\n\n    // If there are error in any of the below operations, things are too far\n    // gone at that point to recover. Could try to remap orignal region, but\n    // these smaller allocation just failed so no guarantee that we can recover\n    // the original allocation at this point\n    if (l_size > 0) {\n        if (!prealloc) {\n            if (uc_mem_map(uc, begin, l_size, perms) != UC_ERR_OK) {\n                goto error;\n            }\n            if (uc_mem_write(uc, begin, backup, l_size) != UC_ERR_OK) {\n                goto error;\n            }\n        } else {\n            if (uc_mem_map_ptr(uc, begin, l_size, perms, backup) != UC_ERR_OK) {\n                goto error;\n            }\n        }\n    }\n\n    if (m_size > 0 && !do_delete) {\n        if (!prealloc) {\n            if (uc_mem_map(uc, address, m_size, perms) != UC_ERR_OK) {\n                goto error;\n            }\n            if (uc_mem_write(uc, address, backup + l_size, m_size) !=\n                UC_ERR_OK) {\n                goto error;\n            }\n        } else {\n            if (uc_mem_map_ptr(uc, address, m_size, perms, backup + l_size) !=\n                UC_ERR_OK) {\n                goto error;\n            }\n        }\n    }\n\n    if (r_size > 0) {\n        if (!prealloc) {\n            if (uc_mem_map(uc, chunk_end, r_size, perms) != UC_ERR_OK) {\n                goto error;\n            }\n            if (uc_mem_write(uc, chunk_end, backup + l_size + m_size, r_size) !=\n                UC_ERR_OK) {\n                goto error;\n            }\n        } else {\n            if (uc_mem_map_ptr(uc, chunk_end, r_size, perms,\n                               backup + l_size + m_size) != UC_ERR_OK) {\n                goto error;\n            }\n        }\n    }\n\n    if (!prealloc) {\n        free(backup);\n    }\n    return true;\n\nerror:\n    if (!prealloc) {\n        free(backup);\n    }\n    return false;\n}",
        "commit_message": "Fix wrong offset used in split_region",
        "cve_desc": "An issue was discovered in split_region in uc.c in Unicorn Engine before 2.0.0-rc5. It allows local attackers to escape the sandbox. An attacker must first obtain the ability to execute crafted code in the target sandbox in order to exploit this vulnerability. The specific flaw exists within the virtual memory manager. The issue results from the faulty comparison of GVA and GPA while calling uc_mem_map_ptr to free part of a claimed memory block. An attacker can leverage this vulnerability to escape the sandbox and execute arbitrary code on the host machine.",
        "target": 1
      }
    ]
  },
  "univention-corporate-server": {
    "0": [],
    "1": []
  },
  "upx": {
    "0": [
      {
        "idx": 245356,
        "reasoning": "The code addresses a potential issue with incorrect handling of `e_shstrtab` (section header string table) offsets, specifically in shared libraries, as highlighted by issue #332. The commit modifies the code to correctly adjust offsets and potentially remove problematic sections like `.interp`, mitigating risks associated with incorrect section table interpretation and preventing potential exploitation scenarios, thus making it a security fix rather than introducing a vulnerability.\n\n\n\n",
        "func": "off_t PackLinuxElf32::pack3(OutputFile *fo, Filter &ft)\n{\n    off_t flen = super::pack3(fo, ft);  // loader follows compressed PT_LOADs\n    // NOTE: PackLinuxElf::pack3  adjusted xct_off for the extra page\n\n    unsigned v_hole = sz_pack2 + lsize;\n    set_te32(&elfout.phdr[0].p_filesz, v_hole);\n    set_te32(&elfout.phdr[0].p_memsz,  v_hole);\n    // Then compressed gaps (including debuginfo.)\n    unsigned total_in = 0, total_out = 0;\n    for (unsigned k = 0; k < e_phnum; ++k) {\n        Extent x;\n        x.size = find_LOAD_gap(phdri, k, e_phnum);\n        if (x.size) {\n            x.offset = get_te32(&phdri[k].p_offset) +\n                       get_te32(&phdri[k].p_filesz);\n            packExtent(x, total_in, total_out, 0, fo);\n        }\n    }\n    // write block end marker (uncompressed size 0)\n    b_info hdr; memset(&hdr, 0, sizeof(hdr));\n    set_le32(&hdr.sz_cpr, UPX_MAGIC_LE32);\n    fo->write(&hdr, sizeof(hdr));\n    flen = fpad4(fo);\n\n    set_te32(&elfout.phdr[0].p_filesz, sz_pack2 + lsize);\n    set_te32(&elfout.phdr[0].p_memsz,  sz_pack2 + lsize);\n    if (0==xct_off) { // not shared library; adjust PT_LOAD\n        // .p_align can be big for segments, but Linux uses 4KiB pages.\n        // This allows [vvar], [vdso], etc to sneak into the gap\n        // between end_text and data, which we wish to prevent\n        // because the expanded program will use that space.\n        // So: pretend 4KiB pages.\n        unsigned pm = (Elf64_Ehdr::EM_PPC64 == e_machine)\n            ? page_mask  // reducing to 4KiB DOES NOT WORK ??\n            : ((~(unsigned)0)<<12);\n        pm = page_mask;  // Revert until consequences can be analyzed\n        v_hole = pm & (~pm + v_hole + get_te32(&elfout.phdr[0].p_vaddr));\n        set_te32(&elfout.phdr[1].p_vaddr, v_hole);\n        set_te32(&elfout.phdr[1].p_align, ((unsigned)0) - pm);\n        elfout.phdr[1].p_paddr = elfout.phdr[1].p_vaddr;\n        elfout.phdr[1].p_offset = 0;\n        set_te32(&elfout.phdr[1].p_memsz, getbrk(phdri, e_phnum) - v_hole);\n        set_te32(&elfout.phdr[1].p_flags, Elf32_Phdr::PF_W|Elf32_Phdr::PF_R);\n    }\n    if (0!=xct_off) {  // shared library\n        unsigned word = (Elf32_Ehdr::EM_ARM==e_machine) + load_va + sz_pack2;  // Thumb mode\n        set_te32(&file_image[user_init_off], word);  // set the hook\n\n        Elf32_Phdr *phdr = (Elf32_Phdr *)lowmem.subref(\n                \"bad e_phoff\", e_phoff, e_phnum * sizeof(Elf32_Phdr));\n        unsigned off = fo->st_size();\n        so_slide = 0;\n        for (unsigned j = 0; j < e_phnum; ++j, ++phdr) {\n            unsigned const len  = get_te32(&phdr->p_filesz);\n            unsigned const ioff = get_te32(&phdr->p_offset);\n            unsigned       align= get_te32(&phdr->p_align);\n            unsigned const type = get_te32(&phdr->p_type);\n            if (Elf32_Phdr::PT_INTERP==type) {\n                // Rotate to highest position, so it can be lopped\n                // by decrementing e_phnum.\n                memcpy((unsigned char *)ibuf, phdr, sizeof(*phdr));  // extract\n                memmove(phdr, 1+phdr, (e_phnum - (1+ j))*sizeof(*phdr));  // overlapping\n                memcpy(&phdr[e_phnum - (1+ j)], (unsigned char *)ibuf, sizeof(*phdr));  // to top\n                --phdr; --e_phnum;\n                set_te16(&ehdri.e_phnum, e_phnum);\n                set_te16(&((Elf32_Ehdr *)(unsigned char *)lowmem)->e_phnum, e_phnum);\n                continue;\n            }\n            if (PT_LOAD32 == type) {\n                if ((xct_off - ioff) < len) { // Change length of compressed PT_LOAD.\n                    set_te32(&phdr->p_filesz, sz_pack2 + lsize - ioff);\n                    set_te32(&phdr->p_memsz,  sz_pack2 + lsize - ioff);\n                }\n                else if (xct_off < ioff) { // Slide subsequent PT_LOAD.\n                    if ((1u<<12) < align) {\n                        align = 1u<<12;\n                        set_te32(&phdr->p_align, align);\n                    }\n                    off += (align-1) & (ioff - off);\n                    fo->seek(  off, SEEK_SET);\n                    fo->write(&file_image[ioff], len);\n                    so_slide = off - ioff;\n                    set_te32(&phdr->p_offset, so_slide + ioff);\n                }\n                continue;  // all done with this PT_LOAD\n            }\n            if (xct_off < ioff)\n                set_te32(&phdr->p_offset, so_slide + ioff);\n        }  // end each Phdr\n\n        if (opt->o_unix.android_shlib) {\n            // Update {DYNAMIC}.sh_offset by so_slide.\n            Elf32_Shdr *shdr = (Elf32_Shdr *)lowmem.subref(\n                    \"bad e_shoff\", xct_off - asl_delta, e_shnum * sizeof(Elf32_Shdr));\n            for (unsigned j = 0; j < e_shnum; ++shdr, ++j) {\n                unsigned sh_type = get_te32(&shdr->sh_type);\n                if (Elf32_Shdr::SHT_DYNAMIC == get_te32(&shdr->sh_type)) {\n                    unsigned offset = get_te32(&shdr->sh_offset);\n                    set_te32(&shdr->sh_offset, so_slide + offset );\n                    fo->seek((j * sizeof(Elf32_Shdr)) + xct_off - asl_delta, SEEK_SET);\n                    fo->rewrite(shdr, sizeof(*shdr));\n                    fo->seek(0, SEEK_END);\n                }\n                if (Elf32_Shdr::SHT_REL == sh_type\n                &&  n_jmp_slot\n                &&  !strcmp(\".rel.plt\", get_te32(&shdr->sh_name) + shstrtab)) {\n                    unsigned f_off = elf_get_offset_from_address(plt_off);\n                    fo->seek(so_slide + f_off, SEEK_SET);  // FIXME: assumes PT_LOAD[1]\n                    fo->rewrite(&file_image[f_off], n_jmp_slot * 4);\n                 }\n            }\n        }\n        else { // !opt->o_unix.android_shlib)\n            ehdri.e_shnum = 0;\n            ehdri.e_shoff = 0;\n            ehdri.e_shstrndx = 0;\n        }\n    }\n    return flen;\n}",
        "commit_message": "Detect bad e_shstrtab better.\n\nhttps://github.com/upx/upx/issues/332\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "An out-of-bounds read access vulnerability was discovered in UPX in PackLinuxElf64::canPack() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service.",
        "target": 0
      },
      {
        "idx": 245357,
        "reasoning": "The code appears safe despite the comment \"// reads beyond, but OK\" because it refers to a controlled `memcpy` within the bounds of the allocated `elfout` buffer, and the subsequent operations manipulate the copied data within that buffer's limits. The assertions and careful size calculations suggest a deliberate attempt to manage memory and avoid overflows, and the identified issue in the linked GitHub issue relates to handling potentially malicious `e_shstrtab` values, which this code doesn't directly address in a vulnerable way.\n\n\n\n",
        "func": "PackOpenBSDElf32x86::generateElfHdr(\n    OutputFile *fo,\n    void const *proto,\n    unsigned const brka\n)\n{\n    cprElfHdr3 *const h3 = (cprElfHdr3 *)(void *)&elfout;\n    memcpy(h3, proto, sizeof(*h3));  // reads beyond, but OK\n    h3->ehdr.e_ident[Elf32_Ehdr::EI_OSABI] = ei_osabi;\n    assert(2==get_te16(&h3->ehdr.e_phnum));\n    set_te16(&h3->ehdr.e_phnum, 3);\n\n    assert(get_te32(&h3->ehdr.e_phoff)     == sizeof(Elf32_Ehdr));\n                         h3->ehdr.e_shoff = 0;\n    assert(get_te16(&h3->ehdr.e_ehsize)    == sizeof(Elf32_Ehdr));\n    assert(get_te16(&h3->ehdr.e_phentsize) == sizeof(Elf32_Phdr));\n           set_te16(&h3->ehdr.e_shentsize, sizeof(Elf32_Shdr));\n                         h3->ehdr.e_shnum = 0;\n                         h3->ehdr.e_shstrndx = 0;\n\n    struct {\n        Elf32_Nhdr nhdr;\n        char name[8];\n        unsigned body;\n    } elfnote;\n\n    unsigned const note_offset = sizeof(*h3) - sizeof(linfo);\n    sz_elf_hdrs = sizeof(elfnote) + note_offset;\n\n    set_te32(&h3->phdr[2].p_type, PT_NOTE32);\n    set_te32(&h3->phdr[2].p_offset, note_offset);\n    set_te32(&h3->phdr[2].p_vaddr, note_offset);\n    set_te32(&h3->phdr[2].p_paddr, note_offset);\n    set_te32(&h3->phdr[2].p_filesz, sizeof(elfnote));\n    set_te32(&h3->phdr[2].p_memsz,  sizeof(elfnote));\n    set_te32(&h3->phdr[2].p_flags, Elf32_Phdr::PF_R);\n    set_te32(&h3->phdr[2].p_align, 4);\n\n    // Q: Same as this->note_body[0 .. this->note_size-1] ?\n    set_te32(&elfnote.nhdr.namesz, 8);\n    set_te32(&elfnote.nhdr.descsz, OPENBSD_DESCSZ);\n    set_te32(&elfnote.nhdr.type,   NHDR_OPENBSD_TAG);\n    memcpy(elfnote.name, \"OpenBSD\", sizeof(elfnote.name));\n    elfnote.body = 0;\n\n    set_te32(&h3->phdr[0].p_filesz, sz_elf_hdrs);\n              h3->phdr[0].p_memsz = h3->phdr[0].p_filesz;\n\n    unsigned const brkb = brka | ((0==(~page_mask & brka)) ? 0x20 : 0);\n    set_te32(&h3->phdr[1].p_type, PT_LOAD32);  // be sure\n    set_te32(&h3->phdr[1].p_offset, ~page_mask & brkb);\n    set_te32(&h3->phdr[1].p_vaddr, brkb);\n    set_te32(&h3->phdr[1].p_paddr, brkb);\n    h3->phdr[1].p_filesz = 0;\n    // Too many kernels have bugs when 0==.p_memsz\n    set_te32(&h3->phdr[1].p_memsz, 1);\n    set_te32(&h3->phdr[1].p_flags, Elf32_Phdr::PF_R | Elf32_Phdr::PF_W);\n\n    if (ph.format==getFormat()) {\n        memset(&h3->linfo, 0, sizeof(h3->linfo));\n        fo->write(h3, sizeof(*h3) - sizeof(h3->linfo));\n        fo->write(&elfnote, sizeof(elfnote));\n        fo->write(&h3->linfo, sizeof(h3->linfo));\n    }\n    else {\n        assert(false);  // unknown ph.format, PackLinuxElf32\n    }\n}",
        "commit_message": "Detect bad e_shstrtab better.\n\nhttps://github.com/upx/upx/issues/332\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "An out-of-bounds read access vulnerability was discovered in UPX in PackLinuxElf64::canPack() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service.",
        "target": 0
      },
      {
        "idx": 245359,
        "reasoning": "This code snippet appears safe as it primarily consists of conditional `addLoader` calls based on filter properties (`ft->id` and `n_mru`). There's no direct evidence of input validation issues, buffer overflows, or other common vulnerabilities within the presented logic; it simply selects different loader sections based on predefined conditions.\n\n\n\n",
        "func": "void PackLinuxElf32x86::addStubEntrySections(Filter const *ft)\n{\n    int const n_mru = ft->n_mru;  // FIXME: belongs to filter? packerf?\n\n// Rely on \"+80CXXXX\" [etc] in getDecompressorSections() packer_c.cpp */\n//    // Here is a quick summary of the format of the output file:\n//    linker->setLoaderAlignOffset(\n//            // Elf32_Ehdr\n//        sizeof(elfout.ehdr) +\n//            // Elf32_Phdr: 1 for exec86, 2 for sh86, 3 for elf86\n//        (get_te16(&elfout.ehdr.e_phentsize) * get_te16(&elfout.ehdr.e_phnum)) +\n//            // checksum UPX! lsize version format\n//        sizeof(l_info) +\n//            // PT_DYNAMIC with DT_NEEDED \"forwarded\" from original file\n//        ((get_te16(&elfout.ehdr.e_phnum)==3)\n//            ? (unsigned) get_te32(&elfout.phdr[2].p_memsz)\n//            : 0) +\n//            // p_progid, p_filesize, p_blocksize\n//        sizeof(p_info) +\n//            // compressed data\n//        b_len + ph.c_len );\n\n            // entry to stub\n    addLoader(\"LEXEC000\", NULL);\n\n    if (ft->id) {\n        { // decompr, unfilter are separate\n            addLoader(\"LXUNF000\", NULL);\n            addLoader(\"LXUNF002\", NULL);\n                if (0x80==(ft->id & 0xF0)) {\n                    if (256==n_mru) {\n                        addLoader(\"MRUBYTE0\", NULL);\n                    }\n                    else if (n_mru) {\n                        addLoader(\"LXMRU005\", NULL);\n                    }\n                    if (n_mru) {\n                        addLoader(\"LXMRU006\", NULL);\n                    }\n                    else {\n                        addLoader(\"LXMRU007\", NULL);\n                    }\n            }\n            else if (0x40==(ft->id & 0xF0)) {\n                addLoader(\"LXUNF008\", NULL);\n            }\n            addLoader(\"LXUNF010\", NULL);\n        }\n        if (n_mru) {\n            addLoader(\"LEXEC009\", NULL);\n        }\n    }\n    addLoader(\"LEXEC010\", NULL);\n    addLoader(getDecompressorSections(), NULL);\n    addLoader(\"LEXEC015\", NULL);\n    if (ft->id) {\n        {  // decompr, unfilter are separate\n            if (0x80!=(ft->id & 0xF0)) {\n                addLoader(\"LXUNF042\", NULL);\n            }\n        }\n        addFilter32(ft->id);\n        { // decompr, unfilter are separate\n            if (0x80==(ft->id & 0xF0)) {\n                if (0==n_mru) {\n                    addLoader(\"LXMRU058\", NULL);\n                }\n            }\n            addLoader(\"LXUNF035\", NULL);\n        }\n    }\n    else {\n        addLoader(\"LEXEC017\", NULL);\n    }\n\n    addLoader(\"IDENTSTR\", NULL);\n    addLoader(\"LEXEC020\", NULL);\n    addLoader(\"FOLDEXEC\", NULL);\n}",
        "commit_message": "Detect bad e_shstrtab better.\n\nhttps://github.com/upx/upx/issues/332\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "An out-of-bounds read access vulnerability was discovered in UPX in PackLinuxElf64::canPack() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service.",
        "target": 0
      },
      {
        "idx": 245360,
        "reasoning": "This code snippet appears safe as it simply adjusts the entry point of the ELF file based on calculated offsets and the location of the `_start` symbol. There's no direct manipulation of user-supplied data or external input that could lead to a buffer overflow, format string vulnerability, or other common exploits within this specific function.",
        "func": "void PackLinuxElf32::updateLoader(OutputFile * /*fo*/)\n{\n    unsigned start = linker->getSymbolOffset(\"_start\");\n    unsigned vbase = get_te32(&elfout.phdr[0].p_vaddr);\n    set_te32(&elfout.ehdr.e_entry, start + sz_pack2 + vbase);\n}",
        "commit_message": "Detect bad e_shstrtab better.\n\nhttps://github.com/upx/upx/issues/332\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "An out-of-bounds read access vulnerability was discovered in UPX in PackLinuxElf64::canPack() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 196795,
        "reasoning": "The code is vulnerable to an out-of-bounds read due to insufficient validation of `sh_offset` and `sh_name` when accessing `shstrtab` within the ELF file's section headers. Specifically, the code checks if `file_size` is less than or equal to `sh_offset`, but doesn't adequately prevent accessing memory beyond the allocated `file_image` buffer when combined with the subsequent dereference of `shstrtab[sh_name]`.",
        "func": "bool PackLinuxElf32::canPack()\n{\n    union {\n        unsigned char buf[sizeof(Elf32_Ehdr) + 14*sizeof(Elf32_Phdr)];\n        //struct { Elf32_Ehdr ehdr; Elf32_Phdr phdr; } e;\n    } u;\n    COMPILE_TIME_ASSERT(sizeof(u.buf) <= 512)\n\n    fi->seek(0, SEEK_SET);\n    fi->readx(u.buf, sizeof(u.buf));\n    fi->seek(0, SEEK_SET);\n    Elf32_Ehdr const *const ehdr = (Elf32_Ehdr *) u.buf;\n\n    // now check the ELF header\n    if (checkEhdr(ehdr) != 0)\n        return false;\n\n    // additional requirements for linux/elf386\n    if (get_te16(&ehdr->e_ehsize) != sizeof(*ehdr)) {\n        throwCantPack(\"invalid Ehdr e_ehsize; try '--force-execve'\");\n        return false;\n    }\n    if (e_phoff != sizeof(*ehdr)) {// Phdrs not contiguous with Ehdr\n        throwCantPack(\"non-contiguous Ehdr/Phdr; try '--force-execve'\");\n        return false;\n    }\n\n    unsigned char osabi0 = u.buf[Elf32_Ehdr::EI_OSABI];\n    // The first PT_LOAD32 must cover the beginning of the file (0==p_offset).\n    Elf32_Phdr const *phdr = phdri;\n    note_size = 0;\n    for (unsigned j=0; j < e_phnum; ++phdr, ++j) {\n        if (j >= 14) {\n            throwCantPack(\"too many ElfXX_Phdr; try '--force-execve'\");\n            return false;\n        }\n        unsigned const p_type = get_te32(&phdr->p_type);\n        unsigned const p_offset = get_te32(&phdr->p_offset);\n        if (1!=exetype && PT_LOAD32 == p_type) { // 1st PT_LOAD\n            exetype = 1;\n            load_va = get_te32(&phdr->p_vaddr);  // class data member\n\n            // Cast on next line is to avoid a compiler bug (incorrect complaint) in\n            // Microsoft (R) C/C++ Optimizing Compiler Version 19.00.24215.1 for x64\n            // error C4319: '~': zero extending 'unsigned int' to 'upx_uint64_t' of greater size\n            unsigned const off = ~page_mask & (unsigned)load_va;\n\n            if (off && off == p_offset) { // specific hint\n                throwCantPack(\"Go-language PT_LOAD: try hemfix.c, or try '--force-execve'\");\n                // Fixing it inside upx fails because packExtent() reads original file.\n                return false;\n            }\n            if (0 != p_offset) { // 1st PT_LOAD must cover Ehdr and Phdr\n                throwCantPack(\"first PT_LOAD.p_offset != 0; try '--force-execve'\");\n                return false;\n            }\n            hatch_off = ~3u & (3+ get_te32(&phdr->p_memsz));\n        }\n        if (PT_NOTE32 == p_type) {\n            unsigned const x = get_te32(&phdr->p_memsz);\n            if ( sizeof(elfout.notes) < x  // beware overflow of note_size\n            ||  (sizeof(elfout.notes) < (note_size += x)) ) {\n                throwCantPack(\"PT_NOTEs too big; try '--force-execve'\");\n                return false;\n            }\n            if (osabi_note && Elf32_Ehdr::ELFOSABI_NONE==osabi0) { // Still seems to be generic.\n                struct {\n                    struct Elf32_Nhdr nhdr;\n                    char name[8];\n                    unsigned body;\n                } note;\n                memset(&note, 0, sizeof(note));\n                fi->seek(p_offset, SEEK_SET);\n                fi->readx(&note, sizeof(note));\n                fi->seek(0, SEEK_SET);\n                if (4==get_te32(&note.nhdr.descsz)\n                &&  1==get_te32(&note.nhdr.type)\n                // &&  0==note.end\n                &&  (1+ strlen(osabi_note))==get_te32(&note.nhdr.namesz)\n                &&  0==strcmp(osabi_note, (char const *)&note.name[0])\n                ) {\n                    osabi0 = ei_osabi;  // Specified by PT_NOTE.\n                }\n            }\n        }\n    }\n    if (Elf32_Ehdr::ELFOSABI_NONE ==osabi0\n    ||  Elf32_Ehdr::ELFOSABI_LINUX==osabi0) { // No EI_OSBAI, no PT_NOTE.\n        unsigned const arm_eabi = 0xff000000u & get_te32(&ehdr->e_flags);\n        if (Elf32_Ehdr::EM_ARM==e_machine\n        &&   (EF_ARM_EABI_VER5==arm_eabi\n          ||  EF_ARM_EABI_VER4==arm_eabi ) ) {\n            // armel-eabi armeb-eabi ARM Linux EABI version 4 is a mess.\n            ei_osabi = osabi0 = Elf32_Ehdr::ELFOSABI_LINUX;\n        }\n        else {\n            osabi0 = opt->o_unix.osabi0;  // Possibly specified by command-line.\n        }\n    }\n    if (osabi0!=ei_osabi) {\n        return false;\n    }\n\n    // We want to compress position-independent executable (gcc -pie)\n    // main programs, but compressing a shared library must be avoided\n    // because the result is no longer usable.  In theory, there is no way\n    // to tell them apart: both are just ET_DYN.  Also in theory,\n    // neither the presence nor the absence of any particular symbol name\n    // can be used to tell them apart; there are counterexamples.\n    // However, we will use the following heuristic suggested by\n    // Peter S. Mazinger <ps.m@gmx.net> September 2005:\n    // If a ET_DYN has __libc_start_main as a global undefined symbol,\n    // then the file is a position-independent executable main program\n    // (that depends on libc.so.6) and is eligible to be compressed.\n    // Otherwise (no __libc_start_main as global undefined): skip it.\n    // Also allow  __uClibc_main  and  __uClibc_start_main .\n\n    if (Elf32_Ehdr::ET_DYN==get_te16(&ehdr->e_type)) {\n        // The DT_SYMTAB has no designated length.  Read the whole file.\n        alloc_file_image(file_image, file_size);\n        fi->seek(0, SEEK_SET);\n        fi->readx(file_image, file_size);\n        memcpy(&ehdri, ehdr, sizeof(Elf32_Ehdr));\n        phdri= (Elf32_Phdr *)((size_t)e_phoff + file_image);  // do not free() !!\n        shdri= (Elf32_Shdr *)((size_t)e_shoff + file_image);  // do not free() !!\n\n        sec_strndx = NULL;\n        shstrtab = NULL;\n        if (e_shnum) {\n            unsigned const e_shstrndx = get_te16(&ehdr->e_shstrndx);\n            if (e_shstrndx) {\n                if (e_shnum <= e_shstrndx) {\n                    char msg[40]; snprintf(msg, sizeof(msg),\n                        \"bad e_shstrndx %#x >= e_shnum %d\", e_shstrndx, e_shnum);\n                    throwCantPack(msg);\n                }\n                sec_strndx = &shdri[e_shstrndx];\n                unsigned const sh_offset = get_te32(&sec_strndx->sh_offset);\n                if ((u32_t)file_size <= sh_offset) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad .e_shstrndx->sh_offset %#x\", sh_offset);\n                    throwCantPack(msg);\n                }\n                shstrtab = (char const *)(sh_offset + file_image);\n            }\n            sec_dynsym = elf_find_section_type(Elf32_Shdr::SHT_DYNSYM);\n            if (sec_dynsym) {\n                unsigned const sh_link = get_te32(&sec_dynsym->sh_link);\n                if (e_shnum <= sh_link) {\n                    char msg[50]; snprintf(msg, sizeof(msg),\n                        \"bad SHT_DYNSYM.sh_link %#x\", sh_link);\n                }\n                sec_dynstr = &shdri[sh_link];\n            }\n\n            if (sec_strndx) {\n                unsigned const sh_name = get_te32(&sec_strndx->sh_name);\n                if (Elf32_Shdr::SHT_STRTAB != get_te32(&sec_strndx->sh_type)\n                || (u32_t)file_size <= sh_name  // FIXME: weak\n                || (sh_name\n                  && 0!=strcmp((char const *)\".shstrtab\", &shstrtab[sh_name]))\n                ) {\n                    throwCantPack(\"bad e_shstrndx\");\n                }\n            }\n        }\n\n        Elf32_Phdr const *pload_x0(0);  // first eXecutable PT_LOAD\n        phdr= phdri;\n        for (int j= e_phnum; --j>=0; ++phdr)\n        if (Elf32_Phdr::PT_DYNAMIC==get_te32(&phdr->p_type)) {\n            dynseg= (Elf32_Dyn const *)(check_pt_dynamic(phdr) + file_image);\n            invert_pt_dynamic(dynseg);\n        }\n        else if (PT_LOAD32==get_te32(&phdr->p_type)) {\n            if (!pload_x0\n            &&  Elf32_Phdr::PF_X & get_te32(&phdr->p_flags)\n            ) {\n                pload_x0 = phdr;\n            }\n            check_pt_load(phdr);\n        }\n        // elf_find_dynamic() returns 0 if 0==dynseg.\n        dynstr=          (char const *)elf_find_dynamic(Elf32_Dyn::DT_STRTAB);\n        dynsym=     (Elf32_Sym const *)elf_find_dynamic(Elf32_Dyn::DT_SYMTAB);\n\n        if (opt->o_unix.force_pie\n        ||      Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1)\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_REL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ))\n        ||  calls_crt1((Elf32_Rel const *)elf_find_dynamic(Elf32_Dyn::DT_JMPREL),\n                                 (int)elf_unsigned_dynamic(Elf32_Dyn::DT_PLTRELSZ))) {\n            is_pie = true;\n            goto proceed;  // calls C library init for main program\n        }\n\n        // Heuristic HACK for shared libraries (compare Darwin (MacOS) Dylib.)\n        // If there is an existing DT_INIT, and if everything that the dynamic\n        // linker ld-linux needs to perform relocations before calling DT_INIT\n        // resides below the first SHT_EXECINSTR Section in one PT_LOAD, then\n        // compress from the first executable Section to the end of that PT_LOAD.\n        // We must not alter anything that ld-linux might touch before it calls\n        // the DT_INIT function.\n        //\n        // Obviously this hack requires that the linker script put pieces\n        // into good positions when building the original shared library,\n        // and also requires ld-linux to behave.\n\n        // Apparently glibc-2.13.90 insists on 0==e_ident[EI_PAD..15],\n        // so compressing shared libraries may be doomed anyway.\n        // 2011-06-01: stub.shlib-init.S works around by installing hatch\n        // at end of .text.\n\n        if (/*jni_onload_sym ||*/ elf_find_dynamic(upx_dt_init)) {\n            if (this->e_machine!=Elf32_Ehdr::EM_386\n            &&  this->e_machine!=Elf32_Ehdr::EM_MIPS\n            &&  this->e_machine!=Elf32_Ehdr::EM_ARM)\n                goto abandon;  // need stub: EM_PPC\n            if (elf_has_dynamic(Elf32_Dyn::DT_TEXTREL)) {\n                throwCantPack(\"DT_TEXTREL found; re-compile with -fPIC\");\n                goto abandon;\n            }\n            if (!(Elf32_Dyn::DF_1_PIE & elf_unsigned_dynamic(Elf32_Dyn::DT_FLAGS_1))) {\n                // not explicitly PIE main program\n                if (Elf32_Ehdr::EM_ARM == e_machine  // Android is common\n                &&  !opt->o_unix.android_shlib  // but not explicit\n                ) {\n                    opt->info_mode++;\n                    info(\"note: use --android-shlib if appropriate\");\n                    opt->info_mode--;\n                }\n            }\n            Elf32_Shdr const *shdr = shdri;\n            xct_va = ~0u;\n            if (e_shnum) {\n                for (int j= e_shnum; --j>=0; ++shdr) {\n                    unsigned const sh_type = get_te32(&shdr->sh_type);\n                    if (Elf32_Shdr::SHF_EXECINSTR & get_te32(&shdr->sh_flags)) {\n                        xct_va = umin(xct_va, get_te32(&shdr->sh_addr));\n                    }\n                    // Hook the first slot of DT_PREINIT_ARRAY or DT_INIT_ARRAY.\n                    if ((     Elf32_Dyn::DT_PREINIT_ARRAY==upx_dt_init\n                        &&  Elf32_Shdr::SHT_PREINIT_ARRAY==sh_type)\n                    ||  (     Elf32_Dyn::DT_INIT_ARRAY   ==upx_dt_init\n                        &&  Elf32_Shdr::SHT_INIT_ARRAY   ==sh_type) ) {\n                        unsigned user_init_ava = get_te32(&shdr->sh_addr);\n                        user_init_off = get_te32(&shdr->sh_offset);\n                        if ((u32_t)file_size <= user_init_off) {\n                            char msg[70]; snprintf(msg, sizeof(msg),\n                                \"bad Elf32_Shdr[%d].sh_offset %#x\",\n                                -1+ e_shnum - j, user_init_off);\n                            throwCantPack(msg);\n                        }\n                        // Check that &file_image[user_init_off] has\n                        // *_RELATIVE relocation, and fetch user_init_va.\n                        // If Elf32_Rela then the actual value is in Rela.r_addend.\n                        int z_rel = dt_table[Elf32_Dyn::DT_REL];\n                        int z_rsz = dt_table[Elf32_Dyn::DT_RELSZ];\n                        if (z_rel && z_rsz) {\n                            unsigned rel_off = get_te32(&dynseg[-1+ z_rel].d_val);\n                            Elf32_Rel *rp = (Elf32_Rel *)&file_image[rel_off];\n                            unsigned relsz   = get_te32(&dynseg[-1+ z_rsz].d_val);\n                            Elf32_Rel *last = (Elf32_Rel *)(relsz + (char *)rp);\n                            for (; rp < last; ++rp) {\n                                unsigned r_va = get_te32(&rp->r_offset);\n                                if (r_va == user_init_ava) { // found the Elf32_Rel\n                                    unsigned r_info = get_te32(&rp->r_info);\n                                    unsigned r_type = ELF32_R_TYPE(r_info);\n                                    if (Elf32_Ehdr::EM_ARM == e_machine\n                                    &&  R_ARM_RELATIVE == r_type) {\n                                        user_init_va = get_te32(&file_image[user_init_off]);\n                                    }\n                                    else {\n                                        char msg[50]; snprintf(msg, sizeof(msg),\n                                            \"bad relocation %#x DT_INIT_ARRAY[0]\",\n                                            r_info);\n                                        throwCantPack(msg);\n                                    }\n                                    break;\n                                }\n                            }\n                        }\n                        unsigned const p_filesz = get_te32(&pload_x0->p_filesz);\n                        if (!((user_init_va - xct_va) < p_filesz)) {\n                            // Not in executable portion of first executable PT_LOAD.\n                            if (0==user_init_va && opt->o_unix.android_shlib) {\n                                // Android allows (0 ==> skip) ?\n                                upx_dt_init = 0;  // force steal of 'extra' DT_NULL\n                                // XXX: FIXME: depends on SHT_DYNAMIC coming later\n                            }\n                            else {\n                                char msg[70]; snprintf(msg, sizeof(msg),\n                                    \"bad init address %#x in Elf32_Shdr[%d].%#x\\n\",\n                                    (unsigned)user_init_va, -1+ e_shnum - j, user_init_off);\n                                throwCantPack(msg);\n                            }\n                        }\n                    }\n                    // By default /usr/bin/ld leaves 4 extra DT_NULL to support pre-linking.\n                    // Take one as a last resort.\n                    if ((Elf32_Dyn::DT_INIT==upx_dt_init || !upx_dt_init)\n                    &&  Elf32_Shdr::SHT_DYNAMIC == sh_type) {\n                        unsigned const n = get_te32(&shdr->sh_size) / sizeof(Elf32_Dyn);\n                        Elf32_Dyn *dynp = (Elf32_Dyn *)&file_image[get_te32(&shdr->sh_offset)];\n                        for (; Elf32_Dyn::DT_NULL != dynp->d_tag; ++dynp) {\n                            if (upx_dt_init == get_te32(&dynp->d_tag)) {\n                                break;  // re-found DT_INIT\n                            }\n                        }\n                        if ((1+ dynp) < (n+ dynseg)) { // not the terminator, so take it\n                            user_init_va = get_te32(&dynp->d_val);  // 0 if (0==upx_dt_init)\n                            set_te32(&dynp->d_tag, upx_dt_init = Elf32_Dyn::DT_INIT);\n                            user_init_off = (char const *)&dynp->d_val - (char const *)&file_image[0];\n                        }\n                    }\n                }\n            }\n            else { // no Sections; use heuristics\n                unsigned const strsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_STRSZ);\n                unsigned const strtab = elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB);\n                unsigned const relsz  = elf_unsigned_dynamic(Elf32_Dyn::DT_RELSZ);\n                unsigned const rel    = elf_unsigned_dynamic(Elf32_Dyn::DT_REL);\n                unsigned const init   = elf_unsigned_dynamic(upx_dt_init);\n                if ((init == (relsz + rel   ) && rel    == (strsz + strtab))\n                ||  (init == (strsz + strtab) && strtab == (relsz + rel   ))\n                ) {\n                    xct_va = init;\n                    user_init_va = init;\n                    user_init_off = elf_get_offset_from_address(init);\n                }\n            }\n            // Rely on 0==elf_unsigned_dynamic(tag) if no such tag.\n            unsigned const va_gash = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n            unsigned const va_hash = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n            unsigned y = 0;\n            if ((y=1, xct_va < va_gash)  ||  (y=2, (0==va_gash && xct_va < va_hash))\n            ||  (y=3, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_STRTAB))\n            ||  (y=4, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_SYMTAB))\n            ||  (y=5, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_REL))\n            ||  (y=6, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_RELA))\n            ||  (y=7, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_JMPREL))\n            ||  (y=8, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERDEF))\n            ||  (y=9, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERSYM))\n            ||  (y=10, xct_va < elf_unsigned_dynamic(Elf32_Dyn::DT_VERNEEDED)) ) {\n                static char const *which[] = {\n                    \"unknown\",\n                    \"DT_GNU_HASH\",\n                    \"DT_HASH\",\n                    \"DT_STRTAB\",\n                    \"DT_SYMTAB\",\n                    \"DT_REL\",\n                    \"DT_RELA\",\n                    \"DT_JMPREL\",\n                    \"DT_VERDEF\",\n                    \"DT_VERSYM\",\n                    \"DT_VERNEEDED\",\n                };\n                char buf[30]; snprintf(buf, sizeof(buf), \"%s above stub\", which[y]);\n                throwCantPack(buf);\n                goto abandon;\n            }\n            if (!opt->o_unix.android_shlib) {\n                phdr = phdri;\n                for (unsigned j= 0; j < e_phnum; ++phdr, ++j) {\n                    unsigned const vaddr = get_te32(&phdr->p_vaddr);\n                    if (PT_NOTE32 == get_te32(&phdr->p_type)\n                    && xct_va < vaddr) {\n                        char buf[40]; snprintf(buf, sizeof(buf),\n                           \"PT_NOTE %#x above stub\", vaddr);\n                        throwCantPack(buf);\n                        goto abandon;\n                    }\n                }\n            }\n            xct_off = elf_get_offset_from_address(xct_va);\n            if (opt->debug.debug_level) {\n                fprintf(stderr, \"shlib canPack: xct_va=%#lx  xct_off=%#lx\\n\",\n                    (long)xct_va, (long)xct_off);\n            }\n            goto proceed;  // But proper packing depends on checking xct_va.\n        }\n        else\n            throwCantPack(\"need DT_INIT; try \\\"void _init(void){}\\\"\");\nabandon:\n        return false;\nproceed: ;\n    }\n    // XXX Theoretically the following test should be first,\n    // but PackUnix::canPack() wants 0!=exetype ?\n    if (!super::canPack())\n        return false;\n    assert(exetype == 1);\n    exetype = 0;\n\n    // set options\n    opt->o_unix.blocksize = blocksize = file_size;\n    return true;\n}",
        "commit_message": "Detect bad e_shstrtab better.\n\nhttps://github.com/upx/upx/issues/332\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "An out-of-bounds read access vulnerability was discovered in UPX in PackLinuxElf64::canPack() function of p_lx_elf.cpp file. An attacker with a crafted input file could trigger this issue that could cause a crash leading to a denial of service.",
        "target": 1
      },
      {
        "idx": 197790,
        "reasoning": "The code is vulnerable due to insufficient bounds checking when accessing dynamic table entries using potentially invalid offsets calculated from `dt_table` and `dynp0`. This can lead to out-of-bounds reads, as demonstrated by the CVE description of a segmentation fault caused by invalid memory access with a crafted input file, ultimately resulting in a denial of service.",
        "func": "PackLinuxElf32::invert_pt_dynamic(Elf32_Dyn const *dynp)\n{\n    if (dt_table[Elf32_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf32_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        unsigned const d_tag = get_te32(&dynp->d_tag);\n        if (d_tag < DT_NUM) {\n            if (Elf32_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te32(&dynp->d_val)\n               != get_te32(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf32_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf32_Dyn::DT_INIT])          upx_dt_init = Elf32_Dyn::DT_INIT;\n    else if (dt_table[Elf32_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf32_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf32_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf32_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf32_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te32(&dynp0[-1+ z_str].d_val);\n        if ((u32_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const x_sym = dt_table[Elf32_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf32_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint32_t const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        upx_uint32_t const v_str = get_te32(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf32_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf32_Sym)\n            : get_te32(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf32_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf32_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf32_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf32_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        unsigned const *const bitmask = (unsigned const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(unsigned) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size / sizeof(unsigned)) <= (n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#x\",\n                n_bucket, n_bitmask, v_sym - v_gsh);\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "commit_message": "Detect 0==DT_SYMTAB in invert_pt_dynamic()\n\nhttps://github.com/upx/upx/issues/333\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "A Segmentaation fault was found in UPX in invert_pt_dynamic() function in p_lx_elf.cpp. An attacker with a crafted input file allows invalid memory address access that could lead to a denial of service.",
        "target": 1
      },
      {
        "idx": 197791,
        "reasoning": "The code is vulnerable due to insufficient validation of dynamic table entries, specifically around `DT_SYMTAB` and `DT_HASH`/`DT_GNU_HASH`, leading to potential out-of-bounds memory access when calculating sizes and offsets. This allows a crafted ELF file to provide malicious values for these entries, causing the code to read from or write to invalid memory locations, ultimately resulting in a denial of service as described in the CVE.",
        "func": "PackLinuxElf64::invert_pt_dynamic(Elf64_Dyn const *dynp)\n{\n    if (dt_table[Elf64_Dyn::DT_NULL]) {\n        return;  // not 1st time; do not change upx_dt_init\n    }\n    Elf64_Dyn const *const dynp0 = dynp;\n    unsigned ndx = 1+ 0;\n    if (dynp)\n    for (; ; ++ndx, ++dynp) {\n        upx_uint64_t const d_tag = get_te64(&dynp->d_tag);\n        if (d_tag>>32) { // outrageous\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad Elf64_Dyn[%d].d_tag %#lx\", -1+ ndx, (long unsigned)d_tag);\n            throwCantPack(msg);\n        }\n        if (d_tag < DT_NUM) {\n            if (Elf64_Dyn::DT_NEEDED != d_tag\n            &&  dt_table[d_tag]\n            &&    get_te64(&dynp->d_val)\n               != get_te64(&dynp0[-1+ dt_table[d_tag]].d_val)) {\n                char msg[50]; snprintf(msg, sizeof(msg),\n                    \"duplicate DT_%#x: [%#x] [%#x]\",\n                    (unsigned)d_tag, -1+ dt_table[d_tag], -1+ ndx);\n                throwCantPack(msg);\n            }\n            dt_table[d_tag] = ndx;\n        }\n        if (Elf64_Dyn::DT_NULL == d_tag) {\n            break;  // check here so that dt_table[DT_NULL] is set\n        }\n    }\n    upx_dt_init = 0;\n         if (dt_table[Elf64_Dyn::DT_INIT])          upx_dt_init = Elf64_Dyn::DT_INIT;\n    else if (dt_table[Elf64_Dyn::DT_PREINIT_ARRAY]) upx_dt_init = Elf64_Dyn::DT_PREINIT_ARRAY;\n    else if (dt_table[Elf64_Dyn::DT_INIT_ARRAY])    upx_dt_init = Elf64_Dyn::DT_INIT_ARRAY;\n\n    unsigned const z_str = dt_table[Elf64_Dyn::DT_STRSZ];\n    if (z_str) {\n        strtab_end = get_te64(&dynp0[-1+ z_str].d_val);\n        if ((u64_t)file_size <= strtab_end) { // FIXME: weak\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_STRSZ %#x\", strtab_end);\n            throwCantPack(msg);\n        }\n    }\n    // DT_SYMTAB has no designated length.\n    // End it when next area else starts; often DT_STRTAB.  (FIXME)\n    unsigned const x_sym = dt_table[Elf64_Dyn::DT_SYMTAB];\n    unsigned const x_str = dt_table[Elf64_Dyn::DT_STRTAB];\n    if (x_sym && x_str) {\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        upx_uint64_t const v_str = get_te64(&dynp0[-1+ x_str].d_val);\n        unsigned const  z_sym = dt_table[Elf64_Dyn::DT_SYMENT];\n        unsigned const sz_sym = !z_sym ? sizeof(Elf64_Sym)\n            : get_te64(&dynp0[-1+ z_sym].d_val);\n        if (sz_sym < sizeof(Elf64_Sym)) {\n            char msg[50]; snprintf(msg, sizeof(msg),\n                \"bad DT_SYMENT %x\", sz_sym);\n            throwCantPack(msg);\n        }\n        if (v_sym < v_str) {\n            symnum_end = (v_str - v_sym) / sz_sym;\n        }\n        if (symnum_end < 1) {\n            throwCantPack(\"bad DT_SYMTAB\");\n        }\n    }\n    // DT_HASH often ends at DT_SYMTAB\n    unsigned const v_hsh = elf_unsigned_dynamic(Elf64_Dyn::DT_HASH);\n    if (v_hsh && file_image) {\n        hashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_HASH);\n        if (!hashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_HASH %#x\", v_hsh);\n            throwCantPack(msg);\n        }\n        unsigned const nbucket = get_te32(&hashtab[0]);\n        unsigned const *const buckets = &hashtab[2];\n        unsigned const *const chains = &buckets[nbucket]; (void)chains;\n\n        unsigned const v_sym = get_te32(&dynp0[-1+ x_sym].d_val);\n        if (!nbucket\n        || (nbucket>>31) || (file_size/sizeof(unsigned)) <= (2*nbucket)  // FIXME: weak\n        || ((v_hsh < v_sym) && (v_sym - v_hsh) < (sizeof(unsigned)*2  // headers\n                + sizeof(*buckets)*nbucket  // buckets\n                + sizeof(*chains) *nbucket  // chains\n           ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_HASH nbucket=%#x  len=%#x\",\n                nbucket, (v_sym - v_hsh));\n            throwCantPack(msg);\n        }\n    }\n    // DT_GNU_HASH often ends at DT_SYMTAB;  FIXME: not for Android?\n    unsigned const v_gsh = elf_unsigned_dynamic(Elf64_Dyn::DT_GNU_HASH);\n    if (v_gsh && file_image) {\n        gashtab = (unsigned const *)elf_find_dynamic(Elf64_Dyn::DT_GNU_HASH);\n        if (!gashtab) {\n            char msg[40]; snprintf(msg, sizeof(msg),\n               \"bad DT_GNU_HASH %#x\", v_gsh);\n            throwCantPack(msg);\n        }\n        unsigned const n_bucket = get_te32(&gashtab[0]);\n        unsigned const n_bitmask = get_te32(&gashtab[2]);\n        unsigned const gnu_shift = get_te32(&gashtab[3]);\n        upx_uint64_t const *const bitmask = (upx_uint64_t const *)(void const *)&gashtab[4];\n        unsigned     const *const buckets = (unsigned const *)&bitmask[n_bitmask];\n        unsigned     const *const hasharr = &buckets[n_bucket]; (void)hasharr;\n      //unsigned     const *const gashend = &hasharr[n_bucket];  // minimum\n\n        upx_uint64_t const v_sym = get_te64(&dynp0[-1+ x_sym].d_val);\n        if (!n_bucket || !n_bitmask\n        || (-1+ n_bitmask) & n_bitmask  // not a power of 2\n        || 8*sizeof(upx_uint64_t) <= gnu_shift  // shifted result always == 0\n        || (n_bucket>>30)  // fie on fuzzers\n        || (n_bitmask>>30)\n        || (file_size/sizeof(unsigned)) <= ((sizeof(*bitmask)/sizeof(unsigned))*n_bitmask + 2*n_bucket)  // FIXME: weak\n        // FIXME: next test does work for Android?\n        || ((v_gsh < v_sym) && (v_sym - v_gsh) < (sizeof(unsigned)*4  // headers\n                + sizeof(*bitmask)*n_bitmask  // bitmask\n                + sizeof(*buckets)*n_bucket  // buckets\n                + sizeof(*hasharr)*n_bucket  // hasharr\n            ))\n        ) {\n            char msg[90]; snprintf(msg, sizeof(msg),\n                \"bad DT_GNU_HASH n_bucket=%#x  n_bitmask=%#x  len=%#lx\",\n                n_bucket, n_bitmask, (long unsigned)(v_sym - v_gsh));\n            throwCantPack(msg);\n        }\n    }\n    unsigned const e_shstrndx = get_te16(&ehdri.e_shstrndx);\n    if (e_shnum <= e_shstrndx\n    &&  !(0==e_shnum && 0==e_shstrndx) ) {\n        char msg[40]; snprintf(msg, sizeof(msg),\n            \"bad .e_shstrndx %d >= .e_shnum %d\", e_shstrndx, e_shnum);\n        throwCantPack(msg);\n    }\n}",
        "commit_message": "Detect 0==DT_SYMTAB in invert_pt_dynamic()\n\nhttps://github.com/upx/upx/issues/333\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "A Segmentaation fault was found in UPX in invert_pt_dynamic() function in p_lx_elf.cpp. An attacker with a crafted input file allows invalid memory address access that could lead to a denial of service.",
        "target": 1
      },
      {
        "idx": 199772,
        "reasoning": "The code is vulnerable due to insufficient validation of ELF header data, specifically `e_entry`, `e_machine`, and other fields within the ELF header structures, allowing a crafted input to trigger out-of-bounds reads. This vulnerability, as described in the CVE, manifests as an invalid pointer read within the `PackLinuxElf64::unpack()` function when processing maliciously formed ELF files.",
        "func": "void PackLinuxElf64::unpack(OutputFile *fo)\n{\n    unsigned const c_phnum = get_te16(&ehdri.e_phnum);\n    upx_uint64_t old_data_off = 0;\n    upx_uint64_t old_data_len = 0;\n    upx_uint64_t old_dtinit = 0;\n\n    unsigned szb_info = sizeof(b_info);\n    {\n        upx_uint64_t const e_entry = get_te64(&ehdri.e_entry);\n        if (e_entry < 0x401180\n        &&  get_te16(&ehdri.e_machine)==Elf64_Ehdr::EM_386) { /* old style, 8-byte b_info */\n            szb_info = 2*sizeof(unsigned);\n        }\n    }\n\n    fi->seek(overlay_offset - sizeof(l_info), SEEK_SET);\n    fi->readx(&linfo, sizeof(linfo));\n    lsize = get_te16(&linfo.l_lsize);\n    p_info hbuf;  fi->readx(&hbuf, sizeof(hbuf));\n    unsigned orig_file_size = get_te32(&hbuf.p_filesize);\n    blocksize = get_te32(&hbuf.p_blocksize);\n    if (file_size > (off_t)orig_file_size || blocksize > orig_file_size\n        || !mem_size_valid(1, blocksize, OVERHEAD))\n        throwCantUnpack(\"p_info corrupted\");\n\n#define MAX_ELF_HDR 1024\n    union {\n        unsigned char buf[MAX_ELF_HDR];\n        //struct { Elf64_Ehdr ehdr; Elf64_Phdr phdr; } e;\n    } u;\n    Elf64_Ehdr *const ehdr = (Elf64_Ehdr *) u.buf;\n    Elf64_Phdr const *phdr = 0;\n\n    ibuf.alloc(blocksize + OVERHEAD);\n    b_info bhdr; memset(&bhdr, 0, sizeof(bhdr));\n    fi->readx(&bhdr, szb_info);\n    ph.u_len = get_te32(&bhdr.sz_unc);\n    ph.c_len = get_te32(&bhdr.sz_cpr);\n    if (ph.c_len > (unsigned)file_size || ph.c_len == 0 || ph.u_len == 0\n    ||  ph.u_len > sizeof(u))\n        throwCantUnpack(\"b_info corrupted\");\n    ph.filter_cto = bhdr.b_cto8;\n\n    // Uncompress Ehdr and Phdrs.\n    if (ibuf.getSize() < ph.c_len  ||  sizeof(u) < ph.u_len)\n        throwCompressedDataViolation();\n    fi->readx(ibuf, ph.c_len);\n    decompress(ibuf, (upx_byte *)ehdr, false);\n    if (ehdr->e_type   !=ehdri.e_type\n    ||  ehdr->e_machine!=ehdri.e_machine\n    ||  ehdr->e_version!=ehdri.e_version\n        // less strict for EM_PPC64 to workaround earlier bug\n    ||  !( ehdr->e_flags==ehdri.e_flags\n        || Elf64_Ehdr::EM_PPC64 == get_te16(&ehdri.e_machine))\n    ||  ehdr->e_ehsize !=ehdri.e_ehsize\n        // check EI_MAG[0-3], EI_CLASS, EI_DATA, EI_VERSION\n    ||  memcmp(ehdr->e_ident, ehdri.e_ident, Elf64_Ehdr::EI_OSABI)) {\n        throwCantUnpack(\"ElfXX_Ehdr corrupted\");\n    }\n    fi->seek(- (off_t) (szb_info + ph.c_len), SEEK_CUR);\n\n    unsigned const u_phnum = get_te16(&ehdr->e_phnum);\n    unsigned total_in = 0;\n    unsigned total_out = 0;\n    unsigned c_adler = upx_adler32(NULL, 0);\n    unsigned u_adler = upx_adler32(NULL, 0);\n\n    // Packed ET_EXE has no PT_DYNAMIC.\n    // Packed ET_DYN has original PT_DYNAMIC for info needed by rtld.\n    bool const is_shlib = !!elf_find_ptype(Elf64_Phdr::PT_DYNAMIC, phdri, c_phnum);\n    if (is_shlib) {\n        // Unpack and output the Ehdr and Phdrs for real.\n        // This depends on position within input file fi.\n        unpackExtent(ph.u_len, fo, total_in, total_out,\n            c_adler, u_adler, false, szb_info);\n\n        // The first PT_LOAD.  Part is not compressed (for benefit of rtld.)\n        // Read enough to position the input for next unpackExtent.\n        fi->seek(0, SEEK_SET);\n        fi->readx(ibuf, overlay_offset + sizeof(hbuf) + szb_info + ph.c_len);\n        overlay_offset -= sizeof(linfo);\n        if (fo) {\n            fo->write(ibuf + ph.u_len, overlay_offset - ph.u_len);\n        }\n        // Search the Phdrs of compressed\n        int n_ptload = 0;\n        phdr = (Elf64_Phdr *) (void *) (1+ (Elf64_Ehdr *)(unsigned char *)ibuf);\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (PT_LOAD64==get_te32(&phdr->p_type) && 0!=n_ptload++) {\n                old_data_off = get_te64(&phdr->p_offset);\n                old_data_len = get_te64(&phdr->p_filesz);\n                break;\n            }\n        }\n\n        total_in  = overlay_offset;\n        total_out = overlay_offset;\n        ph.u_len = 0;\n\n        // Decompress and unfilter the tail of first PT_LOAD.\n        phdr = (Elf64_Phdr *) (void *) (1+ ehdr);\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (PT_LOAD64==get_te32(&phdr->p_type)) {\n                ph.u_len = get_te64(&phdr->p_filesz) - overlay_offset;\n                break;\n            }\n        }\n        unpackExtent(ph.u_len, fo, total_in, total_out,\n            c_adler, u_adler, false, szb_info);\n    }\n    else {  // main executable\n        // Decompress each PT_LOAD.\n        bool first_PF_X = true;\n        phdr = (Elf64_Phdr *) (void *) (1+ ehdr);  // uncompressed\n        for (unsigned j=0; j < u_phnum; ++phdr, ++j) {\n            if (PT_LOAD64==get_te32(&phdr->p_type)) {\n                unsigned const filesz = get_te64(&phdr->p_filesz);\n                unsigned const offset = get_te64(&phdr->p_offset);\n                if (fo)\n                    fo->seek(offset, SEEK_SET);\n                if (Elf64_Phdr::PF_X & get_te32(&phdr->p_flags)) {\n                    unpackExtent(filesz, fo, total_in, total_out,\n                        c_adler, u_adler, first_PF_X, szb_info);\n                    first_PF_X = false;\n                }\n                else {\n                    unpackExtent(filesz, fo, total_in, total_out,\n                        c_adler, u_adler, false, szb_info);\n                }\n            }\n        }\n    }\n    phdr = phdri;\n    load_va = 0;\n    for (unsigned j=0; j < c_phnum; ++j) {\n        if (PT_LOAD64==get_te32(&phdr->p_type)) {\n            load_va = get_te64(&phdr->p_vaddr);\n            break;\n        }\n    }\n    if (is_shlib\n    ||  ((unsigned)(get_te64(&ehdri.e_entry) - load_va) + up4(lsize) +\n                ph.getPackHeaderSize() + sizeof(overlay_offset))\n            < up4(file_size)) {\n        // Loader is not at end; skip past it.\n        funpad4(fi);  // MATCH01\n        unsigned d_info[6]; fi->readx(d_info, sizeof(d_info));\n        if (0==old_dtinit) {\n            old_dtinit = d_info[2 + (0==d_info[0])];\n        }\n        fi->seek(lsize - sizeof(d_info), SEEK_CUR);\n    }\n\n    // The gaps between PT_LOAD and after last PT_LOAD\n    phdr = (Elf64_Phdr *) (u.buf + sizeof(*ehdr));\n    upx_uint64_t hi_offset(0);\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        if (PT_LOAD64==phdr[j].p_type\n        &&  hi_offset < phdr[j].p_offset)\n            hi_offset = phdr[j].p_offset;\n    }\n    for (unsigned j = 0; j < u_phnum; ++j) {\n        unsigned const size = find_LOAD_gap(phdr, j, u_phnum);\n        if (size) {\n            unsigned const where = get_te64(&phdr[j].p_offset) +\n                                   get_te64(&phdr[j].p_filesz);\n            if (fo)\n                fo->seek(where, SEEK_SET);\n            unpackExtent(size, fo, total_in, total_out,\n                c_adler, u_adler, false, szb_info,\n                (phdr[j].p_offset != hi_offset));\n        }\n    }\n\n    // check for end-of-file\n    fi->readx(&bhdr, szb_info);\n    unsigned const sz_unc = ph.u_len = get_te32(&bhdr.sz_unc);\n\n    if (sz_unc == 0) { // uncompressed size 0 -> EOF\n        // note: magic is always stored le32\n        unsigned const sz_cpr = get_le32(&bhdr.sz_cpr);\n        if (sz_cpr != UPX_MAGIC_LE32)  // sz_cpr must be h->magic\n            throwCompressedDataViolation();\n    }\n    else { // extra bytes after end?\n        throwCompressedDataViolation();\n    }\n\n    if (is_shlib) {  // the non-first PT_LOAD\n        int n_ptload = 0;\n        unsigned load_off = 0;\n        phdr = (Elf64_Phdr *) (u.buf + sizeof(*ehdr));\n        for (unsigned j= 0; j < u_phnum; ++j, ++phdr) {\n            if (PT_LOAD64==get_te32(&phdr->p_type) && 0!=n_ptload++) {\n                load_off = get_te64(&phdr->p_offset);\n                fi->seek(old_data_off, SEEK_SET);\n                fi->readx(ibuf, old_data_len);\n                total_in  += old_data_len;\n                total_out += old_data_len;\n                if (fo) {\n                    fo->seek(get_te64(&phdr->p_offset), SEEK_SET);\n                    fo->rewrite(ibuf, old_data_len);\n                }\n            }\n        }\n        // Restore DT_INIT.d_val\n        phdr = (Elf64_Phdr *) (u.buf + sizeof(*ehdr));\n        for (unsigned j= 0; j < u_phnum; ++j, ++phdr) {\n            if (phdr->PT_DYNAMIC==get_te32(&phdr->p_type)) {\n                unsigned const dyn_off = get_te64(&phdr->p_offset);\n                unsigned const dyn_len = get_te64(&phdr->p_filesz);\n                Elf64_Dyn *dyn = (Elf64_Dyn *)((unsigned char *)ibuf +\n                    (dyn_off - load_off));\n                for (unsigned j2= 0; j2 < dyn_len; ++dyn, j2 += sizeof(*dyn)) {\n                    if (dyn->DT_INIT==get_te32(&dyn->d_tag)) {\n                        if (fo) {\n                            fo->seek(sizeof(upx_uint64_t) + j2 + dyn_off, SEEK_SET);\n                            fo->rewrite(&old_dtinit, sizeof(old_dtinit));\n                            fo->seek(0, SEEK_END);\n                        }\n                        break;\n                    }\n                }\n            }\n        }\n    }\n\n    // update header with totals\n    ph.c_len = total_in;\n    ph.u_len = total_out;\n\n    // all bytes must be written\n    if (total_out != orig_file_size)\n        throwEOFException();\n\n    // finally test the checksums\n    if (ph.c_adler != c_adler || ph.u_adler != u_adler)\n        throwChecksumError();\n#undef MAX_ELF_HDR\n}",
        "commit_message": "Protect against bad crafted input.\n\nhttps://github.com/upx/upx/issues/128\n\tmodified:   p_lx_elf.cpp",
        "cve_desc": "p_lx_elf.cpp in UPX 3.94 mishandles ELF headers, which allows remote attackers to cause a denial of service (application crash) or possibly have unspecified other impact via a crafted binary file, as demonstrated by an Invalid Pointer Read in PackLinuxElf64::unpack().",
        "target": 1
      }
    ]
  },
  "util-linux": {
    "0": [
      {
        "idx": 79111,
        "reasoning": "This code snippet from `util-linux` is not flagged as vulnerable because it focuses on safely adding supplemental groups to a user's context. The function includes checks to prevent exceeding the maximum allowed number of groups (`NGROUPS_MAX`) and verifies the existence of the specified group, mitigating potential buffer overflows or access issues.\n\n\n\n",
        "func": "add_supp_group(const char *name, gid_t **groups, size_t *ngroups)\n{\n  struct group *gr;\n\n  if (*ngroups >= NGROUPS_MAX)\n    errx(EXIT_FAILURE,\n\tP_(\"specifying more than %d supplemental group is not possible\",\n\t   \"specifying more than %d supplemental groups is not possible\",\n\t     NGROUPS_MAX - 1), NGROUPS_MAX - 1);\n\n  gr = getgrnam(name);\n  if (!gr)\n    errx(EXIT_FAILURE, _(\"group %s does not exist\"), name);\n\n  *groups = xrealloc(*groups, sizeof(gid_t) * (*ngroups + 1));\n  (*groups)[*ngroups] = gr->gr_gid;\n  (*ngroups)++;\n\n  return gr->gr_gid;\n}\n",
        "commit_message": "su: properly clear child PID\n\nReported-by: Tobias St\u00f6ckmann <tobias@stoeckmann.org>\nSigned-off-by: Karel Zak <kzak@redhat.com>",
        "cve_desc": "A race condition was found in util-linux before 2.32.1 in the way su handled the management of child processes. A local authenticated attacker could use this flaw to kill other processes with root privileges under specific conditions.",
        "target": 0
      }
    ],
    "1": []
  },
  "varnish-modules": {
    "0": [],
    "1": []
  },
  "veyon": {
    "0": [],
    "1": []
  },
  "vim": {
    "0": [],
    "1": []
  },
  "w3m": {
    "0": [],
    "1": []
  },
  "wget": {
    "0": [],
    "1": [
      {
        "idx": 215913,
        "reasoning": "This code is vulnerable to an absolute path traversal due to its handling of potentially malicious `.listing` files from FTP servers. Specifically, the patch aims to prevent duplicate filenames, but fails to account for symlink entries within the listing that, when combined with a regular file entry with the same name, can lead to Wget writing files to arbitrary locations on the system, potentially allowing for arbitrary code execution.",
        "func": "ftp_retrieve_glob (struct url *u, ccon *con, int action)\n{\n  struct fileinfo *f, *start;\n  uerr_t res;\n\n  con->cmd |= LEAVE_PENDING;\n\n  res = ftp_get_listing (u, con, &start);\n  if (res != RETROK)\n    return res;\n  /* First: weed out that do not conform the global rules given in\n     opt.accepts and opt.rejects.  */\n  if (opt.accepts || opt.rejects)\n    {\n      f = start;\n      while (f)\n        {\n          if (f->type != FT_DIRECTORY && !acceptable (f->name))\n            {\n              logprintf (LOG_VERBOSE, _(\"Rejecting %s.\\n\"),\n                         quote (f->name));\n              f = delelement (f, &start);\n            }\n          else\n            f = f->next;\n        }\n    }\n  /* Remove all files with possible harmful names */\n  f = start;\n  while (f)\n    {\n      if (has_insecure_name_p (f->name))\n        {\n          logprintf (LOG_VERBOSE, _(\"Rejecting %s.\\n\"),\n                     quote (f->name));\n          f = delelement (f, &start);\n        }\n      else\n        f = f->next;\n    }\n  /* Now weed out the files that do not match our globbing pattern.\n     If we are dealing with a globbing pattern, that is.  */\n  if (*u->file)\n    {\n      if (action == GLOB_GLOBALL)\n        {\n          int (*matcher) (const char *, const char *, int)\n            = opt.ignore_case ? fnmatch_nocase : fnmatch;\n          int matchres = 0;\n\n          f = start;\n          while (f)\n            {\n              matchres = matcher (u->file, f->name, 0);\n              if (matchres == -1)\n                {\n                  logprintf (LOG_NOTQUIET, _(\"Error matching %s against %s: %s\\n\"),\n                             u->file, quotearg_style (escape_quoting_style, f->name),\n                             strerror (errno));\n                  break;\n                }\n              if (matchres == FNM_NOMATCH)\n                f = delelement (f, &start); /* delete the element from the list */\n              else\n                f = f->next;        /* leave the element in the list */\n            }\n          if (matchres == -1)\n            {\n              freefileinfo (start);\n              return RETRBADPATTERN;\n            }\n        }\n      else if (action == GLOB_GETONE)\n        {\n#ifdef __VMS\n          /* 2009-09-09 SMS.\n           * Odd-ball compiler (\"HP C V7.3-009 on OpenVMS Alpha V7.3-2\")\n           * bug causes spurious %CC-E-BADCONDIT complaint with this\n           * \"?:\" statement.  (Different linkage attributes for strcmp()\n           * and strcasecmp().)  Converting to \"if\" changes the\n           * complaint to %CC-W-PTRMISMATCH on \"cmp = strcmp;\".  Adding\n           * the senseless type cast clears the complaint, and looks\n           * harmless.\n           */\n          int (*cmp) (const char *, const char *)\n            = opt.ignore_case ? strcasecmp : (int (*)())strcmp;\n#else /* def __VMS */\n          int (*cmp) (const char *, const char *)\n            = opt.ignore_case ? strcasecmp : strcmp;\n#endif /* def __VMS [else] */\n          f = start;\n          while (f)\n            {\n              if (0 != cmp(u->file, f->name))\n                f = delelement (f, &start);\n              else\n                f = f->next;\n            }\n        }\n    }\n  if (start)\n    {\n      /* Just get everything.  */\n      res = ftp_retrieve_list (u, start, con);\n    }\n  else\n    {\n      if (action == GLOB_GLOBALL)\n        {\n          /* No luck.  */\n          /* #### This message SUCKS.  We should see what was the\n             reason that nothing was retrieved.  */\n          logprintf (LOG_VERBOSE, _(\"No matches on pattern %s.\\n\"),\n                     quote (u->file));\n        }\n      else if (action == GLOB_GETONE) /* GLOB_GETONE or GLOB_GETALL */\n        {\n          /* Let's try retrieving it anyway.  */\n          con->st |= ON_YOUR_OWN;\n          res = ftp_loop_internal (u, NULL, con, NULL);\n          return res;\n        }\n\n      /* If action == GLOB_GETALL, and the file list is empty, there's\n         no point in trying to download anything or in complaining about\n         it.  (An empty directory should not cause complaints.)\n      */\n    }\n  freefileinfo (start);\n  if (opt.quota && total_downloaded_bytes > opt.quota)\n    return QUOTEXC;\n  else\n    return res;\n}",
        "commit_message": "Add checks for valid listing file in FTP\n\nWhen Wget retrieves a file through FTP, it first downloads a .listing\nfile and parses it for information about the files and other metadata.\nSome servers may serve invalid .listing files. This patch checks for one\nsuch known inconsistency wherein multiple lines in a listing file have\nthe same name. Such a filesystem is clearly not possible and hence we\neliminate duplicate entries here.\n\nSigned-off-by: Darshit Shah <darnir@gmail.com>",
        "cve_desc": "Absolute path traversal vulnerability in GNU Wget before 1.16, when recursion is enabled, allows remote FTP servers to write to arbitrary files, and consequently execute arbitrary code, via a LIST response that references the same filename within two entries, one of which indicates that the filename is for a symlink.",
        "target": 1
      },
      {
        "idx": 215980,
        "reasoning": "The `url_parse` function is vulnerable to CRLF injection because it doesn't properly sanitize the `host` component of a URL, allowing attackers to inject carriage return and line feed characters (`\\r\\n`). These injected characters can then be interpreted as HTTP header separators, enabling attackers to control subsequent HTTP requests made by Wget.",
        "func": "url_parse (const char *url, int *error, struct iri *iri, bool percent_encode)\n{\n  struct url *u;\n  const char *p;\n  bool path_modified, host_modified;\n\n  enum url_scheme scheme;\n  const char *seps;\n\n  const char *uname_b,     *uname_e;\n  const char *host_b,      *host_e;\n  const char *path_b,      *path_e;\n  const char *params_b,    *params_e;\n  const char *query_b,     *query_e;\n  const char *fragment_b,  *fragment_e;\n\n  int port;\n  char *user = NULL, *passwd = NULL;\n\n  const char *url_encoded = NULL;\n\n  int error_code;\n\n  scheme = url_scheme (url);\n  if (scheme == SCHEME_INVALID)\n    {\n      if (url_has_scheme (url))\n        error_code = PE_UNSUPPORTED_SCHEME;\n      else\n        error_code = PE_MISSING_SCHEME;\n      goto error;\n    }\n\n  url_encoded = url;\n\n  if (iri && iri->utf8_encode)\n    {\n      char *new_url = NULL;\n\n      iri->utf8_encode = remote_to_utf8 (iri, iri->orig_url ? iri->orig_url : url, &new_url);\n      if (!iri->utf8_encode)\n        new_url = NULL;\n      else\n        {\n          xfree (iri->orig_url);\n          iri->orig_url = xstrdup (url);\n          url_encoded = reencode_escapes (new_url);\n          if (url_encoded != new_url)\n            xfree (new_url);\n          percent_encode = false;\n        }\n    }\n\n  if (percent_encode)\n    url_encoded = reencode_escapes (url);\n\n  p = url_encoded;\n  p += strlen (supported_schemes[scheme].leading_string);\n  uname_b = p;\n  p = url_skip_credentials (p);\n  uname_e = p;\n\n  /* scheme://user:pass@host[:port]... */\n  /*                    ^              */\n\n  /* We attempt to break down the URL into the components path,\n     params, query, and fragment.  They are ordered like this:\n\n       scheme://host[:port][/path][;params][?query][#fragment]  */\n\n  path_b     = path_e     = NULL;\n  params_b   = params_e   = NULL;\n  query_b    = query_e    = NULL;\n  fragment_b = fragment_e = NULL;\n\n  /* Initialize separators for optional parts of URL, depending on the\n     scheme.  For example, FTP has params, and HTTP and HTTPS have\n     query string and fragment. */\n  seps = init_seps (scheme);\n\n  host_b = p;\n\n  if (*p == '[')\n    {\n      /* Handle IPv6 address inside square brackets.  Ideally we'd\n         just look for the terminating ']', but rfc2732 mandates\n         rejecting invalid IPv6 addresses.  */\n\n      /* The address begins after '['. */\n      host_b = p + 1;\n      host_e = strchr (host_b, ']');\n\n      if (!host_e)\n        {\n          error_code = PE_UNTERMINATED_IPV6_ADDRESS;\n          goto error;\n        }\n\n#ifdef ENABLE_IPV6\n      /* Check if the IPv6 address is valid. */\n      if (!is_valid_ipv6_address(host_b, host_e))\n        {\n          error_code = PE_INVALID_IPV6_ADDRESS;\n          goto error;\n        }\n\n      /* Continue parsing after the closing ']'. */\n      p = host_e + 1;\n#else\n      error_code = PE_IPV6_NOT_SUPPORTED;\n      goto error;\n#endif\n\n      /* The closing bracket must be followed by a separator or by the\n         null char.  */\n      /* http://[::1]... */\n      /*             ^   */\n      if (!strchr (seps, *p))\n        {\n          /* Trailing garbage after []-delimited IPv6 address. */\n          error_code = PE_INVALID_HOST_NAME;\n          goto error;\n        }\n    }\n  else\n    {\n      p = strpbrk_or_eos (p, seps);\n      host_e = p;\n    }\n  ++seps;                       /* advance to '/' */\n\n  if (host_b == host_e)\n    {\n      error_code = PE_INVALID_HOST_NAME;\n      goto error;\n    }\n\n  port = scheme_default_port (scheme);\n  if (*p == ':')\n    {\n      const char *port_b, *port_e, *pp;\n\n      /* scheme://host:port/tralala */\n      /*              ^             */\n      ++p;\n      port_b = p;\n      p = strpbrk_or_eos (p, seps);\n      port_e = p;\n\n      /* Allow empty port, as per rfc2396. */\n      if (port_b != port_e)\n        for (port = 0, pp = port_b; pp < port_e; pp++)\n          {\n            if (!c_isdigit (*pp))\n              {\n                /* http://host:12randomgarbage/blah */\n                /*               ^                  */\n                error_code = PE_BAD_PORT_NUMBER;\n                goto error;\n              }\n            port = 10 * port + (*pp - '0');\n            /* Check for too large port numbers here, before we have\n               a chance to overflow on bogus port values.  */\n            if (port > 0xffff)\n              {\n                error_code = PE_BAD_PORT_NUMBER;\n                goto error;\n              }\n          }\n    }\n  /* Advance to the first separator *after* '/' (either ';' or '?',\n     depending on the scheme).  */\n  ++seps;\n\n  /* Get the optional parts of URL, each part being delimited by\n     current location and the position of the next separator.  */\n#define GET_URL_PART(sepchar, var) do {                         \\\n  if (*p == sepchar)                                            \\\n    var##_b = ++p, var##_e = p = strpbrk_or_eos (p, seps);      \\\n  ++seps;                                                       \\\n} while (0)\n\n  GET_URL_PART ('/', path);\n  if (supported_schemes[scheme].flags & scm_has_params)\n    GET_URL_PART (';', params);\n  if (supported_schemes[scheme].flags & scm_has_query)\n    GET_URL_PART ('?', query);\n  if (supported_schemes[scheme].flags & scm_has_fragment)\n    GET_URL_PART ('#', fragment);\n\n#undef GET_URL_PART\n  assert (*p == 0);\n\n  if (uname_b != uname_e)\n    {\n      /* http://user:pass@host */\n      /*        ^         ^    */\n      /*     uname_b   uname_e */\n      if (!parse_credentials (uname_b, uname_e - 1, &user, &passwd))\n        {\n          error_code = PE_INVALID_USER_NAME;\n          goto error;\n        }\n    }\n\n  u = xnew0 (struct url);\n  u->scheme = scheme;\n  u->host   = strdupdelim (host_b, host_e);\n  u->port   = port;\n  u->user   = user;\n  u->passwd = passwd;\n\n  u->path = strdupdelim (path_b, path_e);\n  path_modified = path_simplify (scheme, u->path);\n  split_path (u->path, &u->dir, &u->file);\n\n  host_modified = lowercase_str (u->host);\n\n  /* Decode %HH sequences in host name.  This is important not so much\n     to support %HH sequences in host names (which other browser\n     don't), but to support binary characters (which will have been\n     converted to %HH by reencode_escapes).  */\n  if (strchr (u->host, '%'))\n    {\n      url_unescape (u->host);\n      host_modified = true;\n\n      /* Apply IDNA regardless of iri->utf8_encode status */\n      if (opt.enable_iri && iri)\n        {\n          char *new = idn_encode (iri, u->host);\n          if (new)\n            {\n              xfree (u->host);\n              u->host = new;\n              u->idn_allocated = true;\n              host_modified = true;\n            }\n        }\n    }\n\n  if (params_b)\n    u->params = strdupdelim (params_b, params_e);\n  if (query_b)\n    u->query = strdupdelim (query_b, query_e);\n  if (fragment_b)\n    u->fragment = strdupdelim (fragment_b, fragment_e);\n\n  if (opt.enable_iri || path_modified || u->fragment || host_modified || path_b == path_e)\n    {\n      /* If we suspect that a transformation has rendered what\n         url_string might return different from URL_ENCODED, rebuild\n         u->url using url_string.  */\n      u->url = url_string (u, URL_AUTH_SHOW);\n\n      if (url_encoded != url)\n        xfree (url_encoded);\n    }\n  else\n    {\n      if (url_encoded == url)\n        u->url = xstrdup (url);\n      else\n        u->url = (char *) url_encoded;\n    }\n\n  return u;\n\n error:\n  /* Cleanup in case of error: */\n  if (url_encoded && url_encoded != url)\n    xfree (url_encoded);\n\n  /* Transmit the error code to the caller, if the caller wants to\n     know.  */\n  if (error)\n    *error = error_code;\n  return NULL;\n}",
        "commit_message": "Fix CRLF injection in Wget host part\n\n* src/url.c (url_parse): Reject control characters in host part of URL\n\nReported-by: Orange Tsai",
        "cve_desc": "CRLF injection vulnerability in the url_parse function in url.c in Wget through 1.19.1 allows remote attackers to inject arbitrary HTTP headers via CRLF sequences in the host subcomponent of a URL.",
        "target": 1
      },
      {
        "idx": 215987,
        "reasoning": "This code is vulnerable to a stack overflow because it fails to validate the chunk size read from the HTTP response before passing it to `fd_read()`. A negative chunk size, resulting from improper parsing with `strtol()`, is truncated to a large positive value when cast to an `int`, allowing an attacker to control the amount of data read into a fixed-size buffer (`dlbuf`) and potentially overflow the stack.",
        "func": "skip_short_body (int fd, wgint contlen, bool chunked)\n{\n  enum {\n    SKIP_SIZE = 512,                /* size of the download buffer */\n    SKIP_THRESHOLD = 4096        /* the largest size we read */\n  };\n  wgint remaining_chunk_size = 0;\n  char dlbuf[SKIP_SIZE + 1];\n  dlbuf[SKIP_SIZE] = '\\0';        /* so DEBUGP can safely print it */\n\n  /* If the body is too large, it makes more sense to simply close the\n     connection than to try to read the body.  */\n  if (contlen > SKIP_THRESHOLD)\n    return false;\n\n  while (contlen > 0 || chunked)\n    {\n      int ret;\n      if (chunked)\n        {\n          if (remaining_chunk_size == 0)\n            {\n              char *line = fd_read_line (fd);\n              char *endl;\n              if (line == NULL)\n                break;\n\n              remaining_chunk_size = strtol (line, &endl, 16);\n              xfree (line);\n\n              if (remaining_chunk_size == 0)\n                {\n                  line = fd_read_line (fd);\n                  xfree (line);\n                  break;\n                }\n            }\n\n          contlen = MIN (remaining_chunk_size, SKIP_SIZE);\n        }\n\n      DEBUGP ((\"Skipping %s bytes of body: [\", number_to_static_string (contlen)));\n\n      ret = fd_read (fd, dlbuf, MIN (contlen, SKIP_SIZE), -1);\n      if (ret <= 0)\n        {\n          /* Don't normally report the error since this is an\n             optimization that should be invisible to the user.  */\n          DEBUGP ((\"] aborting (%s).\\n\",\n                   ret < 0 ? fd_errstr (fd) : \"EOF received\"));\n          return false;\n        }\n      contlen -= ret;\n\n      if (chunked)\n        {\n          remaining_chunk_size -= ret;\n          if (remaining_chunk_size == 0)\n            {\n              char *line = fd_read_line (fd);\n              if (line == NULL)\n                return false;\n              else\n                xfree (line);\n            }\n        }\n\n      /* Safe even if %.*s bogusly expects terminating \\0 because\n         we've zero-terminated dlbuf above.  */\n      DEBUGP ((\"%.*s\", ret, dlbuf));\n    }\n\n  DEBUGP ((\"] done.\\n\"));\n  return true;\n}",
        "commit_message": "Fix stack overflow in HTTP protocol handling (CVE-2017-13089)\n\n* src/http.c (skip_short_body): Return error on negative chunk size\n\nReported-by: Antti Levom\u00e4ki, Christian Jalio, Joonas Pihlaja from Forcepoint\nReported-by: Juhani Eronen from Finnish National Cyber Security Centre",
        "cve_desc": "The http.c:skip_short_body() function is called in some circumstances, such as when processing redirects. When the response is sent chunked in wget before 1.19.2, the chunk parser uses strtol() to read each chunk's length, but doesn't check that the chunk length is a non-negative number. The code then tries to skip the chunk in pieces of 512 bytes by using the MIN() macro, but ends up passing the negative chunk length to connect.c:fd_read(). As fd_read() takes an int argument, the high 32 bits of the chunk length are discarded, leaving fd_read() with a completely attacker controlled length argument.",
        "target": 1
      },
      {
        "idx": 215988,
        "reasoning": "This code is vulnerable to a heap overflow because it fails to validate the chunk size received during HTTP chunked transfer encoding, potentially allowing a negative value to be passed to `fd_read`. The `fd_read` function then uses this (effectively large positive due to integer overflow) value as the number of bytes to read, leading to a buffer over-read and potential corruption of heap metadata.",
        "func": "fd_read_body (const char *downloaded_filename, int fd, FILE *out, wgint toread, wgint startpos,\n\n              wgint *qtyread, wgint *qtywritten, double *elapsed, int flags,\n              FILE *out2)\n{\n  int ret = 0;\n#undef max\n#define max(a,b) ((a) > (b) ? (a) : (b))\n  int dlbufsize = max (BUFSIZ, 8 * 1024);\n  char *dlbuf = xmalloc (dlbufsize);\n\n  struct ptimer *timer = NULL;\n  double last_successful_read_tm = 0;\n\n  /* The progress gauge, set according to the user preferences. */\n  void *progress = NULL;\n\n  /* Non-zero if the progress gauge is interactive, i.e. if it can\n     continually update the display.  When true, smaller timeout\n     values are used so that the gauge can update the display when\n     data arrives slowly. */\n  bool progress_interactive = false;\n\n  bool exact = !!(flags & rb_read_exactly);\n\n  /* Used only by HTTP/HTTPS chunked transfer encoding.  */\n  bool chunked = flags & rb_chunked_transfer_encoding;\n  wgint skip = 0;\n\n  /* How much data we've read/written.  */\n  wgint sum_read = 0;\n  wgint sum_written = 0;\n  wgint remaining_chunk_size = 0;\n\n#ifdef HAVE_LIBZ\n  /* try to minimize the number of calls to inflate() and write_data() per\n     call to fd_read() */\n  unsigned int gzbufsize = dlbufsize * 4;\n  char *gzbuf = NULL;\n  z_stream gzstream;\n\n  if (flags & rb_compressed_gzip)\n    {\n      gzbuf = xmalloc (gzbufsize);\n      if (gzbuf != NULL)\n        {\n          gzstream.zalloc = zalloc;\n          gzstream.zfree = zfree;\n          gzstream.opaque = Z_NULL;\n          gzstream.next_in = Z_NULL;\n          gzstream.avail_in = 0;\n\n          #define GZIP_DETECT 32 /* gzip format detection */\n          #define GZIP_WINDOW 15 /* logarithmic window size (default: 15) */\n          ret = inflateInit2 (&gzstream, GZIP_DETECT | GZIP_WINDOW);\n          if (ret != Z_OK)\n            {\n              xfree (gzbuf);\n              errno = (ret == Z_MEM_ERROR) ? ENOMEM : EINVAL;\n              ret = -1;\n              goto out;\n            }\n        }\n      else\n        {\n          errno = ENOMEM;\n          ret = -1;\n          goto out;\n        }\n    }\n#endif\n\n  if (flags & rb_skip_startpos)\n    skip = startpos;\n\n  if (opt.show_progress)\n    {\n      const char *filename_progress;\n      /* If we're skipping STARTPOS bytes, pass 0 as the INITIAL\n         argument to progress_create because the indicator doesn't\n         (yet) know about \"skipping\" data.  */\n      wgint start = skip ? 0 : startpos;\n      if (opt.dir_prefix)\n        filename_progress = downloaded_filename + strlen (opt.dir_prefix) + 1;\n      else\n        filename_progress = downloaded_filename;\n      progress = progress_create (filename_progress, start, start + toread);\n      progress_interactive = progress_interactive_p (progress);\n    }\n\n  if (opt.limit_rate)\n    limit_bandwidth_reset ();\n\n  /* A timer is needed for tracking progress, for throttling, and for\n     tracking elapsed time.  If either of these are requested, start\n     the timer.  */\n  if (progress || opt.limit_rate || elapsed)\n    {\n      timer = ptimer_new ();\n      last_successful_read_tm = 0;\n    }\n\n  /* Use a smaller buffer for low requested bandwidths.  For example,\n     with --limit-rate=2k, it doesn't make sense to slurp in 16K of\n     data and then sleep for 8s.  With buffer size equal to the limit,\n     we never have to sleep for more than one second.  */\n  if (opt.limit_rate && opt.limit_rate < dlbufsize)\n    dlbufsize = opt.limit_rate;\n\n  /* Read from FD while there is data to read.  Normally toread==0\n     means that it is unknown how much data is to arrive.  However, if\n     EXACT is set, then toread==0 means what it says: that no data\n     should be read.  */\n  while (!exact || (sum_read < toread))\n    {\n      int rdsize;\n      double tmout = opt.read_timeout;\n\n      if (chunked)\n        {\n          if (remaining_chunk_size == 0)\n            {\n              char *line = fd_read_line (fd);\n              char *endl;\n              if (line == NULL)\n                {\n                  ret = -1;\n                  break;\n                }\n              else if (out2 != NULL)\n                fwrite (line, 1, strlen (line), out2);\n\n              remaining_chunk_size = strtol (line, &endl, 16);\n              xfree (line);\n\n              if (remaining_chunk_size == 0)\n                {\n                  ret = 0;\n                  line = fd_read_line (fd);\n                  if (line == NULL)\n                    ret = -1;\n                  else\n                    {\n                      if (out2 != NULL)\n                        fwrite (line, 1, strlen (line), out2);\n                      xfree (line);\n                    }\n                  break;\n                }\n            }\n\n          rdsize = MIN (remaining_chunk_size, dlbufsize);\n        }\n      else\n        rdsize = exact ? MIN (toread - sum_read, dlbufsize) : dlbufsize;\n\n      if (progress_interactive)\n        {\n          /* For interactive progress gauges, always specify a ~1s\n             timeout, so that the gauge can be updated regularly even\n             when the data arrives very slowly or stalls.  */\n          tmout = 0.95;\n          if (opt.read_timeout)\n            {\n              double waittm;\n              waittm = ptimer_read (timer) - last_successful_read_tm;\n              if (waittm + tmout > opt.read_timeout)\n                {\n                  /* Don't let total idle time exceed read timeout. */\n                  tmout = opt.read_timeout - waittm;\n                  if (tmout < 0)\n                    {\n                      /* We've already exceeded the timeout. */\n                      ret = -1, errno = ETIMEDOUT;\n                      break;\n                    }\n                }\n            }\n        }\n      ret = fd_read (fd, dlbuf, rdsize, tmout);\n\n      if (progress_interactive && ret < 0 && errno == ETIMEDOUT)\n        ret = 0;                /* interactive timeout, handled above */\n      else if (ret <= 0)\n        break;                  /* EOF or read error */\n\n      if (progress || opt.limit_rate || elapsed)\n        {\n          ptimer_measure (timer);\n          if (ret > 0)\n            last_successful_read_tm = ptimer_read (timer);\n        }\n\n      if (ret > 0)\n        {\n          int write_res;\n\n          sum_read += ret;\n\n#ifdef HAVE_LIBZ\n          if (gzbuf != NULL)\n            {\n              int err;\n              int towrite;\n              gzstream.avail_in = ret;\n              gzstream.next_in = (unsigned char *) dlbuf;\n\n              do\n                {\n                  gzstream.avail_out = gzbufsize;\n                  gzstream.next_out = (unsigned char *) gzbuf;\n\n                  err = inflate (&gzstream, Z_NO_FLUSH);\n\n                  switch (err)\n                    {\n                    case Z_MEM_ERROR:\n                      errno = ENOMEM;\n                      ret = -1;\n                      goto out;\n                    case Z_NEED_DICT:\n                    case Z_DATA_ERROR:\n                      errno = EINVAL;\n                      ret = -1;\n                      goto out;\n                    case Z_STREAM_END:\n                      if (exact && sum_read != toread)\n                        {\n                          DEBUGP((\"zlib stream ended unexpectedly after \"\n                                  \"%ld/%ld bytes\\n\", sum_read, toread));\n                        }\n                    }\n\n                  towrite = gzbufsize - gzstream.avail_out;\n                  write_res = write_data (out, out2, gzbuf, towrite, &skip,\n                                          &sum_written);\n                  if (write_res < 0)\n                    {\n                      ret = (write_res == -3) ? -3 : -2;\n                      goto out;\n                    }\n                }\n              while (gzstream.avail_out == 0);\n            }\n          else\n#endif\n            {\n              write_res = write_data (out, out2, dlbuf, ret, &skip,\n                                      &sum_written);\n              if (write_res < 0)\n                {\n                  ret = (write_res == -3) ? -3 : -2;\n                  goto out;\n                }\n            }\n\n          if (chunked)\n            {\n              remaining_chunk_size -= ret;\n              if (remaining_chunk_size == 0)\n                {\n                  char *line = fd_read_line (fd);\n                  if (line == NULL)\n                    {\n                      ret = -1;\n                      break;\n                    }\n                  else\n                    {\n                      if (out2 != NULL)\n                        fwrite (line, 1, strlen (line), out2);\n                      xfree (line);\n                    }\n                }\n            }\n        }\n\n      if (opt.limit_rate)\n        limit_bandwidth (ret, timer);\n\n      if (progress)\n        progress_update (progress, ret, ptimer_read (timer));\n#ifdef WINDOWS\n      if (toread > 0 && opt.show_progress)\n        ws_percenttitle (100.0 *\n                         (startpos + sum_read) / (startpos + toread));\n#endif\n    }\n  if (ret < -1)\n    ret = -1;\n\n out:\n  if (progress)\n    progress_finish (progress, ptimer_read (timer));\n\n  if (elapsed)\n    *elapsed = ptimer_read (timer);\n  if (timer)\n    ptimer_destroy (timer);\n\n#ifdef HAVE_LIBZ\n  if (gzbuf != NULL)\n    {\n      int err = inflateEnd (&gzstream);\n      if (ret >= 0)\n        {\n          /* with compression enabled, ret must be 0 if successful */\n          if (err == Z_OK)\n            ret = 0;\n          else\n            {\n              errno = EINVAL;\n              ret = -1;\n            }\n        }\n      xfree (gzbuf);\n\n      if (gzstream.total_in != sum_read)\n        {\n          DEBUGP((\"zlib read size differs from raw read size (%lu/%lu)\\n\",\n                  gzstream.total_in, sum_read));\n        }\n    }\n#endif\n\n  if (qtyread)\n    *qtyread += sum_read;\n  if (qtywritten)\n    *qtywritten += sum_written;\n\n  xfree (dlbuf);\n\n  return ret;\n}",
        "commit_message": "Fix heap overflow in HTTP protocol handling (CVE-2017-13090)\n\n* src/retr.c (fd_read_body): Stop processing on negative chunk size\n\nReported-by: Antti Levom\u00e4ki, Christian Jalio, Joonas Pihlaja from Forcepoint\nReported-by: Juhani Eronen from Finnish National Cyber Security Centre",
        "cve_desc": "The retr.c:fd_read_body() function is called when processing OK responses. When the response is sent chunked in wget before 1.19.2, the chunk parser uses strtol() to read each chunk's length, but doesn't check that the chunk length is a non-negative number. The code then tries to read the chunk in pieces of 8192 bytes by using the MIN() macro, but ends up passing the negative chunk length to retr.c:fd_read(). As fd_read() takes an int argument, the high 32 bits of the chunk length are discarded, leaving fd_read() with a completely attacker controlled length argument. The attacker can corrupt malloc metadata after the allocated buffer.",
        "target": 1
      }
    ]
  },
  "wireshark": {
    "0": [
      {
        "idx": 49864,
        "reasoning": "This code snippet is not directly vulnerable based on the provided information. The commit message and code changes relate to updating function parameters for the Ethernet dissector, focusing on data structure consistency rather than addressing potential security flaws like buffer overflows or injection vulnerabilities.\n\n\n\n",
        "func": "capture_pktap(const guchar *pd, int len, packet_counts *ld)\n{\n\tguint32  hdrlen, rectype, dlt;\n\n\thdrlen = pletoh32(pd);\n\tif (hdrlen < MIN_PKTAP_HDR_LEN || !BYTES_ARE_IN_FRAME(0, len, hdrlen)) {\n\t\tld->other++;\n\t\treturn;\n\t}\n\n\trectype = pletoh32(pd+4);\n\tif (rectype != PKT_REC_PACKET) {\n\t\tld->other++;\n\t\treturn;\n\t}\n\n\tdlt = pletoh32(pd+4);\n\n\t/* XXX - We should probably combine this with capture_info.c:capture_info_packet() */\n\tswitch (dlt) {\n\n\tcase 1: /* DLT_EN10MB */\n\t\tcapture_eth(pd, hdrlen, len, ld);\n\t\treturn;\n\n\tdefault:\n\t\tbreak;\n\t}\n\n\tld->other++;\n}\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 0
      },
      {
        "idx": 49865,
        "reasoning": "This code snippet is not vulnerable. It simply registers a dissector for a specific encapsulation type (\"wtap_encap\") with a handle (`pktap_handle`), and doesn't directly handle any data processing or external input that could lead to exploits; the commit message indicates a change to *how* data is passed to a dissector, not a change that introduces a security risk itself.\n\n\n\n",
        "func": "proto_reg_handoff_pktap(void)\n{\n\tdissector_add_uint(\"wtap_encap\", WTAP_ENCAP_PKTAP, pktap_handle);\n}\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 0
      },
      {
        "idx": 49866,
        "reasoning": "This code snippet is safe as it primarily registers protocol information \u2013 fields, trees, and experts \u2013 for a packet dissection protocol (\"PKTAP\"). It doesn't handle any direct packet data processing or external input that could lead to vulnerabilities like buffer overflows or injection attacks; it simply defines *how* packets should be interpreted, not the interpretation itself.",
        "func": "proto_register_pktap(void)\n{\n\tstatic hf_register_info hf[] = {\n\t  { &hf_pktap_hdrlen,\n\t    { \"Header length\", \"pktap.hdrlen\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_rectype,\n\t    { \"Record type\", \"pktap.rectype\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_dlt,\n\t    { \"DLT\", \"pktap.dlt\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_ifname,\t/* fixed length *and* null-terminated */\n\t    { \"Interface name\", \"pktap.ifname\",\n\t      FT_STRINGZ, BASE_NONE, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_flags,\n\t    { \"Flags\", \"pktap.flags\",\n\t      FT_UINT32, BASE_HEX, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_pfamily,\n\t    { \"Protocol family\", \"pktap.pfamily\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_llhdrlen,\n\t    { \"Link-layer header length\", \"pktap.llhdrlen\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_lltrlrlen,\n\t    { \"Link-layer trailer length\", \"pktap.lltrlrlen\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_pid,\n\t    { \"Process ID\", \"pktap.pid\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_cmdname,\t/* fixed length *and* null-terminated */\n\t    { \"Command name\", \"pktap.cmdname\",\n\t      FT_STRINGZ, BASE_NONE, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_svc_class,\n\t    { \"Service class\", \"pktap.svc_class\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_iftype,\n\t    { \"Interface type\", \"pktap.iftype\",\n\t      FT_UINT16, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_ifunit,\n\t    { \"Interface unit\", \"pktap.ifunit\",\n\t      FT_UINT16, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_epid,\n\t    { \"Effective process ID\", \"pktap.epid\",\n\t      FT_UINT32, BASE_DEC, NULL, 0x0, NULL, HFILL } },\n\t  { &hf_pktap_ecmdname,\t/* fixed length *and* null-terminated */\n\t    { \"Effective command name\", \"pktap.ecmdname\",\n\t      FT_STRINGZ, BASE_NONE, NULL, 0x0, NULL, HFILL } },\n\t};\n\n\tstatic gint *ett[] = {\n\t\t&ett_pktap,\n\t};\n\n\tstatic ei_register_info ei[] = {\n\t    { &ei_pktap_hdrlen_too_short,\n\t      { \"pktap.hdrlen_too_short\", PI_MALFORMED, PI_ERROR,\n\t        \"Header length is too short\", EXPFILL }},\n\t};\n\n\texpert_module_t* expert_pktap;\n\n\tproto_pktap = proto_register_protocol(\"PKTAP packet header\", \"PKTAP\",\n\t    \"pktap\");\n\tproto_register_field_array(proto_pktap, hf, array_length(hf));\n\tproto_register_subtree_array(ett, array_length(ett));\n\texpert_pktap = expert_register_protocol(proto_pktap);\n\texpert_register_field_array(expert_pktap, ei, array_length(ei));\n\n\tpktap_handle = register_dissector(\"pktap\", dissect_pktap, proto_pktap);\n}\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 0
      },
      {
        "idx": 49867,
        "reasoning": "This code snippet is not vulnerable. It simply defines a function to add Protocol Data Unit (PDU) fields to a Wireshark dissection tree, handling offset management and data encoding\u2014it doesn't directly handle network data parsing or external inputs that could lead to exploits like buffer overflows or injection attacks. \n\n\n\n",
        "func": "add_ppi_field_header(tvbuff_t *tvb, proto_tree *tree, int *offset)\n{\n    ptvcursor_t *csr;\n\n    csr = ptvcursor_new(tree, tvb, *offset);\n    ptvcursor_add(csr, hf_ppi_field_type, 2, ENC_LITTLE_ENDIAN);\n    ptvcursor_add(csr, hf_ppi_field_len, 2, ENC_LITTLE_ENDIAN);\n    ptvcursor_free(csr);\n    *offset=ptvcursor_current_offset(csr);\n}\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 0
      },
      {
        "idx": 49868,
        "reasoning": "This code snippet is not vulnerable because it only deals with cleanup of a reassembly table related to A-MPDU frames\u2014a function unrelated to packet dissection or handling potentially malicious network traffic. The commit message and bug reference relate to changes in how Ethernet headers are passed to a dissector, while this code focuses on memory management within a specific reassembly process and doesn't introduce any new attack surface.\n\n\n\n",
        "func": "ampdu_reassemble_cleanup(void)\n{\n    reassembly_table_destroy(&ampdu_reassembly_table);\n}\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 0
      }
    ],
    "1": [
      {
        "idx": 1919,
        "reasoning": "This code is vulnerable because the `dissector_try_uint` function uses the `dlt` value (data link type) directly from the PKTAP header to index into the `wtap_encap_dissector_table` without proper validation. A malicious actor could craft a packet with a `dlt` value that is out of bounds for this table, leading to an invalid memory access and ultimately a denial-of-service crash, as described in CVE-2016-6984.",
        "func": "dissect_pktap(tvbuff_t *tvb, packet_info *pinfo, proto_tree *tree)\n{\n\tproto_tree *pktap_tree = NULL;\n\tproto_item *ti = NULL;\n \ttvbuff_t *next_tvb;\n \tint offset = 0;\n \tguint32 pkt_len, rectype, dlt;\n \n \tcol_set_str(pinfo->cinfo, COL_PROTOCOL, \"PKTAP\");\n \tcol_clear(pinfo->cinfo, COL_INFO);\n\n\tpkt_len = tvb_get_letohl(tvb, offset);\n\tcol_add_fstr(pinfo->cinfo, COL_INFO, \"PKTAP, %u byte header\", pkt_len);\n\n\t/* Dissect the packet */\n\tti = proto_tree_add_item(tree, proto_pktap, tvb, offset, pkt_len, ENC_NA);\n\tpktap_tree = proto_item_add_subtree(ti, ett_pktap);\n\n\tproto_tree_add_item(pktap_tree, hf_pktap_hdrlen, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\tif (pkt_len < MIN_PKTAP_HDR_LEN) {\n\t\tproto_tree_add_expert(tree, pinfo, &ei_pktap_hdrlen_too_short,\n\t\t    tvb, offset, 4);\n\t\treturn;\n\t}\n\toffset += 4;\n\n\tproto_tree_add_item(pktap_tree, hf_pktap_rectype, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\trectype = tvb_get_letohl(tvb, offset);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_dlt, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\tdlt = tvb_get_letohl(tvb, offset);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_ifname, tvb, offset, 24,\n\t    ENC_ASCII|ENC_NA);\n\toffset += 24;\n\tproto_tree_add_item(pktap_tree, hf_pktap_flags, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_pfamily, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_llhdrlen, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_lltrlrlen, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_pid, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_cmdname, tvb, offset, 20,\n\t    ENC_UTF_8|ENC_NA);\n\toffset += 20;\n\tproto_tree_add_item(pktap_tree, hf_pktap_svc_class, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_iftype, tvb, offset, 2,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 2;\n\tproto_tree_add_item(pktap_tree, hf_pktap_ifunit, tvb, offset, 2,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 2;\n\tproto_tree_add_item(pktap_tree, hf_pktap_epid, tvb, offset, 4,\n\t    ENC_LITTLE_ENDIAN);\n\toffset += 4;\n\tproto_tree_add_item(pktap_tree, hf_pktap_ecmdname, tvb, offset, 20,\n\t    ENC_UTF_8|ENC_NA);\n\t/*offset += 20;*/\n \n \tif (rectype == PKT_REC_PACKET) {\n \t\tnext_tvb = tvb_new_subset_remaining(tvb, pkt_len);\n\t\tdissector_try_uint(wtap_encap_dissector_table,\n\t\t    wtap_pcap_encap_to_wtap_encap(dlt), next_tvb, pinfo, tree);\n \t}\n }\n",
        "commit_message": "The WTAP_ENCAP_ETHERNET dissector needs to be passed a struct eth_phdr.\n\nWe now require that.  Make it so.\n\nBug: 12440\nChange-Id: Iffee520976b013800699bde3c6092a3e86be0d76\nReviewed-on: https://code.wireshark.org/review/15424\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "epan/dissectors/packet-pktap.c in the Ethernet dissector in Wireshark 2.x before 2.0.4 mishandles the packet-header data type, which allows remote attackers to cause a denial of service (application crash) via a crafted packet.",
        "target": 1
      },
      {
        "idx": 1925,
        "reasoning": "The code is vulnerable because `sscanf` is used to parse an unsigned integer (`pkt_len`) without proper validation, allowing a negative value to be assigned due to `sscanf`'s behavior with unsigned format specifiers and negative signs. This can lead to an application crash as indicated by the CVE, because the code later checks if `pkt_len` is greater than `WTAP_MAX_PACKET_SIZE` but doesn't prevent it from being a negative value initially.",
        "func": "parse_cosine_packet(FILE_T fh, struct wtap_pkthdr *phdr, Buffer *buf,\n    char *line, int *err, gchar **err_info)\n {\n \tunion wtap_pseudo_header *pseudo_header = &phdr->pseudo_header;\n \tint\tnum_items_scanned;\n\tint\tyy, mm, dd, hr, min, sec, csec;\n\tguint\tpkt_len;\n \tint\tpro, off, pri, rm, error;\n \tguint\tcode1, code2;\n \tchar\tif_name[COSINE_MAX_IF_NAME_LEN] = \"\", direction[6] = \"\";\n\tstruct\ttm tm;\n\tguint8 *pd;\n\tint\ti, hex_lines, n, caplen = 0;\n\n\tif (sscanf(line, \"%4d-%2d-%2d,%2d:%2d:%2d.%9d:\",\n \t\t   &yy, &mm, &dd, &hr, &min, &sec, &csec) == 7) {\n \t\t/* appears to be output to a control blade */\n \t\tnum_items_scanned = sscanf(line,\n\t\t   \"%4d-%2d-%2d,%2d:%2d:%2d.%9d: %5s (%127[A-Za-z0-9/:]), Length:%9u, Pro:%9d, Off:%9d, Pri:%9d, RM:%9d, Err:%9d [%8x, %8x]\",\n \t\t\t&yy, &mm, &dd, &hr, &min, &sec, &csec,\n \t\t\t\t   direction, if_name, &pkt_len,\n \t\t\t\t   &pro, &off, &pri, &rm, &error,\n\t\t\t\t   &code1, &code2);\n\n\t\tif (num_items_scanned != 17) {\n\t\t\t*err = WTAP_ERR_BAD_FILE;\n\t\t\t*err_info = g_strdup(\"cosine: purported control blade line doesn't have code values\");\n\t\t\treturn FALSE;\n\t\t}\n \t} else {\n \t\t/* appears to be output to PE */\n \t\tnum_items_scanned = sscanf(line,\n\t\t   \"%5s (%127[A-Za-z0-9/:]), Length:%9u, Pro:%9d, Off:%9d, Pri:%9d, RM:%9d, Err:%9d [%8x, %8x]\",\n \t\t\t\t   direction, if_name, &pkt_len,\n \t\t\t\t   &pro, &off, &pri, &rm, &error,\n \t\t\t\t   &code1, &code2);\n\n\t\tif (num_items_scanned != 10) {\n\t\t\t*err = WTAP_ERR_BAD_FILE;\n\t\t\t*err_info = g_strdup(\"cosine: header line is neither control blade nor PE output\");\n\t\t\treturn FALSE;\n \t\t}\n \t\tyy = mm = dd = hr = min = sec = csec = 0;\n \t}\n \tif (pkt_len > WTAP_MAX_PACKET_SIZE) {\n \t\t/*\n \t\t * Probably a corrupt capture file; don't blow up trying\n\t\t * to allocate space for an immensely-large packet.\n\t\t */\n\t\t*err = WTAP_ERR_BAD_FILE;\n\t\t*err_info = g_strdup_printf(\"cosine: File has %u-byte packet, bigger than maximum of %u\",\n\t\t    pkt_len, WTAP_MAX_PACKET_SIZE);\n\t\treturn FALSE;\n\t}\n\n\tphdr->rec_type = REC_TYPE_PACKET;\n\tphdr->presence_flags = WTAP_HAS_TS|WTAP_HAS_CAP_LEN;\n\ttm.tm_year = yy - 1900;\n\ttm.tm_mon = mm - 1;\n\ttm.tm_mday = dd;\n\ttm.tm_hour = hr;\n\ttm.tm_min = min;\n\ttm.tm_sec = sec;\n\ttm.tm_isdst = -1;\n\tphdr->ts.secs = mktime(&tm);\n\tphdr->ts.nsecs = csec * 10000000;\n\tphdr->len = pkt_len;\n\n\t/* XXX need to handle other encapsulations like Cisco HDLC,\n\t   Frame Relay and ATM */\n\tif (strncmp(if_name, \"TEST:\", 5) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_TEST;\n\t} else if (strncmp(if_name, \"PPoATM:\", 7) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_PPoATM;\n\t} else if (strncmp(if_name, \"PPoFR:\", 6) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_PPoFR;\n\t} else if (strncmp(if_name, \"ATM:\", 4) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_ATM;\n\t} else if (strncmp(if_name, \"FR:\", 3) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_FR;\n\t} else if (strncmp(if_name, \"HDLC:\", 5) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_HDLC;\n\t} else if (strncmp(if_name, \"PPP:\", 4) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_PPP;\n\t} else if (strncmp(if_name, \"ETH:\", 4) == 0) {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_ETH;\n\t} else {\n\t\tpseudo_header->cosine.encap = COSINE_ENCAP_UNKNOWN;\n\t}\n\tif (strncmp(direction, \"l2-tx\", 5) == 0) {\n\t\tpseudo_header->cosine.direction = COSINE_DIR_TX;\n\t} else if (strncmp(direction, \"l2-rx\", 5) == 0) {\n\t\tpseudo_header->cosine.direction = COSINE_DIR_RX;\n\t}\n\tg_strlcpy(pseudo_header->cosine.if_name, if_name,\n\t\tCOSINE_MAX_IF_NAME_LEN);\n\tpseudo_header->cosine.pro = pro;\n\tpseudo_header->cosine.off = off;\n\tpseudo_header->cosine.pri = pri;\n\tpseudo_header->cosine.rm = rm;\n\tpseudo_header->cosine.err = error;\n\n\t/* Make sure we have enough room for the packet */\n\tws_buffer_assure_space(buf, pkt_len);\n\tpd = ws_buffer_start_ptr(buf);\n\n\t/* Calculate the number of hex dump lines, each\n\t * containing 16 bytes of data */\n\thex_lines = pkt_len / 16 + ((pkt_len % 16) ? 1 : 0);\n\n\tfor (i = 0; i < hex_lines; i++) {\n\t\tif (file_gets(line, COSINE_LINE_LENGTH, fh) == NULL) {\n\t\t\t*err = file_error(fh, err_info);\n\t\t\tif (*err == 0) {\n\t\t\t\t*err = WTAP_ERR_SHORT_READ;\n\t\t\t}\n\t\t\treturn FALSE;\n\t\t}\n\t\tif (empty_line(line)) {\n\t\t\tbreak;\n\t\t}\n\t\tif ((n = parse_single_hex_dump_line(line, pd, i*16)) == -1) {\n\t\t\t*err = WTAP_ERR_BAD_FILE;\n\t\t\t*err_info = g_strdup(\"cosine: hex dump line doesn't have 16 numbers\");\n\t\t\treturn FALSE;\n\t\t}\n\t\tcaplen += n;\n\t}\n\tphdr->caplen = caplen;\n\treturn TRUE;\n}\n",
        "commit_message": "Don't treat the packet length as unsigned.\n\nThe scanf family of functions are as annoyingly bad at handling unsigned\nnumbers as strtoul() is - both of them are perfectly willing to accept a\nvalue beginning with a negative sign as an unsigned value.  When using\nstrtoul(), you can compensate for this by explicitly checking for a '-'\nas the first character of the string, but you can't do that with\nsscanf().\n\nSo revert to having pkt_len be signed, and scanning it with %d, but\ncheck for a negative value and fail if we see a negative value.\n\nBug: 12395\nChange-Id: I43b458a73b0934e9a5c2c89d34eac5a8f21a7455\nReviewed-on: https://code.wireshark.org/review/15223\nReviewed-by: Guy Harris <guy@alum.mit.edu>",
        "cve_desc": "wiretap/cosine.c in the CoSine file parser in Wireshark 1.12.x before 1.12.12 and 2.x before 2.0.4 mishandles sscanf unsigned-integer processing, which allows remote attackers to cause a denial of service (application crash) via a crafted file.",
        "target": 1
      }
    ]
  },
  "x11vnc": {
    "0": [],
    "1": []
  },
  "xbmc": {
    "0": [],
    "1": []
  },
  "znc": {
    "0": [
      {
        "idx": 238151,
        "reasoning": "This code snippet, an assignment operator for a `CConfigEntry` class, is **not directly vulnerable** to the reported issue of attackers gaining admin permissions via `znc.conf` injection. The code safely handles copying a sub-configuration (`m_pSubConfig`) by deleting the existing one and then creating a *copy* of the other's sub-configuration, preventing direct manipulation of the original data and mitigating potential injection risks within this specific assignment operation.\n\n\n\n",
        "func": "CConfigEntry& CConfigEntry::operator=(const CConfigEntry& other) {\n    delete m_pSubConfig;\n    if (other.m_pSubConfig)\n        m_pSubConfig = new CConfig(*other.m_pSubConfig);\n    else\n        m_pSubConfig = nullptr;\n    return *this;\n}",
        "commit_message": "Don't let attackers inject rogue values into znc.conf\n\nBecause of this vulnerability, existing ZNC users could get Admin\npermissions.\n\nThanks for Jeriko One <jeriko.one@gmx.us> for finding and reporting this.",
        "cve_desc": "ZNC before 1.7.1-rc1 does not properly validate untrusted lines coming from the network, allowing a non-admin user to escalate his privilege and inject rogue values into znc.conf.",
        "target": 0
      },
      {
        "idx": 238153,
        "reasoning": "This code snippet focuses on *writing* configuration data to a file, not *parsing* or *interpreting* user-supplied input. The commit message explicitly states the vulnerability lies in allowing attackers to inject rogue values into `znc.conf`, implying the issue is with how the configuration is *read* and processed, not how it's written, making this code safe as presented.\n\n\n\n",
        "func": "void CConfig::Write(CFile& File, unsigned int iIndentation) {\n    CString sIndentation = CString(iIndentation, '\\t');\n\n    auto SingleLine = [](const CString& s) {\n        return s.Replace_n(\"\\r\", \"\").Replace_n(\"\\n\", \"\");\n    };\n\n    for (const auto& it : m_ConfigEntries) {\n        for (const CString& sValue : it.second) {\n            File.Write(SingleLine(sIndentation + it.first + \" = \" + sValue) +\n                       \"\\n\");\n        }\n    }\n\n    for (const auto& it : m_SubConfigs) {\n        for (const auto& it2 : it.second) {\n            File.Write(\"\\n\");\n\n            File.Write(SingleLine(sIndentation + \"<\" + it.first + \" \" +\n                                  it2.first + \">\") +\n                       \"\\n\");\n            it2.second.m_pSubConfig->Write(File, iIndentation + 1);\n            File.Write(SingleLine(sIndentation + \"</\" + it.first + \">\") + \"\\n\");\n        }\n    }\n}",
        "commit_message": "Don't let attackers inject rogue values into znc.conf\n\nBecause of this vulnerability, existing ZNC users could get Admin\npermissions.\n\nThanks for Jeriko One <jeriko.one@gmx.us> for finding and reporting this.",
        "cve_desc": "ZNC before 1.7.1-rc1 does not properly validate untrusted lines coming from the network, allowing a non-admin user to escalate his privilege and inject rogue values into znc.conf.",
        "target": 0
      },
      {
        "idx": 238154,
        "reasoning": "This code snippet is not directly vulnerable because it simply creates a new `CConfig` object as a sub-configuration, relying on the parent `CConfig` for its initial state. The commit message describes a vulnerability related to injecting values into `znc.conf`, which would happen during *configuration parsing and handling* \u2013 a process not represented in this code that only deals with object construction.\n\n\n\n",
        "func": "CConfigEntry::CConfigEntry(const CConfig& Config)\n    : m_pSubConfig(new CConfig(Config)) {}",
        "commit_message": "Don't let attackers inject rogue values into znc.conf\n\nBecause of this vulnerability, existing ZNC users could get Admin\npermissions.\n\nThanks for Jeriko One <jeriko.one@gmx.us> for finding and reporting this.",
        "cve_desc": "ZNC before 1.7.1-rc1 does not properly validate untrusted lines coming from the network, allowing a non-admin user to escalate his privilege and inject rogue values into znc.conf.",
        "target": 0
      }
    ],
    "1": []
  },
  "zziplib": {
    "0": [],
    "1": [
      {
        "idx": 209073,
        "reasoning": "The code is vulnerable to a buffer overflow due to insufficient bounds checking when copying the filename (`hdr->d_name`) from the mapped file or via `io->fd.read`. Specifically, the `u_namlen` value, obtained from the disk entry, is used directly in the `memcpy` or `read` operation without verifying it doesn't lead to reading beyond the allocated buffer, potentially causing a bus error as described in the CVE.",
        "func": "__zzip_parse_root_directory(int fd,\n                            struct _disk_trailer *trailer,\n                            struct zzip_dir_hdr **hdr_return,\n                            zzip_plugin_io_t io)\n{\n    auto struct zzip_disk_entry dirent;\n    struct zzip_dir_hdr *hdr;\n    struct zzip_dir_hdr *hdr0;\n    uint16_t *p_reclen = 0;\n    zzip_off64_t entries;\n    zzip_off64_t zz_offset;     /* offset from start of root directory */\n    char *fd_map = 0;\n    zzip_off64_t zz_fd_gap = 0;\n    zzip_off64_t zz_entries = _disk_trailer_localentries(trailer);\n    zzip_off64_t zz_rootsize = _disk_trailer_rootsize(trailer);\n    zzip_off64_t zz_rootseek = _disk_trailer_rootseek(trailer);\n    __correct_rootseek(zz_rootseek, zz_rootsize, trailer);\n\n    if (zz_entries < 0 || zz_rootseek < 0 || zz_rootseek < 0)\n        return ZZIP_CORRUPTED;\n\n    hdr0 = (struct zzip_dir_hdr *) malloc(zz_rootsize);\n    if (! hdr0)\n        return ZZIP_DIRSIZE;\n    hdr = hdr0;\n    __debug_dir_hdr(hdr);\n\n    if (USE_MMAP && io->fd.sys)\n    {\n        zz_fd_gap = zz_rootseek & (_zzip_getpagesize(io->fd.sys) - 1);\n        HINT4(\" fd_gap=%ld, mapseek=0x%lx, maplen=%ld\", (long) (zz_fd_gap),\n              (long) (zz_rootseek - zz_fd_gap),\n              (long) (zz_rootsize + zz_fd_gap));\n        fd_map =\n            _zzip_mmap(io->fd.sys, fd, zz_rootseek - zz_fd_gap,\n                       zz_rootsize + zz_fd_gap);\n        /* if mmap failed we will fallback to seek/read mode */\n        if (fd_map == MAP_FAILED)\n        {\n            NOTE2(\"map failed: %s\", strerror(errno));\n            fd_map = 0;\n        } else\n        {\n            HINT3(\"mapped *%p len=%li\", fd_map,\n                  (long) (zz_rootsize + zz_fd_gap));\n        }\n    }\n\n    for (entries=0, zz_offset=0; ; entries++)\n    {\n        register struct zzip_disk_entry *d;\n        uint16_t u_extras, u_comment, u_namlen;\n\n#     ifndef ZZIP_ALLOW_MODULO_ENTRIES\n        if (entries >= zz_entries) {\n            if (zz_offset + 256 < zz_rootsize) {\n                FAIL4(\"%li's entry is long before the end of directory - enable modulo_entries? (O:%li R:%li)\",\n                      (long) entries, (long) (zz_offset), (long) zz_rootsize);\n            }\n            break;\n        }\n#     endif\n\n        if (fd_map)\n        {\n            d = (void*)(fd_map+zz_fd_gap+zz_offset); /* fd_map+fd_gap==u_rootseek */\n        } else\n        {\n            if (io->fd.seeks(fd, zz_rootseek + zz_offset, SEEK_SET) < 0)\n                return ZZIP_DIR_SEEK;\n            if (io->fd.read(fd, &dirent, sizeof(dirent)) < __sizeof(dirent))\n                return ZZIP_DIR_READ;\n            d = &dirent;\n        }\n\n        if ((zzip_off64_t) (zz_offset + sizeof(*d)) > zz_rootsize ||\n            (zzip_off64_t) (zz_offset + sizeof(*d)) < 0)\n        {\n            FAIL4(\"%li's entry stretches beyond root directory (O:%li R:%li)\",\n                  (long) entries, (long) (zz_offset), (long) zz_rootsize);\n            break;\n        }\n\n        if (! zzip_disk_entry_check_magic(d)) {\n#        ifndef ZZIP_ALLOW_MODULO_ENTRIES\n            FAIL4(\"%li's entry has no disk_entry magic indicator (O:%li R:%li)\",\n                  (long) entries, (long) (zz_offset), (long) zz_rootsize);\n#        endif\n            break;\n        }\n\n#       if 0 && defined DEBUG\n        zzip_debug_xbuf((unsigned char *) d, sizeof(*d) + 8);\n#       endif\n\n        u_extras = zzip_disk_entry_get_extras(d);\n        u_comment = zzip_disk_entry_get_comment(d);\n        u_namlen = zzip_disk_entry_get_namlen(d);\n        HINT5(\"offset=0x%lx, size %ld, dirent *%p, hdr %p\\n\",\n              (long) (zz_offset + zz_rootseek), (long) zz_rootsize, d, hdr);\n\n        /* writes over the read buffer, Since the structure where data is\n           copied is smaller than the data in buffer this can be done.\n           It is important that the order of setting the fields is considered\n           when filling the structure, so that some data is not trashed in\n           first structure read.\n           at the end the whole copied list of structures  is copied into\n           newly allocated buffer */\n        hdr->d_crc32 = zzip_disk_entry_get_crc32(d);\n        hdr->d_csize = zzip_disk_entry_get_csize(d);\n        hdr->d_usize = zzip_disk_entry_get_usize(d);\n        hdr->d_off = zzip_disk_entry_get_offset(d);\n        hdr->d_compr = zzip_disk_entry_get_compr(d);\n        if (hdr->d_compr > _255)\n            hdr->d_compr = 255;\n\n        if ((zzip_off64_t) (zz_offset + sizeof(*d) + u_namlen) > zz_rootsize ||\n            (zzip_off64_t) (zz_offset + sizeof(*d) + u_namlen) < 0)\n        {\n            FAIL4(\"%li's name stretches beyond root directory (O:%li N:%li)\",\n                  (long) entries, (long) (zz_offset), (long) (u_namlen));\n            break;\n        }\n\n        if (fd_map)\n            {  memcpy(hdr->d_name, fd_map+zz_fd_gap + zz_offset+sizeof(*d), u_namlen); }\n        else\n            { io->fd.read(fd, hdr->d_name, u_namlen); }\n        hdr->d_name[u_namlen] = '\\0';\n        hdr->d_namlen = u_namlen;\n\n        /* update offset by the total length of this entry -> next entry */\n        zz_offset += sizeof(*d) + u_namlen + u_extras + u_comment;\n\n        if (zz_offset > zz_rootsize)\n        {\n            FAIL3(\"%li's entry stretches beyond root directory (O:%li)\",\n                  (long) entries, (long) (zz_offset));\n            entries ++;\n            break;\n        }\n\n        HINT5(\"file %ld { compr=%d crc32=$%x offset=%d\",\n              (long) entries, hdr->d_compr, hdr->d_crc32, hdr->d_off);\n        HINT5(\"csize=%d usize=%d namlen=%d extras=%d\",\n              hdr->d_csize, hdr->d_usize, u_namlen, u_extras);\n        HINT5(\"comment=%d name='%s' %s <sizeof %d> } \",\n              u_comment, hdr->d_name, \"\", (int) sizeof(*d));\n\n        p_reclen = &hdr->d_reclen;\n\n        {\n            register char *p = (char *) hdr;\n            register char *q = aligned4(p + sizeof(*hdr) + u_namlen + 1);\n            *p_reclen = (uint16_t) (q - p);\n            hdr = (struct zzip_dir_hdr *) q;\n        }\n    }                           /*for */\n\n    if (USE_MMAP && fd_map)\n    {\n        HINT3(\"unmap *%p len=%li\", fd_map, (long) (zz_rootsize + zz_fd_gap));\n        _zzip_munmap(io->fd.sys, fd_map, zz_rootsize + zz_fd_gap);\n    }\n\n    if (p_reclen)\n    {\n        *p_reclen = 0;          /* mark end of list */\n\n        if (hdr_return)\n            *hdr_return = hdr0;\n    }                           /* else zero (sane) entries */\n#  ifndef ZZIP_ALLOW_MODULO_ENTRIES\n    return (entries != zz_entries ? ZZIP_CORRUPTED : 0);\n#  else\n    return ((entries & (unsigned)0xFFFF) != zz_entries ? ZZIP_CORRUPTED : 0);\n#  endif\n}",
        "commit_message": "fix for zz_rootsize #41",
        "cve_desc": "An issue was discovered in ZZIPlib 0.13.68. There is a bus error caused by the __zzip_parse_root_directory function of zip.c. Attackers could leverage this vulnerability to cause a denial of service via a crafted zip file.",
        "target": 1
      },
      {
        "idx": 212313,
        "reasoning": "The code is vulnerable to a memory leak because the allocated memory for `hdr0` is only freed in specific error paths within the function, specifically when `io->fd.seeks` or `io->fd.read` fail, or if `hdr_return` is not assigned. If none of these error conditions are met, and `hdr_return` is not assigned, the allocated memory for `hdr0` is never released, leading to a denial of service over time as memory is exhausted.",
        "func": "__zzip_parse_root_directory(int fd,\n                            struct _disk_trailer *trailer,\n                            struct zzip_dir_hdr **hdr_return,\n                            zzip_plugin_io_t io,\n                            zzip_off_t filesize)\n{\n    auto struct zzip_disk_entry dirent;\n    struct zzip_dir_hdr *hdr;\n    struct zzip_dir_hdr *hdr0;\n    uint16_t *p_reclen = 0;\n    zzip_off64_t entries;\n    zzip_off64_t zz_offset;     /* offset from start of root directory */\n    char *fd_map = 0;\n    zzip_off64_t zz_fd_gap = 0;\n    zzip_off64_t zz_entries = _disk_trailer_localentries(trailer);\n    zzip_off64_t zz_rootsize = _disk_trailer_rootsize(trailer);\n    zzip_off64_t zz_rootseek = _disk_trailer_rootseek(trailer);\n    __correct_rootseek(zz_rootseek, zz_rootsize, trailer);\n\n    if (zz_entries <= 0 || zz_rootsize < 0 ||\n        zz_rootseek < 0 || zz_rootseek >= filesize)\n        return ZZIP_CORRUPTED;\n\n    hdr0 = (struct zzip_dir_hdr *) malloc(zz_rootsize);\n    if (! hdr0)\n        return ZZIP_DIRSIZE;\n    hdr = hdr0;\n    __debug_dir_hdr(hdr);\n\n    if (USE_MMAP && io->fd.sys)\n    {\n        zz_fd_gap = zz_rootseek & (_zzip_getpagesize(io->fd.sys) - 1);\n        HINT4(\" fd_gap=%ld, mapseek=0x%lx, maplen=%ld\", (long) (zz_fd_gap),\n              (long) (zz_rootseek - zz_fd_gap),\n              (long) (zz_rootsize + zz_fd_gap));\n        fd_map =\n            _zzip_mmap(io->fd.sys, fd, zz_rootseek - zz_fd_gap,\n                       zz_rootsize + zz_fd_gap);\n        /* if mmap failed we will fallback to seek/read mode */\n        if (fd_map == MAP_FAILED)\n        {\n            NOTE2(\"map failed: %s\", strerror(errno));\n            fd_map = 0;\n        } else\n        {\n            HINT3(\"mapped *%p len=%li\", fd_map,\n                  (long) (zz_rootsize + zz_fd_gap));\n        }\n    }\n\n    for (entries=0, zz_offset=0; ; entries++)\n    {\n        register struct zzip_disk_entry *d;\n        uint16_t u_extras, u_comment, u_namlen;\n\n#     ifndef ZZIP_ALLOW_MODULO_ENTRIES\n        if (entries >= zz_entries) {\n            if (zz_offset + 256 < zz_rootsize) {\n                FAIL4(\"%li's entry is long before the end of directory - enable modulo_entries? (O:%li R:%li)\",\n                      (long) entries, (long) (zz_offset), (long) zz_rootsize);\n            }\n            break;\n        }\n#     endif\n\n        if (fd_map)\n        {\n            d = (void*)(fd_map+zz_fd_gap+zz_offset); /* fd_map+fd_gap==u_rootseek */\n        } else\n        {\n            if (io->fd.seeks(fd, zz_rootseek + zz_offset, SEEK_SET) < 0)\n\t    {\n\t    \tfree(hdr0);\n                return ZZIP_DIR_SEEK;\n\t    }\n            if (io->fd.read(fd, &dirent, sizeof(dirent)) < __sizeof(dirent))\n\t    {\n\t    \tfree(hdr0);\n                return ZZIP_DIR_READ;\n\t    }\n            d = &dirent;\n        }\n\n        if ((zzip_off64_t) (zz_offset + sizeof(*d)) > zz_rootsize ||\n            (zzip_off64_t) (zz_offset + sizeof(*d)) < 0)\n        {\n            FAIL4(\"%li's entry stretches beyond root directory (O:%li R:%li)\",\n                  (long) entries, (long) (zz_offset), (long) zz_rootsize);\n            break;\n        }\n\n        if (! zzip_disk_entry_check_magic(d)) {\n#        ifndef ZZIP_ALLOW_MODULO_ENTRIES\n            FAIL4(\"%li's entry has no disk_entry magic indicator (O:%li R:%li)\",\n                  (long) entries, (long) (zz_offset), (long) zz_rootsize);\n#        endif\n            break;\n        }\n\n#       if 0 && defined DEBUG\n        zzip_debug_xbuf((unsigned char *) d, sizeof(*d) + 8);\n#       endif\n\n        u_extras = zzip_disk_entry_get_extras(d);\n        u_comment = zzip_disk_entry_get_comment(d);\n        u_namlen = zzip_disk_entry_get_namlen(d);\n        HINT5(\"offset=0x%lx, size %ld, dirent *%p, hdr %p\\n\",\n              (long) (zz_offset + zz_rootseek), (long) zz_rootsize, d, hdr);\n\n        /* writes over the read buffer, Since the structure where data is\n           copied is smaller than the data in buffer this can be done.\n           It is important that the order of setting the fields is considered\n           when filling the structure, so that some data is not trashed in\n           first structure read.\n           at the end the whole copied list of structures  is copied into\n           newly allocated buffer */\n        hdr->d_crc32 = zzip_disk_entry_get_crc32(d);\n        hdr->d_csize = zzip_disk_entry_get_csize(d);\n        hdr->d_usize = zzip_disk_entry_get_usize(d);\n        hdr->d_off = zzip_disk_entry_get_offset(d);\n        hdr->d_compr = zzip_disk_entry_get_compr(d);\n        if (hdr->d_compr > _255)\n            hdr->d_compr = 255;\n\n        if ((zzip_off64_t) (zz_offset + sizeof(*d) + u_namlen) > zz_rootsize ||\n            (zzip_off64_t) (zz_offset + sizeof(*d) + u_namlen) < 0)\n        {\n            FAIL4(\"%li's name stretches beyond root directory (O:%li N:%li)\",\n                  (long) entries, (long) (zz_offset), (long) (u_namlen));\n            break;\n        }\n\n        if (fd_map)\n            {  memcpy(hdr->d_name, fd_map+zz_fd_gap + zz_offset+sizeof(*d), u_namlen); }\n        else\n            { io->fd.read(fd, hdr->d_name, u_namlen); }\n        hdr->d_name[u_namlen] = '\\0';\n        hdr->d_namlen = u_namlen;\n\n        /* update offset by the total length of this entry -> next entry */\n        zz_offset += sizeof(*d) + u_namlen + u_extras + u_comment;\n\n        if (zz_offset > zz_rootsize)\n        {\n            FAIL3(\"%li's entry stretches beyond root directory (O:%li)\",\n                  (long) entries, (long) (zz_offset));\n            entries ++;\n            break;\n        }\n\n        HINT5(\"file %ld { compr=%d crc32=$%x offset=%d\",\n              (long) entries, hdr->d_compr, hdr->d_crc32, hdr->d_off);\n        HINT5(\"csize=%d usize=%d namlen=%d extras=%d\",\n              hdr->d_csize, hdr->d_usize, u_namlen, u_extras);\n        HINT5(\"comment=%d name='%s' %s <sizeof %d> } \",\n              u_comment, hdr->d_name, \"\", (int) sizeof(*d));\n\n        p_reclen = &hdr->d_reclen;\n\n        {\n            register char *p = (char *) hdr;\n            register char *q = aligned4(p + sizeof(*hdr) + u_namlen + 1);\n            *p_reclen = (uint16_t) (q - p);\n            hdr = (struct zzip_dir_hdr *) q;\n        }\n    }                           /*for */\n\n    if (USE_MMAP && fd_map)\n    {\n        HINT3(\"unmap *%p len=%li\", fd_map, (long) (zz_rootsize + zz_fd_gap));\n        _zzip_munmap(io->fd.sys, fd_map, zz_rootsize + zz_fd_gap);\n    }\n\n    if (p_reclen)\n    {\n        *p_reclen = 0;          /* mark end of list */\n\n        if (hdr_return)\n            *hdr_return = hdr0;\n\telse\n\t{\n\t    /* If it is not assigned to *hdr_return, it will never be free()'d */\n\t    free(hdr0);\n\t}\n    }                           /* else zero (sane) entries */\n#  ifndef ZZIP_ALLOW_MODULO_ENTRIES\n    return (entries != zz_entries) ? ZZIP_CORRUPTED : 0;\n#  else\n    return ((entries & (unsigned)0xFFFF) != zz_entries) ? ZZIP_CORRUPTED : 0;\n#  endif\n}",
        "commit_message": "One more free() to avoid memory leak.",
        "cve_desc": "An issue was discovered in ZZIPlib through 0.13.69. There is a memory leak triggered in the function __zzip_parse_root_directory in zip.c, which will lead to a denial of service attack.",
        "target": 1
      }
    ]
  }
}