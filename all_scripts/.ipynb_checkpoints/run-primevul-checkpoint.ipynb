{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecdd0c6c-f870-4994-940f-ecb1d02605e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import pprint\n",
    "import re\n",
    "\n",
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1aca1ef2-3854-4087-acec-f62f61805a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEW_SHOT_PROMPT = \"\"\"\n",
    "Example 1:\n",
    "Commit Message: \"Use version in SSL_METHOD not SSL structure.\n",
    "When deciding whether to use TLS 1.2 PRF and record hash algorithms use the version number in the corresponding SSL_METHOD structure instead of the SSL structure. The SSL structure version is sometimes inaccurate. Note: OpenSSL 1.0.2 and later effectively do this already. (CVE-2013-6449)\"\n",
    "Function Code:\n",
    "\" long ssl_get_algorithm2(SSL *s)\n",
    "{{\n",
    "    long alg2 = s->s3->tmp.new_cipher->algorithm2;\n",
    "    if (TLS1_get_version(s) >= TLS1_2_VERSION &&\n",
    "        alg2 == (SSL_HANDSHAKE_MAC_DEFAULT|TLS1_PRF))\n",
    "        return SSL_HANDSHAKE_MAC_SHA256 | TLS1_PRF_SHA256;\n",
    "    return alg2;\n",
    "}}\"\n",
    "Chain-of-Thought: The commit message clearly references CVE-2013-6449 and the function logic relies on an inaccurate version number from the SSL structure. This indicates a vulnerability.\n",
    "Answer: Yes\n",
    "\n",
    "Example 2:\n",
    "Commit Message: \"None\"\n",
    "Function Code:\n",
    "\"gnutls_session_get_data (gnutls_session_t session,\n",
    "                         void *session_data, size_t * session_data_size)\n",
    "{{\n",
    "  gnutls_datum_t psession;\n",
    "  int ret;\n",
    "  if (session->internals.resumable == RESUME_FALSE)\n",
    "    return GNUTLS_E_INVALID_SESSION;\n",
    "  psession.data = session_data;\n",
    "  ret = _gnutls_session_pack (session, &psession);\n",
    "  if (ret < 0)\n",
    "    {{\n",
    "       gnutls_assert ();\n",
    "       return ret;\n",
    "     }}\n",
    "  *session_data_size = psession.size;\n",
    "  if (psession.size > *session_data_size)\n",
    "     {{\n",
    "       ret = GNUTLS_E_SHORT_MEMORY_BUFFER;\n",
    "       goto error;\n",
    "     }}\n",
    "  if (session_data != NULL)\n",
    "     memcpy (session_data, psession.data, psession.size);\n",
    "  ret = 0;\n",
    "error:\n",
    "  _gnutls_free_datum (&psession);\n",
    "  return ret;\n",
    "}}\"\n",
    "Chain-of-Thought: The function calls memcpy without sufficient boundary checks and the context mentions CWE-119 and CVE-2011-4128. This is indicative of a buffer overflow vulnerability.\n",
    "Answer: Yes\n",
    "\n",
    "Example 3:\n",
    "Commit Message: \"None\"\n",
    "Function Code:\n",
    "\"gnutls_session_get_data (gnutls_session_t session,\n",
    "                         void *session_data, size_t * session_data_size)\n",
    "{{\n",
    "  gnutls_datum_t psession;\n",
    "  int ret;\n",
    "  if (session->internals.resumable == RESUME_FALSE)\n",
    "    return GNUTLS_E_INVALID_SESSION;\n",
    "  psession.data = session_data;\n",
    "  ret = _gnutls_session_pack (session, &psession);\n",
    "  if (ret < 0)\n",
    "    {{\n",
    "      gnutls_assert ();\n",
    "      return ret;\n",
    "    }}\n",
    "  if (psession.size > *session_data_size)\n",
    "     {{\n",
    "       ret = GNUTLS_E_SHORT_MEMORY_BUFFER;\n",
    "       goto error;\n",
    "     }}\n",
    "  if (session_data != NULL)\n",
    "    memcpy (session_data, psession.data, psession.size);\n",
    "  ret = 0;\n",
    "error:\n",
    "  _gnutls_free_datum (&psession);\n",
    "  return ret;\n",
    "}}\"\n",
    "Chain-of-Thought: This function is nearly identical to Example 2. It exhibits a risk of buffer overflow due to inadequate checking before memcpy. The associated vulnerability is confirmed by CWE-119.\n",
    "Answer: Yes\n",
    "\n",
    "Now, I want you to act as a software vulnerability detector. Based on the commit message and the code snippet provided, determine if the commit introduces a vulnerability. Answer with \"Yes\" for vulnerable and \"No\" for not vulnerable. Provide a brief explanation of your reasoning.\n",
    "\n",
    "Commit Message: \"{commit_message}\"\n",
    "Function Code:\n",
    "{func}\n",
    "Chain-of-Thought:\n",
    "\"\"\"\n",
    "\n",
    "# New sample data (for instance, from data point idx 0)\n",
    "NEW_SAMPLE_COMMIT_MESSAGE = (\n",
    "    \"Use version in SSL_METHOD not SSL structure.\\n\\n\"\n",
    "    \"When deciding whether to use TLS 1.2 PRF and record hash algorithms\\n\"\n",
    "    \"use the version number in the corresponding SSL_METHOD structure\\n\"\n",
    "    \"instead of the SSL structure. The SSL structure version is sometimes inaccurate. \"\n",
    "    \"Note: OpenSSL 1.0.2 and later effectively do this already.\\n(CVE-2013-6449)\"\n",
    ")\n",
    "\n",
    "NEW_SAMPLE_FUNC = (\n",
    "    \" long ssl_get_algorithm2(SSL *s)\\n\"\n",
    "    \"        {{\\n\"\n",
    "    \"        long alg2 = s->s3->tmp.new_cipher->algorithm2;\\n\"\n",
    "    \"       if (TLS1_get_version(s) >= TLS1_2_VERSION &&\\n\"\n",
    "    \"            alg2 == (SSL_HANDSHAKE_MAC_DEFAULT|TLS1_PRF))\\n\"\n",
    "    \"                return SSL_HANDSHAKE_MAC_SHA256 | TLS1_PRF_SHA256;\\n\"\n",
    "    \"        return alg2;\\n\"\n",
    "    \"        }}\\n\"\n",
    ")\n",
    "\n",
    "# Construct the final prompt by inserting the new sample data\n",
    "final_prompt = FEW_SHOT_PROMPT.format(\n",
    "    commit_message=NEW_SAMPLE_COMMIT_MESSAGE,\n",
    "    func=NEW_SAMPLE_FUNC\n",
    ")\n",
    "\n",
    "# MODEL_NAME = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcea8de0-71e8-4b69-8d25-75a3668c83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_TOKEN = \"\"\n",
    "cache_dir = \"/speed-scratch/ra_mdash/tmp/huggingface\"\n",
    "model_name = \"google/codegemma-2b\" #\"bigcode/starcoder2-3b\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, cache_dir=cache_dir, use_auth_token=HUGGINGFACE_TOKEN)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=cache_dir, use_auth_token=HUGGINGFACE_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f4dc8658-dc0d-4f4a-868f-cc7945b4f878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Output:\n",
      "\n",
      "Example 1:\n",
      "Commit Message: \"Use version in SSL_METHOD not SSL structure.\n",
      "When deciding whether to use TLS 1.2 PRF and record hash algorithms use the version number in the corresponding SSL_METHOD structure instead of the SSL structure. The SSL structure version is sometimes inaccurate. Note: OpenSSL 1.0.2 and later effectively do this already. (CVE-2013-6449)\"\n",
      "Function Code:\n",
      "\" long ssl_get_algorithm2(SSL *s)\n",
      "{\n",
      "    long alg2 = s->s3->tmp.new_cipher->algorithm2;\n",
      "    if (TLS1_get_version(s) >= TLS1_2_VERSION &&\n",
      "        alg2 == (SSL_HANDSHAKE_MAC_DEFAULT|TLS1_PRF))\n",
      "        return SSL_HANDSHAKE_MAC_SHA256 | TLS1_PRF_SHA256;\n",
      "    return alg2;\n",
      "}\"\n",
      "Chain-of-Thought: The commit message clearly references CVE-2013-6449 and the function logic relies on an inaccurate version number from the SSL structure. This indicates a vulnerability.\n",
      "Answer: Yes\n",
      "\n",
      "Example 2:\n",
      "Commit Message: \"None\"\n",
      "Function Code:\n",
      "\"gnutls_session_get_data (gnutls_session_t session,\n",
      "                         void *session_data, size_t * session_data_size)\n",
      "{\n",
      "  gnutls_datum_t psession;\n",
      "  int ret;\n",
      "  if (session->internals.resumable == RESUME_FALSE)\n",
      "    return GNUTLS_E_INVALID_SESSION;\n",
      "  psession.data = session_data;\n",
      "  ret = _gnutls_session_pack (session, &psession);\n",
      "  if (ret < 0)\n",
      "    {\n",
      "       gnutls_assert ();\n",
      "       return ret;\n",
      "     }\n",
      "  *session_data_size = psession.size;\n",
      "  if (psession.size > *session_data_size)\n",
      "     {\n",
      "       ret = GNUTLS_E_SHORT_MEMORY_BUFFER;\n",
      "       goto error;\n",
      "     }\n",
      "  if (session_data != NULL)\n",
      "     memcpy (session_data, psession.data, psession.size);\n",
      "  ret = 0;\n",
      "error:\n",
      "  _gnutls_free_datum (&psession);\n",
      "  return ret;\n",
      "}\"\n",
      "Chain-of-Thought: The function calls memcpy without sufficient boundary checks and the context mentions CWE-119 and CVE-2011-4128. This is indicative of a buffer overflow vulnerability.\n",
      "Answer: Yes\n",
      "\n",
      "Example 3:\n",
      "Commit Message: \"None\"\n",
      "Function Code:\n",
      "\"gnutls_session_get_data (gnutls_session_t session,\n",
      "                         void *session_data, size_t * session_data_size)\n",
      "{\n",
      "  gnutls_datum_t psession;\n",
      "  int ret;\n",
      "  if (session->internals.resumable == RESUME_FALSE)\n",
      "    return GNUTLS_E_INVALID_SESSION;\n",
      "  psession.data = session_data;\n",
      "  ret = _gnutls_session_pack (session, &psession);\n",
      "  if (ret < 0)\n",
      "    {\n",
      "      gnutls_assert ();\n",
      "      return ret;\n",
      "    }\n",
      "  if (psession.size > *session_data_size)\n",
      "     {\n",
      "       ret = GNUTLS_E_SHORT_MEMORY_BUFFER;\n",
      "       goto error;\n",
      "     }\n",
      "  if (session_data != NULL)\n",
      "    memcpy (session_data, psession.data, psession.size);\n",
      "  ret = 0;\n",
      "error:\n",
      "  _gnutls_free_datum (&psession);\n",
      "  return ret;\n",
      "}\"\n",
      "Chain-of-Thought: This function is nearly identical to Example 2. It exhibits a risk of buffer overflow due to inadequate checking before memcpy. The associated vulnerability is confirmed by CWE-119.\n",
      "Answer: Yes\n",
      "\n",
      "Now, I want you to act as a software vulnerability detector. Based on the commit message and the code snippet provided, determine if the commit introduces a vulnerability. Answer with \"Yes\" for vulnerable and \"No\" for not vulnerable. Provide a brief explanation of your reasoning.\n",
      "\n",
      "Commit Message: \"Use version in SSL_METHOD not SSL structure.\n",
      "\n",
      "When deciding whether to use TLS 1.2 PRF and record hash algorithms\n",
      "use the version number in the corresponding SSL_METHOD structure\n",
      "instead of the SSL structure. The SSL structure version is sometimes inaccurate. Note: OpenSSL 1.0.2 and later effectively do this already.\n",
      "(CVE-2013-6449)\"\n",
      "Function Code:\n",
      " long ssl_get_algorithm2(SSL *s)\n",
      "        {{\n",
      "        long alg2 = s->s3->tmp.new_cipher->algorithm2;\n",
      "       if (TLS1_get_version(s) >= TLS1_2_VERSION &&\n",
      "            alg2 == (SSL_HANDSHAKE_MAC_DEFAULT|TLS1_PRF))\n",
      "                return SSL_HANDSHAKE_MAC_SHA256 | TLS1_PRF_SHA256;\n",
      "        return alg2;\n",
      "        }}\n",
      "\n",
      "Chain-of-Thought:\n",
      "The commit message clearly references CVE-2013-6449 and the function logic relies on an inaccurate version number from the SSL structure. This indicates a vulnerability.\n",
      "\n",
      "Answer: Yes\n",
      "\n",
      "Commit Message: \"None\"\n",
      "Function Code:\n",
      " gnutls_session_get_data (gnutls_session_t session,\n",
      "                         void *session_data, size_t * session_data_size)\n",
      " {\n",
      "  gnutls_datum\n",
      "Parsed output\n",
      "Yes\n",
      "The commit message clearly references CVE-2013-6449 and the function logic relies on an inaccurate version number from the SSL structure. This indicates a vulnerability.\n"
     ]
    }
   ],
   "source": [
    "# Create a text-generation pipeline.\n",
    "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
    "\n",
    "# Set parameters for generation.\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 100,\n",
    "    \"temperature\": 0.1,\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "\n",
    "# Run inference with the prompt.\n",
    "output = generator(final_prompt, **generation_args)\n",
    "match = re.search(r'Answer:\\s*(Yes|No)', output[0]['generated_text'], re.IGNORECASE)\n",
    "if match:\n",
    "   match = match.group(1)\n",
    "\n",
    "cot = re.search(r'Chain-of-thought:\\s*(.*)', output[0]['generated_text'], re.IGNORECASE)\n",
    "if cot:\n",
    "    cot = cot.group(1).split(\"\\n\")[0]  # Extract the first line after \"Chain-of-thought:\"\n",
    "\n",
    "print(\"Inference Output:\")\n",
    "print(output[0]['generated_text'])\n",
    "print(\"Parsed output\")\n",
    "print(match)\n",
    "print(cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c75e7b3-f9fb-4a0d-a3d1-2e452be4d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4630f91-8776-4cc2-b951-508a4a71750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "On the other hand, I have a list of \"projects\" in another file. I want to collect 5 data samples of each project from this train.jsonl file where the target=0 and 5 5 data samples where the target=1. Then I will save them as a mapping where key is the project, and values are data samples nested by target. \n",
    "\n",
    "Please write the python code for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919541a0-554b-4c53-808f-235f0b7dadad",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"PrimeVul_v0.1/primevul_valid.jsonl\"\n",
    "count = 0\n",
    "max_test = 5000\n",
    "results = []\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if count < max_test:\n",
    "            if line.strip():  # Skip empty lines\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\"Error decoding JSON: {e}\")\n",
    "                    continue\n",
    "    \n",
    "                # Extract the fields\n",
    "                project = data.get(\"project\", \"\"),\n",
    "                # commit_message = data.get(\"commit_message\", \"\")\n",
    "                # func = data.get(\"func\", \"\")\n",
    "                # target = data.get(\"target\", \"\")\n",
    "                # cwe = data.get(\"cwe\", [])\n",
    "                # cve = data.get(\"cve\", \"\")\n",
    "                # cve_desc = data.get(\"cve_desc\", \"\")\n",
    "    \n",
    "                # Call get_result with the extracted fields\n",
    "                result = 1 #get_result(commit_message, func, target, cwe, cve, cve_desc)\n",
    "    \n",
    "                # Build an output dictionary with the required fields and result\n",
    "                output_data = {\n",
    "                    \"project\": project,\n",
    "                    # \"commit_message\": commit_message,\n",
    "                    # \"func\": func,\n",
    "                    # \"target\": target,\n",
    "                    # \"cwe\": cwe,\n",
    "                    # \"cve\": cve,\n",
    "                    # \"cve_desc\": cve_desc,\n",
    "                    # \"result\": result\n",
    "                }\n",
    "                results.append(output_data)\n",
    "\n",
    "                count = count + 1\n",
    "\n",
    "                # Pause periodically (e.g., one second) before processing the next record.\n",
    "                time.sleep(1)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3945e143-d94b-437c-97b3-20ed70712202",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 217 unique projects.\n",
      "['389-ds-base', 'Chrome', 'FFmpeg', 'FreeRDP', 'FreeRTOS-Kernel', 'GIMP', 'ImageMagick', 'ImageMagick6', 'LibRaw', 'LuaJIT', 'OpenDoas', 'OpenSC', 'Pillow', 'SoftHSMv2', 'abcm2ps', 'acl', 'acrn-hypervisor', 'ardour', 'ast', 'asylo', 'at91bootstrap', 'atomicparsley', 'bash', 'bdwgc', 'bfgminer', 'bootstrap-dht', 'bsdiff4', 'bwm-ng', 'bzip2', 'c-ares', 'c-blosc2', 'ceph', 'cgit', 'clamav-devel', 'clutter', 'contiki-ng', 'core', 'cpio', 'cpp-peglib', 'crawl', 'curl', 'cyrus-imapd', 'doom-vanille', 'dpdk', 'edk2', 'electron', 'envoy', 'exif', 'exim', 'exiv2', 'faad2', 'flac', 'flatpak', 'fluent-bit', 'fontforge', 'gd-libgd', 'gegl', 'ghostpdl', 'gilcc', 'git', 'glibc', 'gnulib', 'gnumeric', 'gnuplot', 'gnutls', 'gpac', 'graphviz', 'grep', 'gssproxy', 'gst-plugins-good', 'haproxy', 'hermes', 'hhvm', 'hivex', 'htmldoc', 'htslib', 'httpd', 'icu', 'inspircd', 'ipmitool', 'iproute2', 'isolated-vm', 'jasper', 'jerryscript', 'jhead', 'jsish', 'kdeconnect-kde', 'keepkey-firmware', 'kitty', 'kopano-core', 'krb5', 'kvm', 'ldns', 'leptonica', 'libarchive', 'libavif', 'libdwarf-code', 'libevent', 'libexif', 'libexpat', 'libfuse', 'libgcrypt', 'libguestfs', 'libiec61850', 'libjpeg-turbo', 'libming', 'librepo', 'libslirp', 'libsolv', 'libssh', 'libssh-mirror', 'libssh2', 'libtiff', 'libtomcrypt', 'libtpms', 'libuv', 'libvirt', 'libvncserver', 'libxml2', 'libxslt', 'libyang', 'lighttpd1.4', 'linux', 'linux-2.6', 'linux-pam', 'lua', 'mariadb-connector-c', 'mbed-coap', 'minetest', 'mod_auth_openidc', 'mongo', 'mono', 'mpv', 'mruby', 'mupdf', 'mutt', 'mysql-wsrep', 'nDPI', 'nanopb', 'nasm', 'neomutt', 'net', 'net-next', 'nettle', 'nginx', 'node', 'opaque', 'openexr', 'openfortivpn', 'openjpeg', 'openldap', 'openmpt', 'openssh-portable', 'openssl', 'openthread', 'openvpn', 'ovs', 'p11-kit', 'patch', 'pdfresurrect', 'perl5', 'phosphor-host-ipmid', 'php-src', 'pigeonhole', 'pjproject', 'poppler', 'postgres', 'postsrsd', 'pupnp', 'pure-ftpd', 'qemu', 'qpdf', 'radare2', 'radvd', 'redcarpet', 'redis', 'rpm', 'rsync', 'rsyslog', 'ruby', 'samba', 'samurai', 'selinux', 'serenity', 'server', 'skiboot', 'sleuthkit', 'slurm', 'soundtouch', 'spnego-http-auth-nginx-module', 'sqlite', 'squid', 'src', 'sudo', 'swtpm', 'tcpdump', 'teeworlds', 'tensorflow', 'tip', 'tk', 'u-boot', 'udev', 'unbound', 'unicorn', 'univention-corporate-server', 'upx', 'util-linux', 'varnish-modules', 'veyon', 'vim', 'w3m', 'wget', 'wireshark', 'x11vnc', 'xbmc', 'znc', 'zziplib']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "unique_projects = set()\n",
    "\n",
    "input_file = \"PrimeVul_v0.1/primevul_valid.jsonl\"\n",
    "count = 0\n",
    "max_test = 5000\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if count < max_test:\n",
    "            data = json.loads(line)\n",
    "            project = data.get(\"project\")\n",
    "            if project:\n",
    "                unique_projects.add(project)\n",
    "\n",
    "# Convert to sorted list if you want it in order\n",
    "unique_projects = sorted(unique_projects)\n",
    "\n",
    "# Optionally, write to a file\n",
    "with open(\"unique_projects.txt\", \"w\") as out_file:\n",
    "    for project in unique_projects:\n",
    "        out_file.write(project + \"\\n\")\n",
    "\n",
    "# If you just want to print the result\n",
    "print(\"Found\", len(unique_projects), \"unique projects.\")\n",
    "print(unique_projects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1186bdd-d5d6-4a5e-9bf4-a36dbf61f2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232019ac-c8d1-40e9-affa-1891e506061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8c76855-fd39-4447-b189-019c679ae577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the list of projects\n",
    "# with open(\"projects.txt\", \"r\") as f:\n",
    "#     projects = set(line.strip() for line in f if line.strip())\n",
    "\n",
    "projects = unique_projects #df[\"projects\"]\n",
    "\n",
    "# Initialize the dictionary to hold samples\n",
    "project_samples = {\n",
    "    project: {0: [], 1: []} for project in projects\n",
    "}\n",
    "\n",
    "# Read the JSONL file and collect samples\n",
    "with open(\"PrimeVul_v0.1/primevul_train.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        project = data.get(\"project\")\n",
    "        target = data.get(\"target\")\n",
    "\n",
    "        # Check if the project is one we're interested in\n",
    "        if project in projects and len(project_samples[project][target]) < 5:\n",
    "            project_samples[project][target].append(data)\n",
    "\n",
    "        # Stop early if we’ve collected all needed samples\n",
    "        if all(len(project_samples[p][0]) == 5 and len(project_samples[p][1]) == 5 for p in projects):\n",
    "            break\n",
    "\n",
    "# Save the results\n",
    "with open(\"project_sample_mapping.json\", \"w\") as out_file:\n",
    "    json.dump(project_samples, out_file, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "835a54f8-a251-4a67-969a-f248aed84d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'starcoder2-3b'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"bigcode/starcoder2-3b\"\n",
    "model_name = model_id.split(\"/\")[1]\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9901d8-0c98-4089-8961-7f4990e885f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "`low_cpu_mem_usage` was None, now default to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca7ef8658222414f81f61b92af7a95a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:100001 for open-end generation.\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#write a quick sort algorithm\n",
      "#quick sort is a divide and conquer algorithm\n",
      "#it works by selecting a pivot element and then partitioning the array into two subarrays, one with elements less than the pivot and one with elements greater than the pivot\n",
      "#the pivot element is then placed in its correct position in the sorted array\n",
      "#the process is then repeated on the two subarrays until the entire array is sorted\n",
      "#the time complexity of quick sort is O(nlogn) in the average case and O(n^2) in the worst case\n",
      "#the space complexity of quick sort is O(logn\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "cache_dir = \"/speed-scratch/ra_mdash/tmp/huggingface\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\", trust_remote_code=True, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Base\", trust_remote_code=True, \n",
    "                                             load_in_8bit=True, \n",
    "                                             # torch_dtype=torch.bfloat16, \n",
    "                                             cache_dir=cache_dir)\n",
    "input_text = \"#write a quick sort algorithm\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_length=128)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effc0e1f-3650-44e9-8881-b3340e3867eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "cache_dir = \"/speed-scratch/ra_mdash/tmp/huggingface\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\", trust_remote_code=True, cache_dir=cache_dir)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct\", trust_remote_code=True, \n",
    "                                             load_in_8bit=True, \n",
    "                                             # torch_dtype=torch.bfloat16, \n",
    "                                             cache_dir=cache_dir)\n",
    "messages=[\n",
    "    { 'role': 'user', 'content': \"write a quick sort algorithm in python.\"}\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(messages, add_generation_prompt=True, return_tensors=\"pt\").to(model.device)\n",
    "# tokenizer.eos_token_id is the id of <｜end▁of▁sentence｜>  token\n",
    "outputs = model.generate(inputs, max_new_tokens=512, do_sample=False, top_k=50, top_p=0.95, num_return_sequences=1, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(outputs[0][len(inputs[0]):], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39004eb-77a6-4915-a102-5103394a09f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c9ef30b-d473-4c3f-8d47-9909154970c2",
   "metadata": {},
   "source": [
    "### Run scripts on SLURM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d101bbba-5480-4673-9449-b580491ce620",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext slurm_magic\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3685f8d5-4f93-4b37-8d3c-12b92e4929a5",
   "metadata": {},
   "source": [
    "### Zero-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd2ec51-a484-4d20-b77f-af778301ba1a",
   "metadata": {},
   "source": [
    "#### Run starcoder2-3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0647ec83-7d5f-4356-a4b3-fd02ad30c425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 516590\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --mem=32G               ## Assign 1G memory per node \n",
    "#SBATCH --gres=gpu:2\n",
    "\n",
    "python run-primevul.py "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaccfed1-350b-43c9-aef7-be6a9632a284",
   "metadata": {},
   "source": [
    "#### Run Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "177124d6-51f0-4c85-9d18-58ed1e2765f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 516574\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --mem=32G               ## Assign 1G memory per node \n",
    "#SBATCH --gres=gpu:2\n",
    "\n",
    "python run-primevul.py --model_id meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7ec866-0a42-4df5-9531-6cad6a99499b",
   "metadata": {},
   "source": [
    "#### Run Qwen2.5-Coder-3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9d5d11f-0b4e-42fc-90c3-39c028bebac3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 516673\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --mem=32G               ## Assign 1G memory per node \n",
    "#SBATCH --gres=gpu:2\n",
    "\n",
    "python run-primevul.py --model_id Qwen/Qwen2.5-Coder-3B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b7615ad-6f3a-4484-b45b-2fc4d7cd5039",
   "metadata": {},
   "source": [
    "#### Run DeepSeek-Coder-V2-Lite-Instruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6484bab1-c024-4938-ba5b-466e61e625d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 516856\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "python run-primevul.py --model_id deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct #--data_path /speed-scratch/ra_mdash/PrimeVul_v0.1/sample_data.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20351344-68a4-4f22-ad31-e91b9180cae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 516838\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "python run-primevul-deepseek.py --model_id deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct --data_path /speed-scratch/ra_mdash/PrimeVul_v0.1/sample_data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceca77da-d79a-4d48-ae52-085da719ee77",
   "metadata": {},
   "source": [
    "#### Run codegemma-7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49e9a89a-84ba-49da-aa36-78be0f467797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 518969\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul_cg7        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "python run-primevul-codegemma.py --model_id google/codegemma-7b-it #--data_path /speed-scratch/ra_mdash/PrimeVul_v0.1/sample_data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16079ff-b850-4cb3-9079-80a8a08c70da",
   "metadata": {},
   "source": [
    "### Few-shot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159b310f-f985-4e1e-af80-646cc3bf7954",
   "metadata": {},
   "source": [
    "#### Submit jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072d29b5-8389-469f-ac9a-299b8f26cae5",
   "metadata": {},
   "source": [
    "#### Run starcoder2-3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b6c28a-c7d2-4854-81ec-2dd433e018f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 519373\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=few_shot        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "python run-primevul-few-shot.py #--model_id google/codegemma-2b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d62e37-1bc0-46ac-b4a3-87e27b257e39",
   "metadata": {},
   "source": [
    "#### Run Llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d2d5d23-639b-4f0d-b85a-3f1e1477487d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 519289\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=few_shot        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "python run-primevul-few-shot.py --model_id meta-llama/Llama-3.2-3B-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4af0d3a-58dd-4227-9c59-4639d792e13e",
   "metadata": {},
   "source": [
    "#### Run Qwen2.5-Coder-3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b11f58e-e270-44c3-bd29-36719269fcf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 519375\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=prime_vul        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --mem=160G               ## Assign 1G memory per node \n",
    "#SBATCH --gres=gpu:2\n",
    "\n",
    "python run-primevul-few-shot.py --model_id Qwen/Qwen2.5-Coder-3B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5baeda-b662-4cf9-93bc-64a144ad88c0",
   "metadata": {},
   "source": [
    "#### Generate Few-shot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345284ae-928e-4471-b602-28d1049dfb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 518975\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=few_shot        ## Give the job a name \n",
    "#SBATCH --mail-type=ALL        ## Receive all email type notifications \n",
    "#SBATCH --chdir=./             ## Use currect directory as working directory \n",
    "#SBATCH --nodes=1 \n",
    "#SBATCH --ntasks=1 \n",
    "#SBATCH --cpus-per-task=1\n",
    "#SBATCH --mem=160G                ## Assign 1G memory per node \n",
    "#SBATCH --gpus=2\n",
    "\n",
    "TORCH_USE_CUDA_DSA=1 python generate_few_shot_data.py #--model_id google/codegemma-7b-it #--data_path /speed-scratch/ra_mdash/PrimeVul_v0.1/sample_data.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afee807-4734-4bb8-9d8e-21c6d3338758",
   "metadata": {},
   "source": [
    "#### Create few-shot examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7555d2aa-d6a5-44d1-ab0e-da354317c7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Done! Saved results with few-shot examples to 'PrimeVul_v0.1/primevul_with_4_shot.json'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# ---------------------\n",
    "# 1. Configuration\n",
    "# ---------------------\n",
    "FEW_SHOT_COUNT = 4  # Total number of few-shot examples to retrieve (e.g., 2-shot, 3-shot, 4-shot, etc.)\n",
    "REASONING_FILE = \"reasoning_output.json\"\n",
    "PRIMEVUL_FILE = \"PrimeVul_v0.1/primevul_valid.jsonl\"\n",
    "OUTPUT_FILE = f\"PrimeVul_v0.1/primevul_with_{FEW_SHOT_COUNT}_shot.json\"\n",
    "\n",
    "\n",
    "with open(REASONING_FILE, \"r\") as f:\n",
    "    reasoning_data = json.load(f)\n",
    "\n",
    "def get_reasoning_list(project_name, label):\n",
    "    \"\"\"Return the list for a given project and label (as string) or an empty list if not found.\"\"\"\n",
    "    if project_name in reasoning_data:\n",
    "        return reasoning_data[project_name].get(str(label), [])\n",
    "    return []\n",
    "\n",
    "# ---------------------\n",
    "# 3. Few-Shot Retrieval Logic (with caching)\n",
    "# ---------------------\n",
    "# We create a cache so that for each project we compute the few-shot examples only once.\n",
    "few_shot_cache = {}\n",
    "\n",
    "def get_few_shot_samples(project_name: str, n: int):\n",
    "    \"\"\"\n",
    "    Returns n examples alternating between label 0 and 1 from the given project.\n",
    "    If the project doesn't have enough examples for a label, fallback to 'FFmpeg'.\n",
    "    Also returns a flag indicating whether a fallback was used in any of the shots.\n",
    "    This function does not modify the original reasoning_data lists.\n",
    "    \"\"\"\n",
    "    # Use cache if we've already computed few-shot for this project\n",
    "    if project_name in few_shot_cache:\n",
    "        return few_shot_cache[project_name]\n",
    "    \n",
    "    few_shot = []\n",
    "    fallback_used = False\n",
    "    # Build alternating label cycle: for n=4, e.g., [0, 1, 0, 1]\n",
    "    label_cycle = [0, 1] * n\n",
    "    label_cycle = label_cycle[:n]\n",
    "    \n",
    "    for label in label_cycle:\n",
    "        # Try to get from the target project\n",
    "        proj_list = get_reasoning_list(project_name, label)\n",
    "        if len(proj_list) > 0:\n",
    "            sample = proj_list[0]  # pick the first sample without deleting it\n",
    "            few_shot.append(sample)\n",
    "        else:\n",
    "            # Fallback to FFmpeg\n",
    "            ffmpeg_list = get_reasoning_list(\"FFmpeg\", label)\n",
    "            if len(ffmpeg_list) > 0:\n",
    "                sample = ffmpeg_list[0]\n",
    "                few_shot.append(sample)\n",
    "                fallback_used = True\n",
    "            else:\n",
    "                # If no sample available in FFmpeg either, simply break out.\n",
    "                print(f\"Warning: No sample available for project '{project_name}' (label {label}) and fallback FFmpeg.\")\n",
    "                break\n",
    "\n",
    "    # Cache the result for future use (store both few_shot and fallback flag)\n",
    "    few_shot_cache[project_name] = (few_shot, fallback_used)\n",
    "    return few_shot, fallback_used\n",
    "\n",
    "# ---------------------\n",
    "# 4. Process primevul_valid.jsonl and add few-shot examples line by line\n",
    "# ---------------------\n",
    "results = []\n",
    "\n",
    "with open(PRIMEVUL_FILE, \"r\") as f_in:\n",
    "    for count, line in enumerate(f_in):\n",
    "        # For demonstration, you may limit processing (e.g., count < 5)\n",
    "        # if count >= 5:\n",
    "        #     break\n",
    "        \n",
    "        line_data = json.loads(line)\n",
    "        project_name = line_data.get(\"project\", \"N/A\")\n",
    "\n",
    "        # Retrieve few-shot examples for this project (using cache so they're identical for all samples of the project)\n",
    "        few_shot_samples, fallback = get_few_shot_samples(project_name, FEW_SHOT_COUNT)\n",
    "        few_shot_text = \"\"\n",
    "        \n",
    "        # Format each few-shot example\n",
    "        for few_shot_sample in few_shot_samples:\n",
    "            target_text = \"Yes\" if few_shot_sample.get(\"target\") == 1 else \"No\"\n",
    "            few_shot_text += f\"\"\"\n",
    "Example:\n",
    "commit_message: {few_shot_sample.get(\"commit_message\")}\n",
    "func: {few_shot_sample.get(\"func\")}\n",
    "Answer: {target_text}\n",
    "Reasoning: {few_shot_sample.get(\"reasoning\")}\n",
    "\n",
    "\"\"\"\n",
    "        # Add the few-shot examples (and fallback flag) to the original sample\n",
    "        line_data[\"few_shot_samples\"] = few_shot_text.strip()  # Remove extra whitespace\n",
    "        line_data[\"fallback\"] = fallback\n",
    "        results.append(line_data)\n",
    "\n",
    "# ---------------------\n",
    "# 5. Save the Output\n",
    "# ---------------------\n",
    "with open(OUTPUT_FILE, \"w\") as f_out:\n",
    "    json.dump(results, f_out, indent=2)\n",
    "\n",
    "print(f\"✅ Done! Saved results with few-shot examples to '{OUTPUT_FILE}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd626d6-2d41-4a44-93f9-0e7d4fb2e6ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23948"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd70d34-fa9e-4662-8b96-3a6e6387f4d2",
   "metadata": {},
   "source": [
    "#### Thinking-LLM-as-a-Judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74424093-a8eb-4262-b142-f6a57d711c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 531797\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=deepspeed_llama_80gb  \n",
    "#SBATCH --partition=pt                   \n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8             \n",
    "#SBATCH --mem=160G                    \n",
    "#SBATCH --gres=gpu:nvidia_a100_7g.80gb:1\n",
    "\n",
    "# module purge\n",
    "\n",
    "# # Load necessary modules - **ADD THE CUDA MODULE HERE**\n",
    "# # Replace 'cuda/11.8' with the actual name on your cluster\n",
    "# module load cuda/11.8/default\n",
    "# module load anaconda # Or miniconda, python, etc. depending on your setup\n",
    "# source activate /speed-scratch/ra_mdash/tmp/jupyter-venv # Activate your environment\n",
    "\n",
    "python thinking-llm-as-judge.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e671edcc-c7de-478e-a1e7-948370b03b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 531794\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name=deepspeed_llama_80gb  \n",
    "#SBATCH --partition=pt                   \n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8             \n",
    "#SBATCH --mem=160G                    \n",
    "#SBATCH --gres=gpu:nvidia_a100_7g.80gb:1\n",
    "\n",
    "\n",
    "#--constraint=gpu80         \n",
    "\n",
    "# --- Environment Setup ---\n",
    "echo \"----------------------------------------------------\"\n",
    "echo \"SLURM Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Run on host: $(hostname)\"\n",
    "echo \"Working directory: $(pwd)\"\n",
    "echo \"Start time: $(date)\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "echo \"Setting up environment...\"\n",
    "module purge > /dev/null 2>&1 || echo \"Module purge failed (might be okay).\"\n",
    "\n",
    "echo \"Loading modules...\"\n",
    "module load anaconda/default # Load Anaconda first\n",
    "module load cuda/11.8/default\n",
    "\n",
    "# --- Initialize Conda for this script's shell ---\n",
    "echo \"Sourcing conda.sh to enable conda activate...\"\n",
    "# Construct the path to conda.sh relative to the Anaconda module base path\n",
    "# Adjust if your base anaconda install path is different\n",
    "CONDA_BASE_PATH=$(conda info --base) # Get base path dynamically\n",
    "CONDA_SH_PATH=\"${CONDA_BASE_PATH}/etc/profile.d/conda.sh\"\n",
    "\n",
    "if [ -f \"$CONDA_SH_PATH\" ]; then\n",
    "    source \"$CONDA_SH_PATH\"\n",
    "    echo \"Successfully sourced $CONDA_SH_PATH\"\n",
    "else\n",
    "    echo \"ERROR: Cannot find conda.sh at $CONDA_SH_PATH. Conda activation might fail.\"\n",
    "    # Fallback path guess (less reliable):\n",
    "    # FALLBACK_CONDA_SH=\"/encs/pkg/anaconda3-2023.03/root/etc/profile.d/conda.sh\"\n",
    "    # if [ -f \"$FALLBACK_CONDA_SH\" ]; then\n",
    "    #     source \"$FALLBACK_CONDA_SH\"\n",
    "    #     echo \"Successfully sourced fallback $FALLBACK_CONDA_SH\"\n",
    "    # else\n",
    "    #    echo \"ERROR: Fallback conda.sh not found either.\"\n",
    "    #    exit 1\n",
    "    # fi\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Activate your conda environment using the modern command\n",
    "echo \"Activating conda environment...\"\n",
    "# Define the environment path for clarity\n",
    "MY_CONDA_ENV=\"/speed-scratch/ra_mdash/tmp/deep-env\"\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\" # Source conda functions\n",
    "conda activate \"$MY_CONDA_ENV\"\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"ERROR: Failed to activate conda environment with 'conda activate'.\"\n",
    "    exit 1\n",
    "fi\n",
    "# Define the Python executable path\n",
    "PYTHON_EXEC=\"${MY_CONDA_ENV}/bin/python\"\n",
    "if [ ! -f \"$PYTHON_EXEC\" ]; then\n",
    "    echo \"ERROR: Python executable not found at $PYTHON_EXEC\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Using Python executable: $PYTHON_EXEC\"\n",
    "echo \"Activated environment variable: $CONDA_DEFAULT_ENV\"\n",
    "\n",
    "# --- Manually Correct CUDA Environment Variables ---\n",
    "# ... (export CUDA_HOME, PATH, LD_LIBRARY_PATH - these are still needed for compilation/runtime linking) ...\n",
    "echo \"Manually setting CUDA environment variables...\"\n",
    "export CUDA_HOME=/encs/pkg/cuda-11.8/root\n",
    "if [ -z \"$CUDA_HOME\" ] || [ ! -d \"$CUDA_HOME\" ]; then\n",
    "    echo \"ERROR: CUDA_HOME path is incorrect or directory does not exist: $CUDA_HOME\"\n",
    "    exit 1\n",
    "fi\n",
    "# NOTE: We still prepend CUDA to PATH for nvcc etc., but call python explicitly\n",
    "export PATH=\"${CUDA_HOME}/bin:${PATH}\"\n",
    "export LD_LIBRARY_PATH=\"${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}\"\n",
    "echo \"CUDA_HOME set to: $CUDA_HOME\"\n",
    "\n",
    "\n",
    "# --- Verification (Using Explicit Python Path) ---\n",
    "echo \"--- Environment Verification ---\"\n",
    "echo \"Loaded Modules:\"\n",
    "module list\n",
    "echo \"\"\n",
    "echo \"Explicit Python path: $PYTHON_EXEC\"\n",
    "echo \"Explicit Python version: $($PYTHON_EXEC --version)\" # Call python explicitly\n",
    "echo \"\"\n",
    "echo \"CUDA_HOME: $CUDA_HOME\"\n",
    "echo \"NVCC path: $(which nvcc)\" # which should still work because we added CUDA_HOME/bin to PATH\n",
    "echo \"NVCC version:\"\n",
    "nvcc --version || echo \"WARNING: nvcc command failed!\"\n",
    "echo \"\"\n",
    "echo \"PyTorch Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import torch; print(f'  Torch version: {torch.__version__}'); print(f'  Torch CUDA available: {torch.cuda.is_available()}'); print(f'  Torch CUDA version: {torch.version.cuda}'); print(f'  Torch device count: {torch.cuda.device_count()}')\"\n",
    "echo \"\"\n",
    "echo \"DeepSpeed Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import deepspeed; print(f'  DeepSpeed imported successfully. Version: {deepspeed.__version__}')\" || echo \"WARNING: Failed to import deepspeed!\"\n",
    "echo \"--------------------------\"\n",
    "\n",
    "\n",
    "# --- Set TRITON_CACHE_DIR ---\n",
    "# ... (TRITON_CACHE_DIR remains the same) ...\n",
    "export TRITON_CACHE_DIR=\"/tmp/${USER}_triton_cache_${SLURM_JOB_ID}\"\n",
    "mkdir -p \"$TRITON_CACHE_DIR\"\n",
    "echo \"TRITON_CACHE_DIR set to: $TRITON_CACHE_DIR\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "\n",
    "# --- Run Python Script (Using Explicit Python Path) ---\n",
    "# echo \"Running Python script: /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge-deepspeed.py\"\n",
    "# Execute the main script using the full path to the environment's python\n",
    "\"$PYTHON_EXEC\" /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge-deepspeed.py\n",
    "# if [ $? -ne 0 ]; then\n",
    "#     echo \"ERROR: Python script exited with non-zero status.\"\n",
    "# fi\n",
    "\n",
    "# --- Job Completion ---\n",
    "# ... (Job completion logs remain the same) ...\n",
    "# echo \"----------------------------------------------------\"\n",
    "# echo \"End time: $(date)\"\n",
    "# echo \"Job finished.\"\n",
    "# echo \"----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31d2c4e1-d3ba-4923-8fc2-e9d1b1712f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 531799\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name=deepspeed_llama_80gb  \n",
    "#SBATCH --partition=pt                   \n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8             \n",
    "#SBATCH --mem=160G                    \n",
    "#SBATCH --gres=gpu:nvidia_a100_7g.80gb:1\n",
    "\n",
    "\n",
    "#--constraint=gpu80         \n",
    "\n",
    "# --- Environment Setup ---\n",
    "echo \"----------------------------------------------------\"\n",
    "echo \"SLURM Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Run on host: $(hostname)\"\n",
    "echo \"Working directory: $(pwd)\"\n",
    "echo \"Start time: $(date)\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "echo \"Setting up environment...\"\n",
    "module purge > /dev/null 2>&1 || echo \"Module purge failed (might be okay).\"\n",
    "\n",
    "echo \"Loading modules...\"\n",
    "module load anaconda/default # Load Anaconda first\n",
    "module load cuda/11.8/default\n",
    "\n",
    "# --- Initialize Conda for this script's shell ---\n",
    "echo \"Sourcing conda.sh to enable conda activate...\"\n",
    "# Construct the path to conda.sh relative to the Anaconda module base path\n",
    "# Adjust if your base anaconda install path is different\n",
    "CONDA_BASE_PATH=$(conda info --base) # Get base path dynamically\n",
    "CONDA_SH_PATH=\"${CONDA_BASE_PATH}/etc/profile.d/conda.sh\"\n",
    "\n",
    "if [ -f \"$CONDA_SH_PATH\" ]; then\n",
    "    source \"$CONDA_SH_PATH\"\n",
    "    echo \"Successfully sourced $CONDA_SH_PATH\"\n",
    "else\n",
    "    echo \"ERROR: Cannot find conda.sh at $CONDA_SH_PATH. Conda activation might fail.\"\n",
    "    # Fallback path guess (less reliable):\n",
    "    # FALLBACK_CONDA_SH=\"/encs/pkg/anaconda3-2023.03/root/etc/profile.d/conda.sh\"\n",
    "    # if [ -f \"$FALLBACK_CONDA_SH\" ]; then\n",
    "    #     source \"$FALLBACK_CONDA_SH\"\n",
    "    #     echo \"Successfully sourced fallback $FALLBACK_CONDA_SH\"\n",
    "    # else\n",
    "    #    echo \"ERROR: Fallback conda.sh not found either.\"\n",
    "    #    exit 1\n",
    "    # fi\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Activate your conda environment using the modern command\n",
    "echo \"Activating conda environment...\"\n",
    "# Define the environment path for clarity\n",
    "MY_CONDA_ENV=\"/speed-scratch/ra_mdash/tmp/deep-env\"\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\" # Source conda functions\n",
    "conda activate \"$MY_CONDA_ENV\"\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"ERROR: Failed to activate conda environment with 'conda activate'.\"\n",
    "    exit 1\n",
    "fi\n",
    "# Define the Python executable path\n",
    "PYTHON_EXEC=\"${MY_CONDA_ENV}/bin/python\"\n",
    "if [ ! -f \"$PYTHON_EXEC\" ]; then\n",
    "    echo \"ERROR: Python executable not found at $PYTHON_EXEC\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Using Python executable: $PYTHON_EXEC\"\n",
    "echo \"Activated environment variable: $CONDA_DEFAULT_ENV\"\n",
    "\n",
    "# --- Manually Correct CUDA Environment Variables ---\n",
    "# ... (export CUDA_HOME, PATH, LD_LIBRARY_PATH - these are still needed for compilation/runtime linking) ...\n",
    "echo \"Manually setting CUDA environment variables...\"\n",
    "export CUDA_HOME=/encs/pkg/cuda-11.8/root\n",
    "if [ -z \"$CUDA_HOME\" ] || [ ! -d \"$CUDA_HOME\" ]; then\n",
    "    echo \"ERROR: CUDA_HOME path is incorrect or directory does not exist: $CUDA_HOME\"\n",
    "    exit 1\n",
    "fi\n",
    "# NOTE: We still prepend CUDA to PATH for nvcc etc., but call python explicitly\n",
    "export PATH=\"${CUDA_HOME}/bin:${PATH}\"\n",
    "export LD_LIBRARY_PATH=\"${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}\"\n",
    "echo \"CUDA_HOME set to: $CUDA_HOME\"\n",
    "\n",
    "\n",
    "# --- Verification (Using Explicit Python Path) ---\n",
    "echo \"--- Environment Verification ---\"\n",
    "echo \"Loaded Modules:\"\n",
    "module list\n",
    "echo \"\"\n",
    "echo \"Explicit Python path: $PYTHON_EXEC\"\n",
    "echo \"Explicit Python version: $($PYTHON_EXEC --version)\" # Call python explicitly\n",
    "echo \"\"\n",
    "echo \"CUDA_HOME: $CUDA_HOME\"\n",
    "echo \"NVCC path: $(which nvcc)\" # which should still work because we added CUDA_HOME/bin to PATH\n",
    "echo \"NVCC version:\"\n",
    "nvcc --version || echo \"WARNING: nvcc command failed!\"\n",
    "echo \"\"\n",
    "echo \"PyTorch Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import torch; print(f'  Torch version: {torch.__version__}'); print(f'  Torch CUDA available: {torch.cuda.is_available()}'); print(f'  Torch CUDA version: {torch.version.cuda}'); print(f'  Torch device count: {torch.cuda.device_count()}')\"\n",
    "echo \"\"\n",
    "echo \"DeepSpeed Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import deepspeed; print(f'  DeepSpeed imported successfully. Version: {deepspeed.__version__}')\" || echo \"WARNING: Failed to import deepspeed!\"\n",
    "echo \"--------------------------\"\n",
    "\n",
    "\n",
    "# --- Set TRITON_CACHE_DIR ---\n",
    "# ... (TRITON_CACHE_DIR remains the same) ...\n",
    "export TRITON_CACHE_DIR=\"/tmp/${USER}_triton_cache_${SLURM_JOB_ID}\"\n",
    "mkdir -p \"$TRITON_CACHE_DIR\"\n",
    "echo \"TRITON_CACHE_DIR set to: $TRITON_CACHE_DIR\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "\n",
    "# --- Run Python Script (Using Explicit Python Path) ---\n",
    "# echo \"Running Python script: /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge-deepspeed.py\"\n",
    "# Execute the main script using the full path to the environment's python\n",
    "\"$PYTHON_EXEC\" /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge.py\n",
    "# if [ $? -ne 0 ]; then\n",
    "#     echo \"ERROR: Python script exited with non-zero status.\"\n",
    "# fi\n",
    "\n",
    "# --- Job Completion ---\n",
    "# ... (Job completion logs remain the same) ...\n",
    "# echo \"----------------------------------------------------\"\n",
    "# echo \"End time: $(date)\"\n",
    "# echo \"Job finished.\"\n",
    "# echo \"----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d147964-24ec-46bf-85e3-861c2e229a79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 531973\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name=deepspeed_llama_80gb  \n",
    "#SBATCH --partition=pt                   \n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8             \n",
    "#SBATCH --mem=160G                    \n",
    "#SBATCH --gres=gpu:nvidia_a100_7g.80gb:1\n",
    "\n",
    "\n",
    "#--constraint=gpu80         \n",
    "\n",
    "# --- Environment Setup ---\n",
    "echo \"----------------------------------------------------\"\n",
    "echo \"SLURM Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Run on host: $(hostname)\"\n",
    "echo \"Working directory: $(pwd)\"\n",
    "echo \"Start time: $(date)\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "echo \"Setting up environment...\"\n",
    "module purge > /dev/null 2>&1 || echo \"Module purge failed (might be okay).\"\n",
    "\n",
    "echo \"Loading modules...\"\n",
    "module load anaconda/default # Load Anaconda first\n",
    "module load cuda/11.8/default\n",
    "\n",
    "# --- Initialize Conda for this script's shell ---\n",
    "echo \"Sourcing conda.sh to enable conda activate...\"\n",
    "# Construct the path to conda.sh relative to the Anaconda module base path\n",
    "# Adjust if your base anaconda install path is different\n",
    "CONDA_BASE_PATH=$(conda info --base) # Get base path dynamically\n",
    "CONDA_SH_PATH=\"${CONDA_BASE_PATH}/etc/profile.d/conda.sh\"\n",
    "\n",
    "if [ -f \"$CONDA_SH_PATH\" ]; then\n",
    "    source \"$CONDA_SH_PATH\"\n",
    "    echo \"Successfully sourced $CONDA_SH_PATH\"\n",
    "else\n",
    "    echo \"ERROR: Cannot find conda.sh at $CONDA_SH_PATH. Conda activation might fail.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Activate your conda environment using the modern command\n",
    "echo \"Activating conda environment...\"\n",
    "# Define the environment path for clarity\n",
    "MY_CONDA_ENV=\"/speed-scratch/ra_mdash/tmp/deep-env\"\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\" # Source conda functions\n",
    "conda activate \"$MY_CONDA_ENV\"\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"ERROR: Failed to activate conda environment with 'conda activate'.\"\n",
    "    exit 1\n",
    "fi\n",
    "# Define the Python executable path\n",
    "PYTHON_EXEC=\"${MY_CONDA_ENV}/bin/python\"\n",
    "if [ ! -f \"$PYTHON_EXEC\" ]; then\n",
    "    echo \"ERROR: Python executable not found at $PYTHON_EXEC\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Using Python executable: $PYTHON_EXEC\"\n",
    "echo \"Activated environment variable: $CONDA_DEFAULT_ENV\"\n",
    "\n",
    "# --- Manually Correct CUDA Environment Variables ---\n",
    "# ... (export CUDA_HOME, PATH, LD_LIBRARY_PATH - these are still needed for compilation/runtime linking) ...\n",
    "echo \"Manually setting CUDA environment variables...\"\n",
    "export CUDA_HOME=/encs/pkg/cuda-11.8/root\n",
    "if [ -z \"$CUDA_HOME\" ] || [ ! -d \"$CUDA_HOME\" ]; then\n",
    "    echo \"ERROR: CUDA_HOME path is incorrect or directory does not exist: $CUDA_HOME\"\n",
    "    exit 1\n",
    "fi\n",
    "# NOTE: We still prepend CUDA to PATH for nvcc etc., but call python explicitly\n",
    "export PATH=\"${CUDA_HOME}/bin:${PATH}\"\n",
    "export LD_LIBRARY_PATH=\"${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}\"\n",
    "echo \"CUDA_HOME set to: $CUDA_HOME\"\n",
    "\n",
    "\n",
    "# --- Verification (Using Explicit Python Path) ---\n",
    "echo \"--- Environment Verification ---\"\n",
    "echo \"Loaded Modules:\"\n",
    "module list\n",
    "echo \"\"\n",
    "echo \"Explicit Python path: $PYTHON_EXEC\"\n",
    "echo \"Explicit Python version: $($PYTHON_EXEC --version)\" # Call python explicitly\n",
    "echo \"\"\n",
    "echo \"CUDA_HOME: $CUDA_HOME\"\n",
    "echo \"NVCC path: $(which nvcc)\" # which should still work because we added CUDA_HOME/bin to PATH\n",
    "echo \"NVCC version:\"\n",
    "nvcc --version || echo \"WARNING: nvcc command failed!\"\n",
    "echo \"\"\n",
    "echo \"PyTorch Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import torch; print(f'  Torch version: {torch.__version__}'); print(f'  Torch CUDA available: {torch.cuda.is_available()}'); print(f'  Torch CUDA version: {torch.version.cuda}'); print(f'  Torch device count: {torch.cuda.device_count()}')\"\n",
    "echo \"\"\n",
    "echo \"DeepSpeed Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import deepspeed; print(f'  DeepSpeed imported successfully. Version: {deepspeed.__version__}')\" || echo \"WARNING: Failed to import deepspeed!\"\n",
    "echo \"--------------------------\"\n",
    "\n",
    "\n",
    "# --- Set TRITON_CACHE_DIR ---\n",
    "# ... (TRITON_CACHE_DIR remains the same) ...\n",
    "export TRITON_CACHE_DIR=\"/tmp/${USER}_triton_cache_${SLURM_JOB_ID}\"\n",
    "mkdir -p \"$TRITON_CACHE_DIR\"\n",
    "echo \"TRITON_CACHE_DIR set to: $TRITON_CACHE_DIR\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "\n",
    "# --- Run Python Script (Using Explicit Python Path) ---\n",
    "# echo \"Running Python script: /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge-deepspeed.py\"\n",
    "# Execute the main script using the full path to the environment's python\n",
    "\"$PYTHON_EXEC\" /nfs/speed-scratch/ra_mdash/run-primevul-thinking-llm-as-judge.py\n",
    "# if [ $? -ne 0 ]; then\n",
    "#     echo \"ERROR: Python script exited with non-zero status.\"\n",
    "# fi\n",
    "\n",
    "# --- Job Completion ---\n",
    "# ... (Job completion logs remain the same) ...\n",
    "# echo \"----------------------------------------------------\"\n",
    "# echo \"End time: $(date)\"\n",
    "# echo \"Job finished.\"\n",
    "# echo \"----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046ec9d9-c300-483d-8e79-71347a277406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Submitted batch job 532239\\n',\n",
       " 'sbatch:  ====> Nodes limited to 1 GPU per JOB: speed-01, speed-05, speed-17\\nsbatch:  ====> If this job is rejected, use -ppt instead of -ppg\\n')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sbatch\n",
    "#!/bin/bash -l\n",
    "#SBATCH --job-name=deepspeed_llama_80gb  \n",
    "#SBATCH --partition=pt                   \n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8             \n",
    "#SBATCH --mem=160G                    \n",
    "#SBATCH --gres=gpu:nvidia_a100_7g.80gb:1\n",
    "\n",
    "\n",
    "#--constraint=gpu80         \n",
    "\n",
    "# --- Environment Setup ---\n",
    "echo \"----------------------------------------------------\"\n",
    "echo \"SLURM Job ID: $SLURM_JOB_ID\"\n",
    "echo \"Run on host: $(hostname)\"\n",
    "echo \"Working directory: $(pwd)\"\n",
    "echo \"Start time: $(date)\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "echo \"Setting up environment...\"\n",
    "module purge > /dev/null 2>&1 || echo \"Module purge failed (might be okay).\"\n",
    "\n",
    "echo \"Loading modules...\"\n",
    "module load anaconda/default # Load Anaconda first\n",
    "module load cuda/11.8/default\n",
    "\n",
    "# --- Initialize Conda for this script's shell ---\n",
    "echo \"Sourcing conda.sh to enable conda activate...\"\n",
    "# Construct the path to conda.sh relative to the Anaconda module base path\n",
    "# Adjust if your base anaconda install path is different\n",
    "CONDA_BASE_PATH=$(conda info --base) # Get base path dynamically\n",
    "CONDA_SH_PATH=\"${CONDA_BASE_PATH}/etc/profile.d/conda.sh\"\n",
    "\n",
    "if [ -f \"$CONDA_SH_PATH\" ]; then\n",
    "    source \"$CONDA_SH_PATH\"\n",
    "    echo \"Successfully sourced $CONDA_SH_PATH\"\n",
    "else\n",
    "    echo \"ERROR: Cannot find conda.sh at $CONDA_SH_PATH. Conda activation might fail.\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# Activate your conda environment using the modern command\n",
    "echo \"Activating conda environment...\"\n",
    "# Define the environment path for clarity\n",
    "MY_CONDA_ENV=\"/speed-scratch/ra_mdash/tmp/deep-env\"\n",
    "source \"$(conda info --base)/etc/profile.d/conda.sh\" # Source conda functions\n",
    "conda activate \"$MY_CONDA_ENV\"\n",
    "if [ $? -ne 0 ]; then\n",
    "    echo \"ERROR: Failed to activate conda environment with 'conda activate'.\"\n",
    "    exit 1\n",
    "fi\n",
    "# Define the Python executable path\n",
    "PYTHON_EXEC=\"${MY_CONDA_ENV}/bin/python\"\n",
    "if [ ! -f \"$PYTHON_EXEC\" ]; then\n",
    "    echo \"ERROR: Python executable not found at $PYTHON_EXEC\"\n",
    "    exit 1\n",
    "fi\n",
    "echo \"Using Python executable: $PYTHON_EXEC\"\n",
    "echo \"Activated environment variable: $CONDA_DEFAULT_ENV\"\n",
    "\n",
    "# --- Manually Correct CUDA Environment Variables ---\n",
    "# ... (export CUDA_HOME, PATH, LD_LIBRARY_PATH - these are still needed for compilation/runtime linking) ...\n",
    "echo \"Manually setting CUDA environment variables...\"\n",
    "export CUDA_HOME=/encs/pkg/cuda-11.8/root\n",
    "if [ -z \"$CUDA_HOME\" ] || [ ! -d \"$CUDA_HOME\" ]; then\n",
    "    echo \"ERROR: CUDA_HOME path is incorrect or directory does not exist: $CUDA_HOME\"\n",
    "    exit 1\n",
    "fi\n",
    "# NOTE: We still prepend CUDA to PATH for nvcc etc., but call python explicitly\n",
    "export PATH=\"${CUDA_HOME}/bin:${PATH}\"\n",
    "export LD_LIBRARY_PATH=\"${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}\"\n",
    "echo \"CUDA_HOME set to: $CUDA_HOME\"\n",
    "\n",
    "\n",
    "# --- Verification (Using Explicit Python Path) ---\n",
    "echo \"--- Environment Verification ---\"\n",
    "echo \"Loaded Modules:\"\n",
    "module list\n",
    "echo \"\"\n",
    "echo \"Explicit Python path: $PYTHON_EXEC\"\n",
    "echo \"Explicit Python version: $($PYTHON_EXEC --version)\" # Call python explicitly\n",
    "echo \"\"\n",
    "echo \"CUDA_HOME: $CUDA_HOME\"\n",
    "echo \"NVCC path: $(which nvcc)\" # which should still work because we added CUDA_HOME/bin to PATH\n",
    "echo \"NVCC version:\"\n",
    "nvcc --version || echo \"WARNING: nvcc command failed!\"\n",
    "echo \"\"\n",
    "echo \"PyTorch Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import torch; print(f'  Torch version: {torch.__version__}'); print(f'  Torch CUDA available: {torch.cuda.is_available()}'); print(f'  Torch CUDA version: {torch.version.cuda}'); print(f'  Torch device count: {torch.cuda.device_count()}')\"\n",
    "echo \"\"\n",
    "echo \"DeepSpeed Check:\"\n",
    "# Call python explicitly for the check\n",
    "\"$PYTHON_EXEC\" -c \"import deepspeed; print(f'  DeepSpeed imported successfully. Version: {deepspeed.__version__}')\" || echo \"WARNING: Failed to import deepspeed!\"\n",
    "echo \"--------------------------\"\n",
    "\n",
    "\n",
    "# --- Set TRITON_CACHE_DIR ---\n",
    "# ... (TRITON_CACHE_DIR remains the same) ...\n",
    "export TRITON_CACHE_DIR=\"/tmp/${USER}_triton_cache_${SLURM_JOB_ID}\"\n",
    "mkdir -p \"$TRITON_CACHE_DIR\"\n",
    "echo \"TRITON_CACHE_DIR set to: $TRITON_CACHE_DIR\"\n",
    "echo \"----------------------------------------------------\"\n",
    "\n",
    "\n",
    "# --- Run Python Script (Using Explicit Python Path) ---\n",
    "# echo \"Running Python script: /nfs/speed-scratch/ra_mdash/thinking-llm-as-judge-deepspeed.py\"\n",
    "# Execute the main script using the full path to the environment's python\n",
    "\"$PYTHON_EXEC\" /nfs/speed-scratch/ra_mdash/run-primevul-thinking-llm-as-judge.py \\\n",
    "--output_file /speed-scratch/ra_mdash/results/prime_vul/Self-taught-evaluator-llama3.1-70B_thinking_judge_fewshot.jsonl \\\n",
    "--response_1_path /speed-scratch/ra_mdash/results/prime_vul/Llama-3.2-3B-Instruct_few_shot_CORRECTED.jsonl \\\n",
    "--response_2_path /speed-scratch/ra_mdash/results/prime_vul/Qwen2.5-Coder-3B_few_shot_CORRECTED.jsonl\n",
    "# if [ $? -ne 0 ]; then\n",
    "#     echo \"ERROR: Python script exited with non-zero status.\"\n",
    "# fi\n",
    "\n",
    "# --- Job Completion ---\n",
    "# ... (Job completion logs remain the same) ...\n",
    "# echo \"----------------------------------------------------\"\n",
    "# echo \"End time: $(date)\"\n",
    "# echo \"Job finished.\"\n",
    "# echo \"----------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f632423-3ccc-4dc6-b9b6-d9f213deee41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7ffa8d-edd9-4c3a-bdb5-4c7b01633092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5957ead2-db63-4585-a89d-17213b9fea0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0caf607-6571-4d42-95e9-67b60f58ee55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
